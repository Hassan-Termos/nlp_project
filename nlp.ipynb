{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'wikitext-2-raw-v1' at C:\\Users\\Lenovo\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-raw-v1\\0.0.0\\b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Mon Feb 10 14:13:07 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      "\n",
      " Senj≈ç no Valkyria 3 : Unrecorded Chronicles ( Japanese : Êà¶Â†¥„ÅÆ„É¥„Ç°„É´„Ç≠„É•„É™„Ç¢3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      "\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the WikiText-2 Raw dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "# Display dataset information\n",
    "# print(dataset)\n",
    "\n",
    "\n",
    "# Print the first 5 examples from the training set\n",
    "# Print the first 5 examples from the training set\n",
    "for i in range(5):\n",
    "    print(dataset[\"train\"][i][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining, DataCollatorForLanguageModeling\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "# Load BERT model for masked language modeling\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8472, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6337,  -6.6730,  -6.6389,  ...,  -6.0923,  -5.9187,  -3.8064],\n",
      "         [ -4.6448,  -4.4396,  -4.8204,  ...,  -4.9353,  -5.9100,  -1.9342],\n",
      "         [ -8.0181,  -8.0007,  -7.9133,  ...,  -7.2930,  -7.1094,  -7.5799],\n",
      "         ...,\n",
      "         [-10.5829, -10.6881, -10.4276,  ...,  -9.1356,  -9.3133, -12.4075],\n",
      "         [-10.8777, -10.9162, -10.9796,  ..., -10.8169, -10.8836, -11.0561],\n",
      "         [-11.6262, -11.5655, -11.6841,  ...,  -8.7754,  -9.1516,  -7.2493]],\n",
      "\n",
      "        [[ -7.1542,  -7.1808,  -7.0953,  ...,  -6.4928,  -6.4795,  -4.2352],\n",
      "         [-11.4073, -11.7677, -11.5320,  ...,  -8.6528, -10.9984,  -8.1621],\n",
      "         [ -7.7024,  -7.9178,  -7.8136,  ...,  -6.0641,  -7.6349,  -6.3140],\n",
      "         ...,\n",
      "         [ -7.1983,  -7.4538,  -7.2127,  ...,  -7.4741,  -6.2153,  -4.8457],\n",
      "         [ -7.7356,  -7.9769,  -7.8405,  ...,  -7.2081,  -7.2196,  -4.6887],\n",
      "         [-13.0859, -13.1836, -12.9249,  ..., -12.3968, -12.8128,  -8.4750]],\n",
      "\n",
      "        [[ -6.7371,  -6.7099,  -6.6443,  ...,  -6.1003,  -5.6975,  -4.2855],\n",
      "         [ -7.4377,  -7.3966,  -7.3818,  ...,  -5.9735,  -5.5330,  -9.4145],\n",
      "         [ -4.8722,  -4.6857,  -4.5969,  ...,  -4.1321,  -3.6670,  -6.5698],\n",
      "         ...,\n",
      "         [ -8.1663,  -8.1008,  -8.3038,  ...,  -7.5924,  -8.2340,  -3.9923],\n",
      "         [ -7.3459,  -7.1809,  -6.8926,  ...,  -6.0599,  -7.3098,  -7.2832],\n",
      "         [ -6.7871,  -6.3983,  -6.2794,  ...,  -6.2832,  -7.1548,  -6.4630]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2215,  -7.2359,  -7.2783,  ...,  -6.6409,  -6.4121,  -3.9228],\n",
      "         [-16.4622, -16.6770, -16.4653,  ..., -15.2682, -12.7927, -11.6200],\n",
      "         [ -6.7807,  -6.6493,  -6.7893,  ...,  -6.0652,  -6.0166,  -4.2353],\n",
      "         ...,\n",
      "         [ -8.0748,  -8.0731,  -8.0631,  ...,  -8.6678,  -8.0306,  -2.7528],\n",
      "         [ -7.4615,  -7.5592,  -7.4519,  ...,  -7.8730,  -6.7267,  -3.8179],\n",
      "         [ -7.7817,  -7.8001,  -7.7678,  ...,  -7.4301,  -7.0592,  -5.1089]],\n",
      "\n",
      "        [[ -6.7735,  -6.7584,  -6.7277,  ...,  -6.2054,  -5.9537,  -4.1653],\n",
      "         [ -7.2440,  -7.2031,  -7.3586,  ...,  -6.4101,  -4.5446,  -6.0850],\n",
      "         [-10.5566, -10.7953, -10.9240,  ...,  -8.4014,  -7.0629,  -7.5838],\n",
      "         ...,\n",
      "         [ -7.2833,  -7.2665,  -6.9613,  ...,  -6.5244,  -6.3711,  -3.2653],\n",
      "         [ -6.3353,  -6.4061,  -5.9600,  ...,  -5.4250,  -5.3473,  -4.1230],\n",
      "         [ -7.1389,  -6.9998,  -6.9004,  ...,  -6.3512,  -6.6752,  -4.6140]],\n",
      "\n",
      "        [[ -6.6720,  -6.6520,  -6.6076,  ...,  -6.1575,  -5.9276,  -4.1498],\n",
      "         [-11.6862, -11.3140, -11.4916,  ..., -11.2766, -10.7750,  -8.9874],\n",
      "         [ -9.9111, -10.0070,  -9.6243,  ...,  -8.4463,  -8.7616,  -6.9882],\n",
      "         ...,\n",
      "         [ -5.5773,  -5.6217,  -5.6528,  ...,  -6.4061,  -5.8898,  -5.8448],\n",
      "         [ -9.1705,  -8.8475,  -9.0260,  ...,  -6.0278,  -6.5083,  -5.2204],\n",
      "         [ -8.5197,  -8.4646,  -8.4787,  ...,  -8.6963,  -7.4444,  -8.0817]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.84720778465271\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3462, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.1431,  -9.1223,  -9.0884,  ...,  -8.7176,  -8.7435,  -7.9299],\n",
      "         [-11.0202, -10.8663, -10.6082,  ...,  -8.9583,  -9.8647, -10.3490],\n",
      "         [ -6.7646,  -6.6331,  -6.7471,  ...,  -7.5891,  -7.4636,  -3.2270],\n",
      "         ...,\n",
      "         [ -6.9884,  -6.6978,  -6.8846,  ...,  -7.0552,  -7.9385,  -2.8218],\n",
      "         [ -7.3080,  -6.9509,  -7.0010,  ...,  -7.5157,  -7.9876,  -1.1612],\n",
      "         [ -7.0558,  -6.9396,  -6.8810,  ...,  -7.5512,  -7.9696,  -2.6629]],\n",
      "\n",
      "        [[-10.6331, -10.8341, -10.5676,  ...,  -9.4586, -10.1345,  -5.9281],\n",
      "         [ -9.9588,  -9.6984,  -9.9465,  ...,  -7.6920,  -8.8849,  -9.9952],\n",
      "         [ -5.5989,  -5.6040,  -5.4864,  ...,  -5.7217,  -7.0570,  -3.5982],\n",
      "         ...,\n",
      "         [ -6.8282,  -6.8198,  -6.6332,  ...,  -7.0473,  -7.6509,  -3.5023],\n",
      "         [ -6.7450,  -6.5533,  -6.3937,  ...,  -7.2238,  -8.5104,  -2.0765],\n",
      "         [ -6.3039,  -6.2743,  -6.1372,  ...,  -6.4953,  -7.3180,  -3.0068]],\n",
      "\n",
      "        [[ -7.4334,  -7.2984,  -7.3203,  ...,  -6.4156,  -6.3740,  -4.1388],\n",
      "         [-11.6131, -11.0838, -11.0068,  ...,  -7.9709,  -8.0837,  -9.1348],\n",
      "         [ -7.5764,  -7.2855,  -7.5151,  ...,  -7.9050,  -8.9302,  -2.3786],\n",
      "         ...,\n",
      "         [ -6.6738,  -6.3382,  -6.4506,  ...,  -6.4503,  -8.0400,  -2.8274],\n",
      "         [ -6.9367,  -6.5042,  -6.7351,  ...,  -6.9372,  -8.7448,  -2.5764],\n",
      "         [ -6.1532,  -5.7949,  -5.9535,  ...,  -6.5017,  -8.0385,  -2.8582]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-11.9445, -11.5711, -11.3636,  ..., -11.3421, -11.8574, -10.5978],\n",
      "         [-16.4359, -16.6665, -16.5957,  ..., -14.9631, -14.0343, -11.3298],\n",
      "         [ -6.6248,  -6.4115,  -6.4977,  ...,  -6.3276,  -8.2439,  -2.1759],\n",
      "         ...,\n",
      "         [ -6.1299,  -5.7402,  -5.8653,  ...,  -6.0926,  -8.0727,  -3.2547],\n",
      "         [ -6.6916,  -6.5372,  -6.3190,  ...,  -7.1541,  -9.3505,  -1.4019],\n",
      "         [ -6.6453,  -6.5493,  -6.5920,  ...,  -7.8089,  -8.6618,  -2.7046]],\n",
      "\n",
      "        [[ -6.9738,  -6.9574,  -6.9015,  ...,  -6.3487,  -5.9102,  -4.4512],\n",
      "         [-13.6665, -13.6830, -13.7401,  ..., -11.7684, -11.5936, -10.2713],\n",
      "         [-10.7658, -10.6043,  -9.8964,  ...,  -9.0433, -10.0165,  -7.4454],\n",
      "         ...,\n",
      "         [ -9.6211,  -9.6745,  -9.5342,  ...,  -8.7948,  -8.4833,  -7.8180],\n",
      "         [ -9.4247,  -9.3821,  -9.4556,  ...,  -8.1607,  -8.5159,  -6.3323],\n",
      "         [ -9.6649,  -9.6785,  -9.6746,  ...,  -8.6873,  -8.2904,  -6.9849]],\n",
      "\n",
      "        [[ -6.8184,  -6.8108,  -6.8544,  ...,  -6.1608,  -5.9679,  -3.7673],\n",
      "         [ -8.8707,  -8.6683,  -8.8881,  ...,  -9.2332,  -9.8428,  -2.6542],\n",
      "         [ -7.5433,  -7.4183,  -7.5525,  ...,  -7.3531,  -8.5677,  -1.6752],\n",
      "         ...,\n",
      "         [ -7.7486,  -7.6182,  -7.8268,  ...,  -7.6112,  -7.6344,  -3.3042],\n",
      "         [ -7.0933,  -7.0315,  -7.1715,  ...,  -7.0572,  -7.6052,  -1.6444],\n",
      "         [ -7.4783,  -7.3757,  -7.4289,  ...,  -7.5616,  -7.7363,  -3.6966]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.3462024927139282\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7596, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.9660,  -9.8219,  -9.7504,  ..., -10.4163,  -9.6714,  -3.8678],\n",
      "         [-11.1071, -11.0161, -11.2117,  ...,  -9.6431,  -8.4544, -10.1708],\n",
      "         [ -6.0351,  -5.7367,  -5.8290,  ...,  -6.6127,  -7.0438,  -3.9605],\n",
      "         ...,\n",
      "         [ -6.8233,  -6.6963,  -6.8008,  ...,  -8.3904,  -8.0223,  -1.0999],\n",
      "         [ -5.7720,  -5.5489,  -5.5700,  ...,  -6.7701,  -7.0638,  -2.6960],\n",
      "         [ -6.9943,  -6.5441,  -6.5545,  ...,  -7.9595,  -8.0041,  -1.8837]],\n",
      "\n",
      "        [[ -6.4828,  -6.4599,  -6.3727,  ...,  -6.0028,  -5.5729,  -4.0215],\n",
      "         [ -9.3695,  -9.3855,  -9.3190,  ...,  -8.8522,  -7.9852,  -8.0018],\n",
      "         [ -7.7040,  -7.9048,  -7.5812,  ...,  -7.9819,  -6.0061,  -4.7884],\n",
      "         ...,\n",
      "         [ -7.1244,  -7.1797,  -7.0498,  ...,  -6.6465,  -6.6200,  -5.3608],\n",
      "         [ -5.3022,  -5.4489,  -5.3127,  ...,  -5.2060,  -6.0099,  -4.7691],\n",
      "         [ -6.8677,  -6.9710,  -6.8622,  ...,  -6.5679,  -6.2137,  -5.0261]],\n",
      "\n",
      "        [[ -6.7484,  -6.7300,  -6.7088,  ...,  -6.1027,  -5.8267,  -4.0317],\n",
      "         [ -5.7658,  -5.8798,  -5.9688,  ...,  -5.8759,  -5.4532,  -1.7143],\n",
      "         [ -7.5308,  -7.4689,  -7.5534,  ...,  -7.7436,  -7.6102,  -1.4979],\n",
      "         ...,\n",
      "         [ -6.2039,  -6.3986,  -6.3225,  ...,  -6.5941,  -5.4610,  -2.2795],\n",
      "         [ -6.2917,  -6.4549,  -6.4400,  ...,  -6.3579,  -6.1680,  -1.4005],\n",
      "         [ -5.9073,  -6.0435,  -6.0591,  ...,  -6.3085,  -5.4441,  -1.7991]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4979,  -6.4920,  -6.4977,  ...,  -6.0061,  -5.6612,  -3.4728],\n",
      "         [ -8.7026,  -8.3953,  -8.5438,  ...,  -8.9602,  -7.5098,  -7.4200],\n",
      "         [ -4.2551,  -3.8985,  -4.2047,  ...,  -4.6555,  -4.7538,  -2.7826],\n",
      "         ...,\n",
      "         [ -6.5468,  -6.2594,  -6.4503,  ...,  -5.5679,  -7.1829,  -3.2357],\n",
      "         [ -7.3728,  -7.1745,  -7.3811,  ...,  -6.8173,  -7.1259,  -3.5787],\n",
      "         [ -7.2558,  -7.0854,  -7.2547,  ...,  -6.7240,  -6.9910,  -5.7841]],\n",
      "\n",
      "        [[ -6.8947,  -6.9085,  -6.8610,  ...,  -6.3435,  -6.1832,  -4.2232],\n",
      "         [-16.9733, -17.3254, -17.0715,  ..., -14.9874, -14.6407, -14.7447],\n",
      "         [-12.6834, -13.1518, -12.3784,  ..., -13.6148, -10.5301, -11.5213],\n",
      "         ...,\n",
      "         [ -8.9596,  -9.0079,  -8.8974,  ...,  -8.1867, -10.0727,  -6.7548],\n",
      "         [ -7.4628,  -7.8085,  -7.3788,  ...,  -7.4008,  -7.7525,  -6.4086],\n",
      "         [-14.3718, -14.7501, -14.7352,  ..., -13.4447, -12.8995,  -9.7318]],\n",
      "\n",
      "        [[ -9.3801,  -9.5358,  -9.0799,  ...,  -8.6589,  -9.8640,  -6.0335],\n",
      "         [-11.6413, -11.3921, -11.4736,  ...,  -8.8959,  -8.9232, -10.3110],\n",
      "         [ -6.2733,  -6.2497,  -6.2151,  ...,  -6.9105,  -7.8210,  -3.2842],\n",
      "         ...,\n",
      "         [ -6.9390,  -6.8714,  -6.8606,  ...,  -7.5065,  -8.1779,  -3.2189],\n",
      "         [ -6.7871,  -6.7158,  -6.7156,  ...,  -7.2674,  -8.7647,  -2.8683],\n",
      "         [ -6.2204,  -6.1839,  -6.2505,  ...,  -6.2281,  -8.2532,  -2.8487]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.759603500366211\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6253, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6480,  -6.6414,  -6.5948,  ...,  -6.1714,  -5.7970,  -4.0284],\n",
      "         [ -8.4633,  -8.4606,  -8.3126,  ...,  -8.0676,  -7.5240,  -6.3343],\n",
      "         [ -6.7776,  -6.8741,  -7.0693,  ...,  -7.3787,  -6.8487,  -8.6568],\n",
      "         ...,\n",
      "         [-15.6546, -16.0121, -16.1037,  ..., -13.4189, -12.5845, -13.6471],\n",
      "         [ -9.2040,  -9.1338,  -9.1881,  ...,  -8.2022,  -7.2295,  -6.0851],\n",
      "         [-15.7803, -15.6209, -15.6179,  ..., -13.1687, -11.6560, -10.3789]],\n",
      "\n",
      "        [[ -7.3658,  -7.2450,  -7.2216,  ...,  -7.4389,  -7.2836,  -4.6024],\n",
      "         [-12.8094, -12.2310, -12.4901,  ...,  -9.2741, -10.4801, -11.8377],\n",
      "         [ -6.3084,  -6.3451,  -6.3015,  ...,  -8.0115,  -7.8317,  -1.0253],\n",
      "         ...,\n",
      "         [ -6.6645,  -6.6748,  -6.4753,  ...,  -7.8354,  -8.1907,  -3.1569],\n",
      "         [ -6.6523,  -6.7878,  -6.6782,  ...,  -7.4102,  -7.6345,  -3.0507],\n",
      "         [ -6.5474,  -6.5824,  -6.5015,  ...,  -7.2372,  -7.5344,  -2.5678]],\n",
      "\n",
      "        [[ -7.3474,  -7.4078,  -7.3983,  ...,  -6.8327,  -6.5124,  -4.2683],\n",
      "         [ -6.7079,  -6.6757,  -6.6760,  ...,  -7.6140,  -7.9016,  -6.2701],\n",
      "         [ -6.7309,  -6.5694,  -6.4756,  ...,  -6.4710,  -6.0472,  -7.3304],\n",
      "         ...,\n",
      "         [ -5.7820,  -5.5842,  -5.6222,  ...,  -5.7191,  -6.0922,  -8.5580],\n",
      "         [ -8.5624,  -8.4929,  -8.3718,  ...,  -8.3517,  -8.3981,  -8.3874],\n",
      "         [ -8.8437,  -9.0408,  -8.6885,  ...,  -8.7217,  -8.7288,  -8.4510]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6476,  -6.6393,  -6.5770,  ...,  -6.1256,  -5.7471,  -4.2828],\n",
      "         [-12.4701, -12.3543, -12.3142,  ..., -10.9003, -10.3851, -12.1494],\n",
      "         [ -4.5566,  -4.7473,  -4.6176,  ...,  -4.1706,  -3.9254,  -7.0694],\n",
      "         ...,\n",
      "         [ -4.1479,  -3.9896,  -3.9756,  ...,  -4.3807,  -4.2011,  -6.9897],\n",
      "         [ -9.3627,  -8.9766,  -9.0351,  ...,  -7.9565,  -6.5773,  -7.1103],\n",
      "         [ -5.8431,  -5.7539,  -5.8606,  ...,  -5.7171,  -5.8350,  -5.6804]],\n",
      "\n",
      "        [[ -7.5763,  -7.4874,  -7.4321,  ...,  -6.7516,  -6.5289,  -3.7974],\n",
      "         [ -7.9293,  -7.9363,  -7.9541,  ...,  -7.1535,  -6.7585,  -2.4198],\n",
      "         [ -8.4718,  -8.5975,  -8.4578,  ...,  -8.1256,  -7.7737,  -0.6090],\n",
      "         ...,\n",
      "         [ -8.3516,  -8.2039,  -8.2756,  ...,  -8.0199,  -7.7596,  -3.0113],\n",
      "         [ -8.2379,  -8.0355,  -8.0610,  ...,  -7.8528,  -8.2581,  -2.5405],\n",
      "         [ -8.1423,  -8.0137,  -7.9274,  ...,  -8.3859,  -8.1907,  -3.2111]],\n",
      "\n",
      "        [[ -6.9612,  -6.9756,  -7.0164,  ...,  -6.3687,  -6.1135,  -3.8409],\n",
      "         [ -7.6584,  -7.7697,  -8.1527,  ...,  -7.6558,  -8.6604,  -4.4409],\n",
      "         [ -9.0656,  -9.5053,  -9.1439,  ...,  -8.3414,  -8.3851,  -6.0550],\n",
      "         ...,\n",
      "         [ -6.4345,  -6.2589,  -6.6205,  ...,  -6.4045,  -7.1251,  -0.7957],\n",
      "         [ -6.6693,  -6.6506,  -6.7980,  ...,  -6.6210,  -7.3061,  -1.0239],\n",
      "         [ -6.9683,  -6.9722,  -7.0976,  ...,  -6.6283,  -7.4910,  -1.5810]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.6252522468566895\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1742, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8535,  -6.8383,  -6.8264,  ...,  -6.0783,  -6.1230,  -3.9669],\n",
      "         [ -5.6390,  -5.7158,  -5.6124,  ...,  -5.4331,  -6.8102,  -5.7220],\n",
      "         [ -9.9510,  -9.9535, -10.0035,  ...,  -8.8932,  -8.8830,  -9.6551],\n",
      "         ...,\n",
      "         [ -4.8903,  -4.4985,  -4.7443,  ...,  -5.9679,  -4.8472,  -2.9644],\n",
      "         [-10.9608, -10.6782, -11.1186,  ..., -10.9346, -10.0941,  -5.5794],\n",
      "         [-11.5849, -11.1421, -11.4762,  ...,  -7.8545,  -8.2122,  -6.0856]],\n",
      "\n",
      "        [[ -7.1836,  -7.2355,  -7.1323,  ...,  -6.6461,  -6.6250,  -4.2215],\n",
      "         [ -8.6219,  -8.4595,  -8.4304,  ...,  -9.3613,  -9.5709,  -4.7821],\n",
      "         [ -0.7967,  -1.2059,  -0.8341,  ...,  -0.9947,  -1.5874,  -3.8048],\n",
      "         ...,\n",
      "         [ -8.5493,  -8.5766,  -8.3526,  ...,  -8.9657,  -8.2711,  -9.0199],\n",
      "         [ -9.1969,  -9.4881,  -9.2593,  ...,  -8.9889,  -8.6081,  -5.1235],\n",
      "         [-11.2808, -10.7516, -11.1162,  ...,  -7.7020,  -8.2501, -10.1577]],\n",
      "\n",
      "        [[ -6.9686,  -6.9302,  -6.9283,  ...,  -6.1723,  -6.0985,  -3.8215],\n",
      "         [ -6.5431,  -6.4649,  -6.6267,  ...,  -6.2927,  -6.2376,  -2.8973],\n",
      "         [ -6.9071,  -6.7015,  -6.6990,  ...,  -6.4297,  -6.5693,  -0.5568],\n",
      "         ...,\n",
      "         [ -6.5197,  -6.3590,  -6.3949,  ...,  -6.0352,  -6.2973,  -0.9195],\n",
      "         [ -6.5432,  -6.3643,  -6.3893,  ...,  -6.0443,  -6.2754,   0.2505],\n",
      "         [ -6.9604,  -6.8553,  -6.9596,  ...,  -6.7317,  -6.7581,  -1.6174]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8354,  -6.8249,  -6.8150,  ...,  -6.2294,  -6.1337,  -4.3553],\n",
      "         [-13.3737, -13.7972, -13.5145,  ..., -12.8314, -12.6569, -14.0419],\n",
      "         [ -9.4271,  -9.4195,  -9.5229,  ...,  -9.5907, -10.6989,  -9.7197],\n",
      "         ...,\n",
      "         [ -8.7583,  -9.2266,  -8.8181,  ...,  -7.9920,  -8.8960,  -9.8487],\n",
      "         [ -7.4105,  -7.6659,  -7.4362,  ...,  -6.5165,  -7.1348,  -8.1670],\n",
      "         [-11.4298, -11.2395, -11.3279,  ...,  -9.2749,  -9.6321,  -9.4769]],\n",
      "\n",
      "        [[ -6.9071,  -6.8997,  -6.8635,  ...,  -6.3657,  -5.9220,  -4.2061],\n",
      "         [-16.3153, -16.0218, -16.2050,  ..., -15.8237, -13.4249, -14.5948],\n",
      "         [ -8.6877,  -8.5961,  -8.6274,  ...,  -8.6013,  -7.7998,  -4.7687],\n",
      "         ...,\n",
      "         [ -4.6062,  -4.9625,  -4.7057,  ...,  -4.0455,  -4.4763,  -5.7189],\n",
      "         [-12.6018, -12.7262, -12.6642,  ..., -10.6425, -10.9022,  -7.6608],\n",
      "         [-10.6629, -10.2594, -10.6191,  ...,  -8.0464,  -8.5026,  -4.6292]],\n",
      "\n",
      "        [[ -6.6962,  -6.6822,  -6.6847,  ...,  -5.9496,  -5.7878,  -3.9638],\n",
      "         [-13.4585, -12.7846, -13.2053,  ..., -11.2663, -11.6992, -11.8899],\n",
      "         [ -7.8367,  -7.5723,  -7.6734,  ...,  -7.6671,  -8.7346,  -2.5819],\n",
      "         ...,\n",
      "         [ -7.8749,  -7.7645,  -7.8835,  ...,  -8.1634,  -8.6625,  -3.0597],\n",
      "         [ -7.4818,  -7.3095,  -7.3273,  ...,  -7.9346,  -8.4458,  -3.2969],\n",
      "         [ -7.3101,  -7.0231,  -7.2272,  ...,  -6.8777,  -8.3385,  -1.6813]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1741702556610107\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.9100, grad_fn=<NllLossBackward0>), logits=tensor([[[-10.5218, -10.6616, -10.6438,  ...,  -9.8793, -10.9413,  -5.9244],\n",
      "         [ -9.0868,  -8.8863,  -8.9045,  ...,  -7.9113,  -8.6511,  -7.9562],\n",
      "         [ -6.1201,  -5.9774,  -6.1301,  ...,  -6.8308,  -8.0043,  -1.3112],\n",
      "         ...,\n",
      "         [ -6.3731,  -6.2404,  -6.3325,  ...,  -6.9345,  -8.3131,  -2.9364],\n",
      "         [ -6.4198,  -6.2206,  -6.4033,  ...,  -7.0397,  -7.8739,  -1.9218],\n",
      "         [ -5.4557,  -5.2978,  -5.3728,  ...,  -5.5292,  -7.6796,  -2.2470]],\n",
      "\n",
      "        [[ -6.8189,  -6.7543,  -6.7059,  ...,  -5.9519,  -5.8784,  -4.0725],\n",
      "         [-13.5601, -13.2018, -13.4953,  ..., -11.6463, -10.4870, -12.3408],\n",
      "         [ -9.7225,  -9.8211,  -9.8651,  ...,  -8.3956,  -7.9741, -12.5560],\n",
      "         ...,\n",
      "         [ -5.9178,  -5.9180,  -5.5790,  ...,  -5.9041,  -5.0021,  -2.3740],\n",
      "         [ -7.1435,  -7.2030,  -7.1487,  ...,  -6.7735,  -7.5325,  -4.6465],\n",
      "         [ -6.4380,  -6.4721,  -6.3142,  ...,  -5.8299,  -6.1656,  -5.7547]],\n",
      "\n",
      "        [[ -6.8308,  -6.8563,  -6.8110,  ...,  -6.3121,  -6.2458,  -4.1611],\n",
      "         [ -7.7724,  -7.8952,  -7.6817,  ...,  -6.3496,  -7.2864,  -4.7448],\n",
      "         [-13.8321, -13.8892, -13.7595,  ..., -12.5755, -11.1779,  -9.6158],\n",
      "         ...,\n",
      "         [ -4.5245,  -4.9509,  -4.5389,  ...,  -4.4523,  -4.0036,  -5.7212],\n",
      "         [ -6.2182,  -6.3944,  -6.2128,  ...,  -5.4493,  -6.0777,  -6.3625],\n",
      "         [ -6.6954,  -6.8046,  -6.6905,  ...,  -6.7026,  -6.9955,  -6.8850]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9254,  -6.8972,  -6.8993,  ...,  -6.3779,  -6.1393,  -4.5021],\n",
      "         [ -9.1905,  -9.2324,  -9.1213,  ..., -10.1170,  -8.6113,  -4.0067],\n",
      "         [-10.8711, -11.1147, -10.7583,  ..., -12.1527, -10.4407,  -7.1972],\n",
      "         ...,\n",
      "         [ -8.8490,  -8.7063,  -8.4795,  ...,  -8.7465,  -7.8370,  -8.1781],\n",
      "         [ -7.2244,  -7.6530,  -7.1850,  ...,  -7.2880,  -6.5606,  -4.8102],\n",
      "         [ -9.1294,  -9.2000,  -9.0554,  ...,  -8.8206,  -7.1892,  -6.4416]],\n",
      "\n",
      "        [[ -6.7623,  -6.7056,  -6.7118,  ...,  -6.0901,  -5.8311,  -4.0032],\n",
      "         [ -7.0534,  -6.9431,  -7.0296,  ...,  -6.1051,  -6.2533,  -5.7568],\n",
      "         [ -6.2413,  -6.4161,  -6.4920,  ...,  -7.4074,  -5.2772,  -6.6458],\n",
      "         ...,\n",
      "         [ -8.2993,  -8.4922,  -8.2988,  ...,  -8.5782,  -7.5976,  -6.7514],\n",
      "         [ -8.1891,  -8.3060,  -8.1846,  ...,  -8.6266,  -7.6462,  -6.0641],\n",
      "         [ -6.9752,  -7.1298,  -6.9144,  ...,  -7.2971,  -6.3049,  -6.1302]],\n",
      "\n",
      "        [[ -6.6046,  -6.6190,  -6.5882,  ...,  -5.9674,  -5.8664,  -4.3428],\n",
      "         [ -8.2926,  -8.2527,  -8.0045,  ...,  -8.7809,  -8.1108,  -4.9092],\n",
      "         [-15.2253, -15.4145, -14.9027,  ..., -13.9313, -11.6702, -10.7174],\n",
      "         ...,\n",
      "         [ -3.3239,  -2.8359,  -3.0643,  ...,  -3.7844,  -4.3547,  -0.5792],\n",
      "         [ -7.2659,  -7.3931,  -7.3520,  ...,  -7.6893,  -7.7793,  -5.4208],\n",
      "         [ -6.7594,  -6.5560,  -6.9306,  ...,  -7.4751,  -7.6201,  -3.7367]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.9100215435028076\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.0463, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7607,  -6.6857,  -6.7166,  ...,  -6.1368,  -5.7808,  -4.0049],\n",
      "         [ -7.2084,  -7.1822,  -7.1880,  ...,  -7.4780,  -7.6721,  -4.6580],\n",
      "         [ -6.6746,  -6.6814,  -6.6772,  ...,  -6.9787,  -6.7663,  -4.4271],\n",
      "         ...,\n",
      "         [ -6.7029,  -6.6806,  -6.7008,  ...,  -6.4868,  -6.5457,  -3.1827],\n",
      "         [ -6.7371,  -6.6761,  -6.7698,  ...,  -6.4794,  -6.8638,  -4.1343],\n",
      "         [ -7.4157,  -7.3957,  -7.3744,  ...,  -7.1573,  -7.1473,  -4.2802]],\n",
      "\n",
      "        [[ -7.1464,  -7.0033,  -7.0090,  ...,  -6.3796,  -6.5197,  -3.5817],\n",
      "         [-12.0771, -11.6137, -11.6276,  ...,  -9.7833,  -9.5901, -11.6535],\n",
      "         [ -6.6605,  -6.5442,  -6.5294,  ...,  -7.1176,  -7.7864,  -2.5098],\n",
      "         ...,\n",
      "         [ -6.8766,  -6.6080,  -6.7028,  ...,  -7.1724,  -7.6017,  -2.3496],\n",
      "         [ -6.4304,  -6.1665,  -6.2160,  ...,  -6.4560,  -7.7787,  -1.0990],\n",
      "         [ -6.9284,  -6.8597,  -6.9803,  ...,  -7.1214,  -7.9407,  -1.9282]],\n",
      "\n",
      "        [[ -6.9692,  -6.9633,  -6.9447,  ...,  -6.3883,  -6.0508,  -3.9085],\n",
      "         [ -7.7994,  -7.7972,  -7.8638,  ...,  -7.5120,  -7.8422,  -3.0737],\n",
      "         [ -6.8582,  -6.7486,  -6.9117,  ...,  -6.7403,  -7.3070,  -2.2842],\n",
      "         ...,\n",
      "         [ -7.4778,  -7.4275,  -7.5291,  ...,  -7.3083,  -7.4773,  -3.0633],\n",
      "         [ -7.3837,  -7.2540,  -7.3698,  ...,  -6.7995,  -7.8259,  -2.8580],\n",
      "         [ -7.4594,  -7.2747,  -7.3993,  ...,  -7.0701,  -7.9578,  -2.7340]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.5439,  -7.3505,  -7.4514,  ...,  -6.6794,  -6.5605,  -4.4664],\n",
      "         [-13.6933, -13.0996, -13.8211,  ..., -10.0038, -11.3359,  -8.8597],\n",
      "         [ -6.7976,  -6.5790,  -6.6031,  ...,  -7.4518,  -8.0641,  -3.1276],\n",
      "         ...,\n",
      "         [ -6.2574,  -5.8450,  -5.8963,  ...,  -6.3260,  -7.3993,  -2.9771],\n",
      "         [ -6.5443,  -6.1731,  -6.3687,  ...,  -6.9050,  -7.7499,  -1.8399],\n",
      "         [ -6.4252,  -6.2146,  -6.3313,  ...,  -6.7814,  -7.5511,  -3.6823]],\n",
      "\n",
      "        [[ -7.0079,  -6.9678,  -6.9901,  ...,  -6.2681,  -6.2228,  -4.0338],\n",
      "         [ -4.9935,  -5.0577,  -5.1778,  ...,  -4.1004,  -5.5878,   0.1539],\n",
      "         [ -7.8546,  -7.8777,  -7.9749,  ...,  -7.4165,  -8.3901,  -2.7049],\n",
      "         ...,\n",
      "         [ -6.4935,  -6.6215,  -6.6430,  ...,  -5.4905,  -6.9295,  -2.9869],\n",
      "         [ -6.7360,  -6.7943,  -6.8089,  ...,  -5.6189,  -6.7312,  -2.9640],\n",
      "         [ -7.8901,  -7.8773,  -7.9570,  ...,  -7.1532,  -7.9228,  -3.5733]],\n",
      "\n",
      "        [[ -6.9501,  -6.9275,  -6.8700,  ...,  -6.4313,  -6.1676,  -4.4166],\n",
      "         [ -6.6330,  -6.4618,  -6.3336,  ...,  -5.7761,  -6.1030,  -7.7016],\n",
      "         [-11.2000, -11.0719, -10.9503,  ..., -10.4117, -11.5545,  -8.0566],\n",
      "         ...,\n",
      "         [ -9.6684,  -9.5810,  -9.3877,  ...,  -8.2060,  -7.3051,  -9.0292],\n",
      "         [ -5.9967,  -6.0483,  -5.9907,  ...,  -5.9950,  -5.9861,  -5.3885],\n",
      "         [-14.2205, -13.6067, -14.3876,  ..., -10.7685, -11.6910,  -9.8226]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.04630184173584\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0458, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6565,  -6.6408,  -6.5957,  ...,  -6.0121,  -5.7919,  -3.9477],\n",
      "         [ -8.3456,  -8.2838,  -7.9780,  ...,  -7.7930,  -7.5910,  -8.3117],\n",
      "         [ -8.1292,  -7.7321,  -7.5959,  ...,  -7.6668,  -9.4492,  -5.2784],\n",
      "         ...,\n",
      "         [ -7.3991,  -7.6153,  -7.3159,  ...,  -7.2677,  -6.3142,  -3.5635],\n",
      "         [ -6.4703,  -6.7363,  -6.4365,  ...,  -5.9825,  -5.6812,  -3.5302],\n",
      "         [ -7.5841,  -7.6270,  -7.5289,  ...,  -6.8394,  -6.6412,  -2.2881]],\n",
      "\n",
      "        [[ -6.4457,  -6.3845,  -6.4157,  ...,  -5.7878,  -5.5910,  -3.8655],\n",
      "         [-10.7181, -10.7977, -10.7380,  ...,  -8.9819,  -7.7236,  -8.2055],\n",
      "         [ -6.4388,  -6.3776,  -6.4787,  ...,  -7.4114,  -7.7222,  -2.7464],\n",
      "         ...,\n",
      "         [ -7.0609,  -6.9282,  -7.0025,  ...,  -7.3359,  -8.4944,  -1.1827],\n",
      "         [ -6.9828,  -6.8053,  -6.9108,  ...,  -7.5967,  -7.9850,  -2.0709],\n",
      "         [ -6.4854,  -6.3986,  -6.4982,  ...,  -6.9863,  -7.9940,  -2.3139]],\n",
      "\n",
      "        [[ -6.6888,  -6.6268,  -6.6275,  ...,  -5.8800,  -5.9944,  -3.7391],\n",
      "         [ -9.7231,  -9.7664,  -9.7679,  ...,  -8.5642,  -9.5590,  -6.5378],\n",
      "         [ -1.5294,  -1.9444,  -1.6852,  ...,  -1.2774,  -2.0665,  -2.3665],\n",
      "         ...,\n",
      "         [ -8.3084,  -8.3667,  -8.3229,  ...,  -8.1910,  -8.9403,  -5.8993],\n",
      "         [ -5.7975,  -6.2536,  -5.7425,  ...,  -6.7553,  -7.2632,  -3.1607],\n",
      "         [ -8.5954,  -8.6157,  -8.6486,  ...,  -8.9613,  -9.3614,  -5.8116]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7144,  -6.6739,  -6.6265,  ...,  -6.0416,  -5.8929,  -4.2277],\n",
      "         [-11.0693, -11.0749, -10.7809,  ...,  -9.8023,  -8.3205, -11.0175],\n",
      "         [ -9.8850,  -9.8428,  -9.6445,  ..., -11.3112,  -7.6487, -11.5134],\n",
      "         ...,\n",
      "         [ -6.2886,  -6.2100,  -6.3278,  ...,  -6.3207,  -6.4254,  -2.6159],\n",
      "         [ -7.6605,  -7.6421,  -7.6507,  ...,  -7.4276,  -7.8708,  -3.2298],\n",
      "         [ -8.1565,  -8.0351,  -7.9633,  ...,  -8.4269,  -7.6708,  -5.4572]],\n",
      "\n",
      "        [[-13.1616, -13.1946, -12.8756,  ..., -12.1224, -12.9267,  -5.0650],\n",
      "         [-12.6676, -12.0132, -12.2192,  ..., -10.7302,  -9.9127, -11.1377],\n",
      "         [ -5.8496,  -5.8094,  -5.7514,  ...,  -6.3057,  -7.5147,  -1.4631],\n",
      "         ...,\n",
      "         [ -5.6777,  -5.4439,  -5.5208,  ...,  -6.2321,  -7.4782,  -2.3662],\n",
      "         [ -7.5250,  -7.4074,  -7.4852,  ...,  -8.0098,  -8.6234,  -0.6180],\n",
      "         [ -6.5850,  -6.3375,  -6.3600,  ...,  -6.5788,  -8.2078,  -2.3379]],\n",
      "\n",
      "        [[ -6.8452,  -6.7825,  -6.8320,  ...,  -6.2687,  -6.0916,  -4.0313],\n",
      "         [ -9.6509,  -9.4207,  -9.8642,  ...,  -6.4028,  -8.7346,  -5.4421],\n",
      "         [ -6.7301,  -6.7791,  -6.7296,  ...,  -7.2861,  -7.8014,  -1.5957],\n",
      "         ...,\n",
      "         [ -6.4650,  -6.2935,  -6.3285,  ...,  -6.4029,  -7.8110,  -2.6021],\n",
      "         [ -6.7987,  -6.5572,  -6.6862,  ...,  -7.0305,  -7.3753,  -1.4698],\n",
      "         [ -6.4749,  -6.3626,  -6.5656,  ...,  -6.6127,  -8.1821,  -1.5955]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.045754909515381\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6710, grad_fn=<NllLossBackward0>), logits=tensor([[[-6.5149e+00, -6.4217e+00, -6.4002e+00,  ..., -5.9116e+00,\n",
      "          -5.5512e+00, -3.9940e+00],\n",
      "         [-6.2382e+00, -6.1891e+00, -6.1709e+00,  ..., -4.8787e+00,\n",
      "          -6.4852e+00, -4.5229e+00],\n",
      "         [-8.9826e+00, -9.1590e+00, -9.3710e+00,  ..., -8.7281e+00,\n",
      "          -8.9416e+00, -6.6913e+00],\n",
      "         ...,\n",
      "         [-7.0346e+00, -6.9601e+00, -6.9041e+00,  ..., -5.4164e+00,\n",
      "          -4.4473e+00, -6.5650e+00],\n",
      "         [-6.0983e+00, -5.9155e+00, -6.0035e+00,  ..., -4.5556e+00,\n",
      "          -5.1224e+00, -4.4465e+00],\n",
      "         [-8.4805e+00, -8.3830e+00, -8.3495e+00,  ..., -6.4944e+00,\n",
      "          -7.3008e+00, -5.4217e+00]],\n",
      "\n",
      "        [[-6.7632e+00, -6.8316e+00, -6.8218e+00,  ..., -6.4798e+00,\n",
      "          -6.3069e+00, -3.9274e+00],\n",
      "         [-8.2858e+00, -8.2621e+00, -8.0499e+00,  ..., -7.9448e+00,\n",
      "          -7.0724e+00, -5.9918e+00],\n",
      "         [-3.7542e+00, -3.5831e+00, -3.7555e+00,  ..., -4.5980e+00,\n",
      "          -4.0297e+00, -2.8888e+00],\n",
      "         ...,\n",
      "         [-5.5533e+00, -5.6799e+00, -5.4771e+00,  ..., -5.5920e+00,\n",
      "          -6.0497e+00, -4.0455e+00],\n",
      "         [-6.0831e+00, -5.9928e+00, -5.8050e+00,  ..., -5.4939e+00,\n",
      "          -4.5130e+00, -4.9180e+00],\n",
      "         [-7.4245e+00, -7.5585e+00, -7.5051e+00,  ..., -7.5365e+00,\n",
      "          -7.0318e+00, -4.6594e+00]],\n",
      "\n",
      "        [[-8.6437e+00, -8.5918e+00, -8.6120e+00,  ..., -7.5548e+00,\n",
      "          -7.3770e+00, -5.9126e+00],\n",
      "         [-6.8510e+00, -6.7294e+00, -6.8892e+00,  ..., -7.0257e+00,\n",
      "          -7.0218e+00, -7.4090e-03],\n",
      "         [-9.2398e+00, -9.1710e+00, -9.6073e+00,  ..., -9.1507e+00,\n",
      "          -9.2757e+00, -9.2923e+00],\n",
      "         ...,\n",
      "         [-7.5194e+00, -7.6550e+00, -7.4234e+00,  ..., -6.9962e+00,\n",
      "          -7.5890e+00, -1.1992e+00],\n",
      "         [-6.1397e+00, -6.1953e+00, -6.1100e+00,  ..., -6.2402e+00,\n",
      "          -6.6230e+00, -2.5710e+00],\n",
      "         [-6.2334e+00, -6.2514e+00, -6.1178e+00,  ..., -6.6182e+00,\n",
      "          -6.3078e+00, -8.6441e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.8168e+00, -6.7865e+00, -6.7939e+00,  ..., -6.0634e+00,\n",
      "          -6.0984e+00, -3.9664e+00],\n",
      "         [-1.6089e+01, -1.5862e+01, -1.6073e+01,  ..., -1.3505e+01,\n",
      "          -1.4731e+01, -1.5131e+01],\n",
      "         [-7.3891e+00, -7.4619e+00, -7.2855e+00,  ..., -7.1242e+00,\n",
      "          -8.6124e+00, -7.3180e+00],\n",
      "         ...,\n",
      "         [-3.9123e+00, -3.9916e+00, -3.8425e+00,  ..., -3.5837e+00,\n",
      "          -4.1805e+00, -4.4778e+00],\n",
      "         [-4.5296e+00, -4.6424e+00, -4.8106e+00,  ..., -4.5242e+00,\n",
      "          -5.4637e+00, -4.2142e+00],\n",
      "         [-7.7282e+00, -7.7471e+00, -7.8982e+00,  ..., -7.6611e+00,\n",
      "          -8.6407e+00, -5.5411e+00]],\n",
      "\n",
      "        [[-1.0461e+01, -1.0502e+01, -1.0276e+01,  ..., -9.6263e+00,\n",
      "          -1.0251e+01, -6.7916e+00],\n",
      "         [-8.9974e+00, -9.0623e+00, -8.7594e+00,  ..., -6.0159e+00,\n",
      "          -5.9871e+00, -8.5289e+00],\n",
      "         [-5.9948e+00, -6.0304e+00, -6.0716e+00,  ..., -5.9470e+00,\n",
      "          -7.0780e+00, -1.9933e+00],\n",
      "         ...,\n",
      "         [-7.4310e+00, -7.3115e+00, -7.3656e+00,  ..., -7.3413e+00,\n",
      "          -8.6349e+00, -3.3697e+00],\n",
      "         [-6.8408e+00, -6.7677e+00, -6.8365e+00,  ..., -6.6495e+00,\n",
      "          -7.7210e+00, -3.2545e+00],\n",
      "         [-6.0946e+00, -6.0636e+00, -6.1924e+00,  ..., -5.6439e+00,\n",
      "          -6.9305e+00, -2.3128e+00]],\n",
      "\n",
      "        [[-7.3078e+00, -7.3395e+00, -7.2603e+00,  ..., -6.7204e+00,\n",
      "          -6.5566e+00, -4.0792e+00],\n",
      "         [-9.1714e+00, -8.9339e+00, -9.0047e+00,  ..., -8.4552e+00,\n",
      "          -7.7232e+00, -6.5335e+00],\n",
      "         [-1.2912e+01, -1.2736e+01, -1.2697e+01,  ..., -1.1253e+01,\n",
      "          -1.0376e+01, -7.8676e+00],\n",
      "         ...,\n",
      "         [-6.3901e+00, -6.8067e+00, -6.5054e+00,  ..., -6.8578e+00,\n",
      "          -6.8580e+00, -4.2863e+00],\n",
      "         [-1.1552e+01, -1.1137e+01, -1.1579e+01,  ..., -8.8671e+00,\n",
      "          -8.7954e+00, -6.1551e+00],\n",
      "         [-1.3737e+01, -1.3998e+01, -1.3698e+01,  ..., -1.1493e+01,\n",
      "          -1.0138e+01, -8.2805e+00]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6709672212600708\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1859, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8559,  -7.6965,  -7.7711,  ...,  -6.8322,  -7.0580,  -4.4328],\n",
      "         [-13.7217, -13.6536, -13.3777,  ..., -10.7615, -11.4606, -12.7915],\n",
      "         [ -5.4110,  -5.1330,  -5.2882,  ...,  -5.9455,  -7.0486,  -2.1661],\n",
      "         ...,\n",
      "         [ -5.7198,  -5.4885,  -5.5090,  ...,  -6.5501,  -7.2675,  -2.4356],\n",
      "         [ -6.1811,  -5.9561,  -6.0390,  ...,  -6.7633,  -7.4971,  -2.4715],\n",
      "         [ -6.3232,  -6.1542,  -6.1747,  ...,  -6.7337,  -7.4052,  -2.3396]],\n",
      "\n",
      "        [[ -6.9290,  -6.9375,  -6.9119,  ...,  -6.3378,  -6.2188,  -4.6558],\n",
      "         [-10.0624, -10.0281, -10.1052,  ...,  -9.6776,  -9.5146,  -8.0480],\n",
      "         [-14.8298, -14.7657, -14.5765,  ..., -12.8485, -12.0099, -14.3382],\n",
      "         ...,\n",
      "         [-10.7141, -10.6125, -10.1894,  ...,  -8.5068,  -8.4983,  -6.2578],\n",
      "         [-12.6893, -12.3297, -12.1759,  ..., -10.5978,  -9.8578,  -8.0153],\n",
      "         [ -9.0383,  -8.6749,  -8.8848,  ...,  -5.8937,  -7.0364,  -5.6109]],\n",
      "\n",
      "        [[ -7.2699,  -7.1703,  -7.1921,  ...,  -6.4765,  -6.5473,  -4.1401],\n",
      "         [-10.3774, -10.4553,  -9.8854,  ...,  -7.3534,  -7.5710,  -9.2774],\n",
      "         [ -5.8894,  -5.7806,  -5.8007,  ...,  -6.5950,  -7.0648,  -0.6015],\n",
      "         ...,\n",
      "         [ -6.8819,  -6.6815,  -6.8935,  ...,  -6.7691,  -8.0388,  -2.4827],\n",
      "         [ -6.6674,  -6.7303,  -6.8168,  ...,  -7.3307,  -8.1600,  -2.6351],\n",
      "         [ -7.4160,  -7.1936,  -7.3656,  ...,  -7.4006,  -8.0955,  -2.2341]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0493,  -7.0701,  -7.0011,  ...,  -6.3945,  -6.2749,  -4.0523],\n",
      "         [-11.4781, -11.1539, -11.4048,  ..., -11.3916,  -8.5045, -10.0043],\n",
      "         [ -6.4815,  -6.5651,  -6.8120,  ...,  -6.2349,  -5.0531,  -4.5243],\n",
      "         ...,\n",
      "         [ -7.9147,  -7.9165,  -7.8755,  ...,  -8.2226,  -6.8404,  -6.5634],\n",
      "         [ -5.0308,  -5.0670,  -5.3820,  ...,  -5.1479,  -6.0387,  -3.1456],\n",
      "         [-12.1286, -11.9721, -12.0315,  ...,  -9.5557,  -9.1667,  -7.9630]],\n",
      "\n",
      "        [[ -6.6984,  -6.7130,  -6.6848,  ...,  -5.8894,  -5.8563,  -3.9741],\n",
      "         [ -7.7088,  -7.6690,  -7.8430,  ...,  -7.6697,  -7.0155,  -4.0326],\n",
      "         [  0.4827,   0.2894,   0.3272,  ...,  -0.2695,  -1.4097,   0.4952],\n",
      "         ...,\n",
      "         [ -7.2015,  -7.1805,  -7.3395,  ...,  -7.4302,  -6.8261,  -5.3994],\n",
      "         [ -5.4421,  -5.4754,  -5.4960,  ...,  -5.6660,  -5.4552,  -5.4644],\n",
      "         [ -7.1633,  -7.2335,  -7.3078,  ...,  -7.4527,  -6.4582,  -5.8453]],\n",
      "\n",
      "        [[-10.0716, -10.2645, -10.1567,  ...,  -9.2598, -12.7900,  -4.2726],\n",
      "         [-11.9856, -12.0125, -11.8199,  ..., -10.4767, -10.0326, -12.0716],\n",
      "         [ -6.5476,  -6.4610,  -6.6109,  ...,  -6.5317,  -8.5200,  -2.1357],\n",
      "         ...,\n",
      "         [ -7.6504,  -7.6517,  -7.6604,  ...,  -7.2860,  -8.8394,  -1.8773],\n",
      "         [ -7.4719,  -7.5080,  -7.7029,  ...,  -7.0926,  -9.0321,  -1.5255],\n",
      "         [ -6.7673,  -6.9271,  -6.8964,  ...,  -6.8297,  -8.0185,  -1.4721]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1859254837036133\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.1448, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8048,  -6.7989,  -6.7815,  ...,  -6.2688,  -5.9452,  -4.0470],\n",
      "         [ -7.1485,  -7.1481,  -7.0470,  ...,  -6.8446,  -6.5542,  -6.7919],\n",
      "         [ -5.9227,  -6.1498,  -5.8978,  ...,  -6.7733,  -7.0725,  -2.7942],\n",
      "         ...,\n",
      "         [ -4.5685,  -4.4987,  -4.2236,  ...,  -5.4800,  -4.1111,  -4.4689],\n",
      "         [ -6.4823,  -6.4857,  -6.4577,  ...,  -7.0439,  -6.3296,  -2.6129],\n",
      "         [-11.7757, -11.4137, -11.4949,  ..., -10.0749,  -8.6624,  -7.4996]],\n",
      "\n",
      "        [[ -6.5067,  -6.4699,  -6.4483,  ...,  -5.8409,  -5.9766,  -3.8239],\n",
      "         [ -8.5620,  -8.5496,  -8.6763,  ...,  -9.3219,  -8.3784,  -8.8188],\n",
      "         [-10.7748, -10.6648, -10.7260,  ...,  -9.6903, -10.0019, -10.8040],\n",
      "         ...,\n",
      "         [-11.4218, -11.5955, -11.3956,  ..., -10.4271,  -9.7085,  -9.3513],\n",
      "         [ -7.2742,  -7.4307,  -7.6077,  ...,  -6.7897,  -7.7366,  -4.6683],\n",
      "         [-11.1172, -10.6654, -11.0564,  ...,  -8.8796,  -8.4185,  -5.1512]],\n",
      "\n",
      "        [[ -6.7319,  -6.6913,  -6.7066,  ...,  -6.1788,  -5.8949,  -3.9031],\n",
      "         [ -7.3331,  -7.2670,  -7.2999,  ...,  -7.3084,  -6.8255,  -3.3226],\n",
      "         [ -6.7070,  -6.6925,  -6.7376,  ...,  -6.9429,  -6.4744,  -2.6388],\n",
      "         ...,\n",
      "         [ -6.8906,  -6.8887,  -6.9098,  ...,  -6.9876,  -6.5630,  -2.6122],\n",
      "         [ -7.1969,  -7.2213,  -7.2170,  ...,  -7.2504,  -6.8665,  -2.8063],\n",
      "         [ -5.7408,  -5.7134,  -5.7639,  ...,  -5.9069,  -5.6136,  -0.9881]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6023,  -7.5723,  -7.5533,  ...,  -6.6762,  -6.7654,  -4.9916],\n",
      "         [-11.2917, -11.1544, -11.0249,  ...,  -8.3611,  -9.0769, -10.4124],\n",
      "         [ -6.4869,  -6.4663,  -6.6370,  ...,  -6.8261,  -8.5144,  -2.4778],\n",
      "         ...,\n",
      "         [ -6.5084,  -6.4322,  -6.4959,  ...,  -7.1099,  -8.0428,  -3.1928],\n",
      "         [ -6.4420,  -6.2728,  -6.3992,  ...,  -6.3898,  -8.3068,  -2.9928],\n",
      "         [ -6.7066,  -6.4996,  -6.7506,  ...,  -6.5328,  -8.4679,  -3.8259]],\n",
      "\n",
      "        [[ -7.2485,  -7.1872,  -7.1535,  ...,  -6.4663,  -6.4688,  -4.0227],\n",
      "         [-14.5346, -14.1337, -14.1617,  ..., -13.6558, -12.2469, -11.7458],\n",
      "         [ -6.2237,  -6.1087,  -6.2365,  ...,  -6.5760,  -7.8048,  -2.7484],\n",
      "         ...,\n",
      "         [ -5.7614,  -5.6790,  -5.8390,  ...,  -5.9965,  -7.1434,  -1.5365],\n",
      "         [ -6.5238,  -6.4623,  -6.5039,  ...,  -7.1673,  -7.5886,  -2.6515],\n",
      "         [ -6.3294,  -6.2178,  -6.2400,  ...,  -6.5947,  -7.5874,  -2.1383]],\n",
      "\n",
      "        [[ -7.0685,  -7.0246,  -7.0161,  ...,  -6.7702,  -6.5352,  -4.0414],\n",
      "         [ -7.5579,  -7.4924,  -7.6447,  ...,  -7.7520,  -8.5218,  -2.2861],\n",
      "         [ -6.9479,  -6.8135,  -6.9485,  ...,  -7.0620,  -7.0935,  -2.1910],\n",
      "         ...,\n",
      "         [ -6.9959,  -7.0074,  -7.0749,  ...,  -7.2080,  -7.4217,  -3.1780],\n",
      "         [ -6.6668,  -6.6208,  -6.7576,  ...,  -6.9668,  -7.5007,  -2.5124],\n",
      "         [ -6.9581,  -6.9097,  -7.0270,  ...,  -7.1298,  -7.4266,  -2.6479]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.1447999477386475\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.9835, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2385,  -7.2334,  -7.2088,  ...,  -6.7930,  -6.2344,  -4.4632],\n",
      "         [ -7.8683,  -7.8562,  -7.5514,  ...,  -7.7305,  -6.6468,  -6.2466],\n",
      "         [ -6.1874,  -5.9668,  -6.0601,  ...,  -7.4962,  -5.3774,  -8.0503],\n",
      "         ...,\n",
      "         [ -7.9177,  -7.8452,  -7.6976,  ...,  -7.9383,  -5.5266,  -5.5683],\n",
      "         [ -8.1011,  -8.3107,  -7.6349,  ...,  -6.4557,  -7.3565,  -5.6191],\n",
      "         [-10.6771, -10.4368, -10.5705,  ...,  -8.4389,  -9.1005,  -6.2443]],\n",
      "\n",
      "        [[ -6.8457,  -6.7925,  -6.8146,  ...,  -6.1963,  -5.9444,  -3.9620],\n",
      "         [ -7.3673,  -7.1943,  -7.1515,  ...,  -8.1247,  -7.4836,  -3.9224],\n",
      "         [ -8.8033,  -8.6188,  -8.6554,  ...,  -9.0365,  -8.4250,  -3.4399],\n",
      "         ...,\n",
      "         [ -7.6556,  -7.4850,  -7.5372,  ...,  -7.6485,  -7.6242,  -3.3728],\n",
      "         [ -7.5505,  -7.4254,  -7.5154,  ...,  -7.3733,  -7.2710,  -3.4302],\n",
      "         [ -7.6307,  -7.5461,  -7.5276,  ...,  -7.2495,  -7.0162,  -3.7239]],\n",
      "\n",
      "        [[ -6.8279,  -6.6092,  -6.6335,  ...,  -5.8679,  -5.9543,  -3.6254],\n",
      "         [ -8.5446,  -8.3056,  -8.1483,  ...,  -5.4555,  -5.5528,  -6.8921],\n",
      "         [ -5.8654,  -5.7163,  -5.8275,  ...,  -6.9368,  -7.7166,  -1.8392],\n",
      "         ...,\n",
      "         [ -6.2072,  -5.9524,  -6.0198,  ...,  -6.7794,  -7.7550,  -0.4630],\n",
      "         [ -6.5978,  -6.2601,  -6.4056,  ...,  -7.1919,  -8.3438,  -1.6842],\n",
      "         [ -6.0827,  -5.8943,  -5.9668,  ...,  -5.8085,  -7.5730,  -1.3212]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1313,  -7.1233,  -7.0330,  ...,  -6.2061,  -6.3883,  -3.0697],\n",
      "         [-13.6932, -13.8165, -13.4570,  ..., -12.4294, -11.5513,  -6.9766],\n",
      "         [-10.4806, -10.6038, -10.3281,  ..., -10.1163,  -9.5847,  -4.2481],\n",
      "         ...,\n",
      "         [ -6.6069,  -6.7575,  -6.4076,  ...,  -6.7680,  -7.2168,  -2.1024],\n",
      "         [ -6.5092,  -6.5354,  -6.5065,  ...,  -6.0260,  -5.9647,  -4.0275],\n",
      "         [ -5.7376,  -5.9622,  -5.7039,  ...,  -5.7447,  -6.5211,  -2.9186]],\n",
      "\n",
      "        [[ -6.9126,  -6.7717,  -6.7766,  ...,  -6.1846,  -5.8420,  -4.1820],\n",
      "         [ -9.6270,  -9.5013,  -9.8255,  ...,  -7.0800,  -7.6412,  -8.0970],\n",
      "         [ -5.3106,  -5.0111,  -5.0951,  ...,  -5.7502,  -6.9850,  -1.8530],\n",
      "         ...,\n",
      "         [ -6.4093,  -6.1771,  -6.2947,  ...,  -6.4778,  -8.4779,  -1.3484],\n",
      "         [ -5.8702,  -5.6582,  -5.6491,  ...,  -6.7063,  -7.9685,  -1.8385],\n",
      "         [ -6.5174,  -6.2175,  -6.4713,  ...,  -7.1064,  -7.9557,  -1.9312]],\n",
      "\n",
      "        [[ -6.2828,  -6.1928,  -6.1859,  ...,  -6.1147,  -5.9208,  -2.7436],\n",
      "         [-11.0570, -10.7460, -10.6363,  ...,  -8.9408,  -8.2282,  -9.7182],\n",
      "         [ -7.3477,  -7.2299,  -7.3685,  ...,  -7.8233,  -7.3299,  -2.4796],\n",
      "         ...,\n",
      "         [ -7.1420,  -7.1024,  -7.2495,  ...,  -7.2555,  -7.4318,  -2.6464],\n",
      "         [ -7.2507,  -7.0161,  -7.2604,  ...,  -7.9429,  -7.5006,  -3.0543],\n",
      "         [ -7.1684,  -7.0255,  -7.1192,  ...,  -7.7978,  -7.3503,  -2.0571]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.983489751815796\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1468, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5462,  -7.4813,  -7.4528,  ...,  -6.4065,  -7.1251,  -3.3871],\n",
      "         [ -8.2891,  -7.8928,  -7.9682,  ...,  -6.7491,  -6.7906,  -8.3176],\n",
      "         [ -6.1456,  -5.9973,  -6.0550,  ...,  -6.8504,  -8.0311,  -2.0195],\n",
      "         ...,\n",
      "         [ -6.9675,  -6.8435,  -6.9472,  ...,  -8.1428,  -8.5818,  -2.6819],\n",
      "         [ -6.6815,  -6.5838,  -6.6965,  ...,  -7.4002,  -8.4800,  -0.6217],\n",
      "         [ -6.4003,  -6.2244,  -6.3335,  ...,  -7.2384,  -7.9101,  -3.4881]],\n",
      "\n",
      "        [[ -6.6427,  -6.7296,  -6.6414,  ...,  -6.1129,  -5.8819,  -4.3932],\n",
      "         [-10.2719, -10.3025, -10.1840,  ...,  -8.9799,  -7.2147,  -9.7451],\n",
      "         [ -7.8203,  -8.0247,  -7.6471,  ...,  -7.0261,  -5.4949,  -8.0401],\n",
      "         ...,\n",
      "         [-11.8684, -12.1544, -12.3803,  ...,  -9.1781,  -8.5893,  -4.4506],\n",
      "         [ -7.2353,  -7.2051,  -7.1762,  ...,  -5.7482,  -5.0925,  -5.4799],\n",
      "         [ -6.3256,  -6.4075,  -6.2789,  ...,  -5.8510,  -6.0745,  -4.6327]],\n",
      "\n",
      "        [[ -6.7740,  -6.8042,  -6.7897,  ...,  -6.0331,  -6.0849,  -4.0060],\n",
      "         [ -9.5559, -10.4199,  -9.8984,  ...,  -8.6657, -11.4452,  -6.3539],\n",
      "         [-12.2100, -12.1252, -12.1520,  ..., -10.8762, -10.5822,  -8.9271],\n",
      "         ...,\n",
      "         [ -6.0119,  -6.1047,  -6.1128,  ...,  -6.0285,  -6.3990,  -6.8240],\n",
      "         [ -5.5080,  -5.5133,  -5.6076,  ...,  -4.9989,  -5.6424,  -6.5053],\n",
      "         [ -7.0046,  -6.9791,  -6.9696,  ...,  -7.2427,  -7.3819,  -6.5164]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8095,  -6.8288,  -6.7256,  ...,  -6.2848,  -6.0368,  -3.9509],\n",
      "         [ -8.9157,  -8.9579,  -9.1043,  ...,  -8.9329,  -7.7404,  -6.2350],\n",
      "         [ -8.9333,  -8.8330,  -8.7384,  ...,  -8.4740,  -7.8660,  -6.5026],\n",
      "         ...,\n",
      "         [ -8.3493,  -8.5836,  -8.2888,  ...,  -6.7806,  -6.8327,  -7.9010],\n",
      "         [ -6.2685,  -6.4140,  -6.2925,  ...,  -5.7981,  -6.0988,  -3.5630],\n",
      "         [-12.7438, -12.1152, -12.1669,  ..., -10.1772, -10.1248,  -8.2392]],\n",
      "\n",
      "        [[ -6.4417,  -6.4669,  -6.4539,  ...,  -5.8354,  -5.8130,  -3.8461],\n",
      "         [ -7.2995,  -7.2786,  -7.2712,  ...,  -6.6711,  -7.0273,  -4.6078],\n",
      "         [ -4.1578,  -4.3456,  -3.9833,  ...,  -2.5677,  -4.0765,  -2.5254],\n",
      "         ...,\n",
      "         [ -6.2517,  -6.2028,  -6.1743,  ...,  -6.5950,  -6.3764,  -1.8984],\n",
      "         [ -4.8428,  -4.7808,  -4.8758,  ...,  -4.7554,  -4.6819,  -4.3192],\n",
      "         [-10.1956,  -9.8583,  -9.6969,  ...,  -7.6650,  -9.6040,  -7.7048]],\n",
      "\n",
      "        [[ -6.7307,  -6.7376,  -6.6793,  ...,  -5.9148,  -5.6902,  -3.8896],\n",
      "         [-11.8289, -11.9921, -11.9783,  ..., -10.3974,  -9.1363,  -8.8077],\n",
      "         [ -9.3844,  -9.3169,  -9.5187,  ...,  -8.9365,  -8.3304,  -5.3883],\n",
      "         ...,\n",
      "         [ -8.1169,  -8.0244,  -8.3106,  ...,  -8.0577,  -6.6909,  -8.6107],\n",
      "         [ -7.3126,  -7.2221,  -7.5624,  ...,  -5.8631,  -6.9359,  -2.5899],\n",
      "         [-10.3682, -10.2822, -10.5298,  ...,  -8.2663,  -7.9940,  -5.0932]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1467580795288086\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3126, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.1632,  -8.0187,  -8.1376,  ...,  -7.6696,  -7.4223,  -5.0140],\n",
      "         [-11.5743, -11.4362, -11.4397,  ...,  -8.7721,  -7.8047, -13.4453],\n",
      "         [ -6.1158,  -6.1798,  -6.0656,  ...,  -6.5382,  -7.1009,  -2.6748],\n",
      "         ...,\n",
      "         [ -7.2921,  -6.9399,  -7.1405,  ...,  -7.1669,  -7.6475,  -3.3544],\n",
      "         [ -7.3373,  -7.0754,  -7.2096,  ...,  -7.2990,  -7.9413,  -3.0034],\n",
      "         [ -6.7043,  -6.5854,  -6.5781,  ...,  -6.7247,  -7.4782,  -3.7994]],\n",
      "\n",
      "        [[ -7.4424,  -7.3171,  -7.3293,  ...,  -6.5115,  -6.3378,  -4.0748],\n",
      "         [ -9.9166,  -9.7651,  -9.5220,  ...,  -6.4144,  -6.8504,  -7.3869],\n",
      "         [ -6.8993,  -6.9496,  -7.0059,  ...,  -7.4709,  -8.1324,  -2.3176],\n",
      "         ...,\n",
      "         [ -6.5439,  -6.3450,  -6.3777,  ...,  -6.4529,  -7.2922,  -2.3501],\n",
      "         [ -7.4891,  -7.3519,  -7.4359,  ...,  -7.5604,  -7.6921,  -2.9209],\n",
      "         [ -6.1600,  -6.0603,  -6.1111,  ...,  -6.4987,  -6.9026,  -2.3443]],\n",
      "\n",
      "        [[ -6.5944,  -6.5500,  -6.5608,  ...,  -5.8146,  -5.8430,  -3.7342],\n",
      "         [-10.8014, -10.6836, -10.2737,  ...,  -7.0205,  -9.6502,  -9.9327],\n",
      "         [ -6.6612,  -6.5952,  -6.6265,  ...,  -7.0853,  -8.0521,  -2.3456],\n",
      "         ...,\n",
      "         [ -7.0746,  -6.9492,  -7.0061,  ...,  -7.1303,  -8.2124,  -1.3623],\n",
      "         [ -6.6643,  -6.6035,  -6.6446,  ...,  -6.9831,  -7.8572,  -2.4347],\n",
      "         [ -7.6293,  -7.6354,  -7.6187,  ...,  -8.0137,  -8.4838,  -3.0147]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-12.3121, -12.7516, -12.7010,  ..., -10.3025, -12.6674,  -6.3421],\n",
      "         [-10.7643, -10.8486, -11.1298,  ...,  -9.0150,  -9.0511,  -9.8497],\n",
      "         [ -6.7675,  -6.6564,  -6.7569,  ...,  -6.9473,  -8.0573,  -2.9141],\n",
      "         ...,\n",
      "         [ -6.4904,  -6.2772,  -6.2320,  ...,  -6.8200,  -8.0643,  -2.5746],\n",
      "         [ -6.3565,  -6.1298,  -6.2565,  ...,  -6.8473,  -7.4828,  -3.2597],\n",
      "         [ -5.7237,  -5.5336,  -5.5459,  ...,  -6.0918,  -7.4903,  -3.3364]],\n",
      "\n",
      "        [[ -6.7774,  -6.7554,  -6.7286,  ...,  -6.2121,  -5.9672,  -3.9674],\n",
      "         [ -8.4279,  -8.1624,  -8.3405,  ...,  -8.3775,  -7.4390,  -5.8336],\n",
      "         [  0.0137,  -0.0869,   0.0983,  ...,  -1.4729,  -2.4440,  -0.3883],\n",
      "         ...,\n",
      "         [ -6.0832,  -5.9095,  -5.8153,  ...,  -6.9777,  -6.2812,  -3.5569],\n",
      "         [ -4.5105,  -4.6016,  -4.5341,  ...,  -4.4148,  -5.2290,  -0.6949],\n",
      "         [ -7.3603,  -7.1453,  -7.0902,  ...,  -7.5527,  -7.2129,  -3.5463]],\n",
      "\n",
      "        [[ -6.8838,  -6.8391,  -6.8750,  ...,  -6.1657,  -6.0605,  -4.0603],\n",
      "         [ -8.8158,  -8.8793,  -8.8455,  ...,  -8.7261,  -7.9115,  -4.3970],\n",
      "         [ -7.5057,  -7.4917,  -7.6453,  ...,  -7.0257,  -7.9519,  -3.5344],\n",
      "         ...,\n",
      "         [ -7.5298,  -7.3402,  -7.6124,  ...,  -8.0586,  -7.5387,  -4.8402],\n",
      "         [ -7.6476,  -7.3649,  -7.6663,  ...,  -7.3165,  -7.9790,  -2.9892],\n",
      "         [ -7.9775,  -7.8706,  -8.1368,  ...,  -7.9365,  -8.1860,  -3.5099]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.31261944770813\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4609, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.4568,  -9.4558,  -9.4961,  ...,  -8.2003,  -8.7871,  -6.5234],\n",
      "         [ -8.9813,  -8.7485,  -8.8636,  ...,  -7.5297,  -8.2044,  -8.1729],\n",
      "         [ -5.9252,  -5.8112,  -5.9337,  ...,  -6.0210,  -7.1165,  -3.4080],\n",
      "         ...,\n",
      "         [ -6.5624,  -6.3930,  -6.5436,  ...,  -7.0419,  -8.0183,  -3.1766],\n",
      "         [ -6.2595,  -6.0968,  -6.3022,  ...,  -6.8447,  -7.4448,  -2.8446],\n",
      "         [ -6.0398,  -5.8542,  -5.9612,  ...,  -6.7191,  -7.5666,  -3.2812]],\n",
      "\n",
      "        [[ -6.7120,  -6.6912,  -6.6858,  ...,  -6.2490,  -5.9796,  -4.1465],\n",
      "         [ -7.0384,  -7.4836,  -7.0237,  ...,  -6.6007,  -5.9625,  -2.3115],\n",
      "         [ -6.8555,  -6.9658,  -6.9675,  ...,  -7.0711,  -6.3591,  -3.0248],\n",
      "         ...,\n",
      "         [ -7.2180,  -7.6473,  -7.1970,  ...,  -7.7187,  -6.6074,  -2.4378],\n",
      "         [ -7.4822,  -7.6399,  -7.4942,  ...,  -7.3497,  -7.0413,  -3.2168],\n",
      "         [ -7.9936,  -8.1228,  -8.0171,  ...,  -8.0588,  -7.5840,  -4.0376]],\n",
      "\n",
      "        [[ -7.2667,  -7.2090,  -7.1733,  ...,  -6.5960,  -6.4753,  -4.1513],\n",
      "         [ -7.3139,  -7.3438,  -7.1089,  ...,  -5.7002,  -4.9338,  -6.9131],\n",
      "         [ -6.1549,  -6.0346,  -6.0457,  ...,  -7.4284,  -7.5090,  -2.1102],\n",
      "         ...,\n",
      "         [ -6.3416,  -6.2399,  -6.2798,  ...,  -7.2760,  -7.2434,  -2.9890],\n",
      "         [ -6.2662,  -6.2069,  -6.1741,  ...,  -7.5627,  -7.5695,  -2.3961],\n",
      "         [ -5.5155,  -5.3432,  -5.2841,  ...,  -6.4859,  -6.9497,  -2.8327]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3973,  -7.4100,  -7.3597,  ...,  -6.7221,  -6.4298,  -4.3850],\n",
      "         [ -5.4613,  -5.4767,  -5.2525,  ...,  -4.2259,  -5.0537,  -4.6892],\n",
      "         [ -7.1514,  -7.2673,  -7.1608,  ...,  -6.1129,  -6.3708,  -6.5293],\n",
      "         ...,\n",
      "         [ -8.4741,  -8.4587,  -8.0395,  ...,  -7.8511,  -7.1994,  -6.6549],\n",
      "         [ -8.4295,  -8.3442,  -8.4998,  ...,  -6.8402,  -7.8884,  -3.6988],\n",
      "         [-12.9838, -12.5033, -12.5624,  ..., -11.2252, -10.5838,  -8.7818]],\n",
      "\n",
      "        [[ -6.8841,  -6.8552,  -6.8059,  ...,  -6.3029,  -6.0044,  -4.3010],\n",
      "         [ -8.9631,  -8.7884,  -8.9124,  ...,  -9.2313,  -7.4720,  -9.1186],\n",
      "         [-10.8183, -10.8353, -10.7536,  ..., -10.7427,  -8.2667, -12.2921],\n",
      "         ...,\n",
      "         [ -7.3134,  -7.4996,  -7.3282,  ...,  -7.8083,  -7.0311,  -5.5888],\n",
      "         [ -7.7484,  -7.7348,  -7.8188,  ...,  -8.0067,  -7.5442,  -5.4019],\n",
      "         [ -7.7628,  -7.8583,  -7.7865,  ...,  -7.8427,  -7.2922,  -6.5322]],\n",
      "\n",
      "        [[ -6.4486,  -6.5306,  -6.4165,  ...,  -6.0091,  -5.6526,  -3.9991],\n",
      "         [-10.3840, -10.1083, -10.3732,  ..., -10.3135,  -8.1711, -11.2560],\n",
      "         [ -5.7341,  -6.0946,  -6.1420,  ...,  -6.5432,  -4.9649, -10.5720],\n",
      "         ...,\n",
      "         [ -6.1218,  -6.1963,  -5.6841,  ...,  -5.9277,  -5.7520,  -8.7060],\n",
      "         [ -6.2188,  -6.0699,  -6.1990,  ...,  -5.5236,  -6.2364,  -4.5852],\n",
      "         [-10.2399, -10.3463, -10.0229,  ...,  -8.6721,  -8.8618,  -7.1640]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.4609456062316895\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3625, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9040,  -6.9208,  -6.8552,  ...,  -6.4766,  -6.4195,  -3.9728],\n",
      "         [ -9.1276,  -9.4462,  -9.2795,  ...,  -9.8476,  -8.2291,  -6.2167],\n",
      "         [ -6.0748,  -6.4813,  -6.3962,  ...,  -7.3265,  -5.8366,  -6.8735],\n",
      "         ...,\n",
      "         [-10.2076, -10.2697, -10.3777,  ...,  -9.9917, -12.2216,  -8.4437],\n",
      "         [ -9.2891,  -8.8692,  -9.3150,  ...,  -8.3679,  -8.6948,  -6.6486],\n",
      "         [-10.3939, -10.8166, -10.4283,  ..., -10.1301,  -7.8113,  -8.3750]],\n",
      "\n",
      "        [[ -8.9686,  -8.8774,  -8.9088,  ...,  -7.8239,  -8.1597,  -4.3634],\n",
      "         [ -9.0979,  -8.7168,  -8.8521,  ...,  -5.8986,  -6.4306,  -6.3574],\n",
      "         [ -7.3420,  -7.3738,  -7.3000,  ...,  -8.0916,  -8.7477,  -3.1802],\n",
      "         ...,\n",
      "         [ -6.4833,  -6.5337,  -6.3890,  ...,  -7.2524,  -8.1285,  -3.3754],\n",
      "         [ -7.0730,  -6.9213,  -7.0110,  ...,  -7.3490,  -8.3146,  -2.9196],\n",
      "         [ -5.6680,  -5.5795,  -5.4711,  ...,  -6.9786,  -7.1397,  -2.2260]],\n",
      "\n",
      "        [[ -6.7591,  -6.7632,  -6.7121,  ...,  -6.1569,  -5.9467,  -4.2408],\n",
      "         [ -5.1210,  -5.2270,  -4.9100,  ...,  -6.1947,  -4.6484,  -6.1017],\n",
      "         [ -3.9400,  -3.9938,  -4.0113,  ...,  -4.9365,  -4.2088,  -4.3921],\n",
      "         ...,\n",
      "         [ -6.8588,  -6.9169,  -6.7395,  ...,  -8.0266,  -5.8733,  -5.0950],\n",
      "         [ -7.2323,  -7.1343,  -7.1242,  ...,  -8.3283,  -6.2840,  -5.2635],\n",
      "         [ -6.5374,  -6.5740,  -6.4893,  ...,  -7.1448,  -5.3293,  -4.4138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9113,  -6.9475,  -6.9319,  ...,  -6.3147,  -6.1440,  -3.9570],\n",
      "         [-12.3781, -12.4816, -12.4998,  ..., -10.7181, -10.8031, -10.0385],\n",
      "         [ -8.2664,  -8.6070,  -8.4678,  ...,  -8.4493,  -9.4281,  -7.4591],\n",
      "         ...,\n",
      "         [ -7.6348,  -7.5498,  -7.6508,  ...,  -6.6494,  -7.4339,  -6.3701],\n",
      "         [ -6.5115,  -6.6782,  -6.2699,  ...,  -5.7026,  -5.4782,  -4.7228],\n",
      "         [-13.9400, -13.3701, -13.6413,  ..., -12.2474, -11.1329,  -9.7836]],\n",
      "\n",
      "        [[ -6.8344,  -6.7936,  -6.7695,  ...,  -6.1321,  -5.9855,  -3.9346],\n",
      "         [ -8.2613,  -8.4980,  -8.4403,  ...,  -7.6055,  -8.9989,  -7.6200],\n",
      "         [ -7.6961,  -7.7201,  -7.7186,  ...,  -7.2995,  -6.0937,  -4.4531],\n",
      "         ...,\n",
      "         [ -3.0704,  -2.9877,  -2.5289,  ...,  -4.3706,  -2.6781,  -0.4522],\n",
      "         [-11.5843, -11.4170, -11.6878,  ..., -10.6135,  -9.8220,  -7.0906],\n",
      "         [-11.7447, -10.9225, -11.2730,  ...,  -9.2870,  -9.0874,  -7.2177]],\n",
      "\n",
      "        [[ -6.9977,  -7.0112,  -6.9927,  ...,  -6.4105,  -6.3186,  -4.3994],\n",
      "         [ -9.9897, -10.0370, -10.0848,  ...,  -9.3174,  -8.3736,  -9.1076],\n",
      "         [ -5.8332,  -6.0556,  -5.9189,  ...,  -5.3997,  -4.0530,  -4.6627],\n",
      "         ...,\n",
      "         [ -3.1769,  -3.1552,  -3.4645,  ...,  -3.8313,  -4.9770,   0.8199],\n",
      "         [ -8.8047,  -8.4925,  -8.8999,  ...,  -8.2523,  -8.1596,  -3.0370],\n",
      "         [-15.3107, -14.9453, -15.4217,  ..., -12.4951, -12.4315,  -9.9150]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.362494468688965\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2694, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6363,  -6.6071,  -6.6419,  ...,  -6.2430,  -6.1762,  -3.6495],\n",
      "         [-10.1486, -10.1425, -10.0529,  ..., -10.9231,  -9.9837,  -5.5931],\n",
      "         [ -9.2927,  -9.4530,  -9.3383,  ...,  -9.4689,  -7.5347,  -6.1536],\n",
      "         ...,\n",
      "         [ -7.3773,  -7.4071,  -7.3744,  ...,  -7.4526,  -7.4242,  -4.2069],\n",
      "         [ -7.7290,  -7.7140,  -7.6997,  ...,  -7.8105,  -7.7417,  -4.6637],\n",
      "         [ -6.0342,  -6.0878,  -5.9740,  ...,  -5.7721,  -5.8086,  -2.7315]],\n",
      "\n",
      "        [[ -6.5275,  -6.4840,  -6.4536,  ...,  -5.8375,  -5.7026,  -3.7407],\n",
      "         [ -7.9853,  -7.9970,  -8.0236,  ...,  -8.5747,  -7.2072,  -5.7127],\n",
      "         [ -3.6128,  -3.6787,  -3.7040,  ...,  -3.4947,  -4.7584,  -2.4965],\n",
      "         ...,\n",
      "         [ -6.1421,  -6.0093,  -6.0850,  ...,  -6.0049,  -6.8053,  -1.5021],\n",
      "         [ -4.3203,  -4.1896,  -4.3114,  ...,  -4.2113,  -5.4739,  -1.4295],\n",
      "         [ -5.3277,  -5.4515,  -5.2854,  ...,  -4.9351,  -6.0088,  -1.1788]],\n",
      "\n",
      "        [[ -5.9113,  -5.9990,  -5.9531,  ...,  -6.2148,  -6.2664,  -1.0928],\n",
      "         [ -9.3809,  -9.0906,  -9.0160,  ...,  -6.4256,  -7.4581,  -9.6950],\n",
      "         [ -5.4774,  -5.3848,  -5.4477,  ...,  -5.8616,  -5.8614,  -0.3016],\n",
      "         ...,\n",
      "         [ -6.4327,  -6.4349,  -6.4461,  ...,  -6.6605,  -6.2368,  -1.2988],\n",
      "         [ -5.3495,  -5.2811,  -5.3583,  ...,  -6.1295,  -5.8054,  -2.5793],\n",
      "         [ -6.3348,  -6.3745,  -6.4144,  ...,  -6.7919,  -6.7782,  -0.6206]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.0351,  -6.0530,  -6.1537,  ...,  -6.6822,  -6.6158,  -3.8806],\n",
      "         [-12.0261, -11.5942, -11.6320,  ...,  -8.0469,  -9.2381, -10.6344],\n",
      "         [ -5.9778,  -6.0536,  -6.1190,  ...,  -7.2035,  -7.8313,  -2.2926],\n",
      "         ...,\n",
      "         [ -6.9888,  -6.8994,  -6.8328,  ...,  -7.7291,  -8.3817,  -3.2732],\n",
      "         [ -7.0058,  -7.0805,  -6.9788,  ...,  -7.9389,  -8.3404,  -2.2420],\n",
      "         [ -6.2509,  -6.3685,  -6.1553,  ...,  -7.4172,  -7.7997,  -2.9869]],\n",
      "\n",
      "        [[ -6.3423,  -6.3943,  -6.3470,  ...,  -5.8784,  -5.5839,  -3.9516],\n",
      "         [ -7.8473,  -8.0384,  -7.9868,  ..., -10.2866,  -5.9199,  -6.8356],\n",
      "         [ -9.3701,  -9.6144,  -9.1415,  ...,  -8.3886,  -8.9361,  -6.4042],\n",
      "         ...,\n",
      "         [ -7.1891,  -7.1210,  -6.9103,  ...,  -7.4123,  -5.2279,  -5.4780],\n",
      "         [ -9.7844,  -9.7861,  -9.5997,  ...,  -9.1770,  -9.0442,  -8.6641],\n",
      "         [ -8.2520,  -8.0017,  -8.2712,  ...,  -7.1033,  -6.7920,  -3.9930]],\n",
      "\n",
      "        [[ -6.6386,  -6.6004,  -6.6052,  ...,  -5.9063,  -5.7692,  -3.8634],\n",
      "         [-12.3679, -12.2724, -12.4016,  ..., -11.9363,  -9.7882,  -6.1898],\n",
      "         [-10.3930, -10.1605, -10.4970,  ..., -10.3627,  -8.0390,  -5.6176],\n",
      "         ...,\n",
      "         [ -9.7901,  -9.1057,  -9.5644,  ...,  -7.3839,  -6.5079,  -5.1222],\n",
      "         [-10.9882, -11.0218, -10.9112,  ...,  -9.6819,  -7.8405,  -6.7880],\n",
      "         [-12.0311, -11.6691, -11.7024,  ..., -11.2311, -10.0889,  -4.8089]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.269352912902832\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4839, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6613,  -6.7002,  -6.6750,  ...,  -6.2732,  -6.3205,  -3.8631],\n",
      "         [ -7.6508,  -7.5813,  -7.5578,  ...,  -7.0719,  -6.6568,  -5.9261],\n",
      "         [ -5.2109,  -5.1141,  -5.3040,  ...,  -6.1888,  -5.5907,  -4.6441],\n",
      "         ...,\n",
      "         [ -5.9862,  -6.1221,  -5.6359,  ...,  -6.6184,  -6.5824,  -1.1791],\n",
      "         [ -5.3551,  -5.6375,  -5.3244,  ...,  -6.1093,  -5.5689,  -3.4563],\n",
      "         [-12.0736, -11.7261, -11.7133,  ..., -10.4761, -10.3484,  -6.7836]],\n",
      "\n",
      "        [[ -7.0711,  -7.0782,  -7.0465,  ...,  -6.4078,  -6.0697,  -4.1624],\n",
      "         [ -9.3326,  -9.0298,  -9.2251,  ...,  -8.6154,  -8.4889,  -7.0624],\n",
      "         [ -8.9615,  -8.9165,  -8.6893,  ...,  -9.1714,  -8.1236,  -7.4807],\n",
      "         ...,\n",
      "         [ -8.9810,  -9.1216,  -9.1649,  ...,  -8.2363,  -8.4577,  -7.1209],\n",
      "         [ -7.3419,  -7.2828,  -6.9817,  ...,  -6.5223,  -7.2402,  -6.8194],\n",
      "         [-12.7866, -12.5722, -13.0096,  ..., -10.7741,  -9.1593, -11.0866]],\n",
      "\n",
      "        [[ -6.6118,  -6.5633,  -6.5861,  ...,  -6.0218,  -5.8052,  -3.9128],\n",
      "         [ -6.8208,  -6.8154,  -6.9313,  ...,  -6.9503,  -6.9298,  -2.7600],\n",
      "         [ -6.4409,  -6.3462,  -6.3811,  ...,  -6.5330,  -6.1367,  -3.1560],\n",
      "         ...,\n",
      "         [ -6.8504,  -6.7884,  -6.9048,  ...,  -6.7711,  -6.7263,  -3.1143],\n",
      "         [ -6.9111,  -6.8288,  -6.9791,  ...,  -6.8707,  -6.8805,  -3.4264],\n",
      "         [ -6.7021,  -6.6376,  -6.7074,  ...,  -6.6399,  -6.8067,  -2.8072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8970,  -6.8833,  -6.8969,  ...,  -6.1358,  -6.1907,  -4.0084],\n",
      "         [ -9.5045,  -9.7060,  -9.6244,  ...,  -8.8784,  -8.1732,  -3.5268],\n",
      "         [ -7.6730,  -7.8621,  -7.7168,  ...,  -7.8393,  -6.0851,  -6.3071],\n",
      "         ...,\n",
      "         [-12.1040, -11.8517, -12.1974,  ...,  -8.3924,  -9.4185,  -3.5327],\n",
      "         [ -6.8123,  -6.9258,  -6.7035,  ...,  -5.8882,  -5.8632,  -4.1312],\n",
      "         [ -6.5516,  -6.6994,  -6.5805,  ...,  -5.7104,  -6.0730,  -4.6308]],\n",
      "\n",
      "        [[ -7.0884,  -7.0309,  -6.9955,  ...,  -6.2617,  -6.4718,  -3.9800],\n",
      "         [-12.9209, -12.8482, -13.0601,  ..., -11.8914,  -9.6012, -12.5810],\n",
      "         [ -9.5813, -10.1694, -10.0621,  ...,  -9.2841,  -8.7257,  -8.1344],\n",
      "         ...,\n",
      "         [ -4.5889,  -4.5356,  -4.1407,  ...,  -5.6920,  -5.6680,  -0.0323],\n",
      "         [ -6.3958,  -6.4226,  -6.5896,  ...,  -6.0332,  -6.7969,  -1.8506],\n",
      "         [-13.4972, -12.8499, -12.9793,  ..., -11.4355, -11.3040, -10.7677]],\n",
      "\n",
      "        [[ -6.0763,  -6.3146,  -6.1159,  ...,  -6.1772,  -6.2606,  -3.4946],\n",
      "         [ -8.8428,  -8.5645,  -8.5811,  ...,  -6.2560,  -6.8476,  -9.3351],\n",
      "         [ -6.4293,  -6.1713,  -6.2689,  ...,  -6.5113,  -6.9315,  -3.0790],\n",
      "         ...,\n",
      "         [ -7.0994,  -6.8503,  -7.0480,  ...,  -7.3541,  -7.2387,  -0.8642],\n",
      "         [ -6.8904,  -6.7963,  -6.7537,  ...,  -7.3333,  -7.6262,  -1.9283],\n",
      "         [ -6.4079,  -6.2439,  -6.0845,  ...,  -6.7287,  -7.0636,  -3.1167]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.483926296234131\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.4223, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5247,  -6.5308,  -6.5534,  ...,  -5.9467,  -5.8084,  -3.8645],\n",
      "         [ -9.1937,  -9.1016,  -8.9891,  ...,  -8.4083,  -8.3720,  -5.8424],\n",
      "         [ -4.2359,  -4.2404,  -4.1713,  ...,  -4.7601,  -3.9029,  -3.1245],\n",
      "         ...,\n",
      "         [ -7.7647,  -7.6551,  -7.6884,  ...,  -7.2860,  -7.5727,  -4.4653],\n",
      "         [ -6.7440,  -6.6784,  -6.6848,  ...,  -6.3914,  -6.4824,  -5.2396],\n",
      "         [ -6.6329,  -6.5669,  -6.5700,  ...,  -6.3760,  -6.2549,  -4.5665]],\n",
      "\n",
      "        [[ -6.9896,  -6.9704,  -6.9325,  ...,  -6.3865,  -6.2451,  -4.2233],\n",
      "         [ -9.2653,  -9.1847,  -9.1243,  ..., -10.0294,  -8.2896,  -5.2229],\n",
      "         [ -9.5954,  -9.6900,  -9.5575,  ..., -10.4071,  -8.3560,  -7.6564],\n",
      "         ...,\n",
      "         [ -7.4355,  -7.4458,  -7.4285,  ...,  -7.6944,  -7.3116,  -3.8546],\n",
      "         [ -7.0992,  -7.1163,  -7.0899,  ...,  -7.7375,  -6.9863,  -4.0965],\n",
      "         [ -7.6490,  -7.5853,  -7.5489,  ...,  -7.8928,  -7.3006,  -4.8161]],\n",
      "\n",
      "        [[ -6.5733,  -6.5635,  -6.4956,  ...,  -5.9666,  -5.8814,  -3.9321],\n",
      "         [ -8.1165,  -7.8895,  -7.8314,  ...,  -8.0894,  -6.9761,  -9.3584],\n",
      "         [ -5.2993,  -5.8240,  -5.4712,  ...,  -5.8855,  -4.2219,  -6.2641],\n",
      "         ...,\n",
      "         [-11.6691, -11.2172, -11.6565,  ..., -12.1050,  -9.2567, -11.8977],\n",
      "         [ -6.3057,  -6.2271,  -6.1780,  ...,  -6.4858,  -5.4868,  -5.8295],\n",
      "         [ -7.9737,  -7.4513,  -7.6241,  ...,  -6.6515,  -5.8880,  -4.8014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8593,  -6.8384,  -6.8439,  ...,  -6.4038,  -6.0885,  -4.1172],\n",
      "         [ -7.2621,  -7.3039,  -7.2968,  ...,  -7.8359,  -7.3021,  -2.8415],\n",
      "         [ -7.5458,  -7.6299,  -7.6378,  ...,  -8.2146,  -7.3507,  -3.7173],\n",
      "         ...,\n",
      "         [ -6.8377,  -6.8544,  -6.8638,  ...,  -6.8980,  -6.5291,  -2.9658],\n",
      "         [ -6.9054,  -6.8833,  -6.9264,  ...,  -6.9338,  -7.1532,  -2.2822],\n",
      "         [ -6.9274,  -7.0031,  -6.9806,  ...,  -6.6257,  -6.7968,  -2.5277]],\n",
      "\n",
      "        [[ -6.6661,  -6.5979,  -6.6349,  ...,  -5.9524,  -6.1805,  -3.5176],\n",
      "         [-12.6004, -12.7111, -12.9988,  ..., -10.0666, -10.2430,  -9.7936],\n",
      "         [ -4.5399,  -4.2940,  -4.5231,  ...,  -4.5473,  -6.0362,  -2.6048],\n",
      "         ...,\n",
      "         [ -5.7927,  -5.6484,  -5.7951,  ...,  -5.6611,  -6.9281,  -1.8968],\n",
      "         [ -5.1529,  -5.0078,  -5.1149,  ...,  -5.5532,  -6.4811,  -0.8374],\n",
      "         [ -5.2791,  -5.2199,  -5.3073,  ...,  -4.9831,  -6.1444,  -1.5681]],\n",
      "\n",
      "        [[ -6.7485,  -6.7284,  -6.7006,  ...,  -6.1454,  -5.8915,  -3.9840],\n",
      "         [ -8.5515,  -8.4402,  -8.2344,  ...,  -8.0090,  -9.2219,  -2.9492],\n",
      "         [-11.7543, -11.2549, -11.4166,  ..., -11.2888,  -9.5549,  -6.3547],\n",
      "         ...,\n",
      "         [ -7.4418,  -7.6137,  -7.4286,  ...,  -6.4453,  -6.3132,  -4.3491],\n",
      "         [ -8.4274,  -8.3322,  -8.2564,  ...,  -8.1099,  -7.8247,  -4.7860],\n",
      "         [ -9.2192,  -8.5462,  -8.7176,  ...,  -6.5195,  -7.3159,  -4.5292]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.4223060607910156\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7163, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3557,  -6.4116,  -6.4196,  ...,  -5.8057,  -5.7534,  -3.7886],\n",
      "         [ -8.6445,  -8.4649,  -8.7936,  ...,  -8.1985,  -7.1338,  -5.2873],\n",
      "         [ -7.7498,  -7.5165,  -7.3567,  ...,  -6.2746,  -4.8852, -10.4131],\n",
      "         ...,\n",
      "         [ -5.7733,  -5.7057,  -5.6895,  ...,  -6.1547,  -5.8667,  -2.4570],\n",
      "         [ -7.4926,  -7.1290,  -7.1876,  ...,  -7.0725,  -7.0514,  -4.7563],\n",
      "         [ -7.2590,  -7.0337,  -7.0987,  ...,  -7.2108,  -7.0655,  -4.0006]],\n",
      "\n",
      "        [[ -7.0642,  -7.0370,  -7.0038,  ...,  -6.5808,  -6.3277,  -4.0050],\n",
      "         [ -8.7166,  -8.6597,  -8.6919,  ...,  -9.0813,  -8.3233,  -5.0325],\n",
      "         [ -8.7308,  -8.7059,  -8.6861,  ...,  -9.0465,  -8.7587,  -3.6543],\n",
      "         ...,\n",
      "         [ -7.5526,  -7.4326,  -7.5101,  ...,  -7.7980,  -7.5366,  -3.4155],\n",
      "         [ -7.0442,  -7.0256,  -7.0408,  ...,  -7.4093,  -7.3538,  -3.1097],\n",
      "         [ -7.5595,  -7.4035,  -7.5044,  ...,  -7.4702,  -7.3668,  -3.5615]],\n",
      "\n",
      "        [[ -5.4990,  -5.6016,  -5.3044,  ...,  -5.8705,  -6.0004,  -5.8965],\n",
      "         [-11.8156, -11.6451, -11.6819,  ...,  -9.5411,  -8.8212, -12.7742],\n",
      "         [ -6.7723,  -6.7248,  -6.8736,  ...,  -7.6519,  -7.3742,  -3.0458],\n",
      "         ...,\n",
      "         [ -7.6677,  -7.6970,  -7.5720,  ...,  -8.4087,  -8.4960,  -2.0083],\n",
      "         [ -6.3328,  -6.4080,  -6.3936,  ...,  -7.2470,  -7.5077,  -2.0454],\n",
      "         [ -5.8408,  -5.9134,  -5.9481,  ...,  -7.1990,  -6.9201,  -2.7350]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.9024,  -9.7495,  -9.8152,  ...,  -8.6765,  -9.3118,  -7.8466],\n",
      "         [-11.0871, -10.9924, -10.9431,  ...,  -9.4302,  -7.2559,  -8.8088],\n",
      "         [ -5.8862,  -5.9692,  -6.0279,  ...,  -6.4170,  -7.1756,  -3.7594],\n",
      "         ...,\n",
      "         [ -6.5197,  -6.3996,  -6.5237,  ...,  -7.1081,  -7.3383,  -3.7198],\n",
      "         [ -5.7810,  -5.8345,  -5.8788,  ...,  -6.6708,  -6.7012,  -3.3614],\n",
      "         [ -6.6960,  -6.5512,  -6.6755,  ...,  -6.9232,  -7.6386,  -3.9205]],\n",
      "\n",
      "        [[ -8.3625,  -8.1236,  -8.2448,  ...,  -7.4656,  -7.5332,  -4.5643],\n",
      "         [ -6.5885,  -6.2191,  -6.1624,  ...,  -3.9831,  -5.9505,  -5.2936],\n",
      "         [ -6.6921,  -6.4475,  -6.6961,  ...,  -7.1438,  -7.8229,  -4.5968],\n",
      "         ...,\n",
      "         [ -6.3748,  -6.1070,  -6.3019,  ...,  -6.1718,  -7.4644,  -3.3324],\n",
      "         [ -7.0222,  -6.9315,  -6.8972,  ...,  -7.2276,  -8.3222,  -3.2581],\n",
      "         [ -5.4964,  -5.3910,  -5.5694,  ...,  -5.8124,  -7.7233,  -3.6967]],\n",
      "\n",
      "        [[ -7.7516,  -7.6544,  -7.6136,  ...,  -6.8823,  -7.1148,  -4.5930],\n",
      "         [ -6.0348,  -6.0616,  -5.9699,  ...,  -4.9533,  -4.6846,  -4.2859],\n",
      "         [ -5.9657,  -6.0348,  -6.0718,  ...,  -6.9332,  -8.0884,  -3.2833],\n",
      "         ...,\n",
      "         [ -6.6509,  -6.4767,  -6.6765,  ...,  -7.7428,  -8.4958,  -2.7994],\n",
      "         [ -5.9427,  -5.7438,  -5.7822,  ...,  -6.1547,  -8.2219,  -1.4786],\n",
      "         [ -5.9799,  -5.8489,  -6.0078,  ...,  -6.4940,  -8.3584,  -1.1171]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.716333031654358\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9028, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8312,  -6.7717,  -6.8234,  ...,  -6.1924,  -6.0918,  -4.0455],\n",
      "         [ -6.7122,  -6.6111,  -6.6437,  ...,  -6.4712,  -6.7176,  -2.6557],\n",
      "         [ -8.5482,  -8.4238,  -8.4318,  ...,  -8.2213,  -7.7505,  -3.3884],\n",
      "         ...,\n",
      "         [ -6.0632,  -5.9531,  -6.0146,  ...,  -6.1690,  -6.2707,  -2.2930],\n",
      "         [ -6.9453,  -6.7905,  -6.8284,  ...,  -6.8620,  -6.8992,  -2.5603],\n",
      "         [ -7.1265,  -7.0343,  -7.0927,  ...,  -6.8526,  -6.8764,  -3.4058]],\n",
      "\n",
      "        [[ -6.5549,  -6.5145,  -6.5108,  ...,  -5.9444,  -5.7345,  -3.8812],\n",
      "         [ -5.7552,  -5.8820,  -6.0465,  ...,  -6.3572,  -5.9166,  -3.2207],\n",
      "         [ -6.8807,  -6.9347,  -6.8267,  ...,  -6.7301,  -6.3806,  -1.6175],\n",
      "         ...,\n",
      "         [ -5.1972,  -5.2308,  -5.3748,  ...,  -5.6982,  -5.3912,  -3.0569],\n",
      "         [ -5.6045,  -5.6231,  -5.6842,  ...,  -5.5540,  -5.7744,  -2.8723],\n",
      "         [ -5.9149,  -5.9598,  -6.0666,  ...,  -6.0840,  -5.9528,  -3.9804]],\n",
      "\n",
      "        [[ -6.3098,  -6.2210,  -6.2659,  ...,  -5.6205,  -5.5073,  -3.8034],\n",
      "         [-11.8043, -11.4844, -10.9204,  ...,  -7.7907,  -9.3660,  -7.0850],\n",
      "         [ -6.1506,  -5.9770,  -6.0766,  ...,  -6.0535,  -7.9034,  -1.7042],\n",
      "         ...,\n",
      "         [ -6.1243,  -5.7955,  -5.8825,  ...,  -6.2791,  -7.8630,  -2.7510],\n",
      "         [ -5.6181,  -5.3445,  -5.5847,  ...,  -6.2642,  -7.2877,  -2.7875],\n",
      "         [ -5.0391,  -4.8333,  -4.9521,  ...,  -5.2916,  -6.4801,  -2.9055]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2248,  -7.2528,  -7.1877,  ...,  -6.6007,  -6.4026,  -4.3685],\n",
      "         [ -8.3720,  -8.5833,  -8.5403,  ...,  -6.9798,  -6.3957,  -7.8028],\n",
      "         [-10.4067, -10.2461, -10.0440,  ...,  -9.7663,  -9.4288,  -8.1295],\n",
      "         ...,\n",
      "         [ -6.1175,  -6.2629,  -6.0226,  ...,  -5.0365,  -5.6616,  -4.8403],\n",
      "         [ -5.3931,  -5.4820,  -5.3919,  ...,  -4.7687,  -5.3513,  -5.8618],\n",
      "         [ -8.9419,  -9.2711,  -9.0768,  ...,  -7.5414,  -7.5110,  -4.4044]],\n",
      "\n",
      "        [[ -6.7303,  -6.7174,  -6.6854,  ...,  -6.2515,  -5.9344,  -4.7913],\n",
      "         [ -9.2881,  -9.2149,  -9.2957,  ...,  -9.4128,  -8.0144,  -9.4293],\n",
      "         [ -7.6842,  -8.1448,  -7.8748,  ...,  -9.0201,  -6.7324,  -8.8887],\n",
      "         ...,\n",
      "         [ -9.7353,  -9.7567,  -9.6481,  ...,  -9.8690,  -8.6224,  -7.8032],\n",
      "         [ -7.3590,  -7.4733,  -7.4319,  ...,  -7.1711,  -7.7480,  -6.1455],\n",
      "         [ -8.7850,  -8.7639,  -8.8812,  ...,  -8.1382,  -8.3778,  -5.6289]],\n",
      "\n",
      "        [[ -7.3876,  -7.3249,  -7.3297,  ...,  -6.5093,  -7.6963,  -2.2284],\n",
      "         [-12.1578, -11.9571, -11.9607,  ..., -10.4308,  -9.7060,  -8.1671],\n",
      "         [ -6.2471,  -6.0172,  -6.1684,  ...,  -6.7475,  -7.5193,  -1.1380],\n",
      "         ...,\n",
      "         [ -6.2561,  -6.0253,  -6.1313,  ...,  -6.7482,  -7.8948,  -2.3081],\n",
      "         [ -5.8118,  -5.6250,  -5.6660,  ...,  -6.8423,  -7.1364,  -2.8122],\n",
      "         [ -6.8771,  -6.7985,  -6.8740,  ...,  -7.7219,  -8.0472,  -2.6395]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.9027756452560425\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.4269, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7227,  -6.6842,  -6.7089,  ...,  -6.2147,  -5.9909,  -3.9428],\n",
      "         [ -7.3026,  -7.2827,  -7.3573,  ...,  -7.9416,  -7.4551,  -4.1264],\n",
      "         [ -6.6337,  -6.7245,  -6.7320,  ...,  -6.8205,  -5.9896,  -4.9962],\n",
      "         ...,\n",
      "         [ -7.3906,  -7.4563,  -7.5485,  ...,  -8.2652,  -7.2769,  -3.8001],\n",
      "         [ -7.3041,  -7.4664,  -7.4385,  ...,  -7.8625,  -7.6624,  -3.9077],\n",
      "         [ -7.1178,  -7.2463,  -7.1217,  ...,  -7.7496,  -7.1163,  -3.5825]],\n",
      "\n",
      "        [[ -6.3944,  -6.3291,  -6.3851,  ...,  -5.7365,  -5.5761,  -3.5749],\n",
      "         [ -7.6295,  -7.4820,  -7.6394,  ...,  -5.0661,  -6.3690,  -6.5318],\n",
      "         [ -6.1432,  -5.9397,  -6.1994,  ...,  -6.9964,  -7.8290,  -1.9052],\n",
      "         ...,\n",
      "         [ -6.8416,  -6.6075,  -6.7162,  ...,  -7.2334,  -8.0024,  -2.8107],\n",
      "         [ -6.2710,  -5.9924,  -6.2234,  ...,  -6.8562,  -7.8858,  -1.6987],\n",
      "         [ -6.0354,  -5.8479,  -5.9651,  ...,  -6.6331,  -7.7641,  -2.1260]],\n",
      "\n",
      "        [[ -6.7725,  -6.7500,  -6.7557,  ...,  -6.3590,  -6.1358,  -4.0569],\n",
      "         [ -8.5432,  -8.5379,  -8.5304,  ...,  -9.6594,  -8.6472,  -3.8787],\n",
      "         [ -6.5796,  -6.6244,  -6.5946,  ...,  -7.1830,  -6.7298,  -3.0912],\n",
      "         ...,\n",
      "         [ -6.4889,  -6.5131,  -6.5359,  ...,  -6.6133,  -6.5890,  -3.0815],\n",
      "         [ -6.1053,  -6.1050,  -6.1167,  ...,  -6.9693,  -6.3969,  -3.1754],\n",
      "         [ -6.4311,  -6.3499,  -6.3947,  ...,  -6.9235,  -6.4342,  -2.7947]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0821,  -7.0400,  -7.0138,  ...,  -6.6321,  -6.4083,  -4.4085],\n",
      "         [ -8.9274,  -8.9617,  -8.8776,  ...,  -9.8027,  -8.5643,  -4.8453],\n",
      "         [ -8.5461,  -8.4321,  -8.4831,  ...,  -9.2945,  -8.2187,  -5.7555],\n",
      "         ...,\n",
      "         [ -6.6308,  -6.6222,  -6.7108,  ...,  -7.5257,  -6.6593,  -4.0452],\n",
      "         [ -6.1902,  -6.2721,  -6.2868,  ...,  -7.0625,  -6.5004,  -4.2510],\n",
      "         [ -6.4856,  -6.6066,  -6.6257,  ...,  -7.5129,  -6.5175,  -4.2313]],\n",
      "\n",
      "        [[ -7.3541,  -7.2964,  -7.3239,  ...,  -6.6312,  -6.3335,  -4.2711],\n",
      "         [ -3.1937,  -3.3977,  -3.0551,  ...,  -3.5732,  -2.6601,  -2.3187],\n",
      "         [ -7.4303,  -8.2107,  -8.0126,  ...,  -6.3843,  -5.5020,  -2.1232],\n",
      "         ...,\n",
      "         [ -3.1595,  -3.1709,  -2.9365,  ...,  -3.1084,  -2.5672,  -0.8645],\n",
      "         [ -3.9555,  -4.3160,  -4.1494,  ...,  -4.4415,  -3.8796,  -2.4277],\n",
      "         [ -5.0233,  -5.0026,  -4.9439,  ...,  -5.1371,  -4.8879,   0.0155]],\n",
      "\n",
      "        [[ -6.8589,  -6.8649,  -6.7321,  ...,  -6.0460,  -6.0547,  -4.0333],\n",
      "         [ -9.8919,  -9.8363, -10.1105,  ...,  -7.6938,  -9.2796, -11.5452],\n",
      "         [ -6.8843,  -6.6907,  -7.2927,  ...,  -7.1826,  -6.9775,  -5.1878],\n",
      "         ...,\n",
      "         [ -7.4248,  -7.4026,  -7.4553,  ...,  -7.9808,  -7.7490,  -5.6836],\n",
      "         [ -7.6678,  -7.6247,  -7.8529,  ...,  -7.3221,  -7.6798,  -4.3871],\n",
      "         [ -8.0617,  -8.0587,  -8.1334,  ...,  -7.9555,  -7.7661,  -6.6876]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.426943302154541\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7913, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9672,  -7.0071,  -6.9491,  ...,  -6.1951,  -6.1309,  -4.2207],\n",
      "         [-13.2833, -13.2936, -13.5310,  ..., -11.7226, -10.8031, -10.0424],\n",
      "         [ -5.9090,  -5.9384,  -6.2336,  ...,  -5.4153,  -4.9586,  -5.7193],\n",
      "         ...,\n",
      "         [ -8.3143,  -8.3566,  -8.5154,  ...,  -7.4923,  -8.4066,  -6.4214],\n",
      "         [ -8.2767,  -8.3914,  -8.3084,  ...,  -6.5488,  -7.8439,  -6.6853],\n",
      "         [ -7.5618,  -7.7908,  -7.8609,  ...,  -7.0505,  -7.5557,  -5.7067]],\n",
      "\n",
      "        [[ -6.9008,  -6.8578,  -6.8442,  ...,  -6.5737,  -6.2699,  -3.9795],\n",
      "         [ -7.8976,  -7.8423,  -7.8913,  ...,  -8.4180,  -7.7711,  -3.5265],\n",
      "         [ -6.7545,  -6.8135,  -6.6749,  ...,  -7.2856,  -6.8391,  -2.7558],\n",
      "         ...,\n",
      "         [ -7.1807,  -7.2093,  -7.1956,  ...,  -7.5425,  -6.9902,  -2.4702],\n",
      "         [ -7.6584,  -7.6088,  -7.5868,  ...,  -7.7326,  -7.4503,  -2.7560],\n",
      "         [ -7.1447,  -7.0554,  -7.1085,  ...,  -7.5073,  -7.0787,  -2.2655]],\n",
      "\n",
      "        [[ -6.4520,  -6.4012,  -6.4329,  ...,  -5.7591,  -5.5949,  -3.8565],\n",
      "         [-10.5160, -10.0996, -10.2474,  ...,  -7.9157,  -7.4232,  -7.5925],\n",
      "         [ -6.6143,  -6.6691,  -6.6324,  ...,  -7.0088,  -7.9318,  -2.6462],\n",
      "         ...,\n",
      "         [ -6.5127,  -6.3392,  -6.4260,  ...,  -6.2234,  -7.1965,  -1.8025],\n",
      "         [ -6.8008,  -6.7180,  -6.7273,  ...,  -6.3806,  -7.1239,  -2.5152],\n",
      "         [ -6.1537,  -5.9816,  -5.9559,  ...,  -6.0192,  -7.3021,  -2.2801]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2831,  -6.2041,  -6.2749,  ...,  -5.6363,  -5.5575,  -3.5077],\n",
      "         [-10.8555, -10.6474, -10.6820,  ...,  -7.7085,  -7.8081,  -8.4465],\n",
      "         [ -4.5782,  -4.7312,  -4.7279,  ...,  -5.5320,  -6.1620,  -2.4944],\n",
      "         ...,\n",
      "         [ -6.1179,  -6.0328,  -6.1087,  ...,  -6.3139,  -6.9797,  -2.5301],\n",
      "         [ -6.7249,  -6.6268,  -6.8907,  ...,  -7.2476,  -7.6460,  -2.1332],\n",
      "         [ -6.7568,  -6.7677,  -6.8854,  ...,  -7.4740,  -7.9069,  -3.5863]],\n",
      "\n",
      "        [[ -6.9066,  -6.9145,  -6.8541,  ...,  -6.0757,  -6.0171,  -3.9766],\n",
      "         [-13.3965, -12.9575, -13.5414,  ..., -10.6649, -12.1767,  -7.8889],\n",
      "         [ -7.9025,  -7.8501,  -8.1162,  ...,  -6.5628,  -8.0762,  -5.5204],\n",
      "         ...,\n",
      "         [ -7.2893,  -7.1973,  -7.3701,  ...,  -7.6562,  -6.2394,  -4.0030],\n",
      "         [ -8.0908,  -8.0095,  -8.1156,  ...,  -8.0889,  -7.5891,  -4.1469],\n",
      "         [ -7.5606,  -7.5373,  -7.6194,  ...,  -7.7682,  -6.6611,  -4.7655]],\n",
      "\n",
      "        [[ -7.1264,  -7.1535,  -7.1133,  ...,  -6.4256,  -6.3021,  -4.2186],\n",
      "         [-12.2730, -12.3527, -12.3456,  ..., -11.1233, -10.0140,  -8.4890],\n",
      "         [ -9.1596,  -9.4545,  -8.7843,  ...,  -8.4928,  -6.4932,  -7.1610],\n",
      "         ...,\n",
      "         [ -6.7101,  -6.7292,  -6.8340,  ...,  -7.0685,  -5.8270,  -5.3488],\n",
      "         [ -7.8602,  -8.0406,  -7.9902,  ...,  -8.8165,  -7.4714,  -6.7050],\n",
      "         [ -7.9683,  -8.0646,  -8.0266,  ...,  -8.6427,  -7.3970,  -7.2064]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.7913066148757935\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9285, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2490,  -7.2439,  -7.2040,  ...,  -6.9731,  -6.5682,  -4.2393],\n",
      "         [ -7.5099,  -7.7407,  -7.5032,  ...,  -7.0846,  -6.5295,  -7.5830],\n",
      "         [-11.3523, -11.5645, -11.2150,  ...,  -9.9685,  -9.9965,  -7.1968],\n",
      "         ...,\n",
      "         [ -5.3882,  -5.6689,  -5.4327,  ...,  -5.5808,  -7.1920,  -5.9432],\n",
      "         [-10.3327, -10.4450, -10.1418,  ..., -10.0699,  -9.8611,  -8.6701],\n",
      "         [-10.8758, -10.4964, -10.7377,  ...,  -9.5281, -10.4220,  -6.3706]],\n",
      "\n",
      "        [[ -6.9377,  -6.8631,  -6.8557,  ...,  -6.2067,  -5.9262,  -4.2125],\n",
      "         [ -8.6186,  -8.4503,  -8.5675,  ...,  -8.5392,  -8.0998,  -4.0520],\n",
      "         [ -8.3583,  -8.0274,  -8.2135,  ...,  -9.0469,  -7.8176,  -3.9284],\n",
      "         ...,\n",
      "         [ -7.2318,  -7.0942,  -7.1199,  ...,  -7.1567,  -6.7354,  -2.8319],\n",
      "         [ -7.1692,  -7.0127,  -7.2028,  ...,  -7.2220,  -7.2285,  -3.3626],\n",
      "         [ -7.8342,  -7.5981,  -7.7662,  ...,  -7.8653,  -7.5921,  -3.9656]],\n",
      "\n",
      "        [[ -6.6677,  -6.6391,  -6.6294,  ...,  -6.4422,  -5.9811,  -3.5326],\n",
      "         [ -8.7802,  -8.6858,  -8.8136,  ..., -10.0765,  -8.6097,  -2.6413],\n",
      "         [ -6.2887,  -6.2330,  -6.2994,  ...,  -7.2485,  -5.6142,  -0.6084],\n",
      "         ...,\n",
      "         [ -5.6435,  -5.6751,  -5.6531,  ...,  -6.3378,  -5.5928,  -0.3579],\n",
      "         [ -6.5586,  -6.5621,  -6.5268,  ...,  -7.4412,  -6.9173,  -1.1730],\n",
      "         [ -6.3099,  -6.3713,  -6.3849,  ...,  -7.3111,  -6.8582,  -0.7530]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8382,  -6.8120,  -6.8280,  ...,  -6.2735,  -6.1237,  -3.9153],\n",
      "         [ -8.7835,  -8.6814,  -8.7283,  ...,  -9.4454,  -8.0862,  -4.0951],\n",
      "         [ -8.2897,  -8.2592,  -8.1669,  ...,  -8.6569,  -7.6673,  -3.9115],\n",
      "         ...,\n",
      "         [ -7.4607,  -7.3799,  -7.4212,  ...,  -7.6847,  -6.9269,  -3.0406],\n",
      "         [ -7.5592,  -7.5047,  -7.5616,  ...,  -8.0177,  -7.2510,  -3.3889],\n",
      "         [ -7.3669,  -7.3079,  -7.3155,  ...,  -7.4332,  -7.0931,  -2.8224]],\n",
      "\n",
      "        [[ -6.7656,  -6.6966,  -6.7291,  ...,  -6.0749,  -5.8996,  -3.8517],\n",
      "         [ -6.3939,  -6.5494,  -6.6146,  ...,  -6.9222,  -7.5494,  -3.1878],\n",
      "         [ -6.2513,  -6.4738,  -6.4097,  ...,  -6.4054,  -6.6018,  -2.8374],\n",
      "         ...,\n",
      "         [ -6.7409,  -6.7693,  -6.8675,  ...,  -6.9489,  -6.9709,  -2.6072],\n",
      "         [ -6.6825,  -6.7922,  -6.9131,  ...,  -6.6818,  -7.0616,  -3.0862],\n",
      "         [ -6.9253,  -6.9885,  -7.0746,  ...,  -6.4026,  -6.9926,  -3.1279]],\n",
      "\n",
      "        [[ -8.5486,  -8.4259,  -8.3751,  ...,  -7.6554,  -7.8700,  -4.6849],\n",
      "         [-12.3541, -11.5735, -11.8500,  ...,  -8.5182,  -9.1764,  -9.8703],\n",
      "         [ -6.3879,  -6.1626,  -6.2785,  ...,  -6.7578,  -7.3638,  -2.3043],\n",
      "         ...,\n",
      "         [ -6.2786,  -6.1355,  -6.1763,  ...,  -6.5831,  -7.9312,  -2.2577],\n",
      "         [ -6.2690,  -6.1038,  -6.2117,  ...,  -6.5855,  -7.3230,  -2.2947],\n",
      "         [ -6.3436,  -6.2296,  -6.3411,  ...,  -6.1088,  -6.7755,  -1.2360]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.928526759147644\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1312, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.0271,  -8.0295,  -8.0174,  ...,  -6.9167,  -6.8236,  -4.1760],\n",
      "         [ -8.9339,  -8.7893,  -9.2488,  ...,  -8.8180,  -6.0310,  -5.0925],\n",
      "         [ -6.0930,  -5.7578,  -6.0250,  ...,  -5.5297,  -5.0800,  -2.8783],\n",
      "         ...,\n",
      "         [ -6.8789,  -6.7168,  -6.9064,  ...,  -6.1000,  -5.9514,  -1.0981],\n",
      "         [ -7.0739,  -7.0937,  -6.8121,  ...,  -6.7091,  -7.0646,  -1.0913],\n",
      "         [ -7.6064,  -7.7585,  -7.5225,  ...,  -7.2179,  -7.0208,  -1.4957]],\n",
      "\n",
      "        [[ -6.2979,  -6.2645,  -6.2410,  ...,  -5.6398,  -5.4607,  -3.8239],\n",
      "         [ -9.0467,  -9.0939,  -9.0014,  ...,  -7.9950,  -7.9121,  -7.6870],\n",
      "         [ -3.0169,  -3.1230,  -3.0333,  ...,  -2.1051,  -2.6364,  -3.3109],\n",
      "         ...,\n",
      "         [ -6.3720,  -6.4442,  -6.3886,  ...,  -5.8146,  -7.1816,  -3.9387],\n",
      "         [ -5.4722,  -5.4306,  -5.4474,  ...,  -5.0000,  -6.6433,  -4.1728],\n",
      "         [ -6.9541,  -7.1215,  -6.8484,  ...,  -6.4910,  -7.4451,  -5.2382]],\n",
      "\n",
      "        [[ -8.7992,  -8.7304,  -8.8119,  ...,  -8.8387,  -9.1351,  -4.5663],\n",
      "         [ -9.4172,  -9.0658,  -8.8398,  ...,  -6.0084,  -7.4039,  -8.7121],\n",
      "         [ -6.5777,  -6.3407,  -6.5111,  ...,  -7.3398,  -8.3069,  -3.8348],\n",
      "         ...,\n",
      "         [ -5.9811,  -5.7851,  -5.8624,  ...,  -6.6969,  -7.8748,  -2.8590],\n",
      "         [ -5.9350,  -5.6505,  -5.6668,  ...,  -6.0207,  -7.4179,  -2.8968],\n",
      "         [ -5.8151,  -5.6123,  -5.6216,  ...,  -6.4107,  -7.8541,  -3.2252]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6245,  -6.6554,  -6.5946,  ...,  -6.1482,  -5.9465,  -3.7677],\n",
      "         [-10.3679, -10.5002, -10.2567,  ...,  -8.4200, -10.5275,  -7.9460],\n",
      "         [-14.7355, -14.5478, -14.2103,  ..., -13.1711, -12.5023,  -8.6055],\n",
      "         ...,\n",
      "         [ -6.8546,  -6.8158,  -7.1368,  ...,  -6.1405,  -6.7581,  -4.4133],\n",
      "         [ -7.6508,  -8.1491,  -7.8748,  ...,  -7.7004,  -8.1464,  -4.4026],\n",
      "         [-12.3247, -12.0167, -12.3945,  ..., -10.4902, -11.0589,  -4.8783]],\n",
      "\n",
      "        [[ -5.1349,  -5.3854,  -5.1592,  ...,  -5.8167,  -4.9949,  -5.9021],\n",
      "         [-10.5415, -10.0210, -10.4683,  ...,  -7.6741,  -8.6649,  -7.9983],\n",
      "         [ -6.7456,  -6.8394,  -6.8766,  ...,  -7.7768,  -7.5397,  -3.7466],\n",
      "         ...,\n",
      "         [ -6.2606,  -6.3870,  -6.3951,  ...,  -7.6923,  -7.0849,  -3.0937],\n",
      "         [ -6.8025,  -6.6496,  -6.6862,  ...,  -7.6154,  -7.2578,  -2.2955],\n",
      "         [ -5.9612,  -5.8402,  -6.0604,  ...,  -6.6841,  -6.9301,  -2.5016]],\n",
      "\n",
      "        [[ -8.9755,  -8.6294,  -8.8507,  ...,  -8.0670,  -8.6705,  -5.3316],\n",
      "         [-10.4031, -10.2755, -10.1130,  ...,  -8.1825,  -9.2923,  -9.6355],\n",
      "         [ -5.9596,  -5.8274,  -5.9293,  ...,  -6.2162,  -7.7441,  -2.6358],\n",
      "         ...,\n",
      "         [ -6.7635,  -6.4337,  -6.6068,  ...,  -7.4915,  -7.7205,  -3.3701],\n",
      "         [ -6.9622,  -6.6425,  -6.8000,  ...,  -7.7703,  -7.8510,  -3.4988],\n",
      "         [ -5.9987,  -5.7503,  -5.8996,  ...,  -6.6258,  -7.2786,  -3.5508]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.131155252456665\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3572, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6726,  -6.6179,  -6.6502,  ...,  -6.0120,  -5.8889,  -4.0293],\n",
      "         [ -6.7918,  -6.5717,  -6.8750,  ...,  -5.6925,  -5.5448,  -2.5195],\n",
      "         [ -5.5721,  -5.5190,  -5.6996,  ...,  -6.2586,  -7.2142,  -2.2971],\n",
      "         ...,\n",
      "         [ -5.8444,  -5.5808,  -5.7633,  ...,  -5.9396,  -7.0674,  -1.2519],\n",
      "         [ -5.9770,  -5.7991,  -5.8916,  ...,  -6.3220,  -7.7562,  -1.8196],\n",
      "         [ -5.9314,  -5.8802,  -5.8455,  ...,  -6.1274,  -7.4883,  -2.4441]],\n",
      "\n",
      "        [[ -7.6741,  -7.5430,  -7.6199,  ...,  -6.6582,  -6.6069,  -4.3957],\n",
      "         [-11.4333, -11.4121, -11.3512,  ...,  -8.6092,  -8.6126,  -7.2130],\n",
      "         [ -6.2256,  -6.1041,  -6.1442,  ...,  -6.7104,  -7.7523,  -2.3015],\n",
      "         ...,\n",
      "         [ -5.2476,  -5.2217,  -5.2315,  ...,  -6.1306,  -6.2467,  -2.6673],\n",
      "         [ -5.4221,  -5.2875,  -5.4187,  ...,  -5.9011,  -6.5070,  -1.6813],\n",
      "         [ -5.8326,  -5.7599,  -5.6899,  ...,  -5.9316,  -6.7896,  -2.1755]],\n",
      "\n",
      "        [[ -6.9615,  -7.0068,  -6.9874,  ...,  -6.2952,  -6.0612,  -4.1247],\n",
      "         [ -6.6696,  -6.5793,  -6.6816,  ...,  -6.9499,  -6.2621,  -2.0880],\n",
      "         [ -6.5727,  -6.6393,  -6.6678,  ...,  -7.3336,  -6.9677,  -4.7796],\n",
      "         ...,\n",
      "         [ -5.9301,  -5.8876,  -5.9203,  ...,  -6.5197,  -5.3095,  -2.6928],\n",
      "         [-14.0982, -13.8829, -14.0730,  ..., -11.6757, -10.0531,  -9.6463],\n",
      "         [-13.3952, -13.2727, -13.3925,  ..., -10.5290, -11.2870,  -6.9408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6598,  -6.6116,  -6.6408,  ...,  -6.1071,  -5.8613,  -4.0370],\n",
      "         [ -7.4728,  -7.4019,  -7.4349,  ...,  -7.1296,  -6.8677,  -4.3838],\n",
      "         [ -6.8361,  -6.8328,  -6.9429,  ...,  -6.6987,  -6.3384,  -4.2768],\n",
      "         ...,\n",
      "         [ -6.7839,  -6.7180,  -6.7934,  ...,  -6.7296,  -6.8848,  -2.9912],\n",
      "         [ -7.1576,  -7.0816,  -7.2254,  ...,  -7.3507,  -6.8824,  -3.6116],\n",
      "         [ -6.9321,  -6.8706,  -6.9628,  ...,  -6.8686,  -6.7023,  -2.9634]],\n",
      "\n",
      "        [[ -6.7843,  -6.7423,  -6.7352,  ...,  -6.1370,  -5.9332,  -3.7211],\n",
      "         [ -7.3552,  -7.1583,  -7.3337,  ...,  -7.3095,  -7.6036,  -2.5356],\n",
      "         [ -7.2199,  -7.0726,  -7.0429,  ...,  -7.1696,  -7.2330,  -2.7838],\n",
      "         ...,\n",
      "         [ -7.1287,  -7.0115,  -7.0978,  ...,  -6.9660,  -7.2293,  -1.2123],\n",
      "         [ -7.0121,  -6.8863,  -6.9599,  ...,  -7.0111,  -7.1351,  -2.0857],\n",
      "         [ -7.1721,  -7.0357,  -7.1509,  ...,  -7.0955,  -7.4137,  -2.6849]],\n",
      "\n",
      "        [[ -6.8112,  -6.7708,  -6.7907,  ...,  -6.6232,  -6.0660,  -4.0471],\n",
      "         [-14.5547, -14.7159, -15.0773,  ..., -13.9593, -11.1255, -19.5685],\n",
      "         [-14.9374, -15.3180, -15.1911,  ..., -13.6127, -11.8379, -16.3156],\n",
      "         ...,\n",
      "         [ -6.7154,  -6.4870,  -6.6249,  ...,  -7.6423,  -6.4280,  -6.6101],\n",
      "         [ -5.9758,  -5.7488,  -5.8328,  ...,  -5.6228,  -5.9665,  -4.5697],\n",
      "         [ -6.3118,  -6.2993,  -6.3667,  ...,  -7.1679,  -6.1361,  -4.7069]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.3571665287017822\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5302, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5819,  -6.5995,  -6.5140,  ...,  -6.3334,  -6.2100,  -3.5934],\n",
      "         [ -5.2453,  -5.3563,  -5.3654,  ...,  -5.4481,  -4.7012,  -3.0437],\n",
      "         [ -1.2156,  -1.4937,  -1.1993,  ...,  -1.3229,  -1.1792,  -4.8749],\n",
      "         ...,\n",
      "         [ -0.3521,  -0.4744,  -0.3483,  ...,  -2.7841,  -0.9531,  -2.4104],\n",
      "         [-14.0245, -14.0549, -14.1770,  ..., -13.0611, -11.3547,  -9.0893],\n",
      "         [-11.1518, -11.4018, -11.1899,  ...,  -8.6970,  -8.4405,  -9.5788]],\n",
      "\n",
      "        [[ -6.9562,  -6.9569,  -6.8940,  ...,  -6.3372,  -6.3702,  -4.6101],\n",
      "         [ -7.7999,  -7.8893,  -8.1092,  ...,  -8.1491,  -7.3610,  -7.4873],\n",
      "         [-16.3182, -16.1528, -16.4099,  ..., -14.8679, -13.3486, -14.9580],\n",
      "         ...,\n",
      "         [ -6.7266,  -6.8326,  -6.7487,  ...,  -7.1001,  -6.4796,  -6.0371],\n",
      "         [ -1.8225,  -1.8877,  -1.9585,  ...,  -3.1940,  -2.7280,  -0.4539],\n",
      "         [ -3.4312,  -3.5299,  -3.4750,  ...,  -4.2495,  -2.9331,  -2.5044]],\n",
      "\n",
      "        [[ -6.6986,  -6.7079,  -6.6526,  ...,  -6.0920,  -5.8512,  -3.9985],\n",
      "         [ -5.3893,  -5.5838,  -5.7289,  ...,  -5.7297,  -5.6665,  -5.8576],\n",
      "         [-11.7212, -11.6621, -11.9446,  ..., -10.5879, -10.3855,  -9.6515],\n",
      "         ...,\n",
      "         [ -7.7074,  -7.8150,  -7.7870,  ...,  -7.0004,  -6.3256,  -9.2042],\n",
      "         [ -7.9131,  -7.9981,  -7.9257,  ...,  -7.1847,  -6.7892,  -7.6962],\n",
      "         [ -8.2555,  -8.3663,  -8.3413,  ...,  -7.5308,  -7.2988,  -8.1297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8411,  -6.8403,  -6.7983,  ...,  -6.1068,  -6.1177,  -4.0293],\n",
      "         [ -7.2919,  -6.9904,  -7.1667,  ...,  -7.9651,  -8.3172,  -2.7384],\n",
      "         [ -7.8510,  -7.9814,  -7.8865,  ...,  -7.4447,  -7.6723,  -6.1554],\n",
      "         ...,\n",
      "         [-13.4826, -13.9569, -13.6314,  ..., -12.5390, -11.5390, -10.9169],\n",
      "         [ -9.9235, -10.2484,  -9.9899,  ..., -11.0558,  -8.9009,  -4.0535],\n",
      "         [-13.6083, -12.9562, -13.1610,  ..., -10.1659, -12.4310,  -8.6265]],\n",
      "\n",
      "        [[ -6.5650,  -6.5408,  -6.5369,  ...,  -5.7683,  -6.1466,  -3.6410],\n",
      "         [ -9.0921,  -8.8328,  -8.9386,  ...,  -5.4911,  -6.1192,  -6.8488],\n",
      "         [ -5.6855,  -5.6444,  -5.6625,  ...,  -5.8647,  -7.6566,  -1.6618],\n",
      "         ...,\n",
      "         [ -6.3550,  -6.2054,  -6.2273,  ...,  -6.0309,  -7.6153,  -2.2447],\n",
      "         [ -5.5049,  -5.4737,  -5.4934,  ...,  -5.5297,  -7.5638,  -0.8755],\n",
      "         [ -6.7806,  -6.6609,  -6.8173,  ...,  -6.7977,  -8.1593,  -0.7289]],\n",
      "\n",
      "        [[ -7.0575,  -7.0661,  -7.0176,  ...,  -6.6039,  -6.2059,  -4.6530],\n",
      "         [-12.2493, -12.0666, -12.2162,  ..., -11.1477,  -9.8697, -11.0441],\n",
      "         [ -8.8449,  -8.3627,  -8.5927,  ...,  -6.9254,  -7.1838,  -8.0089],\n",
      "         ...,\n",
      "         [ -5.6444,  -5.6313,  -5.9028,  ...,  -5.1393,  -5.9366,  -4.9896],\n",
      "         [ -6.6990,  -6.8206,  -6.6791,  ...,  -5.9019,  -6.5200,  -5.6985],\n",
      "         [-12.2917, -11.9955, -12.3491,  ..., -11.0277,  -9.3881,  -9.5405]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.5301971435546875\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6551, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2831,  -7.2061,  -7.2646,  ...,  -6.4394,  -6.3515,  -4.3378],\n",
      "         [-14.5778, -13.9258, -13.9457,  ..., -10.7020, -10.8530,  -9.5273],\n",
      "         [ -5.6862,  -5.7700,  -5.7757,  ...,  -6.4813,  -8.3357,  -2.5063],\n",
      "         ...,\n",
      "         [ -6.7266,  -6.4616,  -6.6644,  ...,  -7.0035,  -8.4748,  -3.6081],\n",
      "         [ -6.3762,  -6.2811,  -6.4547,  ...,  -6.8425,  -8.2811,  -1.3644],\n",
      "         [ -6.3189,  -6.2053,  -6.2971,  ...,  -6.2515,  -7.9400,  -1.9164]],\n",
      "\n",
      "        [[ -6.8179,  -6.8162,  -6.7749,  ...,  -6.2255,  -6.1559,  -3.8699],\n",
      "         [ -8.0288,  -7.6682,  -7.9046,  ...,  -7.9984,  -8.2099,  -4.1175],\n",
      "         [ -5.3965,  -4.9187,  -5.3005,  ...,  -5.2723,  -5.9287,  -2.1046],\n",
      "         ...,\n",
      "         [ -6.9320,  -6.8936,  -7.0686,  ...,  -5.6026,  -6.5704,  -5.9377],\n",
      "         [ -7.2601,  -7.0224,  -7.2103,  ...,  -6.6711,  -7.2751,  -4.7953],\n",
      "         [-10.9906, -10.5400, -10.9876,  ...,  -8.6476,  -7.4370,  -7.7022]],\n",
      "\n",
      "        [[ -6.9869,  -6.9783,  -6.9689,  ...,  -6.3074,  -6.2656,  -4.5543],\n",
      "         [ -5.4445,  -5.5142,  -5.6673,  ...,  -5.7995,  -5.0654,  -5.6355],\n",
      "         [ -5.0907,  -4.8235,  -5.0779,  ...,  -4.8009,  -5.7911,  -2.6885],\n",
      "         ...,\n",
      "         [ -7.3209,  -7.3830,  -7.2953,  ...,  -6.8561,  -7.9550,  -4.4129],\n",
      "         [ -5.0745,  -5.1916,  -5.0868,  ...,  -5.1399,  -5.2785,  -5.3538],\n",
      "         [ -9.7092,  -9.4489,  -9.3463,  ...,  -8.2280, -10.3210,  -8.5137]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7281,  -6.6938,  -6.7146,  ...,  -6.0690,  -6.1896,  -3.7175],\n",
      "         [ -7.2061,  -7.3304,  -7.2662,  ...,  -6.8366,  -7.0158,  -3.1948],\n",
      "         [-12.8746, -12.5658, -12.8971,  ..., -12.6097, -11.0425,  -7.4471],\n",
      "         ...,\n",
      "         [ -6.4678,  -6.4632,  -6.3970,  ...,  -6.5099,  -6.4137,  -4.8982],\n",
      "         [ -6.5631,  -6.6914,  -6.6173,  ...,  -6.2622,  -6.5937,  -4.0588],\n",
      "         [ -7.0167,  -7.1037,  -7.0007,  ...,  -6.3622,  -7.0746,  -3.3960]],\n",
      "\n",
      "        [[ -9.6362,  -9.6026,  -9.5653,  ...,  -8.0030,  -9.2241,  -6.3332],\n",
      "         [ -9.9573, -10.2189, -10.1746,  ...,  -6.9919,  -9.0127,  -7.3469],\n",
      "         [ -6.5477,  -6.4964,  -6.4832,  ...,  -7.4640,  -8.8772,  -2.0548],\n",
      "         ...,\n",
      "         [ -5.2210,  -5.2159,  -5.2205,  ...,  -5.6211,  -7.3868,  -4.0324],\n",
      "         [ -6.0103,  -6.0510,  -6.0368,  ...,  -7.3461,  -8.0303,  -3.0596],\n",
      "         [ -4.8233,  -4.8479,  -4.8048,  ...,  -5.8601,  -7.3792,  -2.8698]],\n",
      "\n",
      "        [[ -6.8527,  -6.8590,  -6.8607,  ...,  -6.2252,  -6.0927,  -4.1921],\n",
      "         [-13.4498, -13.4826, -13.2973,  ..., -11.0171, -11.2691,  -9.1386],\n",
      "         [ -8.1080,  -8.6734,  -8.7032,  ...,  -8.9339,  -7.7289,  -4.4622],\n",
      "         ...,\n",
      "         [-10.1628, -10.3704, -10.0488,  ..., -10.0908,  -8.9928,  -6.1830],\n",
      "         [ -8.8106,  -8.8747,  -8.3422,  ...,  -9.2596,  -7.4567,  -9.5875],\n",
      "         [-12.5231, -12.2580, -12.3906,  ...,  -9.4256, -10.2800,  -6.6576]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.6550798416137695\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6574, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.4239,  -8.1226,  -8.3524,  ...,  -7.6004,  -8.1470,  -4.5230],\n",
      "         [-11.9257, -11.7430, -12.3335,  ...,  -9.0786, -12.5373, -11.5540],\n",
      "         [ -6.4065,  -6.4195,  -6.3257,  ...,  -7.5449,  -7.8505,  -2.7587],\n",
      "         ...,\n",
      "         [ -6.5096,  -6.2284,  -6.4208,  ...,  -6.8104,  -8.3351,  -3.7039],\n",
      "         [ -5.8551,  -5.7414,  -5.7335,  ...,  -6.2965,  -7.7842,  -2.3324],\n",
      "         [ -6.6148,  -6.5895,  -6.6419,  ...,  -6.9562,  -8.0330,  -3.5005]],\n",
      "\n",
      "        [[ -6.4369,  -6.3999,  -6.3906,  ...,  -5.8340,  -5.6405,  -3.7921],\n",
      "         [ -6.1808,  -6.1659,  -6.2878,  ...,  -6.7152,  -6.9778,  -1.4773],\n",
      "         [ -6.2874,  -6.3692,  -6.2599,  ...,  -7.1723,  -6.4226,  -2.4592],\n",
      "         ...,\n",
      "         [ -6.5638,  -6.6706,  -6.6102,  ...,  -6.7856,  -6.5902,  -3.1058],\n",
      "         [ -6.5727,  -6.6639,  -6.6005,  ...,  -6.4009,  -6.7558,  -4.0139],\n",
      "         [ -6.3773,  -6.4335,  -6.4054,  ...,  -6.4602,  -6.5702,  -3.3827]],\n",
      "\n",
      "        [[ -7.3133,  -7.2518,  -7.2362,  ...,  -6.5845,  -6.6763,  -4.2069],\n",
      "         [ -9.1676,  -9.1452,  -9.1499,  ...,  -8.5136,  -9.4088,  -4.5175],\n",
      "         [ -6.4160,  -6.5041,  -6.1156,  ...,  -5.8257,  -6.2846,  -4.7646],\n",
      "         ...,\n",
      "         [ -8.7262,  -9.0738,  -8.7203,  ...,  -6.8572,  -8.5202,  -5.7272],\n",
      "         [ -7.2920,  -7.0541,  -7.0350,  ...,  -7.0244,  -6.6717,  -2.4324],\n",
      "         [-13.6971, -13.6809, -13.5044,  ..., -11.9512, -10.9349,  -5.8349]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.4709,  -5.4334,  -5.4415,  ...,  -5.7378,  -5.7397,  -1.4261],\n",
      "         [-10.8031, -10.8064, -10.6049,  ...,  -8.2428,  -9.7804,  -8.8164],\n",
      "         [ -7.5275,  -7.4213,  -7.3938,  ...,  -7.5515,  -7.4537,  -3.4761],\n",
      "         ...,\n",
      "         [ -5.7523,  -5.5408,  -5.8120,  ...,  -5.9448,  -5.5082,  -1.5933],\n",
      "         [ -6.1132,  -6.0799,  -6.1081,  ...,  -6.4979,  -6.5320,  -2.4429],\n",
      "         [ -6.4845,  -6.4019,  -6.4132,  ...,  -6.9934,  -6.9369,  -3.1759]],\n",
      "\n",
      "        [[ -6.5247,  -6.4572,  -6.5018,  ...,  -5.8323,  -5.7677,  -4.0024],\n",
      "         [ -6.7229,  -6.4112,  -6.5268,  ...,  -6.7801,  -7.6873,  -2.7544],\n",
      "         [ -9.7003,  -9.7661,  -9.0548,  ...,  -9.2203,  -8.9705,  -4.2281],\n",
      "         ...,\n",
      "         [ -5.9592,  -5.8284,  -5.8325,  ...,  -5.9495,  -6.6640,  -2.6833],\n",
      "         [ -7.0093,  -6.8066,  -6.8586,  ...,  -7.1017,  -7.6459,  -2.7947],\n",
      "         [ -6.8335,  -6.5877,  -6.5727,  ...,  -6.9123,  -7.5604,  -2.9068]],\n",
      "\n",
      "        [[ -7.5005,  -7.4401,  -7.3983,  ...,  -6.6226,  -6.4390,  -4.7459],\n",
      "         [ -9.7964,  -9.3749,  -9.5284,  ...,  -7.3301,  -7.4455,  -6.7748],\n",
      "         [ -5.7822,  -5.7418,  -5.7579,  ...,  -6.1473,  -7.4925,  -2.9066],\n",
      "         ...,\n",
      "         [ -5.3393,  -5.2875,  -5.3403,  ...,  -6.0758,  -7.4648,  -2.8143],\n",
      "         [ -5.3280,  -5.4211,  -5.4312,  ...,  -5.7887,  -7.1648,  -3.6296],\n",
      "         [ -5.5758,  -5.5567,  -5.5679,  ...,  -5.9301,  -7.2536,  -3.2096]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6574015617370605\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0938, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5069,  -6.4504,  -6.4583,  ...,  -5.9414,  -5.6700,  -4.0320],\n",
      "         [ -7.9855,  -7.8569,  -7.7699,  ...,  -7.7958,  -7.8038,  -5.3007],\n",
      "         [ -7.9118,  -8.0314,  -7.9870,  ...,  -8.0855,  -7.8294,  -5.6708],\n",
      "         ...,\n",
      "         [ -7.0662,  -6.9384,  -6.9697,  ...,  -7.1152,  -7.0003,  -4.8470],\n",
      "         [ -6.8653,  -6.7499,  -6.8249,  ...,  -6.6080,  -6.7344,  -3.9300],\n",
      "         [ -7.0039,  -6.8964,  -6.9497,  ...,  -6.7411,  -6.9530,  -4.1452]],\n",
      "\n",
      "        [[ -6.5298,  -6.5100,  -6.5228,  ...,  -5.9103,  -5.7409,  -3.9176],\n",
      "         [-13.5197, -14.1751, -14.1110,  ..., -12.9446, -12.4860,  -8.2700],\n",
      "         [-16.8589, -16.9190, -17.0282,  ..., -15.7264, -12.9269, -14.2992],\n",
      "         ...,\n",
      "         [ -7.4252,  -7.2943,  -7.4534,  ...,  -7.6037,  -7.3720,  -2.3059],\n",
      "         [ -7.8272,  -7.8754,  -7.9783,  ...,  -7.8641,  -7.8645,  -3.6958],\n",
      "         [ -8.0931,  -8.0298,  -8.0852,  ...,  -8.5010,  -7.7758,  -4.1780]],\n",
      "\n",
      "        [[ -7.7998,  -7.7908,  -7.8166,  ...,  -6.8183,  -6.7760,  -5.0656],\n",
      "         [-12.1476, -11.8901, -11.9097,  ..., -11.0364, -10.2183,  -9.1089],\n",
      "         [ -6.4549,  -6.2302,  -6.4607,  ...,  -6.9887,  -8.2773,  -2.8279],\n",
      "         ...,\n",
      "         [ -5.6448,  -5.5855,  -5.5436,  ...,  -5.9048,  -7.8349,  -2.2985],\n",
      "         [ -6.4353,  -6.2862,  -6.4511,  ...,  -6.9264,  -8.4034,  -3.3644],\n",
      "         [ -5.5180,  -5.3566,  -5.5286,  ...,  -6.1653,  -7.1076,  -3.5324]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7719,  -6.7490,  -6.7240,  ...,  -6.2024,  -6.0312,  -4.0684],\n",
      "         [ -5.3111,  -5.4337,  -5.1964,  ...,  -4.6221,  -5.7450,  -4.6149],\n",
      "         [-10.9993, -10.3983, -10.7323,  ..., -11.6822,  -8.6177,  -8.8020],\n",
      "         ...,\n",
      "         [ -5.0614,  -5.2625,  -5.1516,  ...,  -5.7250,  -5.6713,  -5.8887],\n",
      "         [ -6.7605,  -6.7358,  -6.7062,  ...,  -6.3156,  -6.9340,  -5.0296],\n",
      "         [-11.0649, -11.3870, -11.2624,  ...,  -9.4015,  -8.3810,  -6.5548]],\n",
      "\n",
      "        [[ -7.1246,  -7.0853,  -7.0373,  ...,  -6.6099,  -6.8560,  -3.8073],\n",
      "         [ -9.7368, -10.0947,  -9.8686,  ...,  -7.7589,  -8.1226,  -8.6383],\n",
      "         [ -5.2392,  -5.2912,  -5.2347,  ...,  -5.9614,  -6.9252,  -2.5058],\n",
      "         ...,\n",
      "         [ -5.6395,  -5.4108,  -5.3957,  ...,  -5.6335,  -6.7706,  -2.5238],\n",
      "         [ -5.6071,  -5.4585,  -5.4365,  ...,  -6.1418,  -7.5435,  -2.9253],\n",
      "         [ -5.8733,  -5.7719,  -5.6902,  ...,  -6.2788,  -7.6844,  -2.1670]],\n",
      "\n",
      "        [[ -6.3784,  -6.3846,  -6.4041,  ...,  -5.9882,  -5.5951,  -3.9341],\n",
      "         [ -7.6147,  -7.7404,  -7.6131,  ...,  -7.9316,  -7.4569,  -4.4269],\n",
      "         [ -7.4818,  -7.6885,  -7.6304,  ...,  -7.6474,  -7.2162,  -5.4899],\n",
      "         ...,\n",
      "         [ -6.5086,  -6.4778,  -6.5153,  ...,  -6.6991,  -6.8105,  -2.9498],\n",
      "         [ -6.7816,  -6.6674,  -6.7337,  ...,  -7.0849,  -6.9795,  -3.4401],\n",
      "         [ -5.9510,  -5.9540,  -6.0233,  ...,  -6.1262,  -6.5377,  -2.7555]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.093816876411438\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6561, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1834,  -7.1968,  -7.2184,  ...,  -6.6905,  -6.4375,  -4.2095],\n",
      "         [ -7.3617,  -7.6985,  -7.8531,  ...,  -8.0713,  -7.1706,  -9.1043],\n",
      "         [ -6.5260,  -6.6543,  -6.8170,  ...,  -6.6755,  -6.4739,  -7.5437],\n",
      "         ...,\n",
      "         [-10.5150, -10.8895, -10.4487,  ..., -10.1456,  -9.2323,  -5.9405],\n",
      "         [ -4.5920,  -4.7136,  -4.3566,  ...,  -4.4479,  -5.5435,  -1.7573],\n",
      "         [-12.1895, -12.0484, -12.3407,  ..., -10.9158, -10.1455,  -9.9357]],\n",
      "\n",
      "        [[ -6.9347,  -6.9548,  -6.9607,  ...,  -6.4616,  -6.4034,  -4.5800],\n",
      "         [-11.8603, -11.4183, -11.3720,  ...,  -8.9310,  -9.4515, -11.0703],\n",
      "         [ -7.2317,  -7.1335,  -7.2664,  ...,  -7.0326,  -7.8392,  -3.1782],\n",
      "         ...,\n",
      "         [ -6.1367,  -6.1913,  -6.2602,  ...,  -5.8935,  -6.9908,  -1.0781],\n",
      "         [ -7.2281,  -7.1338,  -7.2510,  ...,  -6.9570,  -7.8749,  -2.1666],\n",
      "         [ -6.4179,  -6.2515,  -6.5122,  ...,  -6.6906,  -6.9419,  -2.0907]],\n",
      "\n",
      "        [[ -7.0447,  -7.1104,  -7.0625,  ...,  -6.3799,  -6.1337,  -4.3621],\n",
      "         [-10.4849, -10.2671, -10.3032,  ..., -10.3142,  -9.1667,  -9.2764],\n",
      "         [ -8.6626,  -8.2130,  -8.5231,  ...,  -7.7463,  -7.3864,  -6.1060],\n",
      "         ...,\n",
      "         [-10.8647, -10.6523, -10.9106,  ...,  -8.6201,  -8.8323,  -9.3224],\n",
      "         [ -7.9276,  -7.9716,  -7.7604,  ...,  -7.9879,  -7.8729,  -6.4258],\n",
      "         [-10.6177, -10.2920, -10.0327,  ...,  -8.8732,  -8.8601,  -8.8515]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6995,  -6.6705,  -6.6629,  ...,  -6.2259,  -5.9989,  -4.0495],\n",
      "         [ -7.7215,  -7.5300,  -7.7955,  ...,  -8.3336,  -7.5887,  -2.8111],\n",
      "         [ -8.8557,  -8.8601,  -8.9068,  ...,  -9.3189,  -8.7402,  -3.3318],\n",
      "         ...,\n",
      "         [ -5.7798,  -5.8240,  -5.9093,  ...,  -6.2014,  -5.9960,  -2.6497],\n",
      "         [ -6.2658,  -6.2069,  -6.2921,  ...,  -6.5162,  -6.5245,  -3.1931],\n",
      "         [ -6.1709,  -6.1260,  -6.1985,  ...,  -6.8943,  -6.4854,  -2.3706]],\n",
      "\n",
      "        [[ -7.3921,  -7.4616,  -7.4385,  ...,  -6.9025,  -6.6298,  -4.6353],\n",
      "         [ -6.1665,  -6.4413,  -6.3118,  ...,  -7.4703,  -7.7270,  -7.9876],\n",
      "         [ -8.8342,  -9.1639,  -8.8780,  ...,  -8.3537,  -8.8791,  -4.1943],\n",
      "         ...,\n",
      "         [ -6.7067,  -6.8173,  -6.6583,  ...,  -8.0216,  -8.0214,  -6.2254],\n",
      "         [ -8.1535,  -8.0440,  -8.1763,  ...,  -8.2359,  -8.3324,  -6.1239],\n",
      "         [ -7.2509,  -7.6723,  -7.4747,  ...,  -8.3860,  -7.5512,  -8.5005]],\n",
      "\n",
      "        [[ -6.8785,  -6.8760,  -6.8366,  ...,  -6.4930,  -6.2789,  -3.9315],\n",
      "         [-17.3652, -17.1338, -17.4743,  ..., -16.6048, -14.9950, -13.1219],\n",
      "         [ -7.4740,  -7.3985,  -7.4813,  ...,  -8.5965,  -7.5629,  -8.1729],\n",
      "         ...,\n",
      "         [-13.0945, -13.0443, -12.9961,  ..., -11.7103,  -9.3850,  -7.2705],\n",
      "         [ -9.0788,  -9.1589,  -9.4118,  ...,  -8.1888,  -8.4054,  -5.1992],\n",
      "         [-11.9463, -11.5861, -12.2073,  ...,  -9.7933, -10.7228,  -7.2097]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.656053304672241\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7623, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9382,  -6.9161,  -6.9105,  ...,  -6.3515,  -6.1553,  -4.0134],\n",
      "         [ -7.1585,  -7.3496,  -7.3391,  ...,  -6.3836,  -7.1673,  -6.0596],\n",
      "         [ -9.4363,  -9.3796,  -9.4082,  ...,  -8.2913,  -8.0308,  -6.9206],\n",
      "         ...,\n",
      "         [ -6.5471,  -6.6379,  -6.7705,  ...,  -5.5606,  -6.0112,  -5.6843],\n",
      "         [ -5.6162,  -5.1332,  -5.6245,  ...,  -5.9686,  -4.9259,  -5.3572],\n",
      "         [-10.0851,  -9.8203,  -9.7280,  ...,  -8.5489,  -7.5563, -10.1762]],\n",
      "\n",
      "        [[ -9.9034,  -9.6759,  -9.6896,  ...,  -8.7331,  -8.9586,  -5.4234],\n",
      "         [-16.1216, -15.9431, -15.9984,  ..., -13.2216, -14.0123, -12.9638],\n",
      "         [ -6.3014,  -6.1826,  -6.2906,  ...,  -6.4765,  -7.8254,  -1.4219],\n",
      "         ...,\n",
      "         [ -6.1495,  -6.0428,  -6.1807,  ...,  -6.4059,  -7.7681,  -2.1607],\n",
      "         [ -6.1059,  -5.8848,  -6.0929,  ...,  -5.8723,  -7.4071,  -1.6666],\n",
      "         [ -6.1457,  -6.0517,  -6.1374,  ...,  -5.5973,  -7.6382,  -1.6921]],\n",
      "\n",
      "        [[ -7.1293,  -7.1801,  -7.1512,  ...,  -6.4588,  -6.2474,  -5.0411],\n",
      "         [-15.4181, -15.3296, -15.3913,  ..., -13.8728, -12.6517, -12.4975],\n",
      "         [-11.7698, -12.4419, -11.8523,  ..., -12.9370, -10.9607, -10.9985],\n",
      "         ...,\n",
      "         [-12.2124, -12.3638, -11.7912,  ..., -11.1540, -10.6228,  -9.4235],\n",
      "         [-10.7853, -10.4020, -10.3254,  ...,  -9.0581,  -9.0387, -10.1538],\n",
      "         [-12.9826, -12.2539, -12.4721,  ..., -10.5023,  -8.8756,  -8.8512]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8920,  -6.8630,  -6.8360,  ...,  -6.0443,  -6.1027,  -3.7394],\n",
      "         [ -8.2824,  -8.1232,  -8.1955,  ...,  -8.3251,  -7.5412,  -5.8032],\n",
      "         [ -6.1637,  -6.1906,  -6.2137,  ...,  -6.4367,  -5.7905,  -5.7997],\n",
      "         ...,\n",
      "         [ -8.8850,  -8.7929,  -8.9401,  ...,  -8.4536,  -7.7711,  -4.5158],\n",
      "         [ -8.6008,  -8.4784,  -8.6172,  ...,  -8.2228,  -7.2381,  -3.9452],\n",
      "         [ -8.6721,  -8.5162,  -8.6031,  ...,  -8.4215,  -7.7178,  -4.2816]],\n",
      "\n",
      "        [[ -6.3477,  -6.3528,  -6.3259,  ...,  -5.8369,  -5.5836,  -3.8570],\n",
      "         [ -7.1825,  -7.0299,  -7.1340,  ...,  -7.5913,  -7.4709,  -5.8265],\n",
      "         [ -7.1657,  -7.4822,  -7.2023,  ...,  -6.6426,  -6.9987,  -5.2591],\n",
      "         ...,\n",
      "         [ -6.6272,  -6.7911,  -6.9406,  ...,  -7.5381,  -6.4014,  -6.8946],\n",
      "         [ -4.8826,  -4.7439,  -4.9450,  ...,  -4.6593,  -4.3290,  -5.9984],\n",
      "         [-10.1244,  -9.3981, -10.2425,  ...,  -7.9231,  -7.8227,  -3.6301]],\n",
      "\n",
      "        [[-13.7359, -13.9097, -13.5513,  ..., -12.4239, -13.6253,  -6.8078],\n",
      "         [-10.7333, -10.2567, -10.0808,  ...,  -9.0189, -10.2415,  -8.9850],\n",
      "         [ -7.1315,  -7.0914,  -7.1586,  ...,  -7.6452,  -8.6630,  -1.3560],\n",
      "         ...,\n",
      "         [ -5.9614,  -6.0222,  -5.8647,  ...,  -6.4099,  -7.8000,  -1.7447],\n",
      "         [ -5.7255,  -5.8545,  -5.7924,  ...,  -5.9496,  -7.8264,  -0.5082],\n",
      "         [ -5.8421,  -5.9098,  -5.8653,  ...,  -6.4556,  -7.3751,  -1.6263]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.7622923851013184\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6838, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8119,  -7.7837,  -7.8231,  ...,  -7.0333,  -7.1008,  -5.0392],\n",
      "         [-10.1529,  -9.6475,  -9.9176,  ...,  -8.1720,  -7.8662,  -6.3826],\n",
      "         [ -5.2566,  -5.2716,  -5.1086,  ...,  -5.4781,  -6.6885,  -2.1206],\n",
      "         ...,\n",
      "         [ -4.2599,  -4.1103,  -4.1087,  ...,  -4.6436,  -6.0224,  -2.2721],\n",
      "         [ -5.4829,  -5.4178,  -5.3896,  ...,  -5.3526,  -7.3631,  -3.2428],\n",
      "         [ -6.2897,  -6.1972,  -6.0747,  ...,  -6.6636,  -7.0733,  -4.0022]],\n",
      "\n",
      "        [[ -6.7839,  -6.7523,  -6.7371,  ...,  -6.1265,  -5.8980,  -4.1300],\n",
      "         [ -7.2241,  -7.4367,  -7.5321,  ...,  -6.2477,  -5.6217,  -4.8465],\n",
      "         [-14.4104, -14.4826, -14.3818,  ..., -14.0584, -10.8054, -10.0581],\n",
      "         ...,\n",
      "         [ -7.6911,  -7.7545,  -7.8084,  ...,  -6.7081,  -5.8719,  -8.0799],\n",
      "         [ -9.5766,  -9.6142,  -9.5591,  ...,  -8.8038,  -7.9746,  -9.4647],\n",
      "         [-12.8512, -12.2488, -12.2226,  ...,  -9.0418,  -9.9132, -10.1586]],\n",
      "\n",
      "        [[ -7.7014,  -7.7451,  -7.6326,  ...,  -7.6423,  -8.2327,  -5.2473],\n",
      "         [-14.0004, -14.0497, -13.8702,  ..., -12.2161, -10.5775,  -9.2556],\n",
      "         [ -5.8991,  -5.7006,  -5.8667,  ...,  -6.4438,  -6.7571,  -3.1296],\n",
      "         ...,\n",
      "         [ -6.1370,  -5.8530,  -5.9973,  ...,  -6.4485,  -6.8775,  -3.8407],\n",
      "         [ -5.6794,  -5.6937,  -5.6422,  ...,  -6.8184,  -6.9213,  -2.3093],\n",
      "         [ -6.5370,  -6.3606,  -6.4896,  ...,  -6.7674,  -7.4134,  -3.2450]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.1366,  -8.0811,  -8.0273,  ...,  -7.2504,  -7.3776,  -5.4110],\n",
      "         [ -7.3942,  -7.3055,  -7.2866,  ...,  -4.3172,  -6.6462,  -5.7103],\n",
      "         [ -5.8090,  -5.7488,  -5.7482,  ...,  -6.3266,  -7.1310,  -3.0974],\n",
      "         ...,\n",
      "         [ -6.4884,  -6.2359,  -6.4585,  ...,  -6.9140,  -7.5151,  -3.6169],\n",
      "         [ -6.5382,  -6.3486,  -6.2978,  ...,  -6.7122,  -7.4829,  -3.3766],\n",
      "         [ -6.2410,  -6.0594,  -5.9641,  ...,  -6.2534,  -7.0747,  -3.9347]],\n",
      "\n",
      "        [[ -6.9045,  -6.9273,  -6.8594,  ...,  -6.4220,  -6.0936,  -4.2101],\n",
      "         [-13.6825, -13.5069, -13.7545,  ..., -12.7844, -11.2135,  -9.7796],\n",
      "         [ -7.5441,  -7.3905,  -7.3789,  ...,  -6.7142,  -6.2887,  -8.4095],\n",
      "         ...,\n",
      "         [ -7.9961,  -7.7327,  -7.8346,  ...,  -7.4549,  -7.3503,  -6.4773],\n",
      "         [ -6.3414,  -6.1901,  -6.2494,  ...,  -5.7161,  -5.7719,  -7.0941],\n",
      "         [ -6.5098,  -6.4788,  -6.4580,  ...,  -5.7686,  -6.0148,  -7.4240]],\n",
      "\n",
      "        [[ -6.5206,  -6.4809,  -6.4990,  ...,  -5.9498,  -5.6450,  -3.8456],\n",
      "         [ -7.1508,  -7.0210,  -7.1128,  ...,  -7.0014,  -6.6089,  -3.1823],\n",
      "         [ -6.1936,  -6.2189,  -6.2569,  ...,  -6.1884,  -6.3007,  -3.6149],\n",
      "         ...,\n",
      "         [ -5.9500,  -5.9324,  -6.0312,  ...,  -5.8831,  -5.8654,  -2.4603],\n",
      "         [ -6.3227,  -6.2963,  -6.3777,  ...,  -6.2320,  -6.3058,  -2.6731],\n",
      "         [ -5.8991,  -5.9261,  -6.0044,  ...,  -5.8699,  -6.0886,  -2.9609]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.68383526802063\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7646, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9439,  -6.9550,  -6.9293,  ...,  -6.1912,  -5.9890,  -4.3297],\n",
      "         [-13.8728, -13.6052, -13.9206,  ..., -12.9868, -12.0007, -12.0178],\n",
      "         [-16.1776, -16.3984, -16.1768,  ..., -14.6056, -12.9826, -15.3246],\n",
      "         ...,\n",
      "         [ -6.8899,  -6.8999,  -6.8178,  ...,  -6.6923,  -6.6587,  -7.1280],\n",
      "         [ -7.6628,  -7.6046,  -7.6247,  ...,  -7.0990,  -7.2638,  -7.2106],\n",
      "         [ -7.6391,  -7.6631,  -7.5675,  ...,  -7.2328,  -7.4388,  -6.0797]],\n",
      "\n",
      "        [[ -6.7514,  -6.6737,  -6.6835,  ...,  -5.9613,  -5.7966,  -4.0784],\n",
      "         [ -8.9518,  -8.8910,  -8.7324,  ...,  -7.4970,  -6.9708,  -5.9983],\n",
      "         [ -6.8346,  -6.7695,  -6.8673,  ...,  -7.2376,  -7.9044,  -2.7336],\n",
      "         ...,\n",
      "         [ -5.7502,  -5.6168,  -5.7005,  ...,  -6.1069,  -7.3944,  -3.5981],\n",
      "         [ -5.8050,  -5.7556,  -5.6657,  ...,  -6.0724,  -7.3618,  -3.0958],\n",
      "         [ -5.5490,  -5.5031,  -5.4776,  ...,  -5.3626,  -7.1031,  -2.8638]],\n",
      "\n",
      "        [[ -6.9913,  -6.9698,  -6.8835,  ...,  -6.4320,  -5.7789,  -4.3811],\n",
      "         [ -9.9228,  -9.9232, -10.0440,  ...,  -9.6121, -10.6754,  -8.1666],\n",
      "         [-10.9755, -11.3573, -10.7794,  ..., -11.3559,  -7.9201, -12.7179],\n",
      "         ...,\n",
      "         [ -6.3925,  -6.4942,  -6.2739,  ...,  -6.1191,  -6.3831,  -4.9397],\n",
      "         [ -7.5082,  -7.6498,  -7.6710,  ...,  -7.4921,  -6.0467,  -2.4469],\n",
      "         [-13.6254, -13.1307, -13.3644,  ..., -10.4518, -11.3210, -12.6297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8729,  -6.8366,  -6.8300,  ...,  -6.1885,  -6.0182,  -3.4309],\n",
      "         [-15.4959, -15.2427, -15.2554,  ..., -13.6253, -12.6426, -11.8459],\n",
      "         [-11.6958, -12.1354, -11.8870,  ..., -11.4957, -10.0672, -12.4924],\n",
      "         ...,\n",
      "         [ -6.5016,  -6.5010,  -6.5254,  ...,  -6.1194,  -6.3404,  -5.2900],\n",
      "         [ -6.3280,  -6.3185,  -6.3191,  ...,  -6.1357,  -6.1973,  -4.5345],\n",
      "         [ -8.3403,  -8.4128,  -8.4776,  ...,  -8.5054,  -7.7082,  -4.9666]],\n",
      "\n",
      "        [[ -7.3438,  -7.4671,  -7.3812,  ...,  -6.8231,  -6.4567,  -4.3749],\n",
      "         [-12.5466, -12.7101, -12.5853,  ..., -11.9913, -12.0275, -13.0591],\n",
      "         [ -9.0129,  -8.9802,  -8.7612,  ...,  -7.3170,  -7.6117,  -7.5880],\n",
      "         ...,\n",
      "         [-11.7428, -11.6732, -11.2493,  ...,  -9.9470,  -9.7660,  -6.5501],\n",
      "         [ -6.8502,  -6.8087,  -6.6992,  ...,  -5.5748,  -5.9265,  -3.4892],\n",
      "         [-13.0016, -12.5007, -12.9602,  ...,  -9.5662, -10.0063,  -8.9649]],\n",
      "\n",
      "        [[ -9.6930,  -9.5940,  -9.5925,  ...,  -8.6313,  -8.8493,  -6.1496],\n",
      "         [ -9.7644,  -9.8654,  -9.6174,  ...,  -8.5002,  -7.7652,  -8.1373],\n",
      "         [ -6.1648,  -5.9649,  -6.2425,  ...,  -6.6377,  -7.6413,  -3.6452],\n",
      "         ...,\n",
      "         [ -6.3594,  -6.0800,  -6.2738,  ...,  -6.6882,  -7.4724,  -2.6929],\n",
      "         [ -6.1155,  -5.9701,  -6.1391,  ...,  -6.6597,  -7.8058,  -3.3724],\n",
      "         [ -6.5632,  -6.4239,  -6.5381,  ...,  -6.3492,  -8.0160,  -4.0047]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.7646113634109497\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9535, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2199,  -6.1144,  -6.1793,  ...,  -6.2680,  -6.6322,  -4.3287],\n",
      "         [ -9.9374,  -9.8549, -10.0652,  ...,  -7.1848,  -8.4865,  -7.6523],\n",
      "         [ -6.4782,  -6.4291,  -6.4881,  ...,  -7.2918,  -7.5985,  -3.3389],\n",
      "         ...,\n",
      "         [ -7.0384,  -6.9735,  -7.0619,  ...,  -7.2883,  -7.8307,  -1.9226],\n",
      "         [ -5.7603,  -5.5873,  -5.7164,  ...,  -6.8063,  -6.5376,  -2.6888],\n",
      "         [ -7.0440,  -7.0452,  -7.0537,  ...,  -7.5813,  -7.9771,  -4.2158]],\n",
      "\n",
      "        [[ -6.7985,  -6.7373,  -6.7465,  ...,  -6.1720,  -5.9033,  -4.2324],\n",
      "         [ -7.6334,  -7.5080,  -7.5381,  ...,  -7.8743,  -7.1323,  -4.5418],\n",
      "         [ -7.1288,  -7.0512,  -7.0182,  ...,  -7.1340,  -6.4730,  -4.8362],\n",
      "         ...,\n",
      "         [ -6.7936,  -6.7010,  -6.8369,  ...,  -7.0399,  -6.5301,  -4.7332],\n",
      "         [ -6.6752,  -6.5666,  -6.5821,  ...,  -6.6436,  -6.2862,  -3.0875],\n",
      "         [ -6.8839,  -6.7565,  -6.8569,  ...,  -7.2189,  -6.3266,  -4.8993]],\n",
      "\n",
      "        [[ -8.3196,  -8.1822,  -8.0536,  ...,  -8.3601,  -7.5870,  -5.8413],\n",
      "         [ -9.9951, -10.0156,  -9.8782,  ...,  -6.4810,  -8.0054, -11.0663],\n",
      "         [ -5.5602,  -5.4819,  -5.5023,  ...,  -6.3842,  -6.9289,  -3.0540],\n",
      "         ...,\n",
      "         [ -6.4430,  -6.2982,  -6.4224,  ...,  -6.9381,  -7.8822,  -3.5725],\n",
      "         [ -5.8574,  -5.6382,  -5.6926,  ...,  -6.4265,  -7.2484,  -3.2359],\n",
      "         [ -6.3206,  -6.2593,  -6.2137,  ...,  -6.5345,  -7.0090,  -2.2356]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.7018,  -8.5817,  -8.6749,  ...,  -6.8520,  -7.9472,  -4.1230],\n",
      "         [-11.3141, -11.5285, -11.3332,  ...,  -9.1245,  -9.5486,  -9.3880],\n",
      "         [ -5.9943,  -5.6035,  -5.7264,  ...,  -5.6750,  -7.4117,  -1.6207],\n",
      "         ...,\n",
      "         [ -5.2800,  -5.1000,  -5.2243,  ...,  -5.3275,  -7.1226,  -1.4352],\n",
      "         [ -4.5114,  -4.2828,  -4.4032,  ...,  -4.2841,  -6.8630,  -2.3148],\n",
      "         [ -6.1672,  -5.9942,  -5.9555,  ...,  -5.4884,  -7.4310,  -1.5943]],\n",
      "\n",
      "        [[ -6.8709,  -6.9053,  -6.8671,  ...,  -6.0949,  -5.9258,  -4.1924],\n",
      "         [ -4.0802,  -3.8496,  -3.7669,  ...,  -2.9369,  -3.9462,  -2.4970],\n",
      "         [-15.6699, -15.1107, -15.4766,  ..., -12.0357, -11.4895, -11.9762],\n",
      "         ...,\n",
      "         [-14.4347, -14.2374, -14.4517,  ..., -10.7249, -10.8226,  -8.9363],\n",
      "         [ -9.8827,  -9.6446, -10.1267,  ...,  -8.4126,  -7.5782,  -7.2448],\n",
      "         [-13.8190, -13.4431, -13.4326,  ..., -10.9559, -10.5014, -12.2087]],\n",
      "\n",
      "        [[ -6.9234,  -6.9261,  -6.8757,  ...,  -6.4464,  -6.0389,  -4.3953],\n",
      "         [ -6.0668,  -6.0423,  -6.1031,  ...,  -6.3249,  -6.0943,  -3.4545],\n",
      "         [ -5.1339,  -5.3722,  -5.4246,  ...,  -6.9321,  -4.3598,  -1.2781],\n",
      "         ...,\n",
      "         [-10.6569, -10.4418, -10.8079,  ...,  -9.0946,  -8.2191,  -7.0500],\n",
      "         [ -9.8668,  -9.7586,  -9.8106,  ...,  -8.5486,  -9.6514,  -8.5169],\n",
      "         [-14.4550, -13.8284, -13.8291,  ..., -11.3018, -10.2048, -11.9951]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.9534610509872437\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3529, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5491,  -6.5327,  -6.5368,  ...,  -5.9320,  -5.7667,  -3.8398],\n",
      "         [ -6.7484,  -6.6863,  -6.6871,  ...,  -6.8428,  -6.2274,  -3.2917],\n",
      "         [ -5.9869,  -6.1203,  -5.9857,  ...,  -6.6283,  -5.9644,  -2.5715],\n",
      "         ...,\n",
      "         [ -7.0123,  -6.9447,  -7.0759,  ...,  -7.3827,  -7.1943,  -2.6454],\n",
      "         [ -6.3930,  -6.3469,  -6.4427,  ...,  -6.9528,  -6.6042,  -2.1317],\n",
      "         [ -6.4509,  -6.4345,  -6.4440,  ...,  -6.7751,  -6.5287,  -2.1479]],\n",
      "\n",
      "        [[ -6.5800,  -6.5528,  -6.5538,  ...,  -5.9536,  -5.6998,  -4.0123],\n",
      "         [ -5.6686,  -6.0067,  -5.6916,  ...,  -6.1148,  -5.9684,  -6.8235],\n",
      "         [ -5.3135,  -5.6903,  -5.3762,  ...,  -6.1028,  -5.7804,  -6.9843],\n",
      "         ...,\n",
      "         [ -6.3603,  -6.5362,  -6.4436,  ...,  -6.8633,  -6.8747,  -5.9097],\n",
      "         [ -5.5958,  -5.6307,  -5.6457,  ...,  -5.8246,  -6.6148,  -5.6051],\n",
      "         [ -5.7724,  -5.8499,  -5.8199,  ...,  -6.4491,  -6.8607,  -7.2515]],\n",
      "\n",
      "        [[ -6.8797,  -6.8731,  -6.8206,  ...,  -6.4505,  -5.9269,  -4.0915],\n",
      "         [ -9.8175,  -9.6132,  -9.6047,  ...,  -8.7286,  -8.2102,  -8.5855],\n",
      "         [ -7.8907,  -7.8291,  -7.5974,  ...,  -7.6404,  -6.8188,  -7.1512],\n",
      "         ...,\n",
      "         [ -6.8890,  -7.0995,  -6.9806,  ...,  -6.9944,  -6.6956,  -5.0530],\n",
      "         [ -6.8220,  -6.8512,  -6.8746,  ...,  -6.5325,  -6.5354,  -4.2344],\n",
      "         [ -7.0872,  -7.0943,  -7.0690,  ...,  -7.0285,  -6.2859,  -5.4341]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4242,  -6.3651,  -6.4000,  ...,  -5.8199,  -5.6031,  -3.6568],\n",
      "         [-11.6893, -11.2141, -11.4455,  ...,  -8.0777,  -8.1836, -10.0626],\n",
      "         [ -6.1407,  -6.1996,  -6.2338,  ...,  -6.5000,  -7.5568,  -2.5959],\n",
      "         ...,\n",
      "         [ -5.7724,  -5.7384,  -5.7160,  ...,  -6.4163,  -7.5692,  -1.9437],\n",
      "         [ -6.0819,  -5.9425,  -5.8035,  ...,  -6.1614,  -6.6164,  -1.8455],\n",
      "         [ -5.7128,  -5.6192,  -5.5661,  ...,  -5.6507,  -7.2531,  -2.0241]],\n",
      "\n",
      "        [[ -8.0743,  -8.5739,  -7.8218,  ...,  -7.5538,  -7.0111,  -5.1793],\n",
      "         [-12.0334, -11.8279, -11.5690,  ...,  -9.2207, -11.3467, -13.8206],\n",
      "         [ -6.0017,  -6.0106,  -5.9687,  ...,  -6.5660,  -6.8106,  -4.7905],\n",
      "         ...,\n",
      "         [ -7.4477,  -7.4806,  -7.4780,  ...,  -7.7666,  -8.4801,  -5.9685],\n",
      "         [ -5.9627,  -6.1747,  -6.0000,  ...,  -6.6495,  -6.7323,  -3.9865],\n",
      "         [ -7.3030,  -7.3344,  -7.3479,  ...,  -7.8796,  -7.8502,  -5.1086]],\n",
      "\n",
      "        [[ -6.6130,  -6.5789,  -6.5618,  ...,  -5.9037,  -5.7196,  -3.7342],\n",
      "         [ -8.5345,  -8.6493,  -8.3611,  ...,  -8.8212,  -6.6529,  -6.2677],\n",
      "         [ -9.3400, -10.0992,  -9.5595,  ...,  -8.1398,  -9.9697,  -4.0079],\n",
      "         ...,\n",
      "         [ -7.4783,  -7.5081,  -7.4494,  ...,  -7.5634,  -6.2730,  -6.5835],\n",
      "         [ -7.0938,  -7.0742,  -6.9829,  ...,  -7.2914,  -6.3856,  -5.5497],\n",
      "         [ -7.2701,  -7.3371,  -7.2348,  ...,  -7.6061,  -6.3452,  -5.0718]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.352907657623291\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4190, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0461,  -7.0612,  -7.0521,  ...,  -6.5066,  -6.2862,  -4.6187],\n",
      "         [ -5.1321,  -5.2259,  -5.3719,  ...,  -4.3480,  -5.1021,  -6.4556],\n",
      "         [ -2.6927,  -2.6970,  -2.8577,  ...,  -2.7203,  -3.1661,  -5.7142],\n",
      "         ...,\n",
      "         [ -6.0990,  -6.0987,  -6.2512,  ...,  -6.2442,  -5.3738,  -6.7610],\n",
      "         [ -7.2488,  -7.3736,  -7.5490,  ...,  -6.9950,  -7.2274,  -7.6452],\n",
      "         [ -6.7625,  -6.8034,  -6.9027,  ...,  -6.7108,  -6.4361,  -7.9859]],\n",
      "\n",
      "        [[ -6.8814,  -6.8875,  -6.8463,  ...,  -6.3293,  -6.0994,  -4.1423],\n",
      "         [ -8.2119,  -8.2259,  -8.1802,  ...,  -7.8436,  -6.7326,  -4.1829],\n",
      "         [-10.7162, -10.7855, -10.8582,  ..., -11.8443,  -8.0800,  -9.2188],\n",
      "         ...,\n",
      "         [ -8.6332,  -8.6440,  -8.5187,  ...,  -8.6075,  -7.4981,  -7.5131],\n",
      "         [ -7.6702,  -7.7692,  -7.6103,  ...,  -8.0816,  -6.2909,  -6.3957],\n",
      "         [-14.2242, -13.6971, -14.1346,  ..., -11.3055, -12.0118, -10.4276]],\n",
      "\n",
      "        [[ -7.6102,  -7.6436,  -7.5918,  ...,  -6.6260,  -6.8218,  -4.7159],\n",
      "         [-12.3889, -12.4173, -12.2353,  ..., -10.2112, -10.5592,  -9.4336],\n",
      "         [ -6.1062,  -6.0448,  -6.1509,  ...,  -6.5524,  -8.1927,  -2.7633],\n",
      "         ...,\n",
      "         [ -5.4378,  -5.2628,  -5.3756,  ...,  -5.4094,  -7.0159,  -2.4769],\n",
      "         [ -5.8404,  -5.6659,  -5.7236,  ...,  -5.5833,  -7.4774,  -3.4411],\n",
      "         [ -6.8484,  -6.8801,  -6.7963,  ...,  -6.9595,  -7.9215,  -2.2104]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9514,  -6.9898,  -6.9586,  ...,  -6.2593,  -6.1761,  -4.5835],\n",
      "         [ -9.2464,  -9.2469,  -9.0138,  ...,  -8.3915,  -6.9225, -10.3795],\n",
      "         [ -4.4889,  -4.9025,  -4.3343,  ...,  -4.5382,  -3.8201,  -5.5152],\n",
      "         ...,\n",
      "         [-12.2211, -12.3144, -11.9725,  ..., -10.0717,  -9.1376,  -9.2730],\n",
      "         [-11.3197, -11.2592, -11.0854,  ...,  -9.4569,  -9.1703,  -8.0187],\n",
      "         [-13.9207, -13.8278, -13.8563,  ..., -12.4983, -11.1783,  -8.3834]],\n",
      "\n",
      "        [[ -6.8102,  -6.8188,  -6.8794,  ...,  -6.3483,  -6.0332,  -3.8979],\n",
      "         [ -7.4096,  -7.3445,  -7.4034,  ...,  -7.6870,  -7.5997,  -2.8406],\n",
      "         [ -9.4903,  -9.5155,  -9.4912,  ...,  -9.8027,  -9.4044,  -4.2974],\n",
      "         ...,\n",
      "         [ -6.7595,  -6.7624,  -6.8226,  ...,  -6.9113,  -6.9587,  -3.1505],\n",
      "         [ -7.2065,  -7.1821,  -7.1421,  ...,  -7.2703,  -7.0191,  -3.6102],\n",
      "         [ -7.1998,  -7.1959,  -7.1634,  ...,  -7.3017,  -7.2059,  -4.1192]],\n",
      "\n",
      "        [[ -7.1294,  -7.1646,  -7.1008,  ...,  -6.7601,  -6.3972,  -4.4256],\n",
      "         [ -6.5817,  -6.7105,  -6.8563,  ...,  -6.8528,  -5.9000,  -6.5706],\n",
      "         [-12.2220, -12.3312, -12.1094,  ..., -11.8567, -11.4706,  -7.3153],\n",
      "         ...,\n",
      "         [ -9.8381, -10.1685, -10.2369,  ...,  -7.9053,  -8.6895,  -7.1490],\n",
      "         [ -8.5642,  -8.6907,  -8.8344,  ...,  -8.0745,  -8.2738,   0.9124],\n",
      "         [-14.7824, -14.1938, -14.6316,  ..., -11.6647, -12.5172, -11.1898]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.4189720153808594\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.3307, grad_fn=<NllLossBackward0>), logits=tensor([[[-8.7128e+00, -8.5137e+00, -8.5994e+00,  ..., -7.4847e+00,\n",
      "          -8.1761e+00, -5.5056e+00],\n",
      "         [-9.8005e+00, -9.7167e+00, -9.3857e+00,  ..., -8.9633e+00,\n",
      "          -8.5375e+00, -7.0515e+00],\n",
      "         [-5.3286e+00, -5.3614e+00, -5.3547e+00,  ..., -5.9886e+00,\n",
      "          -7.1674e+00, -4.4146e+00],\n",
      "         ...,\n",
      "         [-6.3857e+00, -6.2885e+00, -6.4400e+00,  ..., -7.1506e+00,\n",
      "          -7.7781e+00, -3.6543e+00],\n",
      "         [-6.6299e+00, -6.6028e+00, -6.7023e+00,  ..., -7.4769e+00,\n",
      "          -7.7376e+00, -3.6220e+00],\n",
      "         [-5.2388e+00, -5.1726e+00, -5.2773e+00,  ..., -5.7516e+00,\n",
      "          -6.5856e+00, -4.7370e+00]],\n",
      "\n",
      "        [[-6.6075e+00, -6.5813e+00, -6.5818e+00,  ..., -5.8748e+00,\n",
      "          -5.9195e+00, -3.8660e+00],\n",
      "         [-7.2379e+00, -7.1905e+00, -7.3026e+00,  ..., -6.7293e+00,\n",
      "          -6.5899e+00, -4.3731e+00],\n",
      "         [-5.7724e+00, -5.8186e+00, -5.9147e+00,  ..., -5.5526e+00,\n",
      "          -5.9344e+00, -3.5593e+00],\n",
      "         ...,\n",
      "         [-7.5512e+00, -7.2610e+00, -7.4261e+00,  ..., -7.0593e+00,\n",
      "          -7.7109e+00, -2.0817e+00],\n",
      "         [-6.6967e+00, -6.4926e+00, -6.6982e+00,  ..., -6.2915e+00,\n",
      "          -6.9307e+00, -3.4235e+00],\n",
      "         [-6.9927e+00, -6.8936e+00, -7.0605e+00,  ..., -6.4659e+00,\n",
      "          -7.1893e+00, -3.7784e+00]],\n",
      "\n",
      "        [[-7.6415e+00, -7.5552e+00, -7.5757e+00,  ..., -6.5701e+00,\n",
      "          -6.6528e+00, -4.9981e+00],\n",
      "         [-1.0542e+01, -1.0155e+01, -1.0227e+01,  ..., -7.2497e+00,\n",
      "          -8.6102e+00, -9.8353e+00],\n",
      "         [-5.2834e+00, -5.2027e+00, -5.0987e+00,  ..., -6.1482e+00,\n",
      "          -7.0722e+00, -3.1516e+00],\n",
      "         ...,\n",
      "         [-4.5243e+00, -4.4601e+00, -4.4675e+00,  ..., -4.7890e+00,\n",
      "          -6.4774e+00, -3.4297e+00],\n",
      "         [-4.9464e+00, -4.7518e+00, -4.7339e+00,  ..., -5.3639e+00,\n",
      "          -6.7806e+00, -2.3353e+00],\n",
      "         [-4.9694e+00, -4.8281e+00, -4.7205e+00,  ..., -5.8607e+00,\n",
      "          -7.1452e+00, -3.7337e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8940e+00, -5.8823e+00, -6.1495e+00,  ..., -5.4750e+00,\n",
      "          -5.1430e+00, -3.6888e+00],\n",
      "         [-9.9789e+00, -9.8336e+00, -9.7529e+00,  ..., -7.4092e+00,\n",
      "          -6.6864e+00, -6.9988e+00],\n",
      "         [-6.8421e+00, -7.0539e+00, -7.0843e+00,  ..., -6.8828e+00,\n",
      "          -7.6343e+00, -2.7558e+00],\n",
      "         ...,\n",
      "         [-7.6006e+00, -7.6826e+00, -7.6841e+00,  ..., -7.8790e+00,\n",
      "          -8.3823e+00, -3.7300e+00],\n",
      "         [-7.5923e+00, -7.6716e+00, -7.6141e+00,  ..., -8.3563e+00,\n",
      "          -7.9220e+00, -3.1521e+00],\n",
      "         [-7.5599e+00, -7.6363e+00, -7.6230e+00,  ..., -7.5982e+00,\n",
      "          -7.4807e+00, -4.0280e+00]],\n",
      "\n",
      "        [[-6.4556e+00, -6.4501e+00, -6.4317e+00,  ..., -5.9910e+00,\n",
      "          -5.9294e+00, -2.9474e+00],\n",
      "         [-8.2950e+00, -8.0516e+00, -8.2586e+00,  ..., -9.2560e+00,\n",
      "          -8.6048e+00, -9.9522e-01],\n",
      "         [-7.8236e+00, -7.7979e+00, -7.7926e+00,  ..., -8.4384e+00,\n",
      "          -7.6721e+00, -2.8232e+00],\n",
      "         ...,\n",
      "         [-5.9809e+00, -5.8731e+00, -5.9374e+00,  ..., -6.2038e+00,\n",
      "          -6.5080e+00, -1.0135e+00],\n",
      "         [-5.4003e+00, -5.2114e+00, -5.4630e+00,  ..., -5.8496e+00,\n",
      "          -6.2153e+00, -5.4062e-03],\n",
      "         [-5.6567e+00, -5.5208e+00, -5.6536e+00,  ..., -5.8175e+00,\n",
      "          -6.4822e+00, -6.2071e-01]],\n",
      "\n",
      "        [[-9.3404e+00, -9.7340e+00, -9.8559e+00,  ..., -8.3119e+00,\n",
      "          -8.2143e+00, -5.1442e+00],\n",
      "         [-1.4708e+01, -1.4520e+01, -1.4102e+01,  ..., -1.2590e+01,\n",
      "          -1.1768e+01, -9.7389e+00],\n",
      "         [-5.3666e+00, -5.3905e+00, -5.5196e+00,  ..., -6.6928e+00,\n",
      "          -7.6885e+00, -2.7224e+00],\n",
      "         ...,\n",
      "         [-7.8066e+00, -7.7528e+00, -7.9541e+00,  ..., -8.0654e+00,\n",
      "          -9.2304e+00, -3.7813e+00],\n",
      "         [-7.4399e+00, -7.4646e+00, -7.5303e+00,  ..., -8.2546e+00,\n",
      "          -9.0879e+00, -3.4642e+00],\n",
      "         [-7.1048e+00, -7.1251e+00, -7.2651e+00,  ..., -7.8051e+00,\n",
      "          -8.2878e+00, -4.8281e+00]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.330738067626953\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0675, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6060,  -6.5015,  -6.5510,  ...,  -5.8310,  -5.6296,  -3.5659],\n",
      "         [-11.1982, -11.2011, -10.9948,  ...,  -7.6291,  -8.3793,  -8.0508],\n",
      "         [ -5.8172,  -5.7077,  -5.8338,  ...,  -6.2022,  -7.7918,  -1.4142],\n",
      "         ...,\n",
      "         [ -5.2722,  -5.0505,  -5.0642,  ...,  -5.1124,  -6.7814,  -2.6111],\n",
      "         [ -5.1665,  -4.9487,  -5.0244,  ...,  -5.4122,  -6.7042,  -2.0029],\n",
      "         [ -5.5608,  -5.4749,  -5.4810,  ...,  -5.4467,  -6.9981,  -3.3050]],\n",
      "\n",
      "        [[ -6.7295,  -6.7243,  -6.7403,  ...,  -6.1406,  -6.0104,  -3.8913],\n",
      "         [-13.6650, -13.6807, -13.5972,  ..., -12.8506, -12.4909, -12.6263],\n",
      "         [ -6.9710,  -7.1133,  -7.0015,  ...,  -6.2679,  -6.9560,  -7.3397],\n",
      "         ...,\n",
      "         [ -6.0332,  -6.0489,  -5.9112,  ...,  -5.8158,  -6.1268,  -4.5739],\n",
      "         [ -7.9357,  -7.8459,  -7.8793,  ...,  -7.7271,  -7.8258,  -6.3352],\n",
      "         [ -6.8693,  -6.7212,  -6.7833,  ...,  -6.9458,  -7.2795,  -4.6875]],\n",
      "\n",
      "        [[ -7.2770,  -7.3021,  -7.2981,  ...,  -6.4631,  -6.6029,  -4.0281],\n",
      "         [-13.1526, -13.5618, -13.3881,  ..., -12.6542, -10.4715, -10.9980],\n",
      "         [ -9.5934, -10.0223,  -9.1143,  ..., -10.0502,  -8.8554,  -9.2411],\n",
      "         ...,\n",
      "         [-10.6908, -11.0962, -10.9031,  ...,  -9.7879, -10.7944, -12.3613],\n",
      "         [ -8.5852,  -8.7922,  -8.8834,  ...,  -6.6156,  -7.7997,  -6.3878],\n",
      "         [-13.2206, -12.7786, -13.4087,  ...,  -9.2409, -10.7868,  -9.4562]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5264,  -6.5744,  -6.5073,  ...,  -6.0122,  -5.9144,  -3.8933],\n",
      "         [-11.8796, -12.2814, -12.2367,  ..., -10.8286, -10.4590,  -8.3496],\n",
      "         [ -7.4790,  -7.7026,  -8.0644,  ...,  -7.9892,  -6.2510, -10.1032],\n",
      "         ...,\n",
      "         [ -7.0498,  -7.2003,  -7.2342,  ...,  -7.0234,  -7.0607,  -5.8225],\n",
      "         [ -7.8256,  -7.8328,  -8.1038,  ...,  -8.0723,  -7.8871,  -5.4717],\n",
      "         [ -7.5225,  -7.4621,  -7.7136,  ...,  -7.4984,  -7.5998,  -6.5919]],\n",
      "\n",
      "        [[ -6.4802,  -6.4514,  -6.4756,  ...,  -5.8627,  -5.6794,  -3.9956],\n",
      "         [-11.1806, -10.9117, -11.0872,  ...,  -8.1021,  -7.8282, -10.5572],\n",
      "         [ -7.8999,  -7.8263,  -7.8762,  ...,  -7.7484,  -7.6149,  -6.0990],\n",
      "         ...,\n",
      "         [ -8.0049,  -7.9078,  -8.0275,  ...,  -7.3300,  -7.5162,  -6.3980],\n",
      "         [ -8.0042,  -8.0223,  -8.0439,  ...,  -7.6582,  -7.7631,  -5.1684],\n",
      "         [ -7.4878,  -7.4645,  -7.5082,  ...,  -7.2303,  -7.3656,  -4.2527]],\n",
      "\n",
      "        [[ -8.5470,  -8.4631,  -8.4589,  ...,  -7.4649,  -7.8543,  -4.8973],\n",
      "         [-10.4698,  -9.9150, -10.0486,  ...,  -8.1438,  -8.0762,  -7.5495],\n",
      "         [ -5.3129,  -5.2257,  -5.2165,  ...,  -6.2000,  -7.1273,  -2.4485],\n",
      "         ...,\n",
      "         [ -5.7074,  -5.5233,  -5.3961,  ...,  -6.1428,  -7.3355,  -3.7420],\n",
      "         [ -6.9020,  -6.7868,  -6.6356,  ...,  -7.3934,  -7.7901,  -4.2972],\n",
      "         [ -6.4615,  -6.3255,  -6.3811,  ...,  -6.7755,  -7.9719,  -3.3959]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.0674679279327393\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8414, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1184,  -7.1474,  -7.1179,  ...,  -6.5099,  -6.2468,  -4.3369],\n",
      "         [-13.0096, -13.1286, -13.0065,  ..., -12.4102,  -9.5031, -12.9374],\n",
      "         [ -7.2617,  -7.2924,  -7.5497,  ...,  -5.7612,  -5.8577,  -8.5842],\n",
      "         ...,\n",
      "         [ -6.2564,  -6.4516,  -6.2767,  ...,  -5.7997,  -4.7409,  -5.9405],\n",
      "         [ -6.5061,  -6.7448,  -6.5982,  ...,  -6.3345,  -4.5712,  -6.5507],\n",
      "         [ -4.5776,  -4.7274,  -4.7457,  ...,  -5.4961,  -3.2523,  -6.2209]],\n",
      "\n",
      "        [[ -7.5478,  -7.4476,  -7.4153,  ...,  -6.8045,  -6.8337,  -4.6842],\n",
      "         [ -9.0766,  -8.4453,  -8.6638,  ...,  -7.5867,  -7.0301,  -8.5849],\n",
      "         [ -6.0320,  -6.0497,  -6.0668,  ...,  -6.5775,  -7.5813,  -3.1770],\n",
      "         ...,\n",
      "         [ -6.4431,  -6.1664,  -6.3497,  ...,  -6.6074,  -7.8416,  -3.5496],\n",
      "         [ -5.8995,  -5.7859,  -5.7521,  ...,  -6.3382,  -7.2078,  -3.1386],\n",
      "         [ -6.3116,  -6.1556,  -6.1778,  ...,  -6.3349,  -7.0148,  -3.8006]],\n",
      "\n",
      "        [[ -6.7920,  -6.8104,  -6.7568,  ...,  -6.2478,  -6.0714,  -4.1332],\n",
      "         [ -5.7744,  -5.6893,  -5.8864,  ...,  -5.9073,  -6.7918,  -1.6767],\n",
      "         [-13.7473, -14.1026, -13.5405,  ..., -12.9576, -12.7834, -10.5034],\n",
      "         ...,\n",
      "         [ -6.2640,  -6.3240,  -6.2753,  ...,  -5.9865,  -5.9430,  -3.7688],\n",
      "         [ -8.5385,  -8.5375,  -8.2045,  ...,  -7.9163,  -7.0487,  -4.8017],\n",
      "         [-15.8955, -15.2073, -15.6069,  ..., -12.8269, -12.1905, -10.8705]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8042,  -6.7572,  -6.7815,  ...,  -6.1953,  -6.0445,  -3.8864],\n",
      "         [ -9.3833,  -9.1500,  -9.1567,  ...,  -9.7147,  -9.3780,  -4.8627],\n",
      "         [ -8.0399,  -7.9472,  -7.9107,  ...,  -8.2526,  -8.3348,  -3.9597],\n",
      "         ...,\n",
      "         [ -7.0845,  -7.0048,  -7.0549,  ...,  -7.0697,  -7.1681,  -3.0005],\n",
      "         [ -7.2739,  -7.2193,  -7.2060,  ...,  -7.3984,  -7.2490,  -3.7242],\n",
      "         [ -7.0910,  -6.9290,  -6.9719,  ...,  -7.2747,  -7.3985,  -3.2828]],\n",
      "\n",
      "        [[ -6.8161,  -6.7919,  -6.7970,  ...,  -6.1709,  -5.9859,  -3.7023],\n",
      "         [ -7.7677,  -7.4789,  -7.5162,  ...,  -7.4040,  -7.9052,  -1.8340],\n",
      "         [ -7.3545,  -7.1697,  -7.0766,  ...,  -6.8103,  -7.0587,  -3.4099],\n",
      "         ...,\n",
      "         [ -6.5276,  -6.4734,  -6.5411,  ...,  -6.2413,  -6.3455,  -0.4942],\n",
      "         [ -6.7368,  -6.7190,  -6.6824,  ...,  -6.2226,  -6.3000,  -1.6295],\n",
      "         [ -6.6751,  -6.4826,  -6.5958,  ...,  -6.3552,  -6.3016,  -1.4470]],\n",
      "\n",
      "        [[ -7.3134,  -7.2412,  -7.3267,  ...,  -6.6009,  -6.9357,  -4.3171],\n",
      "         [-11.6659, -11.3019, -11.4733,  ..., -11.2353,  -8.9239,  -8.0481],\n",
      "         [ -5.4653,  -5.5370,  -5.5004,  ...,  -6.3323,  -7.4401,  -2.4541],\n",
      "         ...,\n",
      "         [ -5.5417,  -5.3306,  -5.4176,  ...,  -5.2382,  -6.9379,  -2.1674],\n",
      "         [ -5.8287,  -5.6926,  -5.8076,  ...,  -6.3874,  -7.7317,  -1.8730],\n",
      "         [ -5.3188,  -5.2389,  -5.2841,  ...,  -5.0242,  -7.2443,  -1.8474]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.8414130210876465\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1633, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6746,  -6.6813,  -6.6816,  ...,  -6.0931,  -5.9199,  -4.0451],\n",
      "         [ -5.7644,  -5.5083,  -5.6806,  ...,  -6.9058,  -5.1546,  -3.5138],\n",
      "         [-11.5342, -11.8169, -11.5824,  ...,  -9.8197,  -9.2009, -11.7639],\n",
      "         ...,\n",
      "         [ -5.5799,  -5.7721,  -5.6122,  ...,  -6.7210,  -5.4276,  -6.0975],\n",
      "         [ -4.4652,  -4.7413,  -4.4769,  ...,  -4.8029,  -5.0034,  -4.4206],\n",
      "         [-12.8623, -12.4098, -12.9542,  ..., -10.7159,  -9.0183, -11.0770]],\n",
      "\n",
      "        [[ -6.3872,  -6.3437,  -6.3674,  ...,  -5.7015,  -5.5970,  -3.8320],\n",
      "         [ -6.3690,  -6.2227,  -6.3077,  ...,  -5.9664,  -5.8104,  -2.8889],\n",
      "         [ -9.0792,  -8.9626,  -8.9747,  ...,  -7.6811,  -8.2324,  -6.4145],\n",
      "         ...,\n",
      "         [ -6.2105,  -6.0090,  -6.0948,  ...,  -4.8444,  -5.9924,  -5.1338],\n",
      "         [ -5.6603,  -5.4537,  -5.5593,  ...,  -4.9748,  -5.9396,  -4.3490],\n",
      "         [ -5.9098,  -5.6816,  -5.8884,  ...,  -4.8935,  -5.9445,  -4.7378]],\n",
      "\n",
      "        [[ -6.6527,  -6.6474,  -6.6391,  ...,  -6.0342,  -5.9475,  -3.8451],\n",
      "         [ -6.9708,  -6.6349,  -7.1049,  ...,  -5.0205,  -6.0872,  -7.7734],\n",
      "         [ -6.6429,  -6.4422,  -6.7088,  ...,  -6.6303,  -4.3139,  -5.9502],\n",
      "         ...,\n",
      "         [ -9.1263,  -8.6655,  -8.6372,  ..., -10.0127,  -7.4758,  -7.9641],\n",
      "         [-14.0024, -13.9539, -13.8291,  ..., -13.4862, -11.4752, -11.7392],\n",
      "         [-11.7795, -11.0520, -11.7940,  ...,  -9.5082,  -9.2518,  -6.0282]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9715,  -7.0043,  -6.9381,  ...,  -6.3224,  -6.0176,  -4.3125],\n",
      "         [ -9.7991,  -9.8601,  -9.7917,  ..., -10.5666,  -8.2384,  -8.9714],\n",
      "         [ -6.9976,  -7.0441,  -6.9765,  ...,  -8.8911,  -6.7961,  -7.4692],\n",
      "         ...,\n",
      "         [ -5.2916,  -5.3462,  -5.5677,  ...,  -5.9402,  -3.5424,  -4.8206],\n",
      "         [ -6.0202,  -5.8434,  -6.0514,  ...,  -6.0195,  -4.2679,  -5.1762],\n",
      "         [-13.4667, -12.9091, -13.5797,  ..., -11.1141, -10.7772,  -7.6375]],\n",
      "\n",
      "        [[ -6.6447,  -6.6344,  -6.7141,  ...,  -6.1385,  -5.9598,  -3.5955],\n",
      "         [ -8.7911,  -8.6538,  -8.7677,  ...,  -9.2427,  -8.6366,  -4.1906],\n",
      "         [ -8.6930,  -8.4072,  -8.5103,  ...,  -8.6481,  -8.3649,  -4.1461],\n",
      "         ...,\n",
      "         [ -6.9280,  -6.7577,  -6.8363,  ...,  -6.6832,  -6.6076,  -3.2404],\n",
      "         [ -7.2342,  -7.0364,  -7.1279,  ...,  -6.8845,  -7.1784,  -2.9389],\n",
      "         [ -6.7321,  -6.5682,  -6.7238,  ...,  -6.4132,  -6.8665,  -2.6876]],\n",
      "\n",
      "        [[ -7.1636,  -7.1564,  -7.1070,  ...,  -6.5097,  -6.3687,  -4.6515],\n",
      "         [-12.0562, -12.2053, -11.8654,  ..., -13.8904, -12.1055,  -8.8153],\n",
      "         [-15.2864, -15.2452, -14.9990,  ..., -13.8814, -12.7853, -13.1377],\n",
      "         ...,\n",
      "         [ -8.5063,  -8.5583,  -8.5852,  ...,  -7.8758,  -8.1542,  -4.3242],\n",
      "         [ -6.8251,  -6.9948,  -6.7699,  ...,  -6.6821,  -6.0776,  -5.5227],\n",
      "         [ -8.3805,  -8.6277,  -8.2837,  ...,  -8.6962,  -8.3083,  -6.5271]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1632754802703857\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2368, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5014,  -7.3801,  -7.4184,  ...,  -6.5803,  -6.7401,  -4.4591],\n",
      "         [-10.1978, -10.0325, -10.0343,  ...,  -6.8231,  -8.8323, -11.1407],\n",
      "         [ -5.2078,  -5.0976,  -5.2114,  ...,  -5.6408,  -7.2675,  -1.0176],\n",
      "         ...,\n",
      "         [ -6.2571,  -6.0196,  -6.1911,  ...,  -6.7924,  -8.1089,  -1.8159],\n",
      "         [ -5.4899,  -5.3825,  -5.3882,  ...,  -5.7280,  -7.7946,  -2.4976],\n",
      "         [ -6.0429,  -5.9815,  -6.0541,  ...,  -6.2826,  -8.0240,  -2.6765]],\n",
      "\n",
      "        [[ -6.8059,  -6.7124,  -6.7493,  ...,  -5.8497,  -6.3072,  -4.0082],\n",
      "         [ -9.6393,  -9.3894,  -9.6255,  ...,  -6.9634,  -8.3389,  -7.7879],\n",
      "         [ -7.0719,  -7.1515,  -7.1435,  ...,  -7.4692,  -8.5673,  -3.6472],\n",
      "         ...,\n",
      "         [ -7.1130,  -7.0568,  -7.1557,  ...,  -6.9844,  -7.9129,  -3.6113],\n",
      "         [ -6.2324,  -6.2439,  -6.3509,  ...,  -6.4511,  -7.2725,  -2.5028],\n",
      "         [ -7.6025,  -7.5865,  -7.7202,  ...,  -8.1592,  -9.0000,  -4.5712]],\n",
      "\n",
      "        [[ -6.5988,  -6.5795,  -6.6006,  ...,  -6.0204,  -5.7861,  -3.6513],\n",
      "         [ -7.3418,  -7.2540,  -7.3805,  ...,  -7.4861,  -7.7097,  -4.9543],\n",
      "         [ -9.4395,  -9.8132,  -9.9174,  ...,  -8.3907,  -8.5760, -10.0368],\n",
      "         ...,\n",
      "         [-13.2608, -13.7488, -13.7463,  ..., -12.7249, -11.9751, -10.4981],\n",
      "         [ -5.5066,  -5.2911,  -5.3663,  ...,  -4.2672,  -4.6071,  -3.5272],\n",
      "         [-12.2688, -11.8467, -11.8911,  ...,  -9.7648, -10.1009,  -6.6435]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7245,  -6.7183,  -6.7117,  ...,  -6.1429,  -5.9833,  -3.9825],\n",
      "         [ -5.8172,  -5.7911,  -5.8391,  ...,  -5.3916,  -4.8551,  -5.2959],\n",
      "         [ -5.9329,  -5.9434,  -5.9943,  ...,  -5.2839,  -5.0176,  -2.6018],\n",
      "         ...,\n",
      "         [ -7.1683,  -7.0942,  -7.2387,  ...,  -6.7191,  -6.7480,  -4.4872],\n",
      "         [ -7.2217,  -7.0885,  -7.2854,  ...,  -6.9516,  -6.4464,  -3.9646],\n",
      "         [ -7.5748,  -7.5646,  -7.6166,  ...,  -7.5261,  -6.6905,  -4.4273]],\n",
      "\n",
      "        [[ -6.5132,  -6.4871,  -6.4678,  ...,  -6.0561,  -5.8186,  -3.9075],\n",
      "         [-11.8750, -12.0390, -12.3462,  ...,  -9.3603, -12.0866, -10.7600],\n",
      "         [ -9.5509,  -9.4075,  -9.9262,  ...,  -8.6186, -10.0317,  -5.3572],\n",
      "         ...,\n",
      "         [ -8.0684,  -8.0169,  -8.2142,  ...,  -7.9975,  -8.2833,  -5.9287],\n",
      "         [ -8.0335,  -7.8792,  -8.1137,  ...,  -7.8149,  -8.0724,  -5.6211],\n",
      "         [ -7.9092,  -7.8427,  -8.1105,  ...,  -7.9262,  -8.3206,  -5.0992]],\n",
      "\n",
      "        [[ -6.5786,  -6.5471,  -6.4867,  ...,  -5.8568,  -5.5811,  -3.3648],\n",
      "         [-11.4451, -11.3756, -10.9191,  ..., -10.4132,  -9.6673,  -3.6565],\n",
      "         [ -4.0382,  -4.0730,  -4.1752,  ...,  -4.0606,  -4.2782,   1.2172],\n",
      "         ...,\n",
      "         [ -2.4228,  -2.5261,  -2.3570,  ...,  -3.0814,  -2.0463,   1.4137],\n",
      "         [ -9.0390,  -9.3552,  -8.6597,  ...,  -8.8294,  -7.1264,  -4.4396],\n",
      "         [-12.3274, -12.0321, -12.3391,  ...,  -9.3010, -10.2500,  -7.7491]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.2368462085723877\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7489, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7583,  -6.8009,  -6.7789,  ...,  -6.2493,  -6.3358,  -3.9967],\n",
      "         [-11.2930, -11.5941, -11.4963,  ..., -10.5437,  -9.7787,  -9.0973],\n",
      "         [ -8.3432,  -8.4118,  -8.6259,  ...,  -7.6642,  -6.7881,  -8.1196],\n",
      "         ...,\n",
      "         [ -7.1051,  -6.9778,  -7.0322,  ...,  -7.5660,  -6.8985,  -6.4756],\n",
      "         [ -7.0192,  -6.8218,  -6.9435,  ...,  -7.0172,  -6.4797,  -6.0315],\n",
      "         [ -7.1867,  -7.1544,  -7.2053,  ...,  -7.2573,  -7.1846,  -5.1880]],\n",
      "\n",
      "        [[ -6.8168,  -6.7885,  -6.7884,  ...,  -6.1411,  -5.9579,  -4.1257],\n",
      "         [-11.4064, -11.4103, -11.0195,  ..., -12.0667, -10.7761,  -8.3040],\n",
      "         [-16.3965, -15.9670, -16.3572,  ..., -13.8156, -13.5087, -14.4869],\n",
      "         ...,\n",
      "         [ -6.9541,  -7.0002,  -6.8910,  ...,  -7.6179,  -6.7983,  -4.6629],\n",
      "         [ -6.7608,  -6.4992,  -6.4547,  ...,  -6.9445,  -5.8593,  -2.1624],\n",
      "         [ -8.2922,  -8.1858,  -8.1474,  ...,  -8.3020,  -7.0367,  -5.1926]],\n",
      "\n",
      "        [[ -7.0682,  -7.0492,  -7.0050,  ...,  -6.3820,  -6.4559,  -3.8840],\n",
      "         [ -8.2855,  -8.2096,  -8.2024,  ...,  -8.1767,  -7.2239,  -3.5171],\n",
      "         [ -8.0361,  -7.9803,  -7.8379,  ...,  -7.4668,  -6.6440,  -2.2203],\n",
      "         ...,\n",
      "         [ -5.9242,  -5.7217,  -5.7209,  ...,  -4.5050,  -5.5229,  -2.3549],\n",
      "         [ -1.3324,  -1.4263,  -1.7085,  ...,  -1.1203,  -1.5325,  -1.6294],\n",
      "         [-11.4914, -11.3145, -11.5373,  ...,  -7.1311,  -7.3109,  -7.2585]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6768,  -6.6447,  -6.6580,  ...,  -5.9670,  -5.9781,  -4.1159],\n",
      "         [ -8.9808,  -8.4327,  -8.8878,  ...,  -5.5338,  -7.1588,  -5.7593],\n",
      "         [ -4.9626,  -4.9169,  -4.8584,  ...,  -5.5971,  -7.1343,  -1.6374],\n",
      "         ...,\n",
      "         [ -5.0086,  -4.9929,  -4.8759,  ...,  -5.2290,  -7.2546,  -2.6022],\n",
      "         [ -5.0903,  -5.0525,  -5.0831,  ...,  -5.4145,  -7.6979,  -1.4972],\n",
      "         [ -5.6597,  -5.5778,  -5.5661,  ...,  -5.4926,  -7.3359,  -2.9608]],\n",
      "\n",
      "        [[ -6.8333,  -6.7764,  -6.7246,  ...,  -6.4475,  -5.8441,  -3.3641],\n",
      "         [ -6.5154,  -6.3426,  -6.2527,  ...,  -7.5951,  -7.2798,  -1.1338],\n",
      "         [ -8.5915,  -8.6131,  -8.6787,  ...,  -8.0047,  -9.0535,  -3.4926],\n",
      "         ...,\n",
      "         [ -6.9732,  -6.7759,  -6.8190,  ...,  -7.3914,  -7.2172,  -2.0742],\n",
      "         [ -8.0232,  -7.9360,  -7.8762,  ...,  -8.5207,  -8.3506,  -2.7982],\n",
      "         [ -7.7862,  -7.5318,  -7.5880,  ...,  -8.1525,  -7.9017,  -2.4750]],\n",
      "\n",
      "        [[ -7.2132,  -7.2743,  -7.2291,  ...,  -6.3827,  -6.3340,  -4.2835],\n",
      "         [-11.9039, -11.8537, -11.9126,  ..., -10.3272,  -9.6987, -10.3795],\n",
      "         [-13.1206, -13.0435, -13.5255,  ..., -12.8714, -12.0737, -12.9941],\n",
      "         ...,\n",
      "         [-13.2210, -13.3312, -13.5224,  ..., -10.2751, -11.9166,  -9.9260],\n",
      "         [ -5.5367,  -5.6468,  -5.8758,  ...,  -3.8925,  -5.4235,  -3.9624],\n",
      "         [-13.3085, -12.8587, -13.2976,  ..., -10.0602, -10.4872,  -8.4169]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.7489376068115234\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.2882, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4705,  -6.5003,  -6.4942,  ...,  -5.7297,  -5.6184,  -3.8462],\n",
      "         [ -8.4750,  -8.1500,  -8.2700,  ...,  -8.3048,  -5.6225,  -7.7305],\n",
      "         [ -2.5383,  -2.4593,  -2.6309,  ...,  -3.0132,  -2.6927,  -4.3524],\n",
      "         ...,\n",
      "         [ -5.9017,  -5.7126,  -5.9130,  ...,  -4.9448,  -5.0973,  -5.5012],\n",
      "         [ -4.3020,  -4.4355,  -4.2130,  ...,  -3.5789,  -3.3875,  -5.3081],\n",
      "         [ -4.5024,  -4.4541,  -4.6273,  ...,  -4.3666,  -4.2928,  -5.3254]],\n",
      "\n",
      "        [[ -7.4288,  -7.3407,  -7.3452,  ...,  -6.9784,  -6.7740,  -4.8791],\n",
      "         [-12.6198, -12.4790, -12.4977,  ...,  -9.5451, -10.3847,  -9.7252],\n",
      "         [ -5.4303,  -5.4004,  -5.3831,  ...,  -5.7243,  -7.3836,  -2.9077],\n",
      "         ...,\n",
      "         [ -5.6635,  -5.5776,  -5.6373,  ...,  -5.9516,  -7.7152,  -3.1018],\n",
      "         [ -5.5337,  -5.2695,  -5.4432,  ...,  -5.8742,  -7.5863,  -2.8681],\n",
      "         [ -5.6489,  -5.4237,  -5.6116,  ...,  -5.5590,  -7.5338,  -4.3335]],\n",
      "\n",
      "        [[ -6.8741,  -6.7901,  -6.8032,  ...,  -6.1624,  -5.8251,  -4.4178],\n",
      "         [-12.1295, -11.9156, -11.6234,  ...,  -9.1880,  -8.2541,  -9.9493],\n",
      "         [ -5.8103,  -5.8161,  -5.7921,  ...,  -6.3760,  -7.3945,  -2.1739],\n",
      "         ...,\n",
      "         [ -6.2881,  -6.1782,  -6.1486,  ...,  -6.4763,  -7.8228,  -3.3266],\n",
      "         [ -6.1065,  -6.0934,  -6.0526,  ...,  -6.4254,  -7.6640,  -2.7499],\n",
      "         [ -6.0870,  -6.0651,  -5.8854,  ...,  -6.2240,  -7.1286,  -3.8900]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3703,  -7.3737,  -7.3440,  ...,  -6.6954,  -6.5681,  -3.9243],\n",
      "         [ -7.6823,  -7.5954,  -7.6391,  ...,  -7.0950,  -6.6044,  -5.0693],\n",
      "         [-11.3336, -11.3912, -11.6282,  ...,  -9.0927, -11.0633,  -8.8442],\n",
      "         ...,\n",
      "         [ -7.3700,  -7.3446,  -7.3543,  ...,  -7.0234,  -7.6722,  -4.1269],\n",
      "         [ -7.1304,  -7.1568,  -7.0775,  ...,  -6.6304,  -7.5565,  -4.1585],\n",
      "         [ -6.9116,  -7.1617,  -7.0784,  ...,  -6.7107,  -7.4938,  -4.7552]],\n",
      "\n",
      "        [[-10.7400, -10.7142, -10.4656,  ..., -10.1435, -10.3657,  -6.8470],\n",
      "         [ -7.5942,  -7.7484,  -7.2699,  ...,  -4.4038,  -5.6557, -11.1670],\n",
      "         [ -5.9388,  -6.0901,  -6.1112,  ...,  -6.5306,  -7.8863,  -3.9320],\n",
      "         ...,\n",
      "         [ -5.1273,  -5.2302,  -5.1540,  ...,  -5.6875,  -6.8809,  -4.3567],\n",
      "         [ -5.1509,  -5.1497,  -5.1912,  ...,  -6.0225,  -6.5000,  -2.8699],\n",
      "         [ -5.7099,  -5.6415,  -5.8678,  ...,  -6.1728,  -7.6871,  -4.2439]],\n",
      "\n",
      "        [[ -6.6973,  -6.6700,  -6.6861,  ...,  -6.0469,  -5.8555,  -3.8973],\n",
      "         [ -7.7285,  -7.6062,  -7.7542,  ...,  -8.1901,  -7.9783,  -3.2303],\n",
      "         [ -6.6344,  -6.5692,  -6.6639,  ...,  -7.5007,  -6.6336,  -4.2517],\n",
      "         ...,\n",
      "         [ -6.6881,  -6.6371,  -6.7657,  ...,  -6.9840,  -6.9345,  -3.0087],\n",
      "         [ -6.8532,  -6.7551,  -6.8658,  ...,  -6.7975,  -6.7664,  -3.8236],\n",
      "         [ -7.2662,  -7.1616,  -7.2868,  ...,  -7.3694,  -7.1488,  -3.4255]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 0.2881830930709839\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7497, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5082,  -6.4573,  -6.4682,  ...,  -5.9600,  -5.6499,  -4.1852],\n",
      "         [-13.6809, -13.2038, -13.2778,  ..., -11.4307, -10.6769,  -9.2385],\n",
      "         [ -6.6912,  -6.7235,  -6.7398,  ...,  -6.8059,  -7.2828,  -3.1906],\n",
      "         ...,\n",
      "         [ -6.3156,  -6.3750,  -6.2991,  ...,  -6.7050,  -7.5121,  -3.2468],\n",
      "         [ -5.8878,  -5.8461,  -5.8031,  ...,  -5.8978,  -5.9366,  -4.2632],\n",
      "         [ -6.2538,  -6.2585,  -6.1979,  ...,  -5.9177,  -6.4661,  -4.9046]],\n",
      "\n",
      "        [[ -6.5099,  -6.4832,  -6.4820,  ...,  -5.7766,  -5.8272,  -3.7177],\n",
      "         [-10.1287, -10.0075, -10.0154,  ..., -10.1768, -10.0884,  -4.2631],\n",
      "         [ -7.4577,  -7.1739,  -7.2970,  ...,  -6.9877,  -7.4057,  -3.4356],\n",
      "         ...,\n",
      "         [ -6.7187,  -6.6329,  -6.6993,  ...,  -6.7241,  -6.8902,  -2.7898],\n",
      "         [ -7.3585,  -7.2749,  -7.3745,  ...,  -7.3115,  -7.3453,  -3.0005],\n",
      "         [ -6.9761,  -6.9155,  -6.9422,  ...,  -6.8612,  -6.7307,  -2.6190]],\n",
      "\n",
      "        [[ -6.7044,  -6.6922,  -6.7184,  ...,  -6.2168,  -5.9401,  -4.2299],\n",
      "         [ -1.3471,  -1.4563,  -1.1945,  ...,  -2.4480,  -1.8235,  -2.2228],\n",
      "         [-12.2545, -11.8839, -11.7908,  ..., -10.9906,  -8.0633, -12.0665],\n",
      "         ...,\n",
      "         [ -7.3300,  -7.4144,  -7.2766,  ...,  -7.1964,  -7.5470,  -4.7867],\n",
      "         [ -6.0315,  -5.9795,  -6.0455,  ...,  -6.7796,  -6.9485,  -2.8898],\n",
      "         [ -7.1405,  -7.1846,  -7.0801,  ...,  -7.1618,  -7.1517,  -4.4653]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2680,  -7.2213,  -7.2079,  ...,  -6.6596,  -6.3825,  -3.9086],\n",
      "         [ -7.6096,  -7.7346,  -7.5937,  ...,  -7.2550,  -6.6959,  -2.8116],\n",
      "         [ -8.1310,  -8.2229,  -8.2293,  ...,  -7.5225,  -8.1686,  -6.4611],\n",
      "         ...,\n",
      "         [ -7.4101,  -7.5032,  -7.3747,  ...,  -6.0912,  -7.5542,  -8.3490],\n",
      "         [-13.6351, -13.6638, -13.7034,  ..., -13.2794, -11.3583,  -7.6111],\n",
      "         [-13.7947, -13.2056, -13.5485,  ..., -11.3814, -10.6200,  -8.6340]],\n",
      "\n",
      "        [[ -6.6715,  -6.6087,  -6.6618,  ...,  -6.0221,  -5.9466,  -4.1002],\n",
      "         [-10.1493,  -9.8344,  -9.8181,  ...,  -7.1571,  -6.3526,  -5.0323],\n",
      "         [ -5.3959,  -5.3843,  -5.3729,  ...,  -6.3996,  -7.7203,  -2.7064],\n",
      "         ...,\n",
      "         [ -6.3034,  -6.2794,  -6.2373,  ...,  -6.4083,  -8.0627,  -3.2725],\n",
      "         [ -6.2710,  -6.1304,  -6.1164,  ...,  -6.3351,  -7.8503,  -2.7204],\n",
      "         [ -5.6492,  -5.6982,  -5.6606,  ...,  -5.7768,  -7.3627,  -3.1038]],\n",
      "\n",
      "        [[ -6.7207,  -6.6983,  -6.6972,  ...,  -6.1869,  -6.2307,  -4.4220],\n",
      "         [-10.3675, -10.0362, -10.0617,  ...,  -6.0818,  -8.3700, -10.2122],\n",
      "         [ -6.3584,  -6.4573,  -6.4241,  ...,  -6.9281,  -8.1186,  -2.2187],\n",
      "         ...,\n",
      "         [ -6.4133,  -6.2937,  -6.3677,  ...,  -6.8567,  -8.3376,  -3.3721],\n",
      "         [ -6.2814,  -6.2956,  -6.2522,  ...,  -6.8598,  -8.2573,  -3.2049],\n",
      "         [ -7.2729,  -7.2715,  -7.2722,  ...,  -8.3239,  -8.8992,  -4.5539]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.7497286796569824\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5571, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0656,  -7.0924,  -7.0254,  ...,  -6.4566,  -6.2216,  -4.2358],\n",
      "         [ -4.7256,  -4.8029,  -4.5158,  ...,  -5.0993,  -5.4606,  -4.0689],\n",
      "         [ -9.5557,  -9.2820,  -9.5921,  ..., -10.5535,  -8.5915,  -7.9569],\n",
      "         ...,\n",
      "         [ -6.3211,  -6.4942,  -6.6231,  ...,  -6.9747,  -7.0809,  -5.6923],\n",
      "         [ -6.7129,  -6.8795,  -6.8507,  ...,  -8.3937,  -8.0477,  -5.5734],\n",
      "         [ -6.9186,  -7.1483,  -7.0910,  ...,  -7.6615,  -7.7766,  -5.7981]],\n",
      "\n",
      "        [[ -6.7281,  -6.8812,  -6.7190,  ...,  -6.8976,  -6.5567,  -2.9802],\n",
      "         [-11.4748, -11.0832, -11.1616,  ...,  -9.1041,  -8.9284,  -8.9213],\n",
      "         [ -7.3939,  -7.4402,  -7.4302,  ...,  -8.1391,  -7.7774,  -2.5254],\n",
      "         ...,\n",
      "         [ -7.2894,  -7.4096,  -7.3948,  ...,  -7.1743,  -6.6058,  -3.3429],\n",
      "         [ -7.5584,  -7.5047,  -7.5506,  ...,  -7.7549,  -7.3872,  -3.3861],\n",
      "         [ -7.6892,  -7.7517,  -7.7842,  ...,  -8.0450,  -8.0719,  -2.6647]],\n",
      "\n",
      "        [[ -7.0974,  -7.0990,  -7.0862,  ...,  -6.6373,  -6.2519,  -4.3555],\n",
      "         [-12.0398, -11.9504, -12.0221,  ..., -11.6179, -12.1942,  -9.0554],\n",
      "         [ -7.5137,  -7.7761,  -7.6387,  ...,  -7.0309,  -7.6427,  -7.4477],\n",
      "         ...,\n",
      "         [ -6.0669,  -6.1003,  -6.2562,  ...,  -6.1812,  -5.8841,  -4.9491],\n",
      "         [ -4.9177,  -4.7672,  -4.8463,  ...,  -5.1570,  -4.7940,  -3.1886],\n",
      "         [ -6.9277,  -7.0159,  -7.0754,  ...,  -6.8700,  -7.1521,  -5.7883]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6955,  -6.6692,  -6.6871,  ...,  -6.1316,  -5.8521,  -4.0161],\n",
      "         [ -6.9657,  -6.7475,  -6.8370,  ...,  -7.4123,  -6.9641,  -3.3149],\n",
      "         [ -8.7372,  -8.7314,  -8.7626,  ...,  -8.4776,  -8.1121,  -4.1855],\n",
      "         ...,\n",
      "         [ -6.4644,  -6.4008,  -6.5506,  ...,  -6.7373,  -6.5508,  -3.2775],\n",
      "         [ -6.8624,  -6.7614,  -6.8727,  ...,  -7.0430,  -6.6863,  -3.7654],\n",
      "         [ -7.3976,  -7.2540,  -7.3599,  ...,  -7.7353,  -7.0646,  -4.0973]],\n",
      "\n",
      "        [[ -8.1986,  -8.2222,  -8.2737,  ...,  -7.4224,  -8.1315,  -7.4559],\n",
      "         [-13.4575, -13.1280, -13.3927,  ...,  -9.7908, -11.0771, -11.8821],\n",
      "         [ -4.1470,  -4.2351,  -4.2496,  ...,  -5.3057,  -6.1526,  -4.2053],\n",
      "         ...,\n",
      "         [ -5.3625,  -5.1458,  -5.3495,  ...,  -6.0224,  -6.8671,  -5.1688],\n",
      "         [ -5.4176,  -5.3090,  -5.3636,  ...,  -5.9310,  -6.9906,  -3.9154],\n",
      "         [ -5.5164,  -5.5502,  -5.5547,  ...,  -5.8160,  -6.7012,  -4.7147]],\n",
      "\n",
      "        [[ -6.6484,  -6.6155,  -6.5862,  ...,  -5.8905,  -5.6991,  -4.2739],\n",
      "         [ -9.8212,  -9.6013,  -9.5624,  ...,  -8.7936,  -9.3049,  -7.4968],\n",
      "         [-10.9734, -10.9277, -11.0923,  ...,  -9.2222,  -9.9586, -11.5385],\n",
      "         ...,\n",
      "         [ -4.3460,  -4.7046,  -4.4187,  ...,  -5.2031,  -5.3237,  -3.2929],\n",
      "         [ -7.2327,  -7.3309,  -7.2905,  ...,  -7.5517,  -7.4528,  -6.8660],\n",
      "         [ -6.7831,  -6.9109,  -6.9012,  ...,  -6.8315,  -7.0733,  -6.1583]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.5571056604385376\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0370, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1800,  -7.1565,  -7.1040,  ...,  -6.4531,  -6.4180,  -4.3850],\n",
      "         [-11.5714, -11.4119, -11.2684,  ..., -10.1084,  -9.3380, -10.0214],\n",
      "         [ -8.1829,  -8.3896,  -8.1227,  ...,  -6.7792,  -6.6108, -10.3641],\n",
      "         ...,\n",
      "         [ -7.7373,  -7.8400,  -7.5981,  ...,  -8.1364,  -7.5484,  -5.7205],\n",
      "         [ -2.2048,  -2.1387,  -2.4354,  ...,  -2.5824,  -2.1892,  -2.0796],\n",
      "         [-12.2215, -11.8489, -12.0303,  ..., -10.6311,  -8.8146,  -9.4872]],\n",
      "\n",
      "        [[ -7.9723,  -7.9634,  -8.0281,  ...,  -6.8969,  -6.9157,  -4.2189],\n",
      "         [ -9.1469,  -9.0898,  -9.4116,  ...,  -7.9319,  -7.4247,  -7.5263],\n",
      "         [ -8.7335,  -8.5571,  -9.1455,  ...,  -8.0598,  -7.4827,  -7.1699],\n",
      "         ...,\n",
      "         [ -8.1407,  -8.1008,  -8.0165,  ...,  -6.3193,  -6.1672,  -7.5675],\n",
      "         [ -9.0051,  -8.8571,  -8.8326,  ...,  -8.0134,  -7.9456,  -6.4557],\n",
      "         [ -8.9161,  -8.6888,  -8.6771,  ...,  -7.6975,  -7.4616,  -6.4089]],\n",
      "\n",
      "        [[ -7.2959,  -7.2565,  -7.3033,  ...,  -6.4914,  -6.7306,  -4.6025],\n",
      "         [-11.9939, -11.4901, -11.4260,  ...,  -7.8410,  -9.3075,  -7.6960],\n",
      "         [ -5.5463,  -5.5374,  -5.5155,  ...,  -6.2809,  -7.2275,  -3.5009],\n",
      "         ...,\n",
      "         [ -5.6108,  -5.4689,  -5.6353,  ...,  -5.9998,  -6.9904,  -3.0236],\n",
      "         [ -5.0657,  -5.1560,  -5.1032,  ...,  -5.1776,  -6.5951,  -3.9321],\n",
      "         [ -4.4451,  -4.3609,  -4.4512,  ...,  -4.3481,  -6.0959,  -3.9300]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7826,  -6.7348,  -6.7584,  ...,  -6.0796,  -5.9088,  -4.0665],\n",
      "         [-10.0468,  -9.8484,  -9.9472,  ...,  -7.7001,  -7.1542,  -7.0487],\n",
      "         [ -6.2667,  -6.2627,  -6.2810,  ...,  -6.3672,  -7.5115,  -3.0250],\n",
      "         ...,\n",
      "         [ -5.4752,  -5.4082,  -5.3759,  ...,  -5.8874,  -6.8668,  -2.4224],\n",
      "         [ -5.5654,  -5.5072,  -5.4298,  ...,  -5.5706,  -7.0040,  -2.8644],\n",
      "         [ -6.2976,  -6.1299,  -6.0984,  ...,  -6.3405,  -7.7390,  -3.1538]],\n",
      "\n",
      "        [[ -6.4674,  -6.4657,  -6.4670,  ...,  -5.9188,  -5.6844,  -3.8612],\n",
      "         [ -6.4804,  -6.5073,  -6.6786,  ...,  -6.6723,  -6.6926,  -3.4810],\n",
      "         [ -7.2722,  -7.1227,  -7.1458,  ...,  -7.6233,  -6.8680,  -3.9756],\n",
      "         ...,\n",
      "         [ -6.5808,  -6.5208,  -6.6975,  ...,  -6.5192,  -6.5509,  -2.9643],\n",
      "         [ -7.3283,  -7.3299,  -7.4139,  ...,  -7.1626,  -6.8567,  -3.9580],\n",
      "         [ -6.8040,  -6.7174,  -6.8421,  ...,  -6.8314,  -6.8234,  -3.3848]],\n",
      "\n",
      "        [[ -6.9515,  -6.9754,  -6.9734,  ...,  -6.2753,  -6.1328,  -4.3058],\n",
      "         [ -7.5389,  -7.1210,  -7.5417,  ...,  -7.3035,  -7.3583,  -5.8559],\n",
      "         [ -6.5812,  -6.8062,  -6.5230,  ...,  -7.8319,  -6.8449,  -5.2008],\n",
      "         ...,\n",
      "         [ -6.6846,  -6.4247,  -6.4531,  ...,  -6.3171,  -4.3469,  -6.4726],\n",
      "         [-10.0453, -10.5015, -10.0868,  ...,  -9.8941,  -9.0390, -11.8094],\n",
      "         [-11.4800, -11.2022, -11.2753,  ..., -10.9080,  -8.4012,  -8.6535]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.0369763374328613\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6272, grad_fn=<NllLossBackward0>), logits=tensor([[[-12.6231, -12.4879, -12.1973,  ..., -12.1826, -13.4338,  -9.3605],\n",
      "         [-14.3817, -13.9791, -13.7091,  ..., -12.0810, -11.2449, -11.3928],\n",
      "         [ -6.2392,  -6.3131,  -6.2824,  ...,  -6.9354,  -8.1948,  -4.1720],\n",
      "         ...,\n",
      "         [ -6.0377,  -6.0832,  -6.0982,  ...,  -6.3840,  -8.4518,  -2.3873],\n",
      "         [ -6.2591,  -6.2374,  -6.2844,  ...,  -5.8861,  -8.5308,  -4.4244],\n",
      "         [ -5.9629,  -6.0175,  -6.0680,  ...,  -6.6261,  -8.3783,  -2.9203]],\n",
      "\n",
      "        [[ -6.8018,  -6.7996,  -6.8129,  ...,  -6.1658,  -5.9281,  -4.5289],\n",
      "         [ -5.3983,  -5.6909,  -5.3516,  ...,  -6.3190,  -4.8620,  -8.3661],\n",
      "         [ -4.2015,  -4.2619,  -4.2435,  ...,  -5.0363,  -4.4687,  -6.3273],\n",
      "         ...,\n",
      "         [-10.9449, -10.5329, -10.7089,  ..., -10.3361,  -7.7721, -11.9936],\n",
      "         [ -8.3208,  -8.3952,  -8.3123,  ...,  -9.5275,  -7.3483, -10.8779],\n",
      "         [-13.6328, -13.4097, -13.5537,  ...,  -9.5756, -11.2669, -11.4896]],\n",
      "\n",
      "        [[ -9.0434,  -8.9783,  -9.1043,  ...,  -8.0080,  -8.5054,  -6.3170],\n",
      "         [-10.2566, -10.0179, -10.0248,  ...,  -8.1065,  -8.4016,  -8.9380],\n",
      "         [ -5.5978,  -5.4623,  -5.7400,  ...,  -6.2599,  -7.1243,  -3.6968],\n",
      "         ...,\n",
      "         [ -6.9445,  -6.7436,  -6.7836,  ...,  -7.3916,  -8.0788,  -4.2121],\n",
      "         [ -6.0900,  -6.0328,  -6.1393,  ...,  -6.3257,  -7.4371,  -5.3755],\n",
      "         [ -6.7227,  -6.6201,  -6.5745,  ...,  -6.9012,  -7.7896,  -4.5718]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7758,  -6.7589,  -6.7537,  ...,  -6.1563,  -5.9805,  -4.1867],\n",
      "         [ -6.6162,  -6.7069,  -6.5935,  ...,  -6.4464,  -5.8505,  -5.1575],\n",
      "         [ -6.4164,  -6.5214,  -6.5874,  ...,  -5.7456,  -6.2490,  -3.6221],\n",
      "         ...,\n",
      "         [ -7.2151,  -7.2719,  -7.3249,  ...,  -7.3281,  -6.7826,  -5.1051],\n",
      "         [ -6.5448,  -6.7022,  -6.6155,  ...,  -6.8333,  -5.3148,  -5.1742],\n",
      "         [ -7.3129,  -7.3753,  -7.4483,  ...,  -7.6721,  -6.7217,  -5.5605]],\n",
      "\n",
      "        [[ -6.2641,  -6.2732,  -6.2570,  ...,  -5.7061,  -5.4329,  -3.9678],\n",
      "         [-11.0656, -11.1671, -11.1566,  ...,  -9.3211,  -7.5697, -10.6891],\n",
      "         [ -6.9387,  -7.0412,  -7.1862,  ...,  -7.1326,  -7.8633, -12.1712],\n",
      "         ...,\n",
      "         [ -6.4809,  -6.4866,  -6.5166,  ...,  -7.0075,  -6.4926,  -7.9778],\n",
      "         [ -6.5333,  -6.6008,  -6.5583,  ...,  -7.1458,  -6.7653,  -7.4884],\n",
      "         [ -6.6285,  -6.6969,  -6.6366,  ...,  -7.1773,  -6.6957,  -7.6628]],\n",
      "\n",
      "        [[ -6.7489,  -6.7234,  -6.6928,  ...,  -6.1218,  -5.8130,  -4.1147],\n",
      "         [-10.2013, -10.5011, -10.5724,  ...,  -8.1079,  -6.4720,  -7.5747],\n",
      "         [-10.9737, -11.2551, -11.7346,  ...,  -8.9953,  -9.1115, -10.1519],\n",
      "         ...,\n",
      "         [ -6.0635,  -6.1290,  -6.1919,  ...,  -6.2030,  -5.5902,  -5.3601],\n",
      "         [ -6.0963,  -6.0818,  -6.2239,  ...,  -6.3536,  -6.0767,  -5.0915],\n",
      "         [ -6.5402,  -6.5034,  -6.6196,  ...,  -6.7414,  -5.9930,  -5.9971]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.627195119857788\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2839, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7198,  -6.6577,  -6.6795,  ...,  -5.9954,  -5.8964,  -4.0367],\n",
      "         [-12.9286, -12.2111, -12.5783,  ...,  -9.5928,  -8.9852,  -8.8401],\n",
      "         [ -6.8589,  -6.9043,  -6.7957,  ...,  -6.6971,  -7.1890,  -3.1460],\n",
      "         ...,\n",
      "         [ -7.0474,  -7.0192,  -7.0517,  ...,  -6.9881,  -7.8371,  -3.1849],\n",
      "         [ -6.3884,  -6.4642,  -6.3926,  ...,  -6.6281,  -7.1340,  -2.4676],\n",
      "         [ -6.6534,  -6.6827,  -6.5457,  ...,  -6.3326,  -7.0094,  -3.4190]],\n",
      "\n",
      "        [[ -7.2396,  -7.1940,  -7.2342,  ...,  -6.5060,  -6.5472,  -4.2157],\n",
      "         [ -6.3567,  -5.6863,  -5.7490,  ...,  -4.5319,  -5.9734,  -7.1935],\n",
      "         [ -5.8033,  -5.9717,  -5.9447,  ...,  -6.2050,  -7.4857,  -2.6654],\n",
      "         ...,\n",
      "         [ -5.9105,  -5.9227,  -5.8788,  ...,  -5.5626,  -7.0438,  -2.1885],\n",
      "         [ -5.2410,  -5.2179,  -5.1125,  ...,  -5.4185,  -6.9583,  -2.1222],\n",
      "         [ -6.0247,  -5.9709,  -5.9355,  ...,  -5.8819,  -6.6831,  -2.6460]],\n",
      "\n",
      "        [[ -7.1310,  -7.0250,  -7.0719,  ...,  -6.2001,  -6.0393,  -4.3172],\n",
      "         [-10.7028, -10.3074, -10.4148,  ...,  -8.3399,  -7.9127, -11.1308],\n",
      "         [ -5.5610,  -5.5787,  -5.5825,  ...,  -5.5378,  -7.1510,  -2.0368],\n",
      "         ...,\n",
      "         [ -5.8512,  -5.5888,  -5.7072,  ...,  -5.8945,  -7.2804,  -3.5447],\n",
      "         [ -5.7417,  -5.6367,  -5.6296,  ...,  -6.0016,  -7.1062,  -3.1851],\n",
      "         [ -6.3497,  -5.9752,  -6.1590,  ...,  -6.3995,  -7.6131,  -3.2716]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8522,  -6.8431,  -6.7656,  ...,  -6.2453,  -5.8670,  -4.1920],\n",
      "         [ -9.1383,  -9.2696,  -8.9372,  ...,  -7.7617,  -7.3242,  -8.8421],\n",
      "         [ -7.5269,  -7.6800,  -7.5346,  ...,  -7.4203,  -6.3356,  -7.2051],\n",
      "         ...,\n",
      "         [-13.7565, -14.1469, -13.5305,  ..., -12.9996, -13.9585,  -8.3208],\n",
      "         [-14.7040, -14.9063, -14.6711,  ..., -12.4925, -12.1110, -11.3288],\n",
      "         [-13.9461, -13.6594, -13.5634,  ..., -11.4848, -11.7421, -11.6222]],\n",
      "\n",
      "        [[ -6.7979,  -6.8182,  -6.7755,  ...,  -5.9752,  -5.9897,  -4.0377],\n",
      "         [ -9.0914,  -8.9013,  -9.2515,  ...,  -7.9160,  -8.8229,  -6.2372],\n",
      "         [ -4.3062,  -4.4963,  -4.7409,  ...,  -5.4598,  -5.3063,  -4.7548],\n",
      "         ...,\n",
      "         [ -8.5557,  -8.6650,  -8.5063,  ...,  -7.2420,  -8.5020,  -5.1048],\n",
      "         [ -8.3262,  -8.4478,  -8.3234,  ...,  -7.5583,  -8.1460,  -4.9106],\n",
      "         [ -7.3452,  -7.4843,  -7.4037,  ...,  -6.5418,  -7.1740,  -3.8421]],\n",
      "\n",
      "        [[ -6.6742,  -6.6053,  -6.6359,  ...,  -5.9458,  -5.8060,  -3.8731],\n",
      "         [-12.2465, -12.1871, -12.1983,  ...,  -9.6630, -10.3493, -10.4709],\n",
      "         [ -5.4174,  -5.4512,  -5.3099,  ...,  -5.6227,  -7.0077,  -2.7744],\n",
      "         ...,\n",
      "         [ -5.1902,  -5.1683,  -4.9930,  ...,  -5.5144,  -7.0606,  -3.2134],\n",
      "         [ -5.1646,  -5.1793,  -5.0858,  ...,  -5.5769,  -6.6413,  -2.0565],\n",
      "         [ -4.7976,  -4.7759,  -4.6172,  ...,  -4.8690,  -6.2747,  -2.6979]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.283949613571167\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4862, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4525,  -6.3884,  -6.3891,  ...,  -5.7721,  -5.3516,  -3.7942],\n",
      "         [ -7.6758,  -7.5951,  -7.7211,  ...,  -7.4737,  -7.4794,  -4.0944],\n",
      "         [ -6.6690,  -6.6127,  -6.5719,  ...,  -6.1432,  -6.0112,  -4.0974],\n",
      "         ...,\n",
      "         [ -7.0780,  -7.0454,  -7.1632,  ...,  -6.8533,  -7.0149,  -2.4620],\n",
      "         [ -7.0976,  -7.0834,  -7.1187,  ...,  -6.8989,  -7.2633,  -3.0729],\n",
      "         [ -6.9053,  -6.8928,  -6.9184,  ...,  -6.7765,  -6.4730,  -3.2210]],\n",
      "\n",
      "        [[ -6.5661,  -6.5880,  -6.5652,  ...,  -5.7429,  -5.8577,  -4.1162],\n",
      "         [ -7.4332,  -7.4559,  -7.1069,  ...,  -7.6013,  -7.5005,  -7.0643],\n",
      "         [ -0.8360,  -1.1353,  -0.5939,  ...,  -1.8376,  -1.0205,  -1.8750],\n",
      "         ...,\n",
      "         [ -3.3988,  -3.6980,  -3.0975,  ...,  -3.9657,  -2.5091,  -5.0040],\n",
      "         [ -3.0302,  -3.1504,  -2.7717,  ...,  -3.6042,  -2.4737,  -4.3580],\n",
      "         [ -3.5000,  -3.3953,  -3.1858,  ...,  -3.6418,  -2.6465,  -4.0435]],\n",
      "\n",
      "        [[ -6.5165,  -6.4916,  -6.4680,  ...,  -5.6565,  -5.6145,  -3.8602],\n",
      "         [ -9.3937,  -9.5466,  -9.2897,  ...,  -8.2649,  -8.4195,  -6.9981],\n",
      "         [-13.0174, -13.4330, -12.7742,  ..., -11.3392,  -8.7087,  -8.4029],\n",
      "         ...,\n",
      "         [ -6.9379,  -7.0338,  -6.8446,  ...,  -5.7361,  -5.2534,  -4.5966],\n",
      "         [ -7.4637,  -7.6149,  -7.4730,  ...,  -6.2734,  -5.3119,  -5.5076],\n",
      "         [ -7.6958,  -7.6963,  -7.5397,  ...,  -6.3916,  -5.1003,  -4.6324]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0266,  -7.0256,  -6.9927,  ...,  -6.2016,  -6.1921,  -4.0795],\n",
      "         [-10.2906, -10.8089, -10.3835,  ...,  -9.2815,  -8.9661, -10.0115],\n",
      "         [-14.5621, -14.7571, -14.2473,  ..., -12.2585, -10.9579, -12.8125],\n",
      "         ...,\n",
      "         [-15.2407, -15.2179, -14.7005,  ..., -12.6285, -10.4880, -12.7218],\n",
      "         [-14.7760, -14.3158, -14.2471,  ..., -11.3106,  -9.4206, -11.2860],\n",
      "         [-12.3108, -11.5267, -11.8255,  ...,  -8.1786,  -6.8567, -11.3902]],\n",
      "\n",
      "        [[ -7.3243,  -7.2654,  -7.2605,  ...,  -6.5519,  -6.4112,  -3.6049],\n",
      "         [ -9.0751,  -9.3513,  -8.7534,  ...,  -8.1570,  -6.2771,  -3.7112],\n",
      "         [ -6.5294,  -6.7172,  -6.4305,  ...,  -6.9385,  -5.0097,  -4.8716],\n",
      "         ...,\n",
      "         [ -6.6638,  -6.4742,  -6.4303,  ...,  -5.1032,  -7.4410,   1.8304],\n",
      "         [-11.4653, -11.1367, -11.0519,  ...,  -9.1153,  -9.5188,  -4.8659],\n",
      "         [-12.7777, -12.3969, -12.2557,  ...,  -9.4711,  -9.2258,  -8.5544]],\n",
      "\n",
      "        [[ -8.5963,  -8.7104,  -8.5561,  ...,  -7.6456,  -8.1182,  -3.7814],\n",
      "         [-11.3948, -10.9843, -10.8559,  ...,  -7.9086,  -8.8256, -11.3192],\n",
      "         [ -6.0527,  -6.2039,  -6.0271,  ...,  -6.6917,  -7.7325,  -2.7123],\n",
      "         ...,\n",
      "         [ -5.9290,  -5.9814,  -5.8691,  ...,  -5.8717,  -7.8539,  -3.4635],\n",
      "         [ -6.2539,  -6.4331,  -6.2671,  ...,  -7.2477,  -8.1048,  -3.3789],\n",
      "         [ -6.7280,  -6.7923,  -6.7006,  ...,  -6.8098,  -8.1894,  -2.7165]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.4861810207366943\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3477, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6723,  -6.6773,  -6.6659,  ...,  -6.0028,  -5.8269,  -3.9320],\n",
      "         [ -7.7305,  -7.7996,  -8.0710,  ...,  -7.7550,  -9.2054,  -8.0639],\n",
      "         [ -8.0166,  -8.2083,  -8.3622,  ...,  -7.3732,  -6.4369, -10.3218],\n",
      "         ...,\n",
      "         [ -7.1802,  -7.2290,  -7.2379,  ...,  -6.8930,  -7.2628,  -6.7343],\n",
      "         [ -7.0139,  -7.1334,  -7.1417,  ...,  -6.8998,  -7.1206,  -6.3896],\n",
      "         [ -7.4088,  -7.5737,  -7.5378,  ...,  -6.9011,  -7.2621,  -6.8765]],\n",
      "\n",
      "        [[ -6.8530,  -6.8101,  -6.8371,  ...,  -6.2553,  -6.0168,  -4.1299],\n",
      "         [ -9.5923,  -9.3410,  -9.6671,  ...,  -9.0695,  -8.6693,  -6.9212],\n",
      "         [ -6.6393,  -6.7271,  -6.6520,  ...,  -6.8316,  -5.0581,  -5.2589],\n",
      "         ...,\n",
      "         [ -5.5787,  -5.8182,  -5.7256,  ...,  -5.7960,  -5.6848,  -5.9920],\n",
      "         [ -3.6524,  -3.6644,  -3.6790,  ...,  -2.8835,  -3.7734,  -4.8880],\n",
      "         [ -6.2012,  -6.2793,  -6.2923,  ...,  -6.1654,  -6.0245,  -5.6095]],\n",
      "\n",
      "        [[ -6.8786,  -6.7765,  -6.8178,  ...,  -6.0430,  -6.0149,  -3.9040],\n",
      "         [ -9.2083,  -9.0751,  -9.0868,  ...,  -7.3727,  -6.8970, -10.0205],\n",
      "         [ -5.7583,  -5.5693,  -5.5927,  ...,  -6.8842,  -7.5226,  -2.2618],\n",
      "         ...,\n",
      "         [ -5.8228,  -5.5801,  -5.6599,  ...,  -6.0082,  -7.3228,  -2.6392],\n",
      "         [ -5.5926,  -5.4728,  -5.5772,  ...,  -6.0734,  -7.4013,  -2.2311],\n",
      "         [ -5.2087,  -5.0011,  -5.1121,  ...,  -6.3762,  -6.9219,  -2.3465]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4648,  -6.4837,  -6.4537,  ...,  -5.7104,  -5.8961,  -3.9642],\n",
      "         [-11.9783, -11.9681, -11.8557,  ..., -10.1415,  -9.9124, -11.1622],\n",
      "         [-13.3610, -13.9544, -13.6810,  ..., -11.7815, -11.2470, -13.3388],\n",
      "         ...,\n",
      "         [ -6.7136,  -6.7033,  -6.6607,  ...,  -6.6961,  -7.1254,  -5.6657],\n",
      "         [ -6.7995,  -6.6494,  -6.6710,  ...,  -6.5746,  -6.9900,  -5.7770],\n",
      "         [ -6.6350,  -6.5069,  -6.5688,  ...,  -6.8258,  -6.7384,  -6.8829]],\n",
      "\n",
      "        [[-10.0543, -10.2171, -10.1410,  ..., -10.7894, -10.1859, -10.7589],\n",
      "         [ -9.8864,  -9.5691,  -9.8121,  ...,  -7.5105,  -8.3804,  -8.4348],\n",
      "         [ -5.2024,  -5.3442,  -5.3144,  ...,  -6.6565,  -7.7040,  -2.7663],\n",
      "         ...,\n",
      "         [ -5.8035,  -5.7764,  -5.7178,  ...,  -6.7545,  -7.5762,  -3.2247],\n",
      "         [ -5.8616,  -5.8505,  -5.9072,  ...,  -6.9307,  -8.2470,  -3.2178],\n",
      "         [ -6.0864,  -6.0496,  -6.0065,  ...,  -7.0422,  -8.2242,  -2.5287]],\n",
      "\n",
      "        [[ -6.8264,  -6.7531,  -6.7516,  ...,  -6.3588,  -6.0029,  -4.1948],\n",
      "         [ -9.9407,  -9.9283,  -9.8722,  ...,  -8.9724,  -7.5773,  -8.7429],\n",
      "         [-14.0240, -14.0267, -14.1415,  ..., -11.7194, -11.1638, -11.3507],\n",
      "         ...,\n",
      "         [ -8.3809,  -8.3927,  -8.4930,  ...,  -8.3776,  -7.9489,  -6.5665],\n",
      "         [ -8.3077,  -8.3118,  -8.4534,  ...,  -8.3307,  -7.9997,  -6.9951],\n",
      "         [ -8.2719,  -8.1666,  -8.3288,  ...,  -8.2377,  -7.8009,  -6.9345]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.347673773765564\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3397, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3171,  -7.4101,  -7.4235,  ...,  -6.6364,  -6.4475,  -5.1483],\n",
      "         [ -6.2638,  -6.6326,  -6.3697,  ...,  -5.3195,  -8.1902,  -3.1974],\n",
      "         [ -7.3246,  -7.3762,  -7.7242,  ...,  -5.8156,  -7.2853,  -3.9288],\n",
      "         ...,\n",
      "         [ -9.2524,  -9.5324,  -9.3726,  ...,  -9.8845,  -8.1934,  -8.2792],\n",
      "         [ -4.9492,  -5.5050,  -5.4649,  ...,  -5.3032,  -5.3967,  -5.6555],\n",
      "         [-12.1914, -11.8062, -11.9820,  ..., -10.3264, -10.9347, -12.1992]],\n",
      "\n",
      "        [[ -6.8090,  -6.7694,  -6.7633,  ...,  -6.2871,  -6.0038,  -3.9810],\n",
      "         [ -9.7305,  -9.8597,  -9.5103,  ...,  -9.0506,  -7.8333,  -7.2231],\n",
      "         [-11.8549, -11.7027, -11.5941,  ..., -10.3934,  -8.5823, -11.2904],\n",
      "         ...,\n",
      "         [ -6.8767,  -7.0361,  -6.9509,  ...,  -6.5901,  -6.3728,  -2.8352],\n",
      "         [ -7.8181,  -7.9677,  -7.8150,  ...,  -7.4445,  -6.9662,  -4.7686],\n",
      "         [ -8.3339,  -8.5968,  -8.2565,  ...,  -8.1939,  -7.6481,  -5.1034]],\n",
      "\n",
      "        [[ -6.8395,  -6.8401,  -6.8531,  ...,  -6.2031,  -6.2604,  -4.0208],\n",
      "         [-11.1380, -11.5162, -11.0262,  ..., -12.4549, -10.0204,  -8.6412],\n",
      "         [-16.0572, -16.9017, -16.2968,  ..., -15.4803, -13.3101, -10.5870],\n",
      "         ...,\n",
      "         [ -7.8894,  -7.8689,  -7.6613,  ...,  -6.7195,  -6.8931,  -3.4946],\n",
      "         [ -6.8758,  -7.4123,  -7.0150,  ...,  -8.1042,  -7.7254,  -5.6523],\n",
      "         [-12.8998, -13.0711, -13.5614,  ..., -10.0632, -10.7776,  -8.6173]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4533,  -6.3595,  -6.4095,  ...,  -5.7763,  -5.6305,  -3.7518],\n",
      "         [-10.3400, -10.6926, -10.4418,  ...,  -7.5684,  -6.7261,  -9.0967],\n",
      "         [ -5.5756,  -5.5281,  -5.5176,  ...,  -5.9395,  -7.3949,  -3.2518],\n",
      "         ...,\n",
      "         [ -5.4860,  -5.4065,  -5.4195,  ...,  -6.3856,  -7.4958,  -2.4223],\n",
      "         [ -6.3384,  -6.1217,  -6.1253,  ...,  -6.7214,  -8.1856,  -2.8723],\n",
      "         [ -6.3945,  -6.1782,  -6.2185,  ...,  -6.7235,  -7.4254,  -3.6459]],\n",
      "\n",
      "        [[ -6.6355,  -6.5983,  -6.5568,  ...,  -5.7563,  -5.8330,  -3.9380],\n",
      "         [-14.5968, -13.8451, -14.0904,  ..., -12.1185, -10.5425, -10.4361],\n",
      "         [ -7.0007,  -6.9804,  -6.9635,  ...,  -7.1744,  -7.3081,  -3.8307],\n",
      "         ...,\n",
      "         [ -5.0532,  -5.0027,  -4.9755,  ...,  -5.8963,  -4.6576,  -2.8971],\n",
      "         [ -6.2108,  -6.2058,  -6.1808,  ...,  -6.2773,  -6.3908,  -3.9371],\n",
      "         [ -5.8280,  -5.8242,  -5.7714,  ...,  -6.3662,  -6.0980,  -3.0477]],\n",
      "\n",
      "        [[ -6.6684,  -6.6554,  -6.6449,  ...,  -5.9993,  -5.9184,  -4.0532],\n",
      "         [-13.5721, -13.6891, -13.7511,  ..., -12.2317, -11.1192, -10.8638],\n",
      "         [ -8.9426,  -9.2737,  -8.9332,  ...,  -7.9870,  -7.3444, -12.7998],\n",
      "         ...,\n",
      "         [ -6.8910,  -7.3880,  -7.1991,  ...,  -5.4771,  -4.9068,  -7.8980],\n",
      "         [-12.1628, -12.5868, -12.2755,  ..., -11.4941,  -8.2932,  -8.0537],\n",
      "         [-14.1413, -13.6406, -13.7526,  ..., -11.1759, -11.6209,  -8.8237]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.3396975994110107\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3055, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.8722,  -8.8641,  -8.9362,  ...,  -7.8551,  -8.4248,  -5.5446],\n",
      "         [ -9.9315,  -9.7461,  -9.4173,  ...,  -5.9219,  -7.4010, -10.5068],\n",
      "         [ -5.3463,  -5.2438,  -5.2216,  ...,  -5.9393,  -6.8926,  -4.0200],\n",
      "         ...,\n",
      "         [ -5.7603,  -5.6425,  -5.7185,  ...,  -6.0230,  -7.1850,  -3.8048],\n",
      "         [ -6.8000,  -6.6156,  -6.6604,  ...,  -6.9532,  -8.1276,  -3.5400],\n",
      "         [ -6.3936,  -6.3405,  -6.2960,  ...,  -6.7143,  -7.5025,  -4.3765]],\n",
      "\n",
      "        [[ -7.3584,  -7.3576,  -7.3687,  ...,  -6.5961,  -6.8893,  -4.5828],\n",
      "         [ -9.7970,  -9.5649,  -9.5692,  ...,  -7.3243,  -6.5258,  -9.1472],\n",
      "         [ -5.2726,  -5.3615,  -5.3453,  ...,  -5.8347,  -7.2737,  -3.3741],\n",
      "         ...,\n",
      "         [ -5.6563,  -5.6963,  -5.7402,  ...,  -5.7808,  -7.6119,  -2.6318],\n",
      "         [ -5.7170,  -5.6978,  -5.7424,  ...,  -6.4194,  -7.3348,  -2.1059],\n",
      "         [ -5.4846,  -5.4305,  -5.4915,  ...,  -5.4395,  -6.9986,  -3.2497]],\n",
      "\n",
      "        [[ -6.7945,  -6.7825,  -6.7543,  ...,  -6.3761,  -6.1597,  -4.0960],\n",
      "         [ -7.7701,  -7.7532,  -7.9887,  ...,  -8.3404,  -7.6246,  -2.7360],\n",
      "         [ -6.1632,  -6.0790,  -6.1914,  ...,  -7.1631,  -6.6991,  -2.1056],\n",
      "         ...,\n",
      "         [ -6.3461,  -6.3410,  -6.3873,  ...,  -6.6541,  -6.7507,  -2.1564],\n",
      "         [ -6.5691,  -6.5917,  -6.6099,  ...,  -7.1913,  -6.6841,  -2.5589],\n",
      "         [ -6.4572,  -6.4578,  -6.5061,  ...,  -7.0374,  -6.7839,  -2.3481]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0861,  -6.9365,  -6.9877,  ...,  -6.1730,  -6.2600,  -4.1159],\n",
      "         [-12.3619, -12.1219, -12.2569,  ...,  -9.2675,  -8.6972, -10.1901],\n",
      "         [ -5.0959,  -5.2759,  -5.1202,  ...,  -5.8642,  -6.7846,  -3.7746],\n",
      "         ...,\n",
      "         [ -5.8311,  -5.8659,  -5.7585,  ...,  -6.6770,  -7.1690,  -3.4732],\n",
      "         [ -5.3316,  -5.3400,  -5.4491,  ...,  -6.3179,  -7.4415,  -3.1113],\n",
      "         [ -5.8771,  -5.8299,  -5.8767,  ...,  -6.3274,  -7.7513,  -3.1098]],\n",
      "\n",
      "        [[ -7.1287,  -7.2740,  -7.1126,  ...,  -6.5296,  -6.1782,  -4.9819],\n",
      "         [ -8.0369,  -8.2374,  -8.0296,  ...,  -6.7111,  -7.1478,  -7.6257],\n",
      "         [ -7.0774,  -7.2767,  -7.3282,  ...,  -5.0148,  -6.7149,  -6.6520],\n",
      "         ...,\n",
      "         [ -7.6845,  -7.7679,  -7.6892,  ...,  -7.3105,  -7.9940,  -7.1897],\n",
      "         [ -6.5531,  -6.6568,  -6.5431,  ...,  -6.1820,  -7.1839,  -6.2019],\n",
      "         [ -7.9251,  -8.2048,  -8.1034,  ...,  -7.5108,  -8.0836,  -6.7003]],\n",
      "\n",
      "        [[ -7.1864,  -7.1748,  -7.1633,  ...,  -6.5373,  -6.4121,  -4.9556],\n",
      "         [-13.3574, -13.1581, -13.2196,  ..., -13.5698, -12.0303, -11.7259],\n",
      "         [ -5.5178,  -5.4660,  -5.4718,  ...,  -4.2900,  -4.9706,  -4.8363],\n",
      "         ...,\n",
      "         [ -6.7366,  -6.7460,  -6.7310,  ...,  -7.6894,  -6.3607,  -7.6819],\n",
      "         [ -6.1482,  -6.3105,  -6.2503,  ...,  -6.6549,  -5.7116,  -7.4215],\n",
      "         [ -2.9980,  -3.0837,  -3.1208,  ...,  -3.3650,  -3.9760,  -2.2896]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.3054850101470947\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.2142, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.4372,  -9.4114,  -9.5053,  ...,  -9.2914,  -9.5990,  -5.1198],\n",
      "         [-10.1631, -10.2165, -10.0334,  ...,  -7.5752,  -8.9945, -12.0557],\n",
      "         [ -4.3592,  -4.3575,  -4.4113,  ...,  -5.1921,  -6.1331,  -2.9114],\n",
      "         ...,\n",
      "         [ -4.5177,  -4.2691,  -4.3202,  ...,  -4.9462,  -6.3320,  -3.8752],\n",
      "         [ -5.1654,  -5.0170,  -5.0142,  ...,  -6.0513,  -7.0523,  -3.1930],\n",
      "         [ -5.1404,  -5.0177,  -5.0208,  ...,  -5.8899,  -6.6740,  -3.8761]],\n",
      "\n",
      "        [[ -6.6156,  -6.5670,  -6.5968,  ...,  -6.0253,  -5.7395,  -3.8916],\n",
      "         [ -8.6069,  -8.6551,  -8.6707,  ...,  -8.9695,  -8.2608,  -4.0423],\n",
      "         [ -6.8320,  -6.8040,  -6.7715,  ...,  -6.9591,  -6.6446,  -4.5608],\n",
      "         ...,\n",
      "         [ -6.8497,  -6.8367,  -6.8288,  ...,  -6.8028,  -6.9704,  -2.9771],\n",
      "         [ -6.4267,  -6.4297,  -6.4249,  ...,  -6.3311,  -6.4231,  -3.3014],\n",
      "         [ -6.5497,  -6.6129,  -6.5803,  ...,  -6.4771,  -6.4796,  -3.3807]],\n",
      "\n",
      "        [[ -6.6980,  -6.6799,  -6.6798,  ...,  -6.1118,  -5.8534,  -4.0891],\n",
      "         [ -6.7727,  -6.7813,  -6.7545,  ...,  -6.5333,  -5.5619,  -6.0028],\n",
      "         [ -7.9762,  -8.2411,  -8.1691,  ...,  -7.5765,  -5.4844,  -6.2669],\n",
      "         ...,\n",
      "         [ -6.7453,  -6.7651,  -6.7547,  ...,  -6.8390,  -5.9387,  -7.6747],\n",
      "         [ -6.6929,  -6.7450,  -6.6717,  ...,  -6.7141,  -5.9256,  -7.5433],\n",
      "         [ -6.2525,  -6.3360,  -6.3260,  ...,  -6.3904,  -4.6441,  -5.7138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7336,  -6.6916,  -6.6998,  ...,  -6.1015,  -5.8489,  -3.9204],\n",
      "         [ -8.5996,  -8.4601,  -8.6212,  ...,  -8.9466,  -8.7286,  -4.0997],\n",
      "         [ -7.9111,  -7.8051,  -7.8114,  ...,  -8.0392,  -7.4492,  -4.9735],\n",
      "         ...,\n",
      "         [ -6.9494,  -6.8291,  -6.9910,  ...,  -6.7221,  -7.0494,  -2.8155],\n",
      "         [ -6.7661,  -6.6173,  -6.7707,  ...,  -6.6281,  -6.7878,  -2.6926],\n",
      "         [ -7.1056,  -6.9802,  -7.0784,  ...,  -7.1881,  -7.3774,  -2.8660]],\n",
      "\n",
      "        [[ -6.3090,  -6.3218,  -6.2831,  ...,  -5.5035,  -5.5307,  -3.4292],\n",
      "         [ -9.9807,  -9.5912,  -9.5035,  ..., -10.3567,  -8.1959,  -5.6408],\n",
      "         [-10.9672, -10.9235, -10.8493,  ..., -11.6406,  -9.4190,  -4.7766],\n",
      "         ...,\n",
      "         [ -5.7233,  -5.9111,  -5.9029,  ...,  -4.6996,  -3.6536,  -2.6377],\n",
      "         [ -6.2034,  -6.1815,  -6.1644,  ...,  -4.6784,  -4.3607,  -4.2729],\n",
      "         [-14.7171, -14.4862, -14.7335,  ..., -12.6215, -10.6398, -12.1716]],\n",
      "\n",
      "        [[-11.9093, -11.8007, -11.9555,  ...,  -9.8191, -11.5562,  -9.0215],\n",
      "         [ -9.4046,  -9.5094,  -9.6145,  ...,  -7.6976,  -7.2379,  -8.4439],\n",
      "         [ -5.6763,  -5.5417,  -5.7876,  ...,  -6.7235,  -8.2185,  -1.2959],\n",
      "         ...,\n",
      "         [ -5.7787,  -5.8049,  -5.8171,  ...,  -6.6505,  -8.0791,  -3.4234],\n",
      "         [ -5.2806,  -5.3366,  -5.3333,  ...,  -5.7190,  -7.6465,  -3.0975],\n",
      "         [ -5.3115,  -5.2367,  -5.2567,  ...,  -6.0822,  -7.2406,  -3.1576]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.214150905609131\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.5753, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6166,  -6.6376,  -6.6747,  ...,  -6.2101,  -5.8488,  -3.6130],\n",
      "         [ -7.8175,  -7.8672,  -7.9359,  ...,  -7.9891,  -7.8379,  -3.5762],\n",
      "         [ -8.7587,  -8.7159,  -8.8589,  ...,  -9.1971,  -8.5356,  -2.9533],\n",
      "         ...,\n",
      "         [ -6.3669,  -6.2632,  -6.3999,  ...,  -6.7948,  -6.6676,  -2.5198],\n",
      "         [ -7.0134,  -6.9156,  -7.0064,  ...,  -7.0263,  -7.0355,  -2.6208],\n",
      "         [ -7.0805,  -6.9903,  -7.0582,  ...,  -7.1290,  -6.8139,  -2.2806]],\n",
      "\n",
      "        [[ -6.0801,  -6.0834,  -6.0766,  ...,  -5.9549,  -5.1906,  -3.5250],\n",
      "         [-11.0763, -10.3561, -10.7820,  ...,  -7.7117,  -8.1736, -11.3111],\n",
      "         [ -7.2073,  -7.1505,  -7.2265,  ...,  -7.6238,  -8.0314,  -3.2483],\n",
      "         ...,\n",
      "         [ -6.6685,  -6.6768,  -6.7202,  ...,  -7.3647,  -7.3938,  -2.2141],\n",
      "         [ -6.4816,  -6.6025,  -6.5195,  ...,  -7.0347,  -7.0965,  -2.6720],\n",
      "         [ -7.7929,  -7.8599,  -7.8831,  ...,  -8.7943,  -8.4253,  -4.5981]],\n",
      "\n",
      "        [[ -6.5927,  -6.5427,  -6.5338,  ...,  -5.6464,  -5.7304,  -4.2332],\n",
      "         [-12.1980, -12.1196, -11.9596,  ...,  -8.7508,  -9.2328,  -9.3906],\n",
      "         [ -5.5616,  -5.6618,  -5.5740,  ...,  -6.2187,  -7.4290,  -1.7280],\n",
      "         ...,\n",
      "         [ -5.2683,  -5.2242,  -5.1825,  ...,  -5.6487,  -7.5467,  -1.7693],\n",
      "         [ -6.3059,  -6.3069,  -6.1749,  ...,  -6.9933,  -8.5631,  -2.6165],\n",
      "         [ -4.7666,  -4.7764,  -4.5105,  ...,  -4.7131,  -6.6073,  -1.6251]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.1736,  -5.1944,  -5.1736,  ...,  -5.8427,  -4.8844,   0.1396],\n",
      "         [-12.0238, -11.3795, -11.5782,  ...,  -9.6470,  -8.7022,  -8.0315],\n",
      "         [ -6.4737,  -6.5124,  -6.6006,  ...,  -7.1077,  -7.1109,  -2.3982],\n",
      "         ...,\n",
      "         [ -7.1105,  -7.1332,  -7.1911,  ...,  -7.3631,  -7.5929,  -3.0979],\n",
      "         [ -6.6008,  -6.6764,  -6.8521,  ...,  -6.6581,  -7.3141,  -2.7463],\n",
      "         [ -6.7101,  -6.7855,  -6.7842,  ...,  -6.7513,  -6.4089,  -2.4562]],\n",
      "\n",
      "        [[ -6.6235,  -6.5943,  -6.6063,  ...,  -6.0368,  -5.7396,  -3.9254],\n",
      "         [ -9.7493,  -9.7068,  -9.8078,  ...,  -9.6922,  -9.7283,  -3.6561],\n",
      "         [ -9.3881,  -9.5584,  -9.6673,  ...,  -9.6189,  -9.0703,  -4.2467],\n",
      "         ...,\n",
      "         [ -7.2503,  -7.1657,  -7.2117,  ...,  -7.1681,  -7.6212,  -3.3341],\n",
      "         [ -6.8638,  -6.8017,  -6.8485,  ...,  -6.7865,  -6.9270,  -2.5215],\n",
      "         [ -7.4376,  -7.3298,  -7.4046,  ...,  -7.5436,  -7.3306,  -3.0778]],\n",
      "\n",
      "        [[ -6.7072,  -6.7368,  -6.7562,  ...,  -6.2075,  -5.9938,  -3.8936],\n",
      "         [-10.2653, -10.5592, -10.2650,  ..., -10.1349,  -7.9980,  -7.4349],\n",
      "         [-13.2934, -13.4248, -13.3390,  ..., -11.9631,  -9.6585,  -9.9648],\n",
      "         ...,\n",
      "         [ -7.7540,  -7.9585,  -7.9147,  ...,  -7.9716,  -6.6064,  -7.0196],\n",
      "         [ -5.7094,  -5.8668,  -6.0341,  ...,  -6.6279,  -4.8470,  -5.1094],\n",
      "         [ -5.6978,  -5.7979,  -5.8902,  ...,  -6.4663,  -4.9468,  -5.1147]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.575343370437622\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7239, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8138,  -6.8088,  -6.8809,  ...,  -6.2608,  -6.2606,  -4.0319],\n",
      "         [-10.2355, -10.1119, -10.2670,  ...,  -6.9534,  -6.8406,  -6.9594],\n",
      "         [ -6.5787,  -6.5161,  -6.5102,  ...,  -6.4315,  -7.1841,  -3.1499],\n",
      "         ...,\n",
      "         [ -6.4561,  -6.3976,  -6.3969,  ...,  -6.6629,  -7.2263,  -3.5469],\n",
      "         [ -5.6434,  -5.6543,  -5.5843,  ...,  -5.8494,  -7.2984,  -1.6656],\n",
      "         [ -6.8147,  -6.7763,  -6.7874,  ...,  -6.9502,  -8.0297,  -3.4694]],\n",
      "\n",
      "        [[ -6.8960,  -6.8602,  -6.8426,  ...,  -6.2105,  -5.8908,  -4.2428],\n",
      "         [ -6.1972,  -6.1247,  -6.2526,  ...,  -6.1255,  -5.1648,  -5.3931],\n",
      "         [ -9.4155,  -9.2039,  -9.5700,  ...,  -8.8179,  -7.3855,  -6.2905],\n",
      "         ...,\n",
      "         [ -4.3199,  -4.3910,  -4.3163,  ...,  -3.7640,  -3.6548,  -3.2648],\n",
      "         [-12.3580, -12.3352, -12.1399,  ..., -10.7286, -11.6278, -11.5473],\n",
      "         [-10.9259, -10.4645, -10.4128,  ...,  -6.4567,  -7.0985, -12.0363]],\n",
      "\n",
      "        [[ -7.0397,  -7.0822,  -7.0949,  ...,  -6.6222,  -6.3316,  -4.6941],\n",
      "         [-13.7944, -13.9196, -13.9376,  ..., -12.8326, -11.6597, -12.6845],\n",
      "         [ -8.1417,  -8.6076,  -8.4072,  ...,  -8.7108,  -7.8239,  -8.0575],\n",
      "         ...,\n",
      "         [ -3.7460,  -3.7887,  -3.8800,  ...,  -4.7939,  -3.8075,  -2.3771],\n",
      "         [ -5.4635,  -5.5564,  -5.6040,  ...,  -5.6412,  -5.4493,  -2.4017],\n",
      "         [ -4.9705,  -4.9376,  -5.0276,  ...,  -5.8324,  -5.2795,  -2.4556]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3149,  -7.4159,  -7.3045,  ...,  -6.5889,  -6.4142,  -4.4954],\n",
      "         [ -7.2226,  -7.5619,  -7.5756,  ...,  -8.0423,  -6.2510,  -4.3662],\n",
      "         [ -7.2781,  -7.3695,  -7.1106,  ...,  -5.7734,  -4.4562,  -6.1117],\n",
      "         ...,\n",
      "         [ -7.9661,  -8.1785,  -8.2483,  ...,  -8.0073,  -6.2524,  -6.4642],\n",
      "         [ -7.1469,  -7.5769,  -7.4211,  ...,  -7.2578,  -5.4386,  -5.9894],\n",
      "         [ -9.2737,  -9.5012,  -9.4848,  ...,  -9.6260,  -7.5783,  -6.5448]],\n",
      "\n",
      "        [[ -7.5040,  -7.5300,  -7.5085,  ...,  -6.6728,  -7.2366,  -5.9908],\n",
      "         [-15.6727, -15.4004, -15.4326,  ..., -14.0014, -14.1103, -15.3957],\n",
      "         [ -6.2920,  -6.3399,  -6.3804,  ...,  -6.7577,  -8.0674,  -4.1561],\n",
      "         ...,\n",
      "         [ -5.4179,  -5.3866,  -5.2556,  ...,  -5.2032,  -7.2086,  -4.6165],\n",
      "         [ -6.0117,  -6.1530,  -5.9595,  ...,  -6.2856,  -7.8500,  -4.4387],\n",
      "         [ -6.2673,  -6.2315,  -6.3092,  ...,  -6.7324,  -8.0466,  -4.0243]],\n",
      "\n",
      "        [[ -6.7134,  -6.6070,  -6.6298,  ...,  -6.0487,  -5.6901,  -4.0983],\n",
      "         [-10.9826, -10.1220, -10.3582,  ...,  -8.8644,  -6.7373,  -7.7969],\n",
      "         [ -5.7039,  -5.5934,  -5.5975,  ...,  -6.5561,  -7.4382,  -3.1417],\n",
      "         ...,\n",
      "         [ -5.8228,  -5.6666,  -5.7138,  ...,  -6.3595,  -7.1143,  -3.5096],\n",
      "         [ -6.2094,  -6.0081,  -6.1242,  ...,  -6.7100,  -6.8713,  -4.5997],\n",
      "         [ -5.8412,  -5.6776,  -5.6619,  ...,  -6.2984,  -6.7232,  -3.1985]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.7238757610321045\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8127, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.6922,  -7.8011,  -7.7444,  ...,  -7.1748,  -7.2909,  -4.4643],\n",
      "         [-13.4605, -13.0080, -13.1423,  ..., -10.5399, -10.2916, -10.9998],\n",
      "         [ -5.3870,  -5.4227,  -5.4770,  ...,  -5.9721,  -7.3080,  -2.6808],\n",
      "         ...,\n",
      "         [ -6.3973,  -6.4470,  -6.4424,  ...,  -6.8282,  -7.5879,  -3.9067],\n",
      "         [ -6.6544,  -6.6292,  -6.5153,  ...,  -6.7407,  -7.7495,  -4.2792],\n",
      "         [ -6.1888,  -6.1638,  -6.0834,  ...,  -7.0559,  -7.7269,  -3.1671]],\n",
      "\n",
      "        [[ -6.7358,  -6.7533,  -6.7430,  ...,  -6.1370,  -5.9416,  -3.9630],\n",
      "         [ -7.9501,  -8.1238,  -8.0313,  ...,  -8.3756,  -7.6454,  -7.5502],\n",
      "         [ -9.1862,  -9.1491,  -8.9383,  ...,  -8.9120,  -5.3831,  -8.3474],\n",
      "         ...,\n",
      "         [ -5.4940,  -5.8251,  -5.6344,  ...,  -5.5170,  -6.2566,  -8.0537],\n",
      "         [ -6.1362,  -6.2366,  -6.3021,  ...,  -5.8209,  -5.5495,  -2.3134],\n",
      "         [-12.4295, -11.7622, -12.2671,  ...,  -8.8953,  -9.6177,  -9.2604]],\n",
      "\n",
      "        [[ -7.5726,  -7.6792,  -7.5315,  ...,  -6.7225,  -6.6831,  -5.4303],\n",
      "         [-13.9453, -13.8916, -13.8574,  ..., -13.0916, -11.9194, -11.9516],\n",
      "         [ -9.5676,  -9.6864,  -9.3760,  ...,  -8.6481,  -8.6371,  -9.7715],\n",
      "         ...,\n",
      "         [ -7.6763,  -7.8270,  -7.6572,  ...,  -7.2525,  -8.0284,  -6.7868],\n",
      "         [ -7.0758,  -7.1930,  -7.1017,  ...,  -6.6402,  -6.7252,  -6.3139],\n",
      "         [ -7.7595,  -7.9498,  -7.9007,  ...,  -7.9388,  -8.0095,  -6.1400]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-10.0559,  -9.9011, -10.0954,  ...,  -9.1126, -10.3070,  -6.5393],\n",
      "         [-11.3397, -11.1167, -11.0271,  ...,  -9.2004,  -9.3114,  -9.6232],\n",
      "         [ -5.5552,  -5.3594,  -5.5320,  ...,  -6.3389,  -7.3809,  -2.7679],\n",
      "         ...,\n",
      "         [ -5.7773,  -5.8348,  -5.9460,  ...,  -6.3165,  -7.4258,  -2.8767],\n",
      "         [ -6.4886,  -6.3337,  -6.4841,  ...,  -7.1016,  -8.1332,  -3.1709],\n",
      "         [ -5.9671,  -5.8293,  -5.9658,  ...,  -6.3776,  -7.2508,  -4.0582]],\n",
      "\n",
      "        [[ -6.5210,  -6.4016,  -6.3702,  ...,  -6.1474,  -6.6226,  -3.6367],\n",
      "         [-14.9093, -14.8569, -14.3807,  ..., -13.7100, -10.1444, -12.8542],\n",
      "         [ -5.8753,  -5.8497,  -5.9008,  ...,  -6.5177,  -7.7104,  -3.1925],\n",
      "         ...,\n",
      "         [ -5.7709,  -5.7088,  -5.7105,  ...,  -6.5477,  -7.7120,  -3.0083],\n",
      "         [ -5.3182,  -5.2734,  -5.3405,  ...,  -5.6293,  -7.2449,  -3.7799],\n",
      "         [ -5.6385,  -5.5344,  -5.5812,  ...,  -6.0279,  -7.4988,  -3.5465]],\n",
      "\n",
      "        [[ -6.5896,  -6.5323,  -6.5134,  ...,  -5.8174,  -5.6218,  -3.8888],\n",
      "         [ -8.4948,  -8.7526,  -8.6797,  ...,  -7.7394,  -8.9293,  -2.7758],\n",
      "         [ -7.4922,  -7.9311,  -7.6128,  ...,  -6.1927,  -5.8357,  -3.0325],\n",
      "         ...,\n",
      "         [ -7.0912,  -7.1117,  -6.8763,  ...,  -6.4062,  -7.2261,  -6.1289],\n",
      "         [ -7.8568,  -7.8956,  -7.7909,  ...,  -7.4195,  -8.2570,  -5.2112],\n",
      "         [ -4.5867,  -4.7162,  -4.6634,  ...,  -4.0466,  -4.9528,  -1.7051]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.812699556350708\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.4927, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3611,  -6.4444,  -6.1982,  ...,  -5.8471,  -6.8334,  -5.3543],\n",
      "         [ -8.9363,  -9.0444,  -8.8579,  ...,  -6.2175,  -5.5301, -10.5706],\n",
      "         [ -4.7607,  -4.6441,  -4.6585,  ...,  -5.2514,  -6.7064,  -4.0130],\n",
      "         ...,\n",
      "         [ -5.3163,  -5.1754,  -5.2998,  ...,  -5.3325,  -6.7112,  -2.4164],\n",
      "         [ -4.1392,  -3.8646,  -3.9001,  ...,  -4.2319,  -5.5940,  -3.5669],\n",
      "         [ -5.7428,  -5.6136,  -5.5865,  ...,  -6.3276,  -6.7684,  -4.2877]],\n",
      "\n",
      "        [[ -9.0235,  -8.6940,  -8.7856,  ...,  -7.7188,  -8.0337,  -5.4458],\n",
      "         [-13.0157, -13.0419, -12.7888,  ..., -12.0912, -10.9043, -14.0990],\n",
      "         [ -5.8121,  -5.7499,  -5.6924,  ...,  -6.5108,  -7.3952,  -2.8484],\n",
      "         ...,\n",
      "         [ -5.6332,  -5.3637,  -5.4551,  ...,  -6.5126,  -7.6602,  -2.9704],\n",
      "         [ -5.4622,  -5.3102,  -5.2261,  ...,  -5.7670,  -6.9782,  -3.3872],\n",
      "         [ -5.0843,  -4.8228,  -4.7761,  ...,  -6.4033,  -6.4447,  -3.5679]],\n",
      "\n",
      "        [[ -6.6255,  -6.5509,  -6.5652,  ...,  -5.8189,  -5.9187,  -4.0517],\n",
      "         [-11.8417, -11.4763, -11.7218,  ...,  -9.1745,  -9.0930,  -7.4422],\n",
      "         [ -6.4948,  -6.5772,  -6.4125,  ...,  -7.0978,  -7.7756,  -3.8970],\n",
      "         ...,\n",
      "         [ -6.4196,  -6.4089,  -6.3122,  ...,  -6.4483,  -7.2034,  -3.1536],\n",
      "         [ -6.1027,  -6.1739,  -5.9918,  ...,  -6.3146,  -7.1275,  -4.1707],\n",
      "         [ -6.1658,  -5.9925,  -6.0422,  ...,  -6.1315,  -7.2679,  -3.6385]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6740,  -6.6051,  -6.6738,  ...,  -6.0730,  -6.0103,  -4.0954],\n",
      "         [-10.9998, -10.9313, -10.8978,  ...,  -7.5845,  -9.0270,  -8.6521],\n",
      "         [ -6.3577,  -6.2869,  -6.3387,  ...,  -6.6230,  -8.1923,  -3.4450],\n",
      "         ...,\n",
      "         [ -6.6548,  -6.6253,  -6.6564,  ...,  -6.8180,  -8.7362,  -3.1440],\n",
      "         [ -5.9244,  -5.9209,  -5.9777,  ...,  -6.3332,  -7.7090,  -3.4661],\n",
      "         [ -6.2917,  -6.2037,  -6.1492,  ...,  -6.7007,  -7.6211,  -4.6609]],\n",
      "\n",
      "        [[ -6.9024,  -6.6802,  -6.7004,  ...,  -5.7892,  -7.0038,  -4.8828],\n",
      "         [ -8.6974,  -8.7679,  -8.6471,  ...,  -6.6534,  -6.8867,  -8.5370],\n",
      "         [ -6.0755,  -6.2098,  -6.1510,  ...,  -6.9150,  -7.8120,  -3.6642],\n",
      "         ...,\n",
      "         [ -6.1103,  -6.0592,  -5.9991,  ...,  -7.1212,  -7.8876,  -4.5257],\n",
      "         [ -6.7443,  -6.8534,  -6.6793,  ...,  -7.5818,  -8.4771,  -3.4618],\n",
      "         [ -6.6590,  -6.7158,  -6.6473,  ...,  -7.6678,  -8.3476,  -3.9636]],\n",
      "\n",
      "        [[ -6.3801,  -6.3011,  -6.3328,  ...,  -5.8238,  -5.6149,  -3.9986],\n",
      "         [ -9.6340,  -9.5140,  -9.5945,  ...,  -8.2970,  -8.2427,  -6.6888],\n",
      "         [ -5.3729,  -4.8802,  -5.1492,  ...,  -5.3085,  -5.5004,  -6.9143],\n",
      "         ...,\n",
      "         [ -7.0343,  -7.1370,  -7.2653,  ...,  -7.8495,  -7.7288,  -5.6108],\n",
      "         [ -6.5715,  -6.6381,  -6.7480,  ...,  -7.2574,  -7.6146,  -6.3424],\n",
      "         [ -7.7353,  -7.9032,  -7.9966,  ...,  -8.2676,  -8.5000,  -5.8493]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.49271821975708\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2219, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.0386,  -7.9749,  -7.9397,  ...,  -7.2567,  -6.9442,  -4.7714],\n",
      "         [-11.1731, -10.9963, -11.4086,  ...,  -8.3840,  -8.3179,  -9.2237],\n",
      "         [ -5.6310,  -5.6917,  -5.6110,  ...,  -6.3222,  -7.1752,  -3.4386],\n",
      "         ...,\n",
      "         [ -5.8365,  -5.6878,  -5.7625,  ...,  -6.6835,  -7.8405,  -2.9046],\n",
      "         [ -5.6187,  -5.4215,  -5.4402,  ...,  -6.0992,  -7.1834,  -2.3611],\n",
      "         [ -5.8213,  -5.6037,  -5.6719,  ...,  -6.3296,  -7.8444,  -2.7862]],\n",
      "\n",
      "        [[ -7.9135,  -7.8587,  -7.9381,  ...,  -6.8036,  -7.0730,  -4.7051],\n",
      "         [-18.8310, -18.5264, -18.6621,  ..., -15.4891, -16.3031, -16.3734],\n",
      "         [ -5.3999,  -5.4389,  -5.3283,  ...,  -5.9342,  -7.2705,  -2.3667],\n",
      "         ...,\n",
      "         [ -5.8989,  -5.9174,  -5.7977,  ...,  -5.5754,  -7.4708,  -3.7544],\n",
      "         [ -6.0759,  -6.2334,  -6.0035,  ...,  -6.6763,  -8.3919,  -4.3900],\n",
      "         [ -6.5437,  -6.6547,  -6.5163,  ...,  -6.5207,  -8.7134,  -3.3430]],\n",
      "\n",
      "        [[ -9.2761,  -9.1388,  -9.1362,  ...,  -8.5402,  -8.4933,  -5.0239],\n",
      "         [-10.6668,  -9.7016, -10.2885,  ...,  -7.8192,  -8.9488, -10.4439],\n",
      "         [ -5.8996,  -5.9097,  -5.8741,  ...,  -6.6021,  -7.2826,  -2.5635],\n",
      "         ...,\n",
      "         [ -5.5050,  -5.4888,  -5.4570,  ...,  -5.4701,  -6.8548,  -2.6852],\n",
      "         [ -5.8988,  -5.6329,  -5.7489,  ...,  -5.9301,  -7.2527,  -2.4867],\n",
      "         [ -5.6160,  -5.3649,  -5.4727,  ...,  -5.5751,  -6.7007,  -2.2014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5941,  -6.5860,  -6.5776,  ...,  -5.9659,  -5.9194,  -3.6313],\n",
      "         [ -8.4566,  -8.6076,  -8.6917,  ...,  -9.1637,  -8.4258,  -3.1105],\n",
      "         [ -8.2593,  -8.2448,  -8.2716,  ...,  -8.4567,  -7.8693,  -3.3358],\n",
      "         ...,\n",
      "         [ -6.9504,  -6.9791,  -7.0224,  ...,  -7.2909,  -7.5150,  -2.5154],\n",
      "         [ -7.0350,  -7.0285,  -7.0415,  ...,  -7.3078,  -7.3500,  -2.6474],\n",
      "         [ -6.8955,  -6.8780,  -6.9639,  ...,  -7.5658,  -7.2957,  -2.6231]],\n",
      "\n",
      "        [[ -8.0744,  -8.0770,  -8.0849,  ...,  -7.2586,  -7.3868,  -5.1083],\n",
      "         [-10.7048, -10.3775, -10.1838,  ...,  -8.3370,  -8.4919,  -8.5820],\n",
      "         [ -5.8513,  -5.9743,  -5.9187,  ...,  -6.2563,  -8.1560,  -1.7214],\n",
      "         ...,\n",
      "         [ -6.2872,  -6.2971,  -6.2983,  ...,  -5.7829,  -7.8251,  -2.2999],\n",
      "         [ -6.0256,  -5.9028,  -5.9814,  ...,  -5.6890,  -7.7357,  -2.8564],\n",
      "         [ -6.2873,  -6.2999,  -6.2573,  ...,  -6.1374,  -7.6873,  -3.5193]],\n",
      "\n",
      "        [[ -6.6118,  -6.6837,  -6.7009,  ...,  -6.4095,  -6.1774,  -3.9148],\n",
      "         [ -8.1219,  -8.1824,  -8.2598,  ...,  -8.9553,  -8.8662,  -3.2990],\n",
      "         [ -8.4085,  -8.3815,  -8.6386,  ...,  -8.2008,  -8.4476,  -3.3544],\n",
      "         ...,\n",
      "         [ -6.0889,  -6.2365,  -6.2092,  ...,  -7.0820,  -7.0628,  -1.9092],\n",
      "         [ -6.7089,  -6.7456,  -6.7422,  ...,  -7.7926,  -7.5701,  -2.1748],\n",
      "         [ -5.8270,  -5.8431,  -5.8624,  ...,  -7.3255,  -7.2165,  -1.6722]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.2218846082687378\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0396, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7334,  -6.6980,  -6.7289,  ...,  -5.9158,  -6.0542,  -3.7059],\n",
      "         [ -8.5461,  -8.4523,  -8.4500,  ...,  -8.3775,  -8.3818,  -3.4563],\n",
      "         [ -7.4156,  -7.3699,  -7.4116,  ...,  -7.5245,  -7.4250,  -2.4130],\n",
      "         ...,\n",
      "         [ -6.8989,  -6.8721,  -6.8746,  ...,  -7.0186,  -7.0210,  -1.5353],\n",
      "         [ -6.5545,  -6.4820,  -6.6133,  ...,  -6.5028,  -6.6190,  -1.4668],\n",
      "         [ -6.8786,  -6.7889,  -6.8780,  ...,  -6.6152,  -7.0942,  -1.9621]],\n",
      "\n",
      "        [[ -7.2046,  -7.1584,  -7.1706,  ...,  -6.3208,  -6.2107,  -4.4005],\n",
      "         [-10.4127, -10.0667, -10.2520,  ...,  -7.8656,  -7.6489, -11.0832],\n",
      "         [ -4.9277,  -5.1662,  -4.9256,  ...,  -6.2980,  -6.5986,  -2.0254],\n",
      "         ...,\n",
      "         [ -5.8912,  -5.6916,  -5.7804,  ...,  -6.6670,  -8.2423,  -2.4472],\n",
      "         [ -6.1204,  -6.1643,  -6.1601,  ...,  -6.8302,  -7.9504,  -3.9550],\n",
      "         [ -5.3739,  -5.2828,  -5.3343,  ...,  -6.0766,  -7.1402,  -3.2870]],\n",
      "\n",
      "        [[ -6.6910,  -6.6151,  -6.6733,  ...,  -5.9401,  -5.7346,  -4.3065],\n",
      "         [-14.6450, -13.9634, -13.8946,  ..., -11.2908, -12.2817, -12.6798],\n",
      "         [ -5.7928,  -5.7542,  -5.7403,  ...,  -6.3112,  -7.4962,  -3.2702],\n",
      "         ...,\n",
      "         [ -6.2514,  -6.1848,  -6.0510,  ...,  -6.1474,  -7.0369,  -3.7640],\n",
      "         [ -5.6438,  -5.4820,  -5.4360,  ...,  -6.0028,  -6.9174,  -4.0968],\n",
      "         [ -6.2120,  -6.2460,  -6.0763,  ...,  -6.5857,  -7.4572,  -3.1426]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7707,  -6.7246,  -6.7022,  ...,  -6.0314,  -5.9426,  -4.0756],\n",
      "         [ -6.5177,  -6.3917,  -6.5157,  ...,  -7.3201,  -7.4925,  -2.1745],\n",
      "         [ -7.0931,  -6.8857,  -6.8390,  ...,  -7.0248,  -7.1876,  -1.7258],\n",
      "         ...,\n",
      "         [ -7.2044,  -7.0884,  -7.0682,  ...,  -7.4378,  -7.9849,  -3.1352],\n",
      "         [ -5.9617,  -5.7399,  -5.9417,  ...,  -5.7714,  -6.2569,  -0.9411],\n",
      "         [ -6.1542,  -5.9645,  -5.9737,  ...,  -6.2129,  -6.2693,  -1.3988]],\n",
      "\n",
      "        [[ -6.6964,  -6.6569,  -6.6379,  ...,  -6.0895,  -5.9909,  -3.9693],\n",
      "         [ -7.4474,  -7.4662,  -7.3436,  ...,  -7.7399,  -7.5260,  -2.7732],\n",
      "         [ -6.2716,  -6.4011,  -6.1736,  ...,  -6.1735,  -7.0139,  -3.3087],\n",
      "         ...,\n",
      "         [ -7.2607,  -7.2238,  -7.0204,  ...,  -7.4101,  -7.9471,  -1.9608],\n",
      "         [ -6.8861,  -6.9290,  -6.8101,  ...,  -6.9438,  -7.6724,  -0.9546],\n",
      "         [ -6.7903,  -6.8010,  -6.6114,  ...,  -6.8680,  -7.3356,  -1.9792]],\n",
      "\n",
      "        [[ -6.5206,  -6.5454,  -6.4832,  ...,  -5.8783,  -5.6469,  -3.8924],\n",
      "         [-14.4580, -14.6105, -14.3858,  ..., -12.9733, -12.0008, -11.5446],\n",
      "         [-12.7695, -12.6652, -13.0006,  ..., -14.1600, -12.0128, -10.3030],\n",
      "         ...,\n",
      "         [ -6.8430,  -7.0341,  -6.8882,  ...,  -6.9943,  -7.0479,  -7.1928],\n",
      "         [ -6.1967,  -6.3830,  -6.4508,  ...,  -5.5846,  -6.2623,  -5.5048],\n",
      "         [ -7.6901,  -7.9313,  -7.9790,  ...,  -7.5916,  -7.3104,  -5.9764]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.039613962173462\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.2233, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4070,  -6.3936,  -6.3880,  ...,  -5.6557,  -5.9444,  -3.4283],\n",
      "         [-17.3967, -17.3251, -17.4964,  ..., -15.6092, -13.7553, -13.5041],\n",
      "         [ -5.1565,  -5.6326,  -5.6008,  ...,  -6.0172,  -5.9085,  -2.6418],\n",
      "         ...,\n",
      "         [ -5.7630,  -5.7148,  -5.6930,  ...,  -5.5774,  -6.2374,  -2.3253],\n",
      "         [ -5.8935,  -5.8576,  -6.0019,  ...,  -6.0766,  -6.6367,  -2.7092],\n",
      "         [ -5.8827,  -5.9133,  -5.9966,  ...,  -5.9703,  -6.6166,  -3.0732]],\n",
      "\n",
      "        [[ -6.6207,  -6.5554,  -6.5460,  ...,  -5.8650,  -5.5571,  -3.8493],\n",
      "         [ -8.8647,  -8.7169,  -8.9080,  ...,  -8.2750,  -7.0294,  -6.9954],\n",
      "         [ -4.3817,  -4.4904,  -4.3895,  ...,  -4.8655,  -4.1499,  -4.7228],\n",
      "         ...,\n",
      "         [ -7.2507,  -7.2647,  -7.1406,  ...,  -6.7996,  -5.8263,  -5.1438],\n",
      "         [ -6.6416,  -6.9370,  -6.6969,  ...,  -6.3313,  -5.1114,  -5.2189],\n",
      "         [ -4.9872,  -5.3331,  -5.2264,  ...,  -4.4159,  -2.9801,  -4.8736]],\n",
      "\n",
      "        [[ -6.9433,  -6.9756,  -6.9446,  ...,  -6.3387,  -6.1945,  -3.6131],\n",
      "         [-11.8670, -11.8476, -12.2016,  ..., -11.2321,  -9.6426,  -7.7199],\n",
      "         [-11.2938, -12.0039, -11.8573,  ..., -11.2718,  -8.7608,  -9.5773],\n",
      "         ...,\n",
      "         [ -8.2350,  -8.0834,  -7.9792,  ...,  -9.3169,  -7.6981,  -5.0820],\n",
      "         [ -8.1403,  -8.1267,  -7.9082,  ...,  -8.8901,  -7.5314,  -4.3759],\n",
      "         [ -7.8975,  -7.8160,  -7.7330,  ...,  -8.7993,  -7.4902,  -5.3665]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5206,  -6.5625,  -6.5256,  ...,  -5.9142,  -5.9404,  -3.9370],\n",
      "         [ -7.3462,  -7.2636,  -7.1516,  ...,  -6.4860,  -6.6359,  -6.9512],\n",
      "         [ -5.5670,  -5.6313,  -5.4395,  ...,  -5.3937,  -5.6413,  -5.9140],\n",
      "         ...,\n",
      "         [ -6.7296,  -6.7577,  -6.5955,  ...,  -5.8669,  -6.7760,  -8.6751],\n",
      "         [-11.7595, -11.6990, -11.7610,  ..., -11.0646, -10.6718, -10.5271],\n",
      "         [-13.8774, -13.3761, -13.6162,  ..., -11.7421,  -9.9873,  -9.1509]],\n",
      "\n",
      "        [[ -6.5489,  -6.5035,  -6.4420,  ...,  -5.9653,  -5.8965,  -3.8500],\n",
      "         [-14.2526, -13.9809, -14.1686,  ..., -13.6591, -11.1900, -11.0753],\n",
      "         [-17.5191, -17.3757, -17.2477,  ..., -14.6215, -13.2574, -14.4476],\n",
      "         ...,\n",
      "         [ -6.5480,  -6.5413,  -6.6214,  ...,  -6.0852,  -5.0450,  -6.3399],\n",
      "         [ -5.5750,  -5.7305,  -5.5229,  ...,  -5.7109,  -3.4455,  -5.8903],\n",
      "         [-12.5558, -11.9818, -12.1929,  ...,  -9.4252,  -8.8848, -10.6243]],\n",
      "\n",
      "        [[ -6.8136,  -6.7875,  -6.7877,  ...,  -6.0029,  -5.8967,  -4.0935],\n",
      "         [ -6.8957,  -6.9701,  -6.6787,  ...,  -6.4267,  -6.7267,  -4.9452],\n",
      "         [ -7.1701,  -7.1246,  -6.7413,  ...,  -5.8040,  -6.1594,  -4.2794],\n",
      "         ...,\n",
      "         [ -7.7686,  -7.7974,  -7.6918,  ...,  -7.0546,  -7.0093,  -4.6837],\n",
      "         [ -8.0871,  -8.1301,  -7.8305,  ...,  -6.9587,  -6.9284,  -4.2805],\n",
      "         [ -8.0761,  -8.0762,  -7.8021,  ...,  -6.6134,  -6.4817,  -4.1225]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.223294496536255\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8221, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6519,  -6.7541,  -6.7396,  ...,  -6.7346,  -5.1366,  -7.1549],\n",
      "         [-11.8462, -11.6107, -11.7122,  ...,  -9.0590,  -8.9034, -12.6724],\n",
      "         [ -5.8957,  -6.1230,  -6.0894,  ...,  -7.1693,  -7.5403,  -4.0908],\n",
      "         ...,\n",
      "         [ -6.2303,  -6.3783,  -6.2357,  ...,  -6.4754,  -6.5574,  -5.3808],\n",
      "         [ -6.2162,  -6.5323,  -6.4503,  ...,  -7.2026,  -7.3583,  -3.5786],\n",
      "         [ -7.1196,  -7.2475,  -7.2622,  ...,  -7.7138,  -7.9063,  -4.2902]],\n",
      "\n",
      "        [[ -6.9101,  -6.9371,  -6.9487,  ...,  -6.2296,  -6.1611,  -4.2752],\n",
      "         [-10.7703, -10.5651, -10.6498,  ...,  -8.5134,  -8.3147,  -7.9950],\n",
      "         [ -6.3306,  -6.3332,  -6.4398,  ...,  -6.8986,  -7.6405,  -2.4344],\n",
      "         ...,\n",
      "         [ -6.0322,  -6.0567,  -6.0535,  ...,  -6.6878,  -7.3030,  -2.9430],\n",
      "         [ -6.4092,  -6.5011,  -6.4534,  ...,  -7.1426,  -7.5402,  -4.0072],\n",
      "         [ -5.9153,  -5.9848,  -5.9628,  ...,  -6.6765,  -7.7449,  -2.5395]],\n",
      "\n",
      "        [[ -6.8681,  -6.7690,  -6.7952,  ...,  -6.0349,  -5.8719,  -4.1695],\n",
      "         [-10.9893, -10.7659, -10.6860,  ...,  -8.4966,  -8.8088,  -8.5828],\n",
      "         [ -5.7448,  -5.7317,  -5.7695,  ...,  -5.8946,  -7.1348,  -2.0746],\n",
      "         ...,\n",
      "         [ -6.3019,  -6.2285,  -6.1523,  ...,  -6.0171,  -7.6971,  -3.2491],\n",
      "         [ -6.2215,  -6.1340,  -6.0681,  ...,  -6.3876,  -7.3362,  -3.0088],\n",
      "         [ -5.6778,  -5.6552,  -5.4945,  ...,  -5.5929,  -7.3550,  -2.8277]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7035,  -6.6837,  -6.7563,  ...,  -6.1743,  -5.9511,  -3.4707],\n",
      "         [ -9.2371,  -9.2025,  -9.2347,  ...,  -9.5556,  -9.7388,  -4.6344],\n",
      "         [ -7.0313,  -6.9847,  -6.9750,  ...,  -7.7258,  -8.2580,  -2.7898],\n",
      "         ...,\n",
      "         [ -6.4613,  -6.2702,  -6.3536,  ...,  -6.1934,  -7.0735,  -2.0578],\n",
      "         [ -6.3573,  -6.3064,  -6.4781,  ...,  -6.6865,  -7.2182,  -1.5452],\n",
      "         [ -6.1908,  -6.0979,  -6.2712,  ...,  -6.1319,  -7.2123,  -1.9346]],\n",
      "\n",
      "        [[ -6.3805,  -6.3451,  -6.3590,  ...,  -5.7092,  -5.5259,  -3.8269],\n",
      "         [-17.2126, -16.6405, -16.7740,  ..., -15.0138, -13.9411, -10.9868],\n",
      "         [ -5.7321,  -5.7833,  -5.8118,  ...,  -6.2736,  -7.7634,  -2.9914],\n",
      "         ...,\n",
      "         [ -5.9731,  -6.0019,  -5.9710,  ...,  -5.9474,  -7.4270,  -3.6929],\n",
      "         [ -6.1273,  -6.1870,  -6.1976,  ...,  -6.2470,  -7.6986,  -2.5515],\n",
      "         [ -5.6951,  -5.6577,  -5.7720,  ...,  -5.6439,  -7.0725,  -2.8071]],\n",
      "\n",
      "        [[ -5.8116,  -5.7745,  -5.6531,  ...,  -6.4554,  -4.9967,  -3.3774],\n",
      "         [-11.6052, -11.4891, -11.5993,  ...,  -8.7259,  -9.5788,  -8.4727],\n",
      "         [ -5.9920,  -6.0181,  -6.0823,  ...,  -6.8492,  -7.2533,  -3.6516],\n",
      "         ...,\n",
      "         [ -6.5928,  -6.7222,  -6.5548,  ...,  -7.0296,  -7.1818,  -5.8998],\n",
      "         [ -6.8546,  -6.7913,  -6.7920,  ...,  -7.4844,  -7.6799,  -4.7767],\n",
      "         [ -6.6157,  -6.6686,  -6.6876,  ...,  -7.9005,  -7.4992,  -4.8357]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.822143793106079\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1113, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5481,  -6.5275,  -6.5220,  ...,  -5.9425,  -5.5952,  -3.9882],\n",
      "         [ -8.8029,  -9.1194,  -8.7916,  ...,  -8.3434,  -6.6780,  -7.2034],\n",
      "         [-10.6803, -10.4420, -10.5430,  ...,  -8.6699,  -6.5977,  -9.0048],\n",
      "         ...,\n",
      "         [ -6.8584,  -6.8865,  -6.8910,  ...,  -7.1179,  -5.6923,  -4.3272],\n",
      "         [ -4.7939,  -4.6202,  -4.6279,  ...,  -4.3306,  -3.5690,  -5.3646],\n",
      "         [-11.5725, -11.4429, -11.1708,  ...,  -9.1148,  -9.5577, -11.2295]],\n",
      "\n",
      "        [[ -7.4119,  -7.4216,  -7.4663,  ...,  -6.7763,  -6.7619,  -4.8724],\n",
      "         [-12.6792, -12.3091, -12.7297,  ..., -11.2159,  -9.5740, -11.2867],\n",
      "         [ -5.3792,  -5.5271,  -5.4735,  ...,  -5.9942,  -7.1186,  -3.7423],\n",
      "         ...,\n",
      "         [ -6.5029,  -6.6933,  -6.7392,  ...,  -7.3016,  -8.2918,  -2.6118],\n",
      "         [ -5.6311,  -5.7027,  -5.6767,  ...,  -6.1033,  -7.4307,  -1.4177],\n",
      "         [ -5.8823,  -6.0846,  -6.0529,  ...,  -6.4784,  -7.6914,  -2.2392]],\n",
      "\n",
      "        [[ -7.2848,  -7.2926,  -7.2788,  ...,  -6.5457,  -6.3785,  -3.5361],\n",
      "         [-14.5483, -14.5382, -14.5606,  ..., -13.1850, -11.6654, -12.0172],\n",
      "         [ -8.4832,  -7.9729,  -8.1945,  ...,  -6.7016,  -7.0737,  -6.7680],\n",
      "         ...,\n",
      "         [-12.8204, -12.9005, -12.9535,  ..., -12.3013, -10.3291,  -3.3513],\n",
      "         [-11.6954, -11.5416, -11.8588,  ..., -10.0635,  -9.9913,  -7.1027],\n",
      "         [ -9.2609,  -8.9710,  -8.7174,  ...,  -6.3387,  -7.8783,  -8.4132]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.4678,  -5.7416,  -5.6745,  ...,  -5.8823,  -4.6604,  -3.7810],\n",
      "         [ -9.7005,  -9.2070,  -9.2463,  ...,  -6.3758,  -7.0382,  -9.0507],\n",
      "         [ -6.1462,  -6.2597,  -6.1962,  ...,  -6.8784,  -6.9267,  -5.4411],\n",
      "         ...,\n",
      "         [ -6.9841,  -7.0652,  -6.8993,  ...,  -7.4863,  -7.5102,  -4.7750],\n",
      "         [ -6.9064,  -6.9064,  -6.9321,  ...,  -7.5094,  -7.6971,  -3.4059],\n",
      "         [ -7.4967,  -7.6058,  -7.5497,  ...,  -8.1757,  -8.2290,  -5.5689]],\n",
      "\n",
      "        [[ -6.7925,  -6.7992,  -6.7720,  ...,  -6.1468,  -6.0728,  -4.2104],\n",
      "         [-14.5200, -14.5210, -14.8019,  ..., -12.4122, -10.8776, -17.2459],\n",
      "         [ -9.5368,  -9.6805,  -9.6169,  ...,  -8.7605,  -7.5482,  -9.8787],\n",
      "         ...,\n",
      "         [-14.4772, -14.8811, -14.4146,  ..., -11.8781, -11.9671, -11.0619],\n",
      "         [ -8.3966,  -8.3671,  -7.9550,  ...,  -8.4841,  -6.2791,  -6.0610],\n",
      "         [-10.8900, -10.4859, -10.8249,  ...,  -8.1692,  -9.0008,  -8.9140]],\n",
      "\n",
      "        [[ -6.6634,  -6.6218,  -6.6583,  ...,  -6.0305,  -5.9056,  -3.7695],\n",
      "         [ -7.3747,  -7.3506,  -7.2228,  ...,  -7.9412,  -8.1467,  -1.6363],\n",
      "         [-10.7992, -10.7767, -10.7892,  ..., -12.2347, -10.2868,  -4.9812],\n",
      "         ...,\n",
      "         [ -6.4412,  -6.2675,  -6.2625,  ...,  -6.9742,  -6.9461,  -1.1890],\n",
      "         [ -6.5450,  -6.4242,  -6.4164,  ...,  -7.0589,  -6.6399,  -1.2614],\n",
      "         [ -6.7684,  -6.5599,  -6.5445,  ...,  -6.9212,  -6.5834,  -1.4712]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1113245487213135\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.2368, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0035,  -6.9602,  -6.9882,  ...,  -6.4337,  -6.3274,  -3.9110],\n",
      "         [ -6.9308,  -6.7230,  -6.9422,  ...,  -7.5624,  -7.6462,  -1.7011],\n",
      "         [ -7.6059,  -7.4073,  -7.6327,  ...,  -8.4886,  -7.6387,  -1.4996],\n",
      "         ...,\n",
      "         [ -7.3562,  -7.2654,  -7.3798,  ...,  -7.9000,  -7.4644,  -1.9130],\n",
      "         [ -6.9356,  -6.7960,  -6.8959,  ...,  -7.5203,  -7.1399,  -1.5561],\n",
      "         [ -6.7112,  -6.6113,  -6.7389,  ...,  -7.2876,  -7.2732,  -1.5216]],\n",
      "\n",
      "        [[ -6.7395,  -6.7135,  -6.6860,  ...,  -6.1612,  -6.0094,  -4.2085],\n",
      "         [ -9.1876,  -9.3641,  -9.7473,  ...,  -9.2512,  -8.2707,  -9.4689],\n",
      "         [-11.3180, -11.5754, -11.8492,  ...,  -9.9602,  -8.6506, -13.1503],\n",
      "         ...,\n",
      "         [-14.3265, -14.2805, -14.3422,  ..., -12.0963, -12.0698, -11.8696],\n",
      "         [ -9.4172,  -9.7041,  -9.3939,  ..., -10.5644,  -9.4747, -11.3863],\n",
      "         [-12.1936, -11.9052, -12.1874,  ...,  -9.4611, -10.0964,  -8.7884]],\n",
      "\n",
      "        [[ -6.8750,  -6.7800,  -6.8032,  ...,  -6.2392,  -5.7967,  -4.0958],\n",
      "         [ -6.3330,  -6.2035,  -6.5583,  ...,  -4.7945,  -4.6833,  -5.2880],\n",
      "         [ -7.8623,  -7.8800,  -7.8705,  ...,  -7.9371,  -7.7655,  -3.5670],\n",
      "         ...,\n",
      "         [ -7.3424,  -7.2992,  -7.4128,  ...,  -7.3430,  -7.4294,  -2.5924],\n",
      "         [ -7.4092,  -7.4364,  -7.4586,  ...,  -7.4283,  -7.5770,  -4.0083],\n",
      "         [ -8.1487,  -8.1230,  -8.2069,  ...,  -7.8606,  -8.2306,  -3.1642]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5491,  -6.6130,  -6.5301,  ...,  -5.8435,  -6.0966,  -4.6814],\n",
      "         [-13.8574, -13.9668, -13.8198,  ..., -12.4540, -11.4157, -13.2977],\n",
      "         [ -5.9981,  -6.2510,  -6.2707,  ...,  -6.0621,  -5.4408,  -5.3290],\n",
      "         ...,\n",
      "         [ -3.7170,  -3.8268,  -3.7311,  ...,  -3.1247,  -3.2882,  -3.2717],\n",
      "         [ -5.0852,  -5.2629,  -5.2807,  ...,  -5.4695,  -5.1170,  -3.0349],\n",
      "         [-11.5304, -11.7770, -11.5447,  ...,  -8.4807,  -9.6756,  -8.2959]],\n",
      "\n",
      "        [[ -4.9270,  -4.9488,  -5.1103,  ...,  -5.4404,  -4.3009,  -4.8586],\n",
      "         [-10.7827, -10.3725, -10.4609,  ...,  -7.3630,  -6.7565, -10.7962],\n",
      "         [ -6.6868,  -6.7384,  -6.6459,  ...,  -7.1372,  -7.1397,  -4.2186],\n",
      "         ...,\n",
      "         [ -6.9669,  -7.0441,  -6.9932,  ...,  -7.3278,  -7.3943,  -5.0906],\n",
      "         [ -6.5920,  -6.7765,  -6.6156,  ...,  -6.7868,  -6.5237,  -5.7869],\n",
      "         [ -6.3477,  -6.4189,  -6.2834,  ...,  -6.3201,  -6.7253,  -4.2380]],\n",
      "\n",
      "        [[ -6.9559,  -6.9338,  -6.8457,  ...,  -6.3228,  -6.2241,  -4.0576],\n",
      "         [-12.2685, -12.0533, -12.4729,  ..., -11.0276, -10.8086, -10.1347],\n",
      "         [-11.1218, -10.9222, -10.8708,  ..., -10.8278,  -8.3410,  -8.5684],\n",
      "         ...,\n",
      "         [ -9.9600, -10.0374,  -9.8348,  ...,  -9.5424,  -9.8430,  -6.5242],\n",
      "         [-10.5088, -10.6894, -10.7497,  ...,  -9.7014, -10.1685,  -5.7490],\n",
      "         [-12.1690, -11.9857, -12.6231,  ..., -12.2537, -10.0738,  -7.7539]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.23679518699646\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7014, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0833,  -7.0267,  -7.0390,  ...,  -6.2872,  -6.1538,  -4.1615],\n",
      "         [-11.9255, -11.3412, -11.6786,  ...,  -9.4080,  -8.8552, -10.7780],\n",
      "         [ -5.6429,  -5.6789,  -5.5636,  ...,  -5.5142,  -6.8094,  -3.2405],\n",
      "         ...,\n",
      "         [ -4.6011,  -4.6763,  -4.5556,  ...,  -5.0037,  -6.3627,  -2.9736],\n",
      "         [ -5.1183,  -5.2450,  -5.0595,  ...,  -5.5326,  -6.6012,  -4.0215],\n",
      "         [ -5.2186,  -5.1889,  -5.0305,  ...,  -5.3301,  -7.1219,  -3.1819]],\n",
      "\n",
      "        [[ -7.2441,  -7.3260,  -7.3451,  ...,  -6.8756,  -6.7216,  -4.1846],\n",
      "         [-14.5363, -14.3479, -14.6879,  ..., -12.9622, -12.3003, -13.6104],\n",
      "         [ -3.9603,  -3.9684,  -3.9305,  ...,  -3.8111,  -3.5099,  -6.8946],\n",
      "         ...,\n",
      "         [ -8.5264,  -8.4871,  -8.5882,  ...,  -8.8490,  -8.1437,  -5.1357],\n",
      "         [ -7.1436,  -7.2362,  -7.3193,  ...,  -6.7283,  -7.4128,  -2.4824],\n",
      "         [ -6.6654,  -6.6985,  -6.9566,  ...,  -6.3745,  -6.6862,  -2.3817]],\n",
      "\n",
      "        [[ -6.7886,  -6.7168,  -6.7177,  ...,  -6.2033,  -5.9637,  -4.0847],\n",
      "         [-10.7669, -10.5213, -11.1259,  ...,  -9.3085, -10.1881, -11.7267],\n",
      "         [ -1.2617,  -1.1946,  -1.1054,  ...,   0.2196,  -2.6537,  -1.7237],\n",
      "         ...,\n",
      "         [ -2.0385,  -2.1832,  -1.9592,  ...,  -2.5603,  -2.7257,   0.4878],\n",
      "         [-10.1616, -10.0718, -10.1155,  ...,  -9.1640, -10.1651,  -4.3871],\n",
      "         [-14.6666, -14.4086, -14.5612,  ..., -11.4702, -13.7560, -10.3188]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8178,  -6.7401,  -6.7591,  ...,  -6.0023,  -5.7424,  -4.2357],\n",
      "         [ -9.5242,  -9.8042,  -9.4555,  ...,  -7.6742,  -8.0250,  -8.4544],\n",
      "         [ -5.5850,  -5.6079,  -5.6883,  ...,  -6.0051,  -7.1618,  -3.6126],\n",
      "         ...,\n",
      "         [ -5.3902,  -5.3382,  -5.4145,  ...,  -5.7104,  -7.3817,  -3.9303],\n",
      "         [ -5.0911,  -5.1317,  -5.1967,  ...,  -5.7196,  -7.1638,  -2.9272],\n",
      "         [ -5.7570,  -5.7799,  -5.8285,  ...,  -6.0356,  -7.1334,  -2.9030]],\n",
      "\n",
      "        [[ -7.2805,  -7.2971,  -7.2563,  ...,  -6.5983,  -6.6986,  -4.5696],\n",
      "         [-11.2669, -11.2066, -11.1301,  ..., -10.1628, -10.9109,  -6.0811],\n",
      "         [ -5.7531,  -6.1932,  -6.1525,  ...,  -6.1828,  -5.0726,  -1.3232],\n",
      "         ...,\n",
      "         [ -6.2407,  -6.4453,  -6.4487,  ...,  -7.1399,  -6.4382,  -4.2397],\n",
      "         [ -5.9384,  -6.1182,  -5.9489,  ...,  -7.4365,  -6.5611,  -2.5870],\n",
      "         [ -6.7261,  -6.8432,  -6.9278,  ...,  -7.0714,  -6.6828,  -5.6481]],\n",
      "\n",
      "        [[ -6.7142,  -6.6402,  -6.6602,  ...,  -5.9486,  -5.8164,  -4.0027],\n",
      "         [-10.3216, -10.0570, -10.2226,  ...,  -7.6029,  -9.0683,  -8.8354],\n",
      "         [ -5.5188,  -5.6538,  -5.5388,  ...,  -6.3925,  -7.2848,  -4.2496],\n",
      "         ...,\n",
      "         [ -5.7867,  -5.9628,  -5.7901,  ...,  -5.6008,  -7.3330,  -3.6720],\n",
      "         [ -6.0853,  -6.1147,  -5.9620,  ...,  -6.4236,  -6.7516,  -5.2475],\n",
      "         [ -5.6732,  -5.6292,  -5.5783,  ...,  -5.9715,  -7.2610,  -3.6344]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.701423406600952\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7063, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1703,  -7.1098,  -7.1621,  ...,  -6.4679,  -6.5019,  -3.6876],\n",
      "         [ -9.0388,  -8.8100,  -9.2087,  ...,  -9.6384,  -9.8732,  -2.7279],\n",
      "         [ -8.1541,  -8.1996,  -8.1492,  ...,  -7.9754,  -7.4368,  -4.6938],\n",
      "         ...,\n",
      "         [ -6.9924,  -6.8609,  -7.1204,  ...,  -7.4219,  -7.5631,  -1.7480],\n",
      "         [ -7.0015,  -6.7636,  -7.0886,  ...,  -7.1727,  -7.2834,  -1.8212],\n",
      "         [ -7.0703,  -6.8414,  -7.0729,  ...,  -6.9172,  -7.2152,  -1.1506]],\n",
      "\n",
      "        [[ -6.5050,  -6.5081,  -6.4711,  ...,  -6.0280,  -5.9636,  -3.7978],\n",
      "         [ -7.1514,  -7.0987,  -7.3786,  ...,  -7.7496,  -6.2366,  -8.0058],\n",
      "         [ -9.3298,  -9.1576,  -9.4956,  ...,  -8.9947,  -8.3508,  -9.3509],\n",
      "         ...,\n",
      "         [ -3.2904,  -3.5962,  -3.4003,  ...,  -3.5541,  -5.1200,  -2.2370],\n",
      "         [-13.9034, -14.1629, -14.1277,  ..., -13.9879, -14.1658,  -8.4271],\n",
      "         [-13.4140, -13.6280, -13.5290,  ..., -12.3603, -10.9179,  -9.3024]],\n",
      "\n",
      "        [[ -6.6251,  -6.6323,  -6.6377,  ...,  -6.1116,  -5.8225,  -4.4445],\n",
      "         [-14.4087, -14.4829, -14.5391,  ..., -13.6150, -11.3732, -16.3627],\n",
      "         [ -5.9268,  -5.6425,  -5.9668,  ...,  -6.4854,  -5.5507,  -5.0681],\n",
      "         ...,\n",
      "         [ -7.8081,  -7.8299,  -7.8523,  ...,  -8.5151,  -8.0843,  -6.4337],\n",
      "         [ -5.2726,  -5.2397,  -5.2914,  ...,  -5.3555,  -5.5398,  -1.6154],\n",
      "         [ -7.4252,  -7.4408,  -7.4523,  ...,  -8.1736,  -7.7327,  -7.0116]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4670,  -6.4430,  -6.4375,  ...,  -5.6720,  -5.9986,  -3.7808],\n",
      "         [ -7.5781,  -7.5056,  -7.3141,  ...,  -6.5696,  -5.7106,  -6.5997],\n",
      "         [ -5.6718,  -5.7546,  -5.6774,  ...,  -6.6512,  -8.1904,  -2.1392],\n",
      "         ...,\n",
      "         [ -5.5199,  -5.5762,  -5.4028,  ...,  -6.0318,  -7.4305,  -2.6384],\n",
      "         [ -6.0501,  -5.9652,  -5.9991,  ...,  -6.1907,  -7.8025,  -3.6242],\n",
      "         [ -5.3545,  -5.3908,  -5.2868,  ...,  -5.6959,  -7.6289,  -1.9747]],\n",
      "\n",
      "        [[ -6.6062,  -6.5948,  -6.6213,  ...,  -6.5578,  -6.5627,  -2.9681],\n",
      "         [ -7.4710,  -7.5939,  -7.6316,  ...,  -8.8692,  -9.1553,  -2.7489],\n",
      "         [ -6.9389,  -7.0238,  -7.2466,  ...,  -7.8021,  -8.0833,  -1.6424],\n",
      "         ...,\n",
      "         [ -6.1075,  -5.9802,  -6.1718,  ...,  -6.8685,  -6.4484,  -0.8434],\n",
      "         [ -6.4263,  -6.2754,  -6.5014,  ...,  -7.2572,  -6.8919,  -0.8548],\n",
      "         [ -6.1741,  -5.9913,  -6.1658,  ...,  -6.8238,  -6.5131,  -1.7522]],\n",
      "\n",
      "        [[ -6.3397,  -6.3717,  -6.3679,  ...,  -6.6552,  -6.7137,  -2.7863],\n",
      "         [ -8.7066,  -8.8110,  -8.8777,  ...,  -9.8379,  -9.3134,  -3.6620],\n",
      "         [ -8.7368,  -8.7738,  -8.9365,  ...,  -9.4551,  -9.8341,  -3.4702],\n",
      "         ...,\n",
      "         [ -6.9564,  -6.9817,  -6.9308,  ...,  -7.3908,  -7.2542,  -2.2450],\n",
      "         [ -6.1037,  -6.0138,  -6.1121,  ...,  -6.4917,  -6.4665,  -1.6883],\n",
      "         [ -6.1162,  -5.9280,  -6.0623,  ...,  -6.6945,  -6.7352,  -2.2250]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.706277370452881\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1027, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7334,  -6.7193,  -6.6738,  ...,  -5.9046,  -5.9765,  -3.9232],\n",
      "         [-13.0076, -12.1814, -12.7273,  ...,  -9.2988,  -9.7394, -10.0751],\n",
      "         [ -5.2520,  -5.3562,  -5.4044,  ...,  -5.9591,  -7.0955,  -2.6935],\n",
      "         ...,\n",
      "         [ -5.9161,  -5.9832,  -5.9420,  ...,  -6.2323,  -8.0386,  -4.1207],\n",
      "         [ -5.8069,  -6.0727,  -5.9625,  ...,  -6.4816,  -8.1718,  -3.5979],\n",
      "         [ -6.2435,  -6.2646,  -6.2099,  ...,  -6.4480,  -7.5489,  -4.1505]],\n",
      "\n",
      "        [[ -6.5785,  -6.5131,  -6.5372,  ...,  -5.8433,  -5.5873,  -4.0254],\n",
      "         [-12.1777, -11.6723, -11.9627,  ...,  -8.6549,  -9.6129,  -7.8909],\n",
      "         [ -6.5338,  -6.6694,  -6.5854,  ...,  -7.3815,  -7.8097,  -3.1353],\n",
      "         ...,\n",
      "         [ -6.6179,  -6.6644,  -6.6686,  ...,  -6.9772,  -7.5085,  -2.5044],\n",
      "         [ -7.1883,  -7.3762,  -7.1819,  ...,  -7.9097,  -7.7919,  -3.1313],\n",
      "         [ -6.6423,  -6.7115,  -6.7068,  ...,  -7.0370,  -7.4881,  -3.0296]],\n",
      "\n",
      "        [[ -7.1646,  -7.1387,  -7.0889,  ...,  -6.2853,  -6.4460,  -3.2501],\n",
      "         [-13.1759, -13.3787, -13.3957,  ..., -12.6038, -11.2170,  -5.3363],\n",
      "         [ -2.8283,  -2.8946,  -2.7267,  ...,  -4.0385,  -2.3708,   0.3110],\n",
      "         ...,\n",
      "         [ -9.6096,  -9.5993,  -9.6597,  ...,  -9.6519,  -8.7921,  -1.9981],\n",
      "         [ -9.2494,  -9.4222,  -9.3714,  ...,  -9.6097,  -8.6496,  -1.2245],\n",
      "         [ -9.4386,  -9.5335,  -9.4305,  ...,  -9.5640,  -8.3342,  -1.4951]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9890,  -6.9583,  -6.9381,  ...,  -6.5441,  -6.1681,  -4.0728],\n",
      "         [ -6.1421,  -6.0845,  -6.2785,  ...,  -6.3674,  -5.4950,  -4.2505],\n",
      "         [-15.1837, -15.5758, -15.6781,  ..., -14.8743, -11.9182, -11.6754],\n",
      "         ...,\n",
      "         [ -7.5741,  -7.7715,  -7.6985,  ...,  -6.1645,  -7.2213,  -1.6887],\n",
      "         [ -6.9205,  -7.0950,  -7.0999,  ...,  -6.2503,  -6.6422,  -1.8778],\n",
      "         [-12.0801, -12.1095, -11.9349,  ..., -10.3901,  -9.2427, -10.4124]],\n",
      "\n",
      "        [[ -7.2113,  -7.1754,  -7.2168,  ...,  -6.5008,  -6.4793,  -4.2280],\n",
      "         [-10.0614,  -9.4654,  -9.9398,  ...,  -8.2593,  -7.7627,  -9.5679],\n",
      "         [ -5.7441,  -5.8340,  -5.8126,  ...,  -6.0107,  -7.7704,  -2.8204],\n",
      "         ...,\n",
      "         [ -6.4440,  -6.5847,  -6.5035,  ...,  -6.8903,  -7.4872,  -4.4453],\n",
      "         [ -6.5449,  -6.5006,  -6.4536,  ...,  -6.8130,  -7.2259,  -2.2949],\n",
      "         [ -6.2869,  -6.3938,  -6.2856,  ...,  -6.6334,  -7.3794,  -2.6333]],\n",
      "\n",
      "        [[ -7.1453,  -7.1034,  -7.1044,  ...,  -6.2424,  -6.3145,  -4.5101],\n",
      "         [ -9.6331, -10.2310,  -9.7305,  ...,  -6.0951,  -8.5748, -10.8915],\n",
      "         [ -7.9710,  -8.5367,  -8.4814,  ...,  -8.9086,  -8.0454,  -8.9022],\n",
      "         ...,\n",
      "         [ -7.5132,  -7.8325,  -7.4064,  ...,  -6.1218,  -6.2984,  -8.2259],\n",
      "         [ -6.8467,  -6.9990,  -6.8969,  ...,  -6.8241,  -7.1041,  -4.0566],\n",
      "         [ -8.4414,  -8.7544,  -8.5683,  ...,  -7.7560,  -7.9898,  -2.7346]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1027469635009766\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9280, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3338,  -7.3600,  -7.3194,  ...,  -6.9155,  -6.6207,  -5.0361],\n",
      "         [ -7.2846,  -7.1276,  -7.0828,  ...,  -7.2237,  -7.7938,  -8.0095],\n",
      "         [ -9.1298,  -9.0791,  -9.3770,  ...,  -8.8838,  -9.1333,  -7.2251],\n",
      "         ...,\n",
      "         [-11.4567, -11.5310, -11.9045,  ..., -10.9730, -10.0268,  -9.9177],\n",
      "         [-11.0980, -10.7986, -10.7180,  ..., -10.7968,  -9.3177,  -7.2712],\n",
      "         [-11.8024, -11.9178, -12.1752,  ..., -10.7920, -10.1509,  -9.3026]],\n",
      "\n",
      "        [[ -7.9750,  -8.0762,  -8.0508,  ...,  -7.1011,  -7.6634,  -4.4006],\n",
      "         [-10.3227, -10.2660, -10.3115,  ...,  -8.4652,  -9.0423,  -8.3085],\n",
      "         [ -5.1047,  -5.2660,  -5.1622,  ...,  -5.6313,  -7.5943,  -2.2616],\n",
      "         ...,\n",
      "         [ -5.2706,  -5.3350,  -5.2299,  ...,  -6.1824,  -7.4078,  -3.1268],\n",
      "         [ -5.4630,  -5.4778,  -5.4595,  ...,  -6.2225,  -7.7208,  -2.4526],\n",
      "         [ -5.7183,  -5.8700,  -5.7492,  ...,  -6.3070,  -8.1356,  -2.0968]],\n",
      "\n",
      "        [[ -7.0960,  -7.0716,  -7.0164,  ...,  -6.4790,  -6.2489,  -4.2920],\n",
      "         [ -8.5537,  -8.5741,  -8.4764,  ...,  -8.0003,  -6.0335,  -6.3633],\n",
      "         [ -9.7630,  -9.8646, -10.0110,  ...,  -7.2787,  -6.4437,  -8.3470],\n",
      "         ...,\n",
      "         [ -7.6332,  -8.2225,  -7.9092,  ...,  -8.8166,  -7.3243,  -5.2435],\n",
      "         [ -7.7870,  -8.2012,  -7.8493,  ...,  -8.1647,  -6.5825,  -4.9864],\n",
      "         [-13.6334, -13.3634, -12.9456,  ..., -11.0490,  -9.0470, -11.7505]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-12.5453, -11.9405, -12.1510,  ..., -10.5833, -12.1111,  -6.1087],\n",
      "         [-14.6795, -14.3739, -14.7221,  ..., -11.6363, -12.5600, -13.1096],\n",
      "         [ -5.2916,  -5.2272,  -5.3255,  ...,  -5.4226,  -7.7722,  -2.1560],\n",
      "         ...,\n",
      "         [ -6.3199,  -6.2285,  -6.4016,  ...,  -5.8494,  -8.7689,  -0.4000],\n",
      "         [ -4.9198,  -4.9091,  -4.8227,  ...,  -5.2736,  -7.6165,  -1.5767],\n",
      "         [ -4.7292,  -4.6193,  -4.6046,  ...,  -4.3734,  -6.9890,  -0.6922]],\n",
      "\n",
      "        [[ -6.9300,  -6.8413,  -6.8554,  ...,  -6.0756,  -6.8501,  -3.4435],\n",
      "         [ -6.2984,  -6.0977,  -6.2957,  ...,  -6.8370,  -7.6254,  -1.8999],\n",
      "         [ -8.0819,  -7.9798,  -7.9427,  ...,  -8.3178,  -8.8650,  -4.1380],\n",
      "         ...,\n",
      "         [ -5.7878,  -5.5601,  -5.6543,  ...,  -5.9634,  -6.1643,  -1.5303],\n",
      "         [ -5.9294,  -5.7770,  -5.7658,  ...,  -6.0226,  -6.4286,  -1.4164],\n",
      "         [ -6.0201,  -5.9068,  -5.9583,  ...,  -6.3177,  -6.9781,  -1.7085]],\n",
      "\n",
      "        [[-10.1367,  -9.9851, -10.1303,  ..., -10.0738, -10.7902,  -7.9659],\n",
      "         [-12.5899, -12.7974, -12.7410,  ...,  -9.3212, -10.3069, -10.4527],\n",
      "         [ -5.8746,  -5.9320,  -5.9071,  ...,  -6.7946,  -7.6459,  -2.7167],\n",
      "         ...,\n",
      "         [ -5.8958,  -5.9408,  -5.8662,  ...,  -7.1543,  -7.6414,  -4.8983],\n",
      "         [ -5.8323,  -5.7334,  -5.8478,  ...,  -7.5632,  -7.5060,  -3.7672],\n",
      "         [ -4.1971,  -4.2436,  -4.2303,  ...,  -5.7927,  -6.8193,  -3.8274]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.9279953241348267\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0983, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4745,  -7.4438,  -7.4720,  ...,  -6.9100,  -6.8359,  -5.3492],\n",
      "         [ -8.8162,  -8.2662,  -8.7964,  ...,  -8.1554,  -7.1131,  -8.9738],\n",
      "         [ -5.5786,  -5.7483,  -5.7119,  ...,  -6.4417,  -6.7269,  -4.4601],\n",
      "         ...,\n",
      "         [ -5.8317,  -5.8683,  -5.8203,  ...,  -6.4707,  -6.3579,  -5.6235],\n",
      "         [ -5.9689,  -6.2360,  -6.0898,  ...,  -6.3189,  -6.8990,  -5.4052],\n",
      "         [ -5.1076,  -5.4296,  -5.2952,  ...,  -6.2787,  -5.4918,  -4.4823]],\n",
      "\n",
      "        [[-10.0020,  -9.9338,  -9.8498,  ...,  -9.7669,  -9.3753,  -5.4565],\n",
      "         [-10.9519, -11.1909, -11.0495,  ...,  -8.9103,  -8.9937, -11.5443],\n",
      "         [ -6.1310,  -6.0632,  -5.9687,  ...,  -6.8404,  -8.1173,  -3.8777],\n",
      "         ...,\n",
      "         [ -6.1291,  -5.9608,  -5.7999,  ...,  -7.3472,  -6.7171,  -5.1441],\n",
      "         [ -6.2233,  -6.1836,  -6.1386,  ...,  -7.1912,  -7.2773,  -4.3610],\n",
      "         [ -6.3859,  -6.3727,  -6.3381,  ...,  -6.9956,  -7.1297,  -4.0996]],\n",
      "\n",
      "        [[ -7.4594,  -7.4126,  -7.4497,  ...,  -6.8436,  -6.6276,  -3.8623],\n",
      "         [-11.7315, -12.1392, -12.0500,  ..., -11.3864,  -9.2890,  -6.5588],\n",
      "         [ -6.3696,  -6.6857,  -7.2383,  ...,  -7.0969,  -6.6064,  -2.5498],\n",
      "         ...,\n",
      "         [ -6.4405,  -6.0590,  -6.4167,  ...,  -4.8052,  -3.7743,  -3.8168],\n",
      "         [ -8.7407,  -8.6987,  -8.8198,  ...,  -9.3064,  -8.0974,  -5.0917],\n",
      "         [ -9.2880,  -9.2658,  -9.2953,  ...,  -9.3674,  -8.4420,  -4.9899]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0531,  -7.0162,  -7.0087,  ...,  -6.3295,  -6.0079,  -4.3397],\n",
      "         [ -7.5917,  -7.4141,  -7.4328,  ...,  -7.2108,  -5.8849,  -3.1216],\n",
      "         [ -8.5128,  -9.0040,  -8.7124,  ...,  -8.1288,  -7.5559,  -5.9400],\n",
      "         ...,\n",
      "         [-15.5228, -15.4741, -15.7627,  ..., -14.8484, -13.2539, -13.0099],\n",
      "         [ -6.6284,  -6.3153,  -6.4217,  ...,  -8.2204,  -6.9866,  -3.5685],\n",
      "         [-11.7409, -11.4436, -11.4091,  ...,  -9.3330, -10.7496, -10.7063]],\n",
      "\n",
      "        [[ -7.1120,  -7.0738,  -7.0746,  ...,  -6.3899,  -6.4338,  -4.6178],\n",
      "         [-15.6794, -15.4898, -15.6303,  ..., -14.4802, -12.9872, -12.6805],\n",
      "         [-13.5715, -13.5128, -13.8248,  ..., -12.8989, -13.9725, -14.1667],\n",
      "         ...,\n",
      "         [ -8.6482,  -8.9128,  -8.6817,  ...,  -9.2510,  -8.5552,  -5.8323],\n",
      "         [ -7.7162,  -7.6501,  -7.3744,  ...,  -7.3609,  -5.5573,  -7.0714],\n",
      "         [ -7.9371,  -7.8801,  -7.7724,  ...,  -8.6344,  -7.1053,  -4.7173]],\n",
      "\n",
      "        [[ -6.7802,  -6.8017,  -6.6210,  ...,  -6.1582,  -5.8054,  -3.1260],\n",
      "         [ -9.1884,  -9.1664,  -9.0525,  ...,  -8.5980,  -7.7786,  -7.3088],\n",
      "         [ -8.9286,  -9.0130,  -8.3839,  ...,  -8.8435,  -7.5688,  -7.5372],\n",
      "         ...,\n",
      "         [ -7.2235,  -7.4110,  -7.4431,  ...,  -6.8187,  -5.8196,  -7.6588],\n",
      "         [ -8.0121,  -8.2263,  -8.1388,  ...,  -7.3122,  -6.3276,  -5.4834],\n",
      "         [-11.7272, -11.1520, -11.4832,  ...,  -9.5493,  -9.7348,  -8.6216]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.0983293056488037\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1461, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4646,  -6.4375,  -6.4286,  ...,  -5.8984,  -5.6522,  -3.7481],\n",
      "         [ -9.3492,  -9.1517,  -9.2347,  ...,  -8.3966,  -9.9356,  -5.7885],\n",
      "         [ -5.8807,  -5.8740,  -6.0428,  ...,  -5.2437,  -5.6840,  -5.0590],\n",
      "         ...,\n",
      "         [ -5.9392,  -5.9381,  -5.9825,  ...,  -6.4329,  -6.5607,  -2.8149],\n",
      "         [ -6.1017,  -6.1030,  -6.1779,  ...,  -6.1528,  -6.7318,  -3.3183],\n",
      "         [ -5.9577,  -5.9777,  -6.1163,  ...,  -6.0923,  -6.5890,  -2.8312]],\n",
      "\n",
      "        [[ -6.6728,  -6.6588,  -6.6384,  ...,  -6.0584,  -5.8345,  -3.9855],\n",
      "         [-16.9685, -16.9320, -17.1363,  ..., -16.5054, -14.8119, -12.3067],\n",
      "         [ -9.0205,  -9.1484,  -9.1043,  ...,  -8.5781,  -9.1337,  -5.8667],\n",
      "         ...,\n",
      "         [-11.0570, -11.2044, -10.9183,  ..., -10.3530,  -8.5791,  -9.0837],\n",
      "         [ -7.2725,  -7.3347,  -7.3703,  ...,  -7.7758,  -6.2179,  -3.8337],\n",
      "         [-13.2671, -13.1254, -13.0857,  ..., -10.1610,  -9.5686,  -9.6787]],\n",
      "\n",
      "        [[ -7.0205,  -7.1049,  -7.0285,  ...,  -6.3226,  -6.0463,  -4.7834],\n",
      "         [ -8.4310,  -8.5734,  -8.8891,  ...,  -9.0841,  -7.4118, -10.3612],\n",
      "         [ -7.6131,  -7.9729,  -8.1058,  ...,  -7.7145,  -7.4287,  -5.9239],\n",
      "         ...,\n",
      "         [ -5.2174,  -5.7235,  -5.7660,  ...,  -6.3820,  -4.8808,  -7.8787],\n",
      "         [ -6.5346,  -6.8003,  -6.7885,  ...,  -7.6654,  -5.6557,  -4.0750],\n",
      "         [ -7.0236,  -7.1499,  -7.1468,  ...,  -7.8877,  -6.2873,  -5.6471]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9671,  -6.8873,  -6.8503,  ...,  -6.2437,  -6.0000,  -4.1792],\n",
      "         [-12.0674, -12.1573, -12.0741,  ..., -10.8537, -10.9310,  -8.9135],\n",
      "         [-16.3838, -16.0057, -16.1286,  ..., -12.6560, -13.5245, -12.4240],\n",
      "         ...,\n",
      "         [ -8.2572,  -8.0189,  -8.1684,  ...,  -8.0944,  -7.7397,  -6.8588],\n",
      "         [ -6.8602,  -6.8374,  -6.8067,  ...,  -7.5367,  -7.3929,  -6.9360],\n",
      "         [ -8.1933,  -8.0186,  -8.2490,  ...,  -7.7849,  -7.9744,  -5.7611]],\n",
      "\n",
      "        [[-14.2643, -14.5598, -14.4649,  ..., -14.9703, -13.2968,  -9.5162],\n",
      "         [ -9.6033,  -9.6249,  -9.5875,  ...,  -7.8806,  -7.8202,  -9.3202],\n",
      "         [ -5.6340,  -5.6732,  -5.7187,  ...,  -6.6270,  -8.1956,  -1.7468],\n",
      "         ...,\n",
      "         [ -5.1191,  -5.4266,  -5.2933,  ...,  -5.7481,  -7.5747,  -2.3044],\n",
      "         [ -6.3965,  -6.4259,  -6.5355,  ...,  -7.1661,  -8.5057,  -3.1974],\n",
      "         [ -5.9609,  -6.0501,  -6.0555,  ...,  -6.9486,  -8.2844,  -2.5402]],\n",
      "\n",
      "        [[ -6.8262,  -6.8335,  -6.8447,  ...,  -6.1696,  -6.3908,  -3.8628],\n",
      "         [-16.6213, -16.7714, -16.9743,  ..., -15.5914, -14.5979, -13.4740],\n",
      "         [-10.9758, -10.9889, -11.1295,  ...,  -9.3799,  -9.1448,  -7.5367],\n",
      "         ...,\n",
      "         [-14.0726, -13.9789, -14.5594,  ..., -12.6348, -11.2075,  -9.3288],\n",
      "         [-12.7735, -12.7480, -12.8006,  ..., -11.5181, -11.7735, -12.7661],\n",
      "         [-13.6237, -13.3846, -13.6044,  ..., -10.9404, -13.4180,  -9.9045]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1461143493652344\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.7013, grad_fn=<NllLossBackward0>), logits=tensor([[[-7.3015e+00, -7.1773e+00, -7.2021e+00,  ..., -6.9395e+00,\n",
      "          -6.9424e+00, -3.6040e+00],\n",
      "         [-1.0077e+01, -9.5905e+00, -1.0096e+01,  ..., -7.4601e+00,\n",
      "          -8.3922e+00, -8.7402e+00],\n",
      "         [-6.3738e+00, -6.3073e+00, -6.3596e+00,  ..., -7.1733e+00,\n",
      "          -7.4542e+00, -1.7921e+00],\n",
      "         ...,\n",
      "         [-6.4526e+00, -6.3981e+00, -6.4518e+00,  ..., -7.9191e+00,\n",
      "          -6.7009e+00, -3.4726e+00],\n",
      "         [-6.6141e+00, -6.5696e+00, -6.5692e+00,  ..., -7.3839e+00,\n",
      "          -6.7286e+00, -3.2101e+00],\n",
      "         [-7.1028e+00, -6.9050e+00, -7.0323e+00,  ..., -7.4780e+00,\n",
      "          -7.5890e+00, -2.8495e+00]],\n",
      "\n",
      "        [[-6.5507e+00, -6.5122e+00, -6.5400e+00,  ..., -5.7434e+00,\n",
      "          -6.1939e+00, -3.6087e+00],\n",
      "         [-7.9858e+00, -7.8735e+00, -8.0441e+00,  ..., -7.8268e+00,\n",
      "          -8.2283e+00, -3.1401e+00],\n",
      "         [-6.6486e+00, -6.6191e+00, -6.7740e+00,  ..., -6.6689e+00,\n",
      "          -6.9802e+00, -1.5392e+00],\n",
      "         ...,\n",
      "         [-5.9786e+00, -5.9215e+00, -6.0552e+00,  ..., -6.3725e+00,\n",
      "          -6.2718e+00, -9.4868e-01],\n",
      "         [-5.7988e+00, -5.7957e+00, -5.9564e+00,  ..., -6.0493e+00,\n",
      "          -6.6686e+00, -9.7651e-01],\n",
      "         [-5.4604e+00, -5.3580e+00, -5.5564e+00,  ..., -5.5583e+00,\n",
      "          -5.8129e+00, -7.9499e-03]],\n",
      "\n",
      "        [[-7.0423e+00, -7.0108e+00, -7.0401e+00,  ..., -6.3811e+00,\n",
      "          -6.1892e+00, -4.2840e+00],\n",
      "         [-1.3188e+01, -1.2829e+01, -1.2723e+01,  ..., -1.0769e+01,\n",
      "          -9.1377e+00, -1.2538e+01],\n",
      "         [-5.3857e+00, -5.4153e+00, -5.4941e+00,  ..., -6.8153e+00,\n",
      "          -7.3957e+00, -4.5808e+00],\n",
      "         ...,\n",
      "         [-6.1948e+00, -6.1156e+00, -6.1264e+00,  ..., -6.9670e+00,\n",
      "          -7.2745e+00, -5.2396e+00],\n",
      "         [-5.3124e+00, -5.3489e+00, -5.3029e+00,  ..., -5.9618e+00,\n",
      "          -7.1047e+00, -4.5914e+00],\n",
      "         [-5.8401e+00, -5.8300e+00, -5.8021e+00,  ..., -7.0998e+00,\n",
      "          -7.2335e+00, -3.8842e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.1916e+00, -8.0757e+00, -8.0970e+00,  ..., -6.9200e+00,\n",
      "          -7.1400e+00, -4.4995e+00],\n",
      "         [-1.2104e+01, -1.1552e+01, -1.1654e+01,  ..., -9.8437e+00,\n",
      "          -1.1152e+01, -1.2741e+01],\n",
      "         [-5.4700e+00, -5.3108e+00, -5.3873e+00,  ..., -5.7848e+00,\n",
      "          -7.5066e+00, -3.2595e+00],\n",
      "         ...,\n",
      "         [-6.0385e+00, -6.0103e+00, -5.8824e+00,  ..., -6.2015e+00,\n",
      "          -7.4571e+00, -2.7600e+00],\n",
      "         [-5.4605e+00, -5.4371e+00, -5.3963e+00,  ..., -5.8076e+00,\n",
      "          -7.4126e+00, -3.0887e+00],\n",
      "         [-5.5252e+00, -5.6413e+00, -5.4541e+00,  ..., -5.9862e+00,\n",
      "          -7.6381e+00, -3.2061e+00]],\n",
      "\n",
      "        [[-6.5717e+00, -6.5176e+00, -6.5567e+00,  ..., -5.8484e+00,\n",
      "          -5.5354e+00, -3.4879e+00],\n",
      "         [-1.3452e+01, -1.2879e+01, -1.2878e+01,  ..., -1.0627e+01,\n",
      "          -1.0710e+01, -8.4766e+00],\n",
      "         [-6.4003e+00, -6.6095e+00, -6.5689e+00,  ..., -7.3317e+00,\n",
      "          -8.1791e+00, -5.0515e+00],\n",
      "         ...,\n",
      "         [-5.9916e+00, -6.0282e+00, -5.9230e+00,  ..., -6.9324e+00,\n",
      "          -7.5033e+00, -2.9050e+00],\n",
      "         [-6.5558e+00, -6.7760e+00, -6.6580e+00,  ..., -7.2681e+00,\n",
      "          -8.3159e+00, -3.5960e+00],\n",
      "         [-6.5680e+00, -6.5994e+00, -6.6112e+00,  ..., -6.7100e+00,\n",
      "          -7.7517e+00, -4.2865e+00]],\n",
      "\n",
      "        [[-7.0691e+00, -6.9963e+00, -7.0312e+00,  ..., -6.6561e+00,\n",
      "          -6.7120e+00, -4.2990e+00],\n",
      "         [-7.2076e+00, -7.3019e+00, -7.3051e+00,  ..., -7.6071e+00,\n",
      "          -8.0245e+00, -1.0593e+00],\n",
      "         [-7.4792e+00, -7.6307e+00, -7.7865e+00,  ..., -7.9574e+00,\n",
      "          -8.0524e+00, -2.1185e+00],\n",
      "         ...,\n",
      "         [-6.5165e+00, -6.4203e+00, -6.5493e+00,  ..., -7.8410e+00,\n",
      "          -7.0090e+00, -2.4726e+00],\n",
      "         [-6.0290e+00, -6.0102e+00, -6.1288e+00,  ..., -6.9102e+00,\n",
      "          -6.7433e+00, -1.7834e+00],\n",
      "         [-6.0954e+00, -6.0229e+00, -6.0738e+00,  ..., -6.5896e+00,\n",
      "          -6.6361e+00, -2.2411e+00]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 0.7012555599212646\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7104, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9013,  -6.8337,  -6.8782,  ...,  -6.0775,  -6.0003,  -4.1485],\n",
      "         [-11.2686, -11.1115, -11.1766,  ...,  -8.5843,  -9.4140,  -9.5439],\n",
      "         [ -6.1502,  -6.2091,  -6.2198,  ...,  -6.5101,  -7.2350,  -3.2045],\n",
      "         ...,\n",
      "         [ -6.5515,  -6.6249,  -6.5468,  ...,  -6.5303,  -7.0609,  -3.8136],\n",
      "         [ -5.7779,  -5.9204,  -5.8148,  ...,  -5.9997,  -6.6422,  -3.1063],\n",
      "         [ -6.4372,  -6.4785,  -6.5379,  ...,  -6.3368,  -7.4894,  -2.1337]],\n",
      "\n",
      "        [[ -6.7979,  -6.6876,  -6.7251,  ...,  -6.0692,  -6.3419,  -3.0535],\n",
      "         [ -6.9134,  -6.7351,  -6.9760,  ...,  -7.4914,  -8.2092,   0.0360],\n",
      "         [ -7.9626,  -7.7400,  -7.7687,  ...,  -9.0132,  -8.8309,  -3.3037],\n",
      "         ...,\n",
      "         [ -6.1554,  -5.9489,  -6.1641,  ...,  -6.0459,  -6.8952,  -0.7484],\n",
      "         [ -6.3663,  -6.1888,  -6.3602,  ...,  -6.1429,  -6.6179,  -0.7652],\n",
      "         [ -6.6745,  -6.4760,  -6.7249,  ...,  -6.9222,  -7.2627,  -1.2906]],\n",
      "\n",
      "        [[ -7.2271,  -7.2008,  -7.1655,  ...,  -6.3567,  -6.1322,  -4.0294],\n",
      "         [-12.9783, -13.0388, -12.8966,  ..., -10.8903, -10.7129,  -9.4519],\n",
      "         [ -6.0065,  -6.1898,  -6.2569,  ...,  -5.1119,  -4.7658,  -5.1589],\n",
      "         ...,\n",
      "         [ -6.5498,  -6.4951,  -6.7656,  ...,  -5.0747,  -6.0011,  -3.7583],\n",
      "         [ -9.1742,  -9.1399,  -9.0850,  ...,  -8.6942,  -7.1487,  -5.1020],\n",
      "         [ -9.5002,  -9.5348,  -9.3982,  ...,  -9.1640,  -8.0262,  -5.4980]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.7908,  -7.7327,  -7.6934,  ...,  -7.0079,  -7.0354,  -4.4616],\n",
      "         [-13.5421, -13.2496, -13.3950,  ..., -11.9006, -11.3568,  -9.3283],\n",
      "         [-11.9642, -11.8481, -11.6175,  ..., -10.8884, -10.2051,  -6.3736],\n",
      "         ...,\n",
      "         [ -5.4672,  -5.3731,  -5.4575,  ...,  -5.7776,  -5.9843,  -6.5510],\n",
      "         [ -6.1184,  -6.1004,  -6.2153,  ...,  -6.3537,  -6.7037,  -6.0762],\n",
      "         [ -6.7654,  -6.7415,  -6.6616,  ...,  -6.5432,  -6.7959,  -5.7164]],\n",
      "\n",
      "        [[ -6.5209,  -6.4519,  -6.5011,  ...,  -5.7708,  -5.6994,  -3.7713],\n",
      "         [-16.9564, -16.5689, -16.7734,  ..., -13.8730, -14.6166, -12.2892],\n",
      "         [ -5.0477,  -5.1803,  -5.0719,  ...,  -5.3876,  -7.0589,  -3.3352],\n",
      "         ...,\n",
      "         [ -5.4579,  -5.5291,  -5.4270,  ...,  -5.5912,  -7.1353,  -2.3629],\n",
      "         [ -5.8139,  -5.9068,  -5.7203,  ...,  -6.0182,  -7.1228,  -3.1435],\n",
      "         [ -5.7670,  -5.9355,  -5.7389,  ...,  -5.4361,  -7.1338,  -3.4801]],\n",
      "\n",
      "        [[ -6.8499,  -6.8404,  -6.8237,  ...,  -6.0798,  -6.1178,  -3.3383],\n",
      "         [ -8.4658,  -8.1206,  -8.6473,  ...,  -7.9490,  -8.4341,  -7.9359],\n",
      "         [ -4.9681,  -4.9887,  -5.0752,  ...,  -5.6019,  -5.9414,  -4.3831],\n",
      "         ...,\n",
      "         [ -4.0712,  -4.1415,  -4.1846,  ...,  -4.1808,  -4.3930,  -1.3734],\n",
      "         [ -4.6017,  -4.7802,  -4.7665,  ...,  -4.8864,  -4.6115,  -3.2148],\n",
      "         [ -3.2961,  -3.4158,  -3.4797,  ...,  -3.4787,  -4.1579,  -2.0030]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.710416555404663\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8741, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6458,  -6.5476,  -6.6675,  ...,  -5.9505,  -6.7165,  -2.9011],\n",
      "         [ -5.3163,  -5.2057,  -5.3835,  ...,  -5.9643,  -7.1703,   2.0513],\n",
      "         [ -5.3142,  -5.0661,  -5.3010,  ...,  -7.0797,  -7.1259,   1.4229],\n",
      "         ...,\n",
      "         [ -6.2858,  -6.1298,  -6.2276,  ...,  -6.4662,  -7.0861,   0.6925],\n",
      "         [ -6.6638,  -6.4341,  -6.5591,  ...,  -6.5764,  -7.0042,  -0.7649],\n",
      "         [ -6.4357,  -6.2380,  -6.4652,  ...,  -6.3762,  -6.9093,   0.1489]],\n",
      "\n",
      "        [[ -6.4474,  -6.3916,  -6.4461,  ...,  -5.9200,  -5.9500,  -3.5823],\n",
      "         [ -6.0601,  -5.9829,  -6.2083,  ...,  -6.4732,  -6.5326,  -1.5957],\n",
      "         [ -7.4289,  -7.4909,  -7.5523,  ...,  -7.4839,  -7.7721,  -1.7818],\n",
      "         ...,\n",
      "         [ -6.2523,  -6.0077,  -6.2133,  ...,  -6.3053,  -6.4288,  -1.6118],\n",
      "         [ -6.1332,  -5.9446,  -6.1663,  ...,  -6.7482,  -6.4747,  -0.8876],\n",
      "         [ -6.3382,  -6.1674,  -6.3563,  ...,  -6.8463,  -6.8910,  -1.2772]],\n",
      "\n",
      "        [[ -7.1866,  -7.1845,  -7.1795,  ...,  -6.6022,  -6.4302,  -4.6192],\n",
      "         [ -7.7564,  -7.4837,  -7.8090,  ...,  -6.7761,  -7.2122,  -5.6187],\n",
      "         [ -9.7156, -10.0963, -10.1977,  ...,  -8.2107,  -8.8835,  -8.5134],\n",
      "         ...,\n",
      "         [ -5.3405,  -5.2528,  -5.4660,  ...,  -4.9556,  -5.3996,  -4.6497],\n",
      "         [ -5.1265,  -5.0630,  -5.2779,  ...,  -5.0930,  -5.4860,  -3.9961],\n",
      "         [ -6.2997,  -6.2912,  -6.4490,  ...,  -6.3081,  -6.7854,  -4.1037]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6559,  -6.6327,  -6.6554,  ...,  -6.0127,  -5.8810,  -3.7960],\n",
      "         [ -7.9838,  -7.7882,  -7.9825,  ...,  -6.9976,  -7.2493,  -5.3572],\n",
      "         [ -9.2545,  -9.3452,  -9.3550,  ...,  -9.4078,  -7.8139,  -2.6641],\n",
      "         ...,\n",
      "         [-13.6722, -13.7306, -13.7614,  ..., -11.9131, -10.9690,  -4.8407],\n",
      "         [ -9.1052,  -9.3273,  -9.3374,  ...,  -8.6063,  -8.5788,  -2.1207],\n",
      "         [-13.1845, -12.5139, -12.9841,  ..., -10.1899,  -9.0059, -12.1300]],\n",
      "\n",
      "        [[ -7.2018,  -7.1991,  -7.1797,  ...,  -6.6716,  -6.4181,  -4.1520],\n",
      "         [-12.4963, -12.3281, -12.6574,  ..., -11.7684, -10.5499, -11.2260],\n",
      "         [-11.4399, -11.5834, -11.6315,  ..., -10.2016,  -8.5772, -10.9287],\n",
      "         ...,\n",
      "         [ -5.3202,  -5.6774,  -5.5051,  ...,  -5.1013,  -5.5653,  -6.4365],\n",
      "         [ -8.3053,  -8.3059,  -8.2639,  ...,  -8.3240,  -8.4595,  -5.2339],\n",
      "         [ -9.3467,  -8.7371,  -8.9794,  ...,  -7.8190,  -8.6802,  -7.9670]],\n",
      "\n",
      "        [[ -6.8696,  -6.7839,  -6.7919,  ...,  -6.1120,  -6.0410,  -4.1236],\n",
      "         [ -8.2514,  -8.6633,  -8.6170,  ...,  -7.6941,  -7.1648,  -7.4613],\n",
      "         [ -6.1982,  -6.0448,  -6.0892,  ...,  -6.7331,  -5.4592,  -4.5139],\n",
      "         ...,\n",
      "         [ -8.0761,  -8.0454,  -7.8956,  ...,  -6.9080,  -6.5385,  -6.5453],\n",
      "         [ -7.0045,  -6.9998,  -6.7351,  ...,  -5.9016,  -5.4227,  -5.8940],\n",
      "         [ -7.9886,  -8.0545,  -8.0860,  ...,  -7.4207,  -7.3212,  -6.0348]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.874114990234375\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7707, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5489,  -6.5467,  -6.5079,  ...,  -5.9846,  -5.8096,  -4.0777],\n",
      "         [-10.8451, -11.1499, -10.9637,  ..., -10.9289,  -9.2047,  -9.1360],\n",
      "         [-11.0634, -10.9836, -10.8546,  ..., -10.7604,  -8.9452,  -9.2711],\n",
      "         ...,\n",
      "         [ -6.5246,  -6.6190,  -6.6025,  ...,  -6.9089,  -6.2287,  -6.4429],\n",
      "         [ -7.4492,  -7.4410,  -7.5237,  ...,  -7.8929,  -6.8293,  -5.9104],\n",
      "         [ -6.5610,  -6.6288,  -6.6793,  ...,  -6.9675,  -6.2061,  -5.7085]],\n",
      "\n",
      "        [[ -6.6728,  -6.6033,  -6.6278,  ...,  -5.9796,  -5.7968,  -4.0651],\n",
      "         [ -8.5881,  -8.8398,  -8.5958,  ...,  -8.5721,  -6.9417,  -7.6925],\n",
      "         [-10.8483, -10.7716, -10.4562,  ...,  -9.7781,  -9.5643,  -6.2071],\n",
      "         ...,\n",
      "         [ -5.3080,  -5.1665,  -5.0971,  ...,  -4.9446,  -5.6328,  -4.6919],\n",
      "         [ -5.8509,  -5.7217,  -5.6970,  ...,  -5.6056,  -5.9899,  -3.8048],\n",
      "         [ -5.8283,  -5.8046,  -5.6301,  ...,  -6.3670,  -6.4620,  -3.1218]],\n",
      "\n",
      "        [[ -6.6713,  -6.6741,  -6.6649,  ...,  -6.0126,  -5.9292,  -4.0893],\n",
      "         [ -6.2603,  -6.5316,  -6.4739,  ...,  -7.3166,  -6.8076,  -3.3470],\n",
      "         [-10.6750, -10.5145, -10.3408,  ..., -10.5236,  -9.6787,  -6.5685],\n",
      "         ...,\n",
      "         [ -5.5925,  -5.6721,  -5.7726,  ...,  -6.2873,  -5.1115,  -3.5384],\n",
      "         [ -4.5285,  -4.3967,  -4.7249,  ...,  -5.3810,  -3.8930,  -4.4228],\n",
      "         [ -7.3075,  -7.3784,  -7.4793,  ...,  -7.3603,  -6.5930,  -4.7810]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8909,  -6.8415,  -6.8297,  ...,  -6.0717,  -6.2572,  -3.9231],\n",
      "         [-13.2985, -13.3026, -13.5646,  ..., -12.5720, -12.2009, -10.5355],\n",
      "         [-12.6507, -12.8764, -12.9572,  ..., -11.1722, -10.8619, -11.5163],\n",
      "         ...,\n",
      "         [ -7.8996,  -7.8933,  -7.8408,  ...,  -7.6560,  -7.6266,  -4.4561],\n",
      "         [ -7.3603,  -7.2309,  -7.1318,  ...,  -7.3949,  -6.2067,  -3.0956],\n",
      "         [ -7.6220,  -7.5573,  -7.4499,  ...,  -7.6483,  -7.0813,  -4.1097]],\n",
      "\n",
      "        [[ -6.9517,  -6.9120,  -6.9363,  ...,  -6.2653,  -6.1208,  -4.1457],\n",
      "         [-10.4357,  -9.9117, -10.2604,  ...,  -9.3098,  -9.6486,  -9.2980],\n",
      "         [ -5.8046,  -5.8671,  -5.8722,  ...,  -6.6638,  -7.3147,  -3.7626],\n",
      "         ...,\n",
      "         [ -5.5657,  -5.5284,  -5.4656,  ...,  -6.2175,  -6.4793,  -4.3379],\n",
      "         [ -6.0015,  -6.1123,  -6.0524,  ...,  -6.9881,  -7.2454,  -4.2699],\n",
      "         [ -5.7329,  -5.7674,  -5.7295,  ...,  -5.8301,  -6.6856,  -3.6681]],\n",
      "\n",
      "        [[ -6.7505,  -6.7905,  -6.7833,  ...,  -6.1604,  -6.2810,  -4.0766],\n",
      "         [-10.7004, -10.2703, -10.2780,  ...,  -7.0657,  -7.2069,  -9.1944],\n",
      "         [ -6.4719,  -6.4846,  -6.4732,  ...,  -6.9854,  -7.4628,  -5.1646],\n",
      "         ...,\n",
      "         [ -6.4344,  -6.4239,  -6.4404,  ...,  -6.8230,  -7.6197,  -3.8559],\n",
      "         [ -6.7669,  -6.8159,  -6.7913,  ...,  -7.3089,  -7.9343,  -4.4754],\n",
      "         [ -5.7147,  -5.7843,  -5.6483,  ...,  -5.9809,  -7.0735,  -3.3832]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.770742416381836\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5657, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7454,  -6.7720,  -6.7296,  ...,  -6.1551,  -5.8511,  -4.2127],\n",
      "         [-10.0069, -10.1580,  -9.9970,  ..., -10.1623,  -9.2933,  -8.3036],\n",
      "         [ -3.2953,  -3.1137,  -3.5143,  ...,  -4.1033,  -4.1652,  -4.0249],\n",
      "         ...,\n",
      "         [ -2.0018,  -1.4663,  -1.8857,  ...,  -3.5635,  -0.3993,  -2.9326],\n",
      "         [ -9.6459,  -9.2907,  -9.5992,  ...,  -9.5403,  -8.7018,  -1.9836],\n",
      "         [-14.4576, -14.2202, -14.5432,  ..., -11.6804, -12.9078, -12.9156]],\n",
      "\n",
      "        [[ -6.8202,  -6.7997,  -6.7841,  ...,  -6.0919,  -5.9523,  -4.1152],\n",
      "         [-13.7293, -13.5668, -13.8585,  ..., -12.6198, -10.9961,  -8.4925],\n",
      "         [ -9.0277,  -9.0426,  -9.1115,  ...,  -8.1454,  -8.9796,  -2.3224],\n",
      "         ...,\n",
      "         [-11.6838, -11.8316, -11.6946,  ..., -10.4536,  -8.7537, -10.3888],\n",
      "         [-13.8485, -13.7008, -13.8798,  ..., -12.8762, -10.4468, -10.6354],\n",
      "         [-11.7212, -11.1991, -11.5320,  ...,  -9.5517,  -8.4220, -11.6881]],\n",
      "\n",
      "        [[-10.0894, -10.2083, -10.2940,  ..., -10.5130,  -9.8099,  -5.6245],\n",
      "         [-10.8067,  -9.5997, -10.0554,  ...,  -8.3683,  -9.1249, -11.0212],\n",
      "         [ -5.7006,  -5.5646,  -5.5956,  ...,  -6.5722,  -7.2682,  -3.3528],\n",
      "         ...,\n",
      "         [ -5.3339,  -5.2906,  -5.4711,  ...,  -6.0813,  -6.3050,  -3.8262],\n",
      "         [ -5.6812,  -5.7369,  -5.6149,  ...,  -5.7457,  -6.7157,  -3.5010],\n",
      "         [ -6.5556,  -6.4603,  -6.4747,  ...,  -7.6592,  -7.4895,  -4.3187]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-11.1726, -11.0237, -11.0665,  ...,  -9.8601,  -9.8417,  -6.8135],\n",
      "         [-14.9749, -14.2488, -14.5857,  ..., -13.1139, -12.7609,  -9.6183],\n",
      "         [ -5.2885,  -5.4254,  -5.2870,  ...,  -5.1752,  -6.9087,  -3.5724],\n",
      "         ...,\n",
      "         [ -5.4153,  -5.2030,  -5.0852,  ...,  -5.7048,  -7.0987,  -4.9869],\n",
      "         [ -6.5005,  -6.2911,  -6.3203,  ...,  -6.6309,  -7.7961,  -5.3538],\n",
      "         [ -6.2607,  -6.0534,  -6.1371,  ...,  -6.3698,  -7.0264,  -4.7656]],\n",
      "\n",
      "        [[ -6.9200,  -6.8900,  -6.9046,  ...,  -6.1419,  -5.9919,  -4.1651],\n",
      "         [ -9.3201,  -8.7809,  -9.0590,  ...,  -7.1330,  -7.7752,  -8.0275],\n",
      "         [ -5.6023,  -5.5041,  -5.4670,  ...,  -5.7890,  -6.9301,  -2.8229],\n",
      "         ...,\n",
      "         [ -4.8893,  -4.8245,  -4.7370,  ...,  -4.7530,  -6.1997,  -3.2874],\n",
      "         [ -5.7303,  -5.6648,  -5.5939,  ...,  -5.6669,  -6.5545,  -3.9203],\n",
      "         [ -5.9172,  -5.9270,  -5.8385,  ...,  -6.1314,  -7.1032,  -3.6444]],\n",
      "\n",
      "        [[ -7.2284,  -7.3205,  -7.1972,  ...,  -6.4470,  -6.6459,  -4.0583],\n",
      "         [-14.4430, -13.9188, -14.2738,  ..., -13.4131, -11.6085, -12.2561],\n",
      "         [-10.0425,  -9.8354, -10.3148,  ...,  -9.6687,  -9.1426,  -4.1377],\n",
      "         ...,\n",
      "         [ -5.9447,  -6.1875,  -6.1220,  ...,  -5.7238,  -5.5557,  -3.4906],\n",
      "         [ -6.5012,  -6.5073,  -6.6015,  ...,  -6.4338,  -5.8538,  -4.1404],\n",
      "         [ -5.1329,  -5.2795,  -5.3936,  ...,  -5.7420,  -4.6486,  -3.7184]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.5656887292861938\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8269, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0598,  -6.9964,  -7.0833,  ...,  -6.3015,  -6.2445,  -4.1331],\n",
      "         [-17.6352, -17.3765, -17.5893,  ..., -14.9930, -11.7427, -14.4989],\n",
      "         [-10.6287, -10.6872, -10.8397,  ...,  -9.4511,  -7.5949,  -9.4429],\n",
      "         ...,\n",
      "         [ -6.8015,  -6.6521,  -6.7551,  ...,  -6.2641,  -6.3233,  -4.6021],\n",
      "         [ -5.8000,  -5.8431,  -5.8849,  ...,  -5.4728,  -5.3465,  -4.5085],\n",
      "         [ -6.2969,  -6.1101,  -6.3370,  ...,  -6.1424,  -5.9964,  -4.6723]],\n",
      "\n",
      "        [[ -8.5296,  -8.4660,  -8.5290,  ...,  -7.4241,  -7.7317,  -5.0761],\n",
      "         [-13.3027, -12.9911, -13.1300,  ...,  -9.8516,  -9.5424,  -9.6107],\n",
      "         [ -5.4252,  -5.3736,  -5.4304,  ...,  -6.5955,  -7.0233,  -4.7895],\n",
      "         ...,\n",
      "         [ -5.9618,  -6.0722,  -5.7942,  ...,  -5.9605,  -7.0594,  -5.6523],\n",
      "         [ -5.5594,  -5.6062,  -5.5713,  ...,  -5.9210,  -6.6082,  -4.4462],\n",
      "         [ -5.8624,  -5.9424,  -5.9607,  ...,  -6.7425,  -7.1453,  -5.6077]],\n",
      "\n",
      "        [[ -6.7925,  -6.7767,  -6.7405,  ...,  -6.1313,  -5.8930,  -4.1358],\n",
      "         [ -9.6341,  -9.7927, -10.0984,  ...,  -9.1541,  -7.5771,  -7.7151],\n",
      "         [-15.3174, -15.2231, -15.2617,  ..., -15.8306, -13.8305, -10.7371],\n",
      "         ...,\n",
      "         [ -5.8268,  -5.6100,  -5.8167,  ...,  -5.8113,  -5.4528,  -2.7818],\n",
      "         [ -8.8800,  -9.0663,  -8.7930,  ...,  -7.8587,  -7.9766,  -6.2414],\n",
      "         [-14.8621, -14.5293, -14.6567,  ..., -13.3800, -11.8374,  -9.2916]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5487,  -6.5036,  -6.5333,  ...,  -5.7949,  -5.6669,  -3.9476],\n",
      "         [-12.1547, -12.0450, -12.0582,  ...,  -9.2449,  -9.6079,  -7.8390],\n",
      "         [ -5.9943,  -6.1711,  -6.0663,  ...,  -6.5339,  -7.9331,  -3.5683],\n",
      "         ...,\n",
      "         [ -5.9801,  -6.2134,  -6.0251,  ...,  -6.4601,  -7.6089,  -3.9995],\n",
      "         [ -5.4541,  -5.7381,  -5.6502,  ...,  -6.0902,  -7.3895,  -3.4939],\n",
      "         [ -5.6127,  -5.8826,  -5.7828,  ...,  -6.0599,  -7.6895,  -3.5791]],\n",
      "\n",
      "        [[ -7.3755,  -7.3394,  -7.3160,  ...,  -6.6171,  -6.3611,  -4.7860],\n",
      "         [ -9.2649,  -9.4041,  -9.1894,  ...,  -9.2431,  -8.3226,  -7.9680],\n",
      "         [ -9.9465,  -9.5978,  -9.5183,  ..., -10.1765,  -7.3218,  -9.2058],\n",
      "         ...,\n",
      "         [-16.5856, -16.8400, -16.9047,  ..., -14.8460, -15.2153, -14.0127],\n",
      "         [ -5.8743,  -6.2189,  -5.9544,  ...,  -6.2742,  -4.8489,  -6.2096],\n",
      "         [-13.7442, -13.0610, -13.3051,  ..., -12.1827, -11.7571,  -8.7609]],\n",
      "\n",
      "        [[ -6.5138,  -6.5024,  -6.4745,  ...,  -5.9177,  -5.8459,  -4.0160],\n",
      "         [-13.6173, -13.8597, -13.8612,  ..., -13.1795, -12.4129, -11.9855],\n",
      "         [-11.4643, -11.3555, -11.4828,  ..., -11.6761, -10.1133,  -7.0407],\n",
      "         ...,\n",
      "         [-15.0424, -15.4021, -14.9845,  ..., -14.5723, -12.6610, -13.0922],\n",
      "         [ -6.9895,  -6.9999,  -7.1452,  ...,  -6.9549,  -6.9946,  -5.3276],\n",
      "         [-11.0253, -10.6829, -11.0409,  ...,  -8.2764,  -9.9001,  -8.6081]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.8268723487854004\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2186, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8533,  -6.8338,  -6.7723,  ...,  -6.3801,  -6.0420,  -4.1802],\n",
      "         [ -7.2406,  -7.2226,  -7.2157,  ...,  -6.1850,  -7.0517,  -3.4826],\n",
      "         [-15.1395, -15.3974, -14.9504,  ..., -12.5764, -10.5685, -15.3753],\n",
      "         ...,\n",
      "         [-11.5709, -11.5222, -11.2919,  ..., -10.6230,  -8.8712,  -9.7724],\n",
      "         [ -5.7289,  -5.6812,  -5.2709,  ...,  -6.1283,  -3.5496,  -4.1410],\n",
      "         [-10.8420, -10.6674, -10.5795,  ...,  -9.1728,  -9.6801,  -8.3348]],\n",
      "\n",
      "        [[ -7.3142,  -7.3188,  -7.2544,  ...,  -6.8431,  -6.6662,  -4.1205],\n",
      "         [ -8.3937,  -8.5383,  -8.4404,  ...,  -8.0703,  -7.1467,  -8.5434],\n",
      "         [ -4.4253,  -4.3282,  -4.2737,  ...,  -4.3261,  -3.3474,  -2.9278],\n",
      "         ...,\n",
      "         [-12.6453, -12.9325, -12.5939,  ..., -11.6023, -10.2208, -10.8188],\n",
      "         [ -7.7279,  -7.6908,  -7.7440,  ...,  -6.2358,  -6.5185,  -6.0007],\n",
      "         [-10.8874, -11.0160, -11.1896,  ...,  -9.3497,  -9.7660,  -9.7638]],\n",
      "\n",
      "        [[ -7.0657,  -7.0844,  -7.0220,  ...,  -6.6459,  -6.2443,  -4.1264],\n",
      "         [-11.1614, -11.0022, -10.9895,  ...,  -8.5443, -10.4344,  -7.2783],\n",
      "         [ -5.4783,  -5.5637,  -5.5003,  ...,  -6.1719,  -6.7874,  -1.7937],\n",
      "         ...,\n",
      "         [ -6.1596,  -6.1832,  -6.1709,  ...,  -6.7339,  -6.7432,  -1.5108],\n",
      "         [ -5.6109,  -5.6651,  -5.5515,  ...,  -6.0374,  -6.3912,  -1.8236],\n",
      "         [ -5.9600,  -6.1605,  -6.1349,  ...,  -6.5443,  -6.7802,  -1.9257]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6114,  -6.6169,  -6.6274,  ...,  -5.8571,  -5.7108,  -3.5797],\n",
      "         [ -6.7265,  -7.2479,  -7.2501,  ...,  -5.1873,  -6.3921,  -2.7633],\n",
      "         [ -7.6121,  -7.4925,  -7.7354,  ...,  -6.6580,  -6.7165,  -5.1644],\n",
      "         ...,\n",
      "         [ -6.1565,  -6.2662,  -6.1710,  ...,  -5.2100,  -5.4989,  -4.5897],\n",
      "         [ -6.1407,  -6.2727,  -6.0344,  ...,  -5.9259,  -6.2025,  -4.4411],\n",
      "         [ -5.8692,  -6.0004,  -5.8142,  ...,  -5.6635,  -6.0739,  -3.7343]],\n",
      "\n",
      "        [[ -6.9362,  -6.8661,  -6.8744,  ...,  -6.4366,  -6.2156,  -4.3943],\n",
      "         [ -9.9460,  -9.9373,  -9.8745,  ..., -10.5329,  -8.4417, -10.4629],\n",
      "         [ -9.2288,  -9.2526,  -9.1267,  ...,  -9.0435,  -7.9441,  -6.8382],\n",
      "         ...,\n",
      "         [ -6.7402,  -6.9352,  -6.7594,  ...,  -7.0047,  -6.2151,  -4.8732],\n",
      "         [ -6.4606,  -6.8108,  -6.5916,  ...,  -6.6559,  -6.2078,  -3.0659],\n",
      "         [ -6.6918,  -6.6791,  -6.7931,  ...,  -7.1758,  -6.5112,  -4.1749]],\n",
      "\n",
      "        [[-12.1665, -12.2331, -12.3674,  ..., -12.1384, -12.9379, -10.3220],\n",
      "         [-11.3075, -10.9037, -10.9039,  ...,  -7.8359,  -8.3230,  -9.4550],\n",
      "         [ -5.1144,  -4.9736,  -4.9373,  ...,  -6.4903,  -6.7714,  -3.0102],\n",
      "         ...,\n",
      "         [ -5.2189,  -5.0218,  -4.9488,  ...,  -6.8170,  -6.1012,  -4.2247],\n",
      "         [ -5.7070,  -5.4002,  -5.4670,  ...,  -7.2059,  -7.4738,  -2.9122],\n",
      "         [ -5.0323,  -4.8052,  -4.8309,  ...,  -6.3619,  -6.6412,  -3.1361]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.2185893058776855\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8332, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8631,  -6.9147,  -6.8444,  ...,  -6.1432,  -6.2164,  -4.0744],\n",
      "         [ -9.2622,  -9.2286,  -9.2135,  ...,  -9.2988,  -8.0131,  -8.3458],\n",
      "         [ -3.8973,  -3.9412,  -4.5559,  ...,  -4.2171,  -4.6390,  -5.3363],\n",
      "         ...,\n",
      "         [ -7.6241,  -7.4187,  -7.2615,  ...,  -7.5357,  -7.1693,  -5.3749],\n",
      "         [ -7.4917,  -7.3722,  -7.5656,  ...,  -8.0087,  -7.8894,  -6.3003],\n",
      "         [-12.4279, -12.1367, -11.9984,  ...,  -9.7287, -11.2203,  -6.9752]],\n",
      "\n",
      "        [[ -6.4677,  -6.5681,  -6.5564,  ...,  -6.1102,  -5.6134,  -4.2988],\n",
      "         [ -6.8915,  -7.0486,  -7.1363,  ...,  -7.0899,  -6.2877,  -4.8726],\n",
      "         [-11.0621, -10.9373, -10.8583,  ..., -11.9220,  -9.3355,  -9.1901],\n",
      "         ...,\n",
      "         [ -4.9494,  -5.3202,  -5.4720,  ...,  -6.3884,  -5.3010,  -8.8550],\n",
      "         [-11.6801, -11.4144, -11.6833,  ..., -10.2743, -11.2039,  -9.5308],\n",
      "         [-12.5916, -12.4931, -12.8753,  ..., -11.3226, -11.3376, -10.6135]],\n",
      "\n",
      "        [[-10.3014, -10.1231, -10.1463,  ...,  -9.3119,  -9.9118,  -7.0581],\n",
      "         [-11.9595, -11.9401, -11.8465,  ...,  -8.7811,  -8.7704, -10.5155],\n",
      "         [ -5.0365,  -5.0840,  -4.9952,  ...,  -5.8648,  -7.3796,  -1.4459],\n",
      "         ...,\n",
      "         [ -5.2509,  -5.0636,  -5.0623,  ...,  -5.5614,  -6.9246,  -2.8575],\n",
      "         [ -5.3439,  -5.3882,  -5.1948,  ...,  -5.7993,  -6.9680,  -3.7781],\n",
      "         [ -4.9179,  -4.9582,  -4.6533,  ...,  -5.5531,  -6.7342,  -4.2130]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3019,  -7.3479,  -7.2771,  ...,  -6.6636,  -6.2970,  -4.4833],\n",
      "         [ -5.3002,  -5.0635,  -5.6013,  ...,  -5.9635,  -5.8527,  -2.0044],\n",
      "         [-15.4292, -15.2274, -15.5655,  ..., -13.7550, -11.8469, -11.6844],\n",
      "         ...,\n",
      "         [ -8.1174,  -8.1161,  -8.3129,  ...,  -8.0586,  -7.2507,  -4.9690],\n",
      "         [ -8.1993,  -8.3273,  -8.4454,  ...,  -8.0957,  -7.5522,  -3.6721],\n",
      "         [ -8.2431,  -8.2307,  -8.4579,  ...,  -8.2097,  -7.5852,  -4.3797]],\n",
      "\n",
      "        [[ -5.9276,  -6.0227,  -5.9029,  ...,  -5.4321,  -6.5424,  -4.3232],\n",
      "         [-12.4377, -12.3429, -12.3419,  ...,  -8.4231, -10.0602,  -8.2655],\n",
      "         [ -6.1873,  -6.3553,  -6.3003,  ...,  -6.3554,  -7.3589,  -4.2965],\n",
      "         ...,\n",
      "         [ -6.6016,  -6.6995,  -6.5925,  ...,  -6.7495,  -7.1949,  -4.7349],\n",
      "         [ -6.0352,  -6.1704,  -6.1193,  ...,  -6.4441,  -7.0960,  -4.2579],\n",
      "         [ -5.8267,  -5.9392,  -6.0103,  ...,  -6.2281,  -7.0419,  -3.7725]],\n",
      "\n",
      "        [[ -7.1595,  -7.1917,  -7.1395,  ...,  -6.7465,  -6.3262,  -4.4888],\n",
      "         [-13.2364, -13.1349, -13.5019,  ..., -12.4522, -12.8835,  -7.7842],\n",
      "         [-11.0932, -10.8905, -11.3625,  ..., -12.1347,  -9.5138, -10.2326],\n",
      "         ...,\n",
      "         [ -8.5163,  -8.5759,  -8.5449,  ...,  -9.2772,  -8.0457,  -5.8118],\n",
      "         [ -8.5256,  -8.6591,  -8.5803,  ...,  -9.3416,  -8.0707,  -5.5980],\n",
      "         [ -7.3379,  -7.4845,  -7.4346,  ...,  -8.5582,  -6.9609,  -6.0764]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.8331888914108276\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1313, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6467,  -6.6734,  -6.6446,  ...,  -6.0739,  -5.8188,  -4.4100],\n",
      "         [ -6.2386,  -6.2990,  -6.3713,  ...,  -6.5489,  -6.5984,  -4.1684],\n",
      "         [-10.7998, -10.6492, -10.7683,  ..., -10.1175, -10.5383,  -6.7419],\n",
      "         ...,\n",
      "         [ -7.5999,  -7.6507,  -7.7433,  ...,  -8.0279,  -7.3076,  -5.6663],\n",
      "         [ -7.8016,  -7.9305,  -8.0185,  ...,  -8.2228,  -7.8914,  -5.8307],\n",
      "         [ -7.3582,  -7.4499,  -7.4893,  ...,  -7.5967,  -7.3666,  -5.3201]],\n",
      "\n",
      "        [[ -7.1187,  -7.0914,  -7.1317,  ...,  -6.2944,  -6.1512,  -4.2611],\n",
      "         [-15.5862, -15.3478, -15.2595,  ..., -12.3056, -12.3263, -14.0654],\n",
      "         [ -4.3351,  -4.5699,  -4.3842,  ...,  -4.6596,  -6.5802,  -4.6918],\n",
      "         ...,\n",
      "         [ -5.9616,  -6.1453,  -5.9727,  ...,  -5.3219,  -7.5612,  -5.1777],\n",
      "         [ -5.9439,  -6.1189,  -6.0131,  ...,  -6.3649,  -7.4564,  -4.8880],\n",
      "         [ -6.2019,  -6.3711,  -6.3205,  ...,  -6.6047,  -7.2689,  -4.3488]],\n",
      "\n",
      "        [[ -6.5832,  -6.4612,  -6.5214,  ...,  -5.8417,  -5.8621,  -3.4267],\n",
      "         [ -6.2134,  -6.1229,  -6.0818,  ...,  -6.0816,  -6.7317,  -1.2697],\n",
      "         [ -8.6768,  -8.7231,  -8.7861,  ...,  -7.8296,  -7.6849,  -6.1842],\n",
      "         ...,\n",
      "         [ -6.0704,  -5.9758,  -5.9718,  ...,  -5.7041,  -6.2982,  -2.1071],\n",
      "         [ -5.6382,  -5.4981,  -5.6116,  ...,  -5.5882,  -6.0629,  -1.0320],\n",
      "         [ -6.9903,  -6.8211,  -7.1341,  ...,  -6.4986,  -7.1206,  -2.8347]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-13.8588, -13.9718, -13.3682,  ..., -12.2862, -13.0272, -12.2210],\n",
      "         [-12.5966, -11.7069, -12.1832,  ..., -10.6998, -10.1821,  -9.7617],\n",
      "         [ -4.9579,  -4.9537,  -4.9207,  ...,  -6.2298,  -7.1660,  -3.7536],\n",
      "         ...,\n",
      "         [ -5.6947,  -5.7495,  -5.6707,  ...,  -6.1974,  -7.5279,  -5.3027],\n",
      "         [ -4.9159,  -4.9783,  -4.9180,  ...,  -5.7253,  -7.0731,  -4.3602],\n",
      "         [ -5.4350,  -5.2584,  -5.2521,  ...,  -5.8865,  -6.8031,  -5.0501]],\n",
      "\n",
      "        [[ -6.8276,  -6.8063,  -6.7929,  ...,  -6.0568,  -5.9540,  -4.3434],\n",
      "         [-12.7401, -12.5617, -12.8138,  ..., -11.2150, -10.5614, -10.1742],\n",
      "         [ -9.7474,  -9.7861,  -9.9865,  ...,  -8.3451,  -9.3367, -10.8284],\n",
      "         ...,\n",
      "         [ -6.5950,  -6.8704,  -6.9745,  ...,  -7.7589,  -6.4050,  -5.0155],\n",
      "         [ -5.8489,  -6.0083,  -6.2173,  ...,  -7.1094,  -5.2393,  -3.4482],\n",
      "         [ -5.5794,  -5.7236,  -5.9472,  ...,  -7.0337,  -5.2506,  -4.0380]],\n",
      "\n",
      "        [[ -6.5467,  -6.5345,  -6.5701,  ...,  -5.6407,  -6.0622,  -3.3274],\n",
      "         [-10.0742,  -9.9877,  -9.9046,  ...,  -9.6493, -10.0152,  -3.5085],\n",
      "         [ -6.3408,  -6.3398,  -6.2733,  ...,  -6.4807,  -5.9258,  -2.0859],\n",
      "         ...,\n",
      "         [ -6.3059,  -6.0436,  -6.2447,  ...,  -5.9568,  -5.7448,  -1.1932],\n",
      "         [ -6.8617,  -6.6765,  -6.8176,  ...,  -6.6206,  -6.7112,  -2.2718],\n",
      "         [ -6.1897,  -6.0526,  -6.1246,  ...,  -6.1902,  -5.6748,  -1.0882]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.131254196166992\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6386, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2446,  -7.2197,  -7.1930,  ...,  -6.5688,  -6.2629,  -4.1271],\n",
      "         [-15.6854, -15.3672, -15.3824,  ..., -13.9868, -11.0913, -13.2107],\n",
      "         [-12.9938, -14.1446, -13.3321,  ..., -13.0649, -10.5026,  -7.3594],\n",
      "         ...,\n",
      "         [-13.8146, -13.7912, -13.5943,  ..., -10.4385,  -8.9736, -11.9083],\n",
      "         [ -9.1467,  -9.0051,  -9.3030,  ...,  -8.9484,  -6.6545,  -8.7774],\n",
      "         [-13.7773, -13.4813, -13.6033,  ..., -12.0691, -11.0666,  -7.6660]],\n",
      "\n",
      "        [[ -6.2841,  -6.2093,  -6.1753,  ...,  -5.8027,  -5.5429,  -3.0636],\n",
      "         [-11.3627, -10.9398, -11.1749,  ...,  -8.2567,  -9.4957,  -9.7815],\n",
      "         [ -5.7593,  -5.8411,  -5.8379,  ...,  -6.1240,  -7.2180,  -3.2260],\n",
      "         ...,\n",
      "         [ -6.4456,  -6.4189,  -6.3212,  ...,  -7.0509,  -7.3443,  -3.4669],\n",
      "         [ -6.3039,  -6.2602,  -6.2031,  ...,  -6.6769,  -6.9654,  -3.7329],\n",
      "         [ -6.1868,  -6.2479,  -6.1391,  ...,  -6.5530,  -7.2307,  -2.9661]],\n",
      "\n",
      "        [[ -7.0865,  -7.0251,  -7.0022,  ...,  -6.4336,  -6.4968,  -4.4789],\n",
      "         [ -7.9391,  -7.7636,  -8.0829,  ...,  -8.1377,  -8.5309,  -2.1168],\n",
      "         [ -7.9273,  -7.8777,  -7.9647,  ...,  -7.7548,  -8.3209,  -3.4049],\n",
      "         ...,\n",
      "         [ -6.4837,  -6.3480,  -6.5471,  ...,  -6.6775,  -6.7354,  -2.0729],\n",
      "         [ -6.8620,  -6.6618,  -6.9974,  ...,  -7.1285,  -7.6412,  -2.7028],\n",
      "         [ -6.6032,  -6.4372,  -6.7401,  ...,  -6.8144,  -7.3150,  -2.6985]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0350,  -7.0327,  -6.9648,  ...,  -6.3884,  -6.2777,  -4.2592],\n",
      "         [ -7.6348,  -7.6242,  -7.8475,  ...,  -7.1638,  -6.7283,  -5.6761],\n",
      "         [-10.5004, -10.1900, -10.1061,  ...,  -8.8742,  -7.8802, -10.7238],\n",
      "         ...,\n",
      "         [ -8.8462,  -8.4614,  -8.8028,  ...,  -7.7022,  -7.9748,  -6.1036],\n",
      "         [ -4.3295,  -4.5395,  -4.2786,  ...,  -5.3696,  -4.3253,  -1.1863],\n",
      "         [-12.7472, -12.2668, -12.7525,  ...,  -9.9879, -10.0134,  -9.6937]],\n",
      "\n",
      "        [[ -6.5176,  -6.4968,  -6.5007,  ...,  -5.9346,  -5.7028,  -4.0631],\n",
      "         [-10.5051, -10.4009, -10.4519,  ..., -10.5350, -10.3511,  -9.6974],\n",
      "         [ -8.7813,  -8.7517,  -8.6488,  ...,  -7.5482,  -6.4735,  -7.7433],\n",
      "         ...,\n",
      "         [-15.0757, -14.4469, -14.7868,  ..., -13.3026, -11.2278,  -9.6979],\n",
      "         [-11.3878, -11.4086, -11.4574,  ..., -10.0837,  -9.6118,  -8.4716],\n",
      "         [ -7.7904,  -8.0898,  -7.9387,  ...,  -7.7262,  -6.8468,  -7.2151]],\n",
      "\n",
      "        [[ -6.3213,  -6.2334,  -6.2358,  ...,  -5.7024,  -5.8612,  -3.2829],\n",
      "         [ -6.6609,  -6.4988,  -6.5374,  ...,  -7.0367,  -7.0059,  -2.5873],\n",
      "         [-12.2877, -12.4283, -12.3663,  ..., -10.9828, -13.0295,  -8.2152],\n",
      "         ...,\n",
      "         [ -5.4951,  -5.3387,  -5.3029,  ...,  -5.4180,  -6.2100,  -1.2099],\n",
      "         [ -7.7805,  -7.8591,  -7.5257,  ...,  -8.3439,  -9.0137,  -4.3431],\n",
      "         [ -5.7602,  -5.6012,  -5.6685,  ...,  -6.0722,  -6.3782,  -1.9367]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6385948657989502\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4852, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6341,  -6.5966,  -6.5681,  ...,  -5.8739,  -5.7747,  -3.6837],\n",
      "         [ -6.6379,  -6.4933,  -6.4363,  ...,  -7.2836,  -7.0076,  -1.9459],\n",
      "         [ -6.7952,  -7.0677,  -7.0197,  ...,  -6.8901,  -6.5725,  -0.9697],\n",
      "         ...,\n",
      "         [ -6.9934,  -6.8246,  -6.8089,  ...,  -7.4120,  -7.3333,  -0.9306],\n",
      "         [ -6.6214,  -6.5507,  -6.5979,  ...,  -6.9784,  -7.0058,  -0.7546],\n",
      "         [ -6.9438,  -6.7618,  -6.9914,  ...,  -7.1879,  -6.8943,  -0.6728]],\n",
      "\n",
      "        [[ -6.6765,  -6.6064,  -6.6384,  ...,  -5.9131,  -5.8909,  -4.0481],\n",
      "         [-12.9741, -12.8142, -12.9138,  ...,  -9.8006, -10.6488, -11.7021],\n",
      "         [ -6.6794,  -6.7537,  -6.7309,  ...,  -6.6156,  -6.6471,  -7.0833],\n",
      "         ...,\n",
      "         [ -6.9049,  -6.8065,  -6.8455,  ...,  -7.5553,  -6.9296,  -5.5865],\n",
      "         [ -6.9247,  -6.8046,  -7.2762,  ...,  -6.9813,  -7.3132,  -5.0790],\n",
      "         [ -6.6914,  -6.6432,  -7.0905,  ...,  -6.5849,  -6.8224,  -4.3073]],\n",
      "\n",
      "        [[ -6.9060,  -6.8893,  -6.8772,  ...,  -6.1973,  -6.1665,  -4.2443],\n",
      "         [ -8.6672,  -8.6975,  -8.8357,  ...,  -6.5721,  -9.6034,  -7.7281],\n",
      "         [-11.3942, -11.9750, -11.7905,  ..., -11.6325, -11.5890,  -9.2156],\n",
      "         ...,\n",
      "         [ -7.7655,  -8.0348,  -8.0459,  ...,  -8.3585,  -8.1032,  -5.9664],\n",
      "         [ -8.1306,  -8.3304,  -8.3741,  ...,  -8.0698,  -7.8088,  -5.8796],\n",
      "         [ -7.3888,  -7.6328,  -7.6997,  ...,  -7.7170,  -7.6514,  -5.4556]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1620,  -7.1875,  -7.1832,  ...,  -6.8534,  -6.5694,  -4.2295],\n",
      "         [-10.9364, -10.7956, -10.7032,  ...,  -8.5256,  -9.4450,  -9.8870],\n",
      "         [ -5.6495,  -5.6509,  -5.5866,  ...,  -6.3523,  -7.0575,  -3.0072],\n",
      "         ...,\n",
      "         [ -6.4040,  -6.4092,  -6.3858,  ...,  -6.4964,  -7.4388,  -3.8069],\n",
      "         [ -5.5861,  -5.6279,  -5.5576,  ...,  -5.6487,  -6.9192,  -2.6602],\n",
      "         [ -5.9929,  -5.9754,  -5.9108,  ...,  -6.3951,  -6.9707,  -4.0020]],\n",
      "\n",
      "        [[-12.1095, -11.8989, -12.1082,  ..., -11.3432, -12.8412,  -9.8840],\n",
      "         [-10.2338, -10.4061, -10.2751,  ...,  -7.5044,  -8.4778,  -7.8710],\n",
      "         [ -5.8029,  -6.0941,  -5.9675,  ...,  -6.6005,  -7.9527,  -3.8330],\n",
      "         ...,\n",
      "         [ -6.5962,  -6.9818,  -6.6589,  ...,  -7.8533,  -8.5444,  -5.2484],\n",
      "         [ -6.4521,  -6.6204,  -6.5918,  ...,  -7.2544,  -8.4289,  -4.3912],\n",
      "         [ -7.1370,  -7.2325,  -7.1266,  ...,  -8.1195,  -8.8399,  -4.8944]],\n",
      "\n",
      "        [[ -6.7659,  -6.7237,  -6.7697,  ...,  -5.8929,  -5.9889,  -4.1660],\n",
      "         [ -9.6754,  -9.1537,  -9.3713,  ...,  -7.8390,  -8.4515,  -8.8421],\n",
      "         [ -5.4168,  -5.5079,  -5.4703,  ...,  -5.8473,  -7.2129,  -4.5111],\n",
      "         ...,\n",
      "         [ -5.5442,  -5.7772,  -5.6223,  ...,  -5.6084,  -7.4436,  -4.8321],\n",
      "         [ -5.0432,  -5.1196,  -4.9760,  ...,  -5.6804,  -6.3161,  -5.0537],\n",
      "         [ -5.3531,  -5.5480,  -5.3847,  ...,  -5.9559,  -7.2025,  -4.3643]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.485205888748169\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6052, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5941,  -6.4480,  -6.5222,  ...,  -5.9540,  -6.1998,  -3.1318],\n",
      "         [ -7.9493,  -7.7537,  -7.9766,  ...,  -8.3555,  -7.3932,  -4.3691],\n",
      "         [ -6.5954,  -6.4567,  -6.6544,  ...,  -7.1805,  -6.6678,  -2.2865],\n",
      "         ...,\n",
      "         [ -6.7030,  -6.6154,  -6.7731,  ...,  -6.7835,  -6.8966,  -2.4832],\n",
      "         [ -6.1832,  -5.9849,  -6.2498,  ...,  -6.2096,  -6.7210,  -2.1782],\n",
      "         [ -6.9730,  -6.8003,  -6.9666,  ...,  -7.1583,  -6.9305,  -2.8958]],\n",
      "\n",
      "        [[ -6.9397,  -6.9134,  -6.9000,  ...,  -6.3322,  -6.1705,  -4.3910],\n",
      "         [ -6.3573,  -6.2406,  -5.7860,  ...,  -7.7031,  -5.1520,  -4.5854],\n",
      "         [ -5.3525,  -5.4704,  -5.3480,  ...,  -5.6644,  -5.1171,  -5.7072],\n",
      "         ...,\n",
      "         [ -6.7499,  -6.9108,  -6.8761,  ...,  -6.0589,  -5.2567,  -5.3312],\n",
      "         [ -7.4348,  -7.7509,  -7.6376,  ...,  -6.7867,  -6.6037,  -6.2076],\n",
      "         [ -7.5839,  -7.6068,  -7.6197,  ...,  -7.4151,  -6.8313,  -5.8317]],\n",
      "\n",
      "        [[ -6.5471,  -6.5086,  -6.4766,  ...,  -5.9533,  -5.6721,  -4.2977],\n",
      "         [ -7.6020,  -7.7938,  -7.7959,  ...,  -7.3801,  -6.0246,  -7.2985],\n",
      "         [ -8.2471,  -8.7029,  -8.4413,  ...,  -8.8989,  -6.8011, -10.0167],\n",
      "         ...,\n",
      "         [ -7.6464,  -7.5805,  -7.6793,  ...,  -8.2731,  -6.8673,  -6.4762],\n",
      "         [ -7.1909,  -7.3447,  -7.3278,  ...,  -7.9127,  -6.4445,  -6.4544],\n",
      "         [ -7.3490,  -7.3509,  -7.4111,  ...,  -7.6608,  -6.4174,  -7.1142]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6092,  -7.6373,  -7.5847,  ...,  -6.8065,  -6.8287,  -4.2539],\n",
      "         [ -8.7857,  -8.6000,  -9.2456,  ...,  -8.6055,  -9.7239,  -6.4491],\n",
      "         [ -6.9940,  -7.0490,  -7.5574,  ...,  -7.8381,  -6.3630,  -7.9124],\n",
      "         ...,\n",
      "         [ -6.3443,  -6.1782,  -6.3795,  ...,  -5.6151,  -6.7942,  -3.7764],\n",
      "         [ -6.4389,  -6.3512,  -6.6921,  ...,  -5.8068,  -6.8203,  -4.2380],\n",
      "         [ -5.7679,  -5.8489,  -6.0056,  ...,  -4.7925,  -6.5443,  -3.9686]],\n",
      "\n",
      "        [[ -6.7734,  -6.6634,  -6.7457,  ...,  -6.3958,  -6.6064,  -3.3852],\n",
      "         [ -7.1268,  -7.1305,  -7.2135,  ...,  -7.5452,  -7.9408,  -2.9643],\n",
      "         [ -7.8681,  -7.8202,  -7.7911,  ...,  -7.9330,  -8.6866,  -4.9661],\n",
      "         ...,\n",
      "         [ -5.9726,  -5.8625,  -5.9982,  ...,  -6.3272,  -6.7036,  -2.8677],\n",
      "         [ -6.0085,  -5.8496,  -5.9816,  ...,  -6.2154,  -6.5735,  -2.1155],\n",
      "         [ -6.0989,  -6.0374,  -6.1741,  ...,  -6.5813,  -6.9540,  -2.9686]],\n",
      "\n",
      "        [[ -6.5785,  -6.6156,  -6.6202,  ...,  -5.5647,  -5.8762,  -4.1804],\n",
      "         [-12.1969, -12.1860, -12.3559,  ..., -10.0007, -10.0584,  -9.7495],\n",
      "         [ -4.7624,  -5.0041,  -4.8666,  ...,  -5.0853,  -6.0567,  -4.1615],\n",
      "         ...,\n",
      "         [ -5.7984,  -5.9146,  -5.8277,  ...,  -5.7872,  -7.2030,  -4.7803],\n",
      "         [ -5.0697,  -5.0878,  -5.0822,  ...,  -5.2828,  -6.6704,  -3.9168],\n",
      "         [ -5.6040,  -5.7564,  -5.5914,  ...,  -5.5884,  -6.6264,  -4.8881]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.605163097381592\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8128, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6793,  -6.6199,  -6.6596,  ...,  -6.0783,  -6.0629,  -3.4077],\n",
      "         [ -8.2783,  -8.1500,  -8.2453,  ...,  -8.4331,  -8.4620,  -4.4521],\n",
      "         [ -7.6647,  -7.8065,  -7.8284,  ...,  -7.7768,  -8.3833,  -3.8863],\n",
      "         ...,\n",
      "         [ -6.3959,  -6.2456,  -6.4225,  ...,  -6.5819,  -6.2122,  -3.8502],\n",
      "         [ -6.2477,  -6.0482,  -6.2876,  ...,  -6.0949,  -6.7563,  -3.1423],\n",
      "         [ -6.3451,  -6.2202,  -6.4066,  ...,  -6.3574,  -6.7842,  -3.4493]],\n",
      "\n",
      "        [[ -7.2939,  -7.3322,  -7.3175,  ...,  -6.5689,  -6.9466,  -3.6965],\n",
      "         [ -9.9057,  -9.6027, -10.1800,  ...,  -7.0763,  -8.5981,  -8.0480],\n",
      "         [ -5.7929,  -5.9912,  -5.9752,  ...,  -6.8304,  -7.5482,  -4.1697],\n",
      "         ...,\n",
      "         [ -6.0839,  -6.2489,  -6.1772,  ...,  -5.9713,  -7.2772,  -2.8683],\n",
      "         [ -6.2303,  -6.3732,  -6.4486,  ...,  -6.3135,  -7.4085,  -2.7725],\n",
      "         [ -5.6502,  -5.7393,  -5.7492,  ...,  -6.2146,  -6.9611,  -3.5372]],\n",
      "\n",
      "        [[ -8.6265,  -8.5283,  -8.5731,  ...,  -7.3758,  -7.7205,  -4.8009],\n",
      "         [-12.6083, -12.2738, -12.4121,  ..., -11.3465, -10.1146,  -8.4205],\n",
      "         [ -5.6603,  -5.8959,  -6.0207,  ...,  -6.2604,  -8.0276,  -4.7509],\n",
      "         ...,\n",
      "         [ -5.0344,  -5.4486,  -5.3218,  ...,  -5.3794,  -6.7699,  -4.8166],\n",
      "         [ -4.7755,  -5.0466,  -5.0236,  ...,  -5.6110,  -7.3281,  -4.4464],\n",
      "         [ -4.2414,  -4.6889,  -4.5190,  ...,  -5.4137,  -6.8739,  -3.8727]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-12.2496, -12.1373, -12.3105,  ..., -11.0192, -12.2537,  -8.2808],\n",
      "         [-13.3781, -13.2750, -13.3687,  ..., -10.5973, -10.5007, -10.5680],\n",
      "         [ -5.5891,  -5.7009,  -5.6483,  ...,  -6.2777,  -7.8070,  -5.4693],\n",
      "         ...,\n",
      "         [ -5.6664,  -5.8140,  -5.7252,  ...,  -6.2477,  -7.3037,  -6.0412],\n",
      "         [ -5.9082,  -6.0802,  -6.1328,  ...,  -6.4448,  -8.1605,  -5.5890],\n",
      "         [ -5.1544,  -5.2125,  -5.0817,  ...,  -5.4923,  -6.9091,  -4.9595]],\n",
      "\n",
      "        [[ -6.4365,  -6.3766,  -6.4127,  ...,  -5.8907,  -5.9755,  -3.0736],\n",
      "         [ -6.2102,  -6.2196,  -6.1068,  ...,  -6.4942,  -6.5249,  -2.2414],\n",
      "         [ -8.2320,  -8.0435,  -8.1838,  ...,  -7.5175,  -8.7593,  -4.0584],\n",
      "         ...,\n",
      "         [ -6.5371,  -6.4396,  -6.4837,  ...,  -6.7095,  -6.6340,  -2.5267],\n",
      "         [ -6.3470,  -6.2372,  -6.3158,  ...,  -6.4801,  -6.6561,  -2.1089],\n",
      "         [ -6.6355,  -6.5559,  -6.6501,  ...,  -6.5773,  -6.6903,  -2.2026]],\n",
      "\n",
      "        [[ -5.8722,  -5.9951,  -5.9191,  ...,  -6.3625,  -6.0426,  -3.6448],\n",
      "         [-12.0872, -11.8535, -12.0287,  ...,  -8.5333,  -8.9837, -12.2313],\n",
      "         [ -5.7155,  -5.8244,  -5.9010,  ...,  -6.2310,  -7.1403,  -4.8756],\n",
      "         ...,\n",
      "         [ -5.7228,  -5.8604,  -5.7609,  ...,  -6.2193,  -7.0780,  -4.4589],\n",
      "         [ -5.6696,  -5.7728,  -5.8444,  ...,  -6.4209,  -6.9035,  -5.3942],\n",
      "         [ -5.4498,  -5.8128,  -5.6009,  ...,  -5.8788,  -6.3095,  -5.7551]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.812769889831543\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8086, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0059,  -7.0264,  -6.9694,  ...,  -6.3093,  -6.5044,  -4.3807],\n",
      "         [-11.6828, -11.5336, -11.4186,  ..., -10.4185, -10.5585,  -6.5952],\n",
      "         [ -5.9638,  -6.2246,  -6.2403,  ...,  -5.8144,  -6.4870,  -5.3049],\n",
      "         ...,\n",
      "         [ -7.2677,  -7.2411,  -7.4267,  ...,  -7.1498,  -7.6180,  -5.0134],\n",
      "         [ -7.1185,  -7.0673,  -7.3051,  ...,  -7.1366,  -7.9410,  -5.9718],\n",
      "         [ -6.9476,  -6.9130,  -7.1251,  ...,  -6.9402,  -7.4855,  -5.4901]],\n",
      "\n",
      "        [[ -6.6178,  -6.5406,  -6.6110,  ...,  -5.8725,  -5.8097,  -4.0009],\n",
      "         [-12.4628, -11.9411, -12.0665,  ...,  -8.9970,  -9.8320,  -8.7098],\n",
      "         [ -4.5432,  -4.6048,  -4.7165,  ...,  -5.2202,  -7.0955,  -3.6136],\n",
      "         ...,\n",
      "         [ -6.1666,  -6.1902,  -6.1259,  ...,  -6.6058,  -7.8190,  -4.7287],\n",
      "         [ -5.5617,  -5.4360,  -5.5071,  ...,  -5.8741,  -7.6605,  -5.7932],\n",
      "         [ -6.4086,  -6.3588,  -6.4358,  ...,  -6.4345,  -7.6987,  -6.2268]],\n",
      "\n",
      "        [[ -6.6751,  -6.5390,  -6.5872,  ...,  -6.0714,  -5.9643,  -3.8687],\n",
      "         [-10.3602, -10.5207, -10.5070,  ..., -10.0627, -10.2089,  -6.9069],\n",
      "         [-10.5055, -10.6713, -10.7502,  ..., -10.5766, -10.6223,  -7.0739],\n",
      "         ...,\n",
      "         [ -6.7210,  -6.5452,  -6.7684,  ...,  -7.1222,  -7.1042,  -3.5282],\n",
      "         [ -6.6625,  -6.6341,  -6.7365,  ...,  -7.0058,  -7.2315,  -4.0211],\n",
      "         [ -6.5703,  -6.4563,  -6.5036,  ...,  -6.4921,  -7.2584,  -3.4621]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5213,  -6.4304,  -6.4962,  ...,  -5.9910,  -6.1708,  -3.1583],\n",
      "         [-10.7371, -10.5477, -10.6457,  ..., -10.8686, -11.5201,  -4.6675],\n",
      "         [ -7.2689,  -7.2501,  -7.2580,  ...,  -7.0632,  -7.1698,  -3.4101],\n",
      "         ...,\n",
      "         [ -6.4838,  -6.3595,  -6.4048,  ...,  -6.2358,  -6.4101,  -2.7064],\n",
      "         [ -5.8683,  -5.7197,  -5.9017,  ...,  -5.7977,  -6.4444,  -2.3547],\n",
      "         [ -6.6365,  -6.4094,  -6.5737,  ...,  -6.6155,  -6.9493,  -3.0684]],\n",
      "\n",
      "        [[ -6.4465,  -6.3657,  -6.4056,  ...,  -5.6955,  -5.9951,  -3.4483],\n",
      "         [ -6.0114,  -5.9014,  -6.1595,  ...,  -6.4485,  -6.1579,  -1.6285],\n",
      "         [ -5.8738,  -5.7923,  -6.0528,  ...,  -6.8886,  -5.9069,   0.2915],\n",
      "         ...,\n",
      "         [ -6.1809,  -6.0148,  -6.1593,  ...,  -6.1927,  -5.9676,  -1.8190],\n",
      "         [ -6.3845,  -6.1725,  -6.2953,  ...,  -6.5688,  -6.3795,  -1.6319],\n",
      "         [ -6.4143,  -6.1642,  -6.3275,  ...,  -6.4144,  -6.3971,  -1.7772]],\n",
      "\n",
      "        [[ -6.5824,  -6.5882,  -6.5433,  ...,  -6.0860,  -5.7606,  -3.7186],\n",
      "         [ -5.9060,  -6.2048,  -6.3235,  ...,  -5.3947,  -5.8908,  -4.1752],\n",
      "         [ -5.4960,  -5.8839,  -5.6217,  ...,  -6.1750,  -5.4809,  -3.3745],\n",
      "         ...,\n",
      "         [  0.5282,   0.2318,   0.5452,  ...,  -0.7766,  -0.7318,   1.9717],\n",
      "         [ -5.2532,  -5.5929,  -5.4596,  ...,  -5.4468,  -5.6553,  -4.1094],\n",
      "         [-12.0439, -11.8697, -11.8047,  ...,  -9.7658, -11.3287,  -7.4483]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.808579444885254\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7275, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4459,  -6.4357,  -6.3977,  ...,  -6.0509,  -5.6545,  -3.9713],\n",
      "         [ -7.5428,  -7.8303,  -7.3568,  ...,  -7.5846,  -6.6853,  -4.6988],\n",
      "         [ -3.8864,  -3.9892,  -3.8487,  ...,  -4.3097,  -2.6933,  -3.9977],\n",
      "         ...,\n",
      "         [ -8.7546,  -8.8094,  -8.7439,  ...,  -9.0005,  -5.7757, -10.1892],\n",
      "         [ -9.3913,  -9.7929,  -9.4787,  ...,  -8.7334,  -9.3952,  -5.7995],\n",
      "         [-14.8905, -14.4007, -14.4766,  ..., -12.0493, -12.5053,  -9.5504]],\n",
      "\n",
      "        [[ -6.8431,  -6.7893,  -6.8262,  ...,  -6.1558,  -6.0966,  -3.5944],\n",
      "         [ -7.4725,  -7.4102,  -7.4775,  ...,  -7.6789,  -7.8761,  -2.8930],\n",
      "         [ -8.4894,  -8.3473,  -8.6284,  ...,  -9.0777,  -8.7114,  -5.6366],\n",
      "         ...,\n",
      "         [ -6.9026,  -6.7367,  -6.9210,  ...,  -7.0857,  -7.2508,  -2.4174],\n",
      "         [ -7.0470,  -6.8137,  -6.8830,  ...,  -7.3116,  -7.1426,  -1.8486],\n",
      "         [ -6.7643,  -6.5200,  -6.6933,  ...,  -6.9922,  -7.2363,  -1.8349]],\n",
      "\n",
      "        [[ -7.0339,  -6.9725,  -6.9509,  ...,  -6.5565,  -6.2799,  -4.5239],\n",
      "         [-17.1088, -16.8975, -17.1878,  ..., -15.2784, -15.1642, -14.0868],\n",
      "         [ -9.7239,  -9.6991,  -9.3269,  ...,  -9.8543, -10.6555,  -9.9548],\n",
      "         ...,\n",
      "         [ -8.4587,  -8.0688,  -8.0825,  ...,  -7.2051,  -7.4631,  -9.9786],\n",
      "         [ -7.4210,  -7.1182,  -7.4978,  ...,  -7.7381,  -7.8501,  -6.3222],\n",
      "         [-11.4914, -11.2288, -11.5917,  ...,  -9.0962, -10.0612,  -9.6129]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1667,  -7.1437,  -7.1509,  ...,  -6.5862,  -6.2980,  -4.3206],\n",
      "         [ -9.6043,  -9.7395,  -9.9450,  ...,  -9.1737,  -8.5604,  -9.2349],\n",
      "         [ -9.3139,  -9.2412,  -9.7704,  ..., -10.0240,  -8.8834,  -8.2353],\n",
      "         ...,\n",
      "         [-14.4851, -14.1248, -14.2607,  ..., -13.1410, -13.1503, -11.1698],\n",
      "         [-13.9754, -14.2696, -14.4380,  ..., -13.0155, -11.9408, -11.2510],\n",
      "         [-14.1776, -14.3498, -14.1708,  ..., -12.0347, -12.2742,  -9.3091]],\n",
      "\n",
      "        [[ -6.8447,  -6.8409,  -6.8060,  ...,  -6.1118,  -6.1359,  -3.9738],\n",
      "         [ -8.0965,  -8.3543,  -8.2126,  ...,  -8.1252,  -7.6436,  -8.9324],\n",
      "         [ -6.3978,  -6.3210,  -6.3444,  ...,  -6.3896,  -5.1616,  -6.2161],\n",
      "         ...,\n",
      "         [ -8.3826,  -8.5497,  -8.4659,  ...,  -8.1954,  -7.5943,  -7.2195],\n",
      "         [ -8.3002,  -8.3496,  -8.3630,  ...,  -8.0229,  -7.3272,  -7.3690],\n",
      "         [ -8.1406,  -8.3003,  -8.2446,  ...,  -7.6918,  -7.0569,  -7.8599]],\n",
      "\n",
      "        [[ -7.1347,  -7.1348,  -7.1513,  ...,  -6.6400,  -6.5155,  -4.2750],\n",
      "         [-11.2143, -10.9737, -10.7624,  ...,  -8.1281,  -8.9674,  -9.3006],\n",
      "         [ -5.6308,  -5.8958,  -5.9300,  ...,  -6.0619,  -7.9598,  -3.4164],\n",
      "         ...,\n",
      "         [ -5.0133,  -5.0507,  -4.9954,  ...,  -5.3719,  -6.8279,  -3.8700],\n",
      "         [ -5.9483,  -5.9619,  -5.9058,  ...,  -5.8613,  -7.2333,  -3.8821],\n",
      "         [ -5.5879,  -5.6729,  -5.6312,  ...,  -5.8870,  -7.0698,  -4.4347]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.7274748086929321\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7679, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0202,  -6.9735,  -6.9640,  ...,  -6.4175,  -6.1227,  -4.2739],\n",
      "         [ -8.6944,  -8.6180,  -8.8414,  ...,  -9.1489,  -6.9345,  -6.3199],\n",
      "         [ -4.6509,  -4.7391,  -4.6475,  ...,  -5.4545,  -2.7979,  -6.4898],\n",
      "         ...,\n",
      "         [ -6.9583,  -6.7996,  -7.1415,  ...,  -6.1848,  -7.4809,  -2.9451],\n",
      "         [ -5.5615,  -5.3723,  -5.6077,  ...,  -4.9134,  -4.7299,  -3.4382],\n",
      "         [-12.4581, -12.1085, -12.3374,  ...,  -9.4230,  -9.9523, -11.8516]],\n",
      "\n",
      "        [[ -6.6412,  -6.5122,  -6.5591,  ...,  -5.9256,  -6.1128,  -3.8652],\n",
      "         [ -8.2176,  -7.9915,  -8.3558,  ...,  -8.9620,  -9.3454,  -4.6555],\n",
      "         [ -8.0008,  -7.9814,  -8.1085,  ...,  -8.7192,  -8.3821,  -4.8789],\n",
      "         ...,\n",
      "         [ -6.0673,  -5.8554,  -6.0225,  ...,  -5.8289,  -6.6619,  -2.8772],\n",
      "         [ -6.1351,  -6.0014,  -6.1192,  ...,  -6.1499,  -6.3342,  -1.8299],\n",
      "         [ -5.8430,  -5.7328,  -5.9097,  ...,  -6.1286,  -6.6466,  -2.4073]],\n",
      "\n",
      "        [[ -6.6712,  -6.6411,  -6.6805,  ...,  -5.9293,  -5.7409,  -3.9314],\n",
      "         [-14.6603, -13.7911, -14.0569,  ..., -10.4365, -12.0952, -10.1092],\n",
      "         [ -5.3786,  -5.5187,  -5.4854,  ...,  -6.0696,  -7.2137,  -4.1709],\n",
      "         ...,\n",
      "         [ -6.2244,  -6.3224,  -6.2310,  ...,  -6.3263,  -7.8985,  -3.8754],\n",
      "         [ -6.1457,  -6.2612,  -6.2526,  ...,  -6.4618,  -8.1512,  -4.1226],\n",
      "         [ -5.4895,  -5.5765,  -5.5845,  ...,  -5.7386,  -7.1455,  -3.9357]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7290,  -6.6496,  -6.7123,  ...,  -6.2151,  -6.3485,  -3.7376],\n",
      "         [ -9.5168,  -9.4654,  -9.5822,  ...,  -9.3022,  -9.1495,  -5.7588],\n",
      "         [ -7.0072,  -6.9093,  -7.0115,  ...,  -8.0808,  -6.8237,  -3.9440],\n",
      "         ...,\n",
      "         [ -6.7387,  -6.6243,  -6.7749,  ...,  -7.1293,  -6.7423,  -3.9217],\n",
      "         [ -6.5774,  -6.4805,  -6.5274,  ...,  -6.7999,  -6.3965,  -2.6259],\n",
      "         [ -6.7146,  -6.6158,  -6.6825,  ...,  -6.8943,  -6.2756,  -3.9787]],\n",
      "\n",
      "        [[ -6.5113,  -6.4588,  -6.4667,  ...,  -5.9269,  -5.6105,  -3.9388],\n",
      "         [ -5.3919,  -5.6771,  -5.4905,  ...,  -6.0218,  -6.0180,  -5.6342],\n",
      "         [ -6.4185,  -6.2278,  -6.3411,  ...,  -6.4096,  -5.3995,  -4.5369],\n",
      "         ...,\n",
      "         [ -8.3636,  -8.6336,  -8.3823,  ...,  -8.4123,  -7.9109,  -5.0061],\n",
      "         [ -7.9427,  -8.0913,  -7.9339,  ...,  -7.9716,  -6.9667,  -5.7537],\n",
      "         [ -8.0361,  -8.2142,  -8.0463,  ...,  -7.9228,  -7.2453,  -5.4270]],\n",
      "\n",
      "        [[ -6.1004,  -6.0294,  -6.0197,  ...,  -5.5223,  -5.8309,  -3.2430],\n",
      "         [ -7.9267,  -7.8278,  -7.8175,  ...,  -8.0761,  -7.8691,  -3.6688],\n",
      "         [ -7.6484,  -7.4140,  -7.4096,  ...,  -7.8404,  -7.3392,  -4.1154],\n",
      "         ...,\n",
      "         [ -6.1840,  -6.0777,  -6.1317,  ...,  -6.1221,  -6.0832,  -3.4060],\n",
      "         [ -5.9594,  -5.8256,  -5.9058,  ...,  -6.1722,  -6.2832,  -3.3669],\n",
      "         [ -6.0314,  -5.9098,  -6.0297,  ...,  -6.1347,  -6.0492,  -2.7966]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.767904281616211\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3124, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7257,  -6.6940,  -6.6989,  ...,  -6.1099,  -5.8389,  -4.3615],\n",
      "         [ -5.7737,  -5.8650,  -6.0974,  ...,  -6.8637,  -6.6960,  -6.4218],\n",
      "         [ -6.8164,  -6.7275,  -6.9355,  ...,  -8.9237,  -7.5382,  -7.9190],\n",
      "         ...,\n",
      "         [-15.0429, -14.5654, -14.9113,  ..., -12.0111, -12.5419,  -9.5516],\n",
      "         [-11.9373, -11.9798, -11.8294,  ..., -11.9439, -11.5278, -10.8858],\n",
      "         [-11.9888, -12.0633, -12.0876,  ..., -11.2767, -11.6250,  -8.3268]],\n",
      "\n",
      "        [[-12.7225, -12.4740, -12.6039,  ..., -10.3619, -11.2245,  -7.1694],\n",
      "         [-10.7943, -10.5980, -10.5007,  ...,  -8.0410,  -9.0790,  -9.9420],\n",
      "         [ -5.7560,  -5.9522,  -5.8996,  ...,  -6.3910,  -8.3137,  -5.0264],\n",
      "         ...,\n",
      "         [ -5.2409,  -5.5140,  -5.2675,  ...,  -5.4222,  -7.5392,  -5.0423],\n",
      "         [ -5.9253,  -6.2408,  -6.0319,  ...,  -6.1361,  -7.6593,  -4.9431],\n",
      "         [ -7.7624,  -7.8219,  -7.5193,  ...,  -6.7238,  -7.8959,  -5.3193]],\n",
      "\n",
      "        [[ -8.1676,  -8.1524,  -8.2506,  ...,  -7.5791,  -7.6310,  -4.3416],\n",
      "         [-12.5470, -12.3729, -12.3666,  ...,  -9.0809, -10.1443,  -9.1750],\n",
      "         [ -5.7339,  -5.6990,  -5.8583,  ...,  -6.0409,  -7.6692,  -3.6794],\n",
      "         ...,\n",
      "         [ -5.6196,  -5.6459,  -5.7070,  ...,  -5.9630,  -6.4244,  -4.7172],\n",
      "         [ -5.2153,  -5.1551,  -5.2126,  ...,  -5.3253,  -6.9921,  -3.9222],\n",
      "         [ -6.3584,  -6.2113,  -6.2994,  ...,  -6.5881,  -7.7022,  -5.2708]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1009,  -7.0901,  -7.0678,  ...,  -6.4513,  -6.1381,  -4.4530],\n",
      "         [-12.7488, -12.3054, -12.7185,  ..., -12.3574, -10.2506, -11.8056],\n",
      "         [ -8.9317,  -8.9869,  -9.2840,  ...,  -9.7161,  -7.5261,  -5.4122],\n",
      "         ...,\n",
      "         [ -6.9591,  -7.0100,  -7.1086,  ...,  -7.6305,  -6.9053,  -6.9195],\n",
      "         [ -7.3477,  -7.4621,  -7.4488,  ...,  -7.3172,  -7.6708,  -6.9974],\n",
      "         [ -7.2410,  -7.2764,  -7.3463,  ...,  -7.6594,  -6.8977,  -6.5411]],\n",
      "\n",
      "        [[ -6.9048,  -6.8785,  -6.8760,  ...,  -6.1687,  -6.0596,  -4.3049],\n",
      "         [-11.4092, -11.7387, -11.6343,  ..., -12.5290,  -9.6795, -10.0132],\n",
      "         [ -7.2938,  -7.5163,  -7.5381,  ...,  -6.8492,  -6.0836,  -7.5402],\n",
      "         ...,\n",
      "         [ -6.2970,  -6.4227,  -6.2845,  ...,  -3.8600,  -5.1227, -10.2439],\n",
      "         [ -7.3966,  -7.3921,  -7.3854,  ...,  -5.9296,  -7.7348,  -4.0175],\n",
      "         [-11.1856, -10.8529, -11.2487,  ...,  -9.1144,  -9.5325,  -7.5548]],\n",
      "\n",
      "        [[ -6.7724,  -6.6622,  -6.7349,  ...,  -6.2500,  -6.0464,  -4.2384],\n",
      "         [-13.9314, -13.6449, -14.0892,  ..., -12.5353, -13.3705, -11.4193],\n",
      "         [ -7.8007,  -7.6801,  -7.8596,  ...,  -7.5156,  -7.0356,  -4.9796],\n",
      "         ...,\n",
      "         [ -6.4777,  -6.3910,  -6.5389,  ...,  -5.8013,  -6.8881,  -3.7089],\n",
      "         [ -6.4306,  -6.2652,  -6.3932,  ...,  -5.5156,  -6.9215,  -3.1973],\n",
      "         [ -6.1964,  -6.0684,  -6.2571,  ...,  -5.6649,  -6.9046,  -3.4565]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.3123693466186523\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.6118, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5945,  -6.5411,  -6.5173,  ...,  -6.0001,  -5.6839,  -3.9880],\n",
      "         [-12.3128, -12.1675, -12.2246,  ..., -10.0946, -10.4310,  -9.6285],\n",
      "         [ -9.7834,  -9.9565,  -9.5776,  ...,  -8.2466,  -7.6222,  -7.6370],\n",
      "         ...,\n",
      "         [ -4.7266,  -4.9962,  -4.7228,  ...,  -5.6982,  -3.6805,  -4.7233],\n",
      "         [-11.8137, -11.9090, -11.7697,  ...,  -9.6046,  -9.4495,  -8.9864],\n",
      "         [-13.2035, -13.0490, -13.2516,  ..., -10.1234, -11.3335,  -8.4350]],\n",
      "\n",
      "        [[-11.9115, -11.9283, -12.0579,  ...,  -9.6298, -11.6030,  -8.4344],\n",
      "         [ -8.3095,  -8.0492,  -8.3932,  ...,  -6.3550,  -7.5251, -10.5063],\n",
      "         [ -5.4946,  -5.8196,  -5.7457,  ...,  -5.6565,  -7.5873,  -4.8769],\n",
      "         ...,\n",
      "         [ -6.6778,  -6.9826,  -7.0117,  ...,  -7.0323,  -8.9282,  -6.4715],\n",
      "         [ -5.5365,  -5.7626,  -5.7426,  ...,  -5.7796,  -7.2720,  -6.0584],\n",
      "         [ -5.7956,  -5.9247,  -6.0369,  ...,  -5.8534,  -7.8012,  -4.5524]],\n",
      "\n",
      "        [[ -8.0200,  -7.9843,  -7.9991,  ...,  -7.1207,  -7.1721,  -4.6288],\n",
      "         [-13.1974, -12.9739, -12.8047,  ..., -10.5947, -10.3831, -13.0497],\n",
      "         [ -6.0846,  -6.2494,  -6.3087,  ...,  -6.8608,  -7.5248,  -5.0717],\n",
      "         ...,\n",
      "         [ -5.5325,  -5.7875,  -5.5909,  ...,  -6.0006,  -7.7447,  -4.5517],\n",
      "         [ -5.9571,  -6.1101,  -6.1033,  ...,  -6.5756,  -7.2429,  -5.2212],\n",
      "         [ -6.2271,  -6.4116,  -6.4220,  ...,  -7.0912,  -8.1696,  -3.9908]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4934,  -6.5125,  -6.5061,  ...,  -6.1378,  -5.6651,  -4.1967],\n",
      "         [-13.9392, -14.0025, -13.9883,  ..., -13.3090, -10.3393, -13.7816],\n",
      "         [ -6.5604,  -6.3059,  -6.5961,  ...,  -6.8055,  -5.8099,  -7.5493],\n",
      "         ...,\n",
      "         [ -5.0799,  -6.0287,  -5.3158,  ...,  -4.9336,  -4.3970,  -6.1425],\n",
      "         [ -6.6764,  -6.9958,  -6.9862,  ...,  -6.0836,  -6.5395,  -1.7261],\n",
      "         [-11.3124, -11.1046, -10.8762,  ...,  -9.6728,  -9.9353,  -7.7568]],\n",
      "\n",
      "        [[-13.0074, -12.7945, -13.0245,  ..., -11.1392, -13.3795,  -5.6694],\n",
      "         [-16.1715, -15.7115, -15.6874,  ..., -13.6096, -14.6076, -13.8154],\n",
      "         [ -7.2654,  -7.2806,  -7.4020,  ...,  -7.8662,  -8.8574,  -4.7194],\n",
      "         ...,\n",
      "         [ -6.5773,  -6.6242,  -6.5029,  ...,  -6.5701,  -8.2807,  -5.3770],\n",
      "         [ -6.5160,  -6.5601,  -6.5965,  ...,  -6.7486,  -8.4365,  -5.6558],\n",
      "         [ -6.3583,  -6.4698,  -6.4675,  ...,  -6.4586,  -8.8199,  -4.2400]],\n",
      "\n",
      "        [[ -7.0259,  -6.9937,  -7.0050,  ...,  -6.1108,  -6.0826,  -4.2540],\n",
      "         [ -9.7014,  -9.6174,  -9.5491,  ...,  -8.0327,  -6.8809,  -8.1580],\n",
      "         [ -5.5704,  -5.6526,  -5.6801,  ...,  -5.8687,  -7.4956,  -3.0251],\n",
      "         ...,\n",
      "         [ -6.0887,  -6.2149,  -6.1029,  ...,  -5.5007,  -7.1225,  -3.4001],\n",
      "         [ -6.3518,  -6.3625,  -6.3548,  ...,  -5.9753,  -7.0795,  -4.2020],\n",
      "         [ -5.5414,  -5.6393,  -5.5829,  ...,  -5.6088,  -7.2534,  -4.5202]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.6118075847625732\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6943, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6315,  -6.5663,  -6.5789,  ...,  -5.9047,  -5.7048,  -3.7466],\n",
      "         [-13.7936, -14.1672, -13.8428,  ..., -10.9058, -11.6539,  -9.6714],\n",
      "         [-14.8266, -15.5962, -15.1116,  ..., -13.4633, -13.5413,  -6.8259],\n",
      "         ...,\n",
      "         [ -7.4323,  -7.4278,  -7.3294,  ...,  -6.6658,  -6.6048,  -4.6634],\n",
      "         [ -7.5951,  -7.5163,  -7.3516,  ...,  -6.7640,  -6.9301,  -4.9540],\n",
      "         [ -7.7192,  -7.6753,  -7.6453,  ...,  -7.1605,  -7.1501,  -5.0457]],\n",
      "\n",
      "        [[ -6.8062,  -6.7440,  -6.7818,  ...,  -6.0401,  -6.0885,  -4.1235],\n",
      "         [ -6.5801,  -6.5099,  -6.7118,  ...,  -6.8573,  -6.9618,  -3.5748],\n",
      "         [ -8.8927,  -8.7593,  -8.8585,  ...,  -8.6765,  -9.4146,  -5.3595],\n",
      "         ...,\n",
      "         [ -6.6858,  -6.5492,  -6.5183,  ...,  -6.0641,  -6.2858,  -4.0061],\n",
      "         [ -7.1961,  -7.1325,  -7.1442,  ...,  -6.8755,  -7.5774,  -5.0380],\n",
      "         [ -6.7000,  -6.6634,  -6.7879,  ...,  -6.7730,  -7.2283,  -3.7573]],\n",
      "\n",
      "        [[ -7.0943,  -7.0267,  -7.0612,  ...,  -6.4504,  -6.1825,  -4.3647],\n",
      "         [-11.7991, -11.7360, -11.5245,  ...,  -8.5870, -10.6533,  -7.8441],\n",
      "         [ -5.2413,  -5.3711,  -5.2000,  ...,  -6.1727,  -7.1338,  -4.3982],\n",
      "         ...,\n",
      "         [ -6.3091,  -6.3289,  -6.1289,  ...,  -6.5915,  -7.4669,  -4.6462],\n",
      "         [ -6.0902,  -6.1462,  -6.0251,  ...,  -6.7054,  -7.6889,  -4.9707],\n",
      "         [ -6.1753,  -6.2713,  -6.1556,  ...,  -6.3817,  -7.8873,  -5.2129]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.8019,  -7.8034,  -7.7693,  ...,  -6.9238,  -7.1562,  -4.5627],\n",
      "         [-11.2668, -11.0835, -11.0057,  ...,  -8.2428,  -7.3594, -10.5566],\n",
      "         [ -5.1078,  -5.2303,  -5.2140,  ...,  -6.0173,  -7.4327,  -3.2998],\n",
      "         ...,\n",
      "         [ -5.4748,  -5.5739,  -5.5092,  ...,  -5.9938,  -7.7829,  -3.7396],\n",
      "         [ -6.4692,  -6.5817,  -6.6036,  ...,  -6.6626,  -7.8344,  -4.0358],\n",
      "         [ -6.0849,  -6.2744,  -6.2186,  ...,  -6.3087,  -7.7524,  -3.4978]],\n",
      "\n",
      "        [[ -6.7187,  -6.7062,  -6.6791,  ...,  -6.1407,  -5.7582,  -4.1330],\n",
      "         [ -7.6424,  -7.6244,  -7.2207,  ...,  -6.2539,  -7.0886,  -6.5109],\n",
      "         [ -8.6959,  -8.7804,  -8.4190,  ...,  -8.1073,  -6.3846,  -7.9476],\n",
      "         ...,\n",
      "         [ -6.4610,  -6.4825,  -6.0968,  ...,  -4.5430,  -5.5481,  -5.1245],\n",
      "         [ -8.1265,  -8.2538,  -8.0960,  ...,  -8.2647,  -6.8468,  -5.2029],\n",
      "         [ -5.4643,  -5.7564,  -5.5885,  ...,  -4.8944,  -4.1516,  -2.8558]],\n",
      "\n",
      "        [[ -7.2813,  -7.3052,  -7.3328,  ...,  -6.8522,  -6.6724,  -4.6819],\n",
      "         [-13.8821, -13.9421, -14.0995,  ..., -12.8742, -11.1185, -12.0687],\n",
      "         [ -8.2123,  -7.9997,  -8.2006,  ...,  -7.1794,  -6.7711,  -7.0034],\n",
      "         ...,\n",
      "         [ -6.3429,  -6.2006,  -6.3213,  ...,  -6.3147,  -5.2312,  -5.5183],\n",
      "         [ -7.7093,  -7.5628,  -7.6592,  ...,  -6.9249,  -6.6513,  -6.6699],\n",
      "         [-12.6051, -12.0125, -12.5866,  ..., -10.1500, -10.5653,  -8.1460]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6942919492721558\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2676, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6654,  -6.6125,  -6.6418,  ...,  -6.0066,  -5.9549,  -3.8677],\n",
      "         [ -9.1236,  -8.9528,  -8.9328,  ...,  -9.1187, -10.0061,  -4.3484],\n",
      "         [-11.3227, -11.6068, -11.5431,  ..., -10.4700, -11.2502,  -7.4052],\n",
      "         ...,\n",
      "         [ -6.2929,  -6.0787,  -6.2504,  ...,  -6.7341,  -7.1326,  -2.3721],\n",
      "         [ -6.7421,  -6.5199,  -6.7346,  ...,  -6.4823,  -6.7957,  -2.9633],\n",
      "         [ -6.9936,  -6.8446,  -7.0510,  ...,  -7.6353,  -7.1904,  -3.7079]],\n",
      "\n",
      "        [[ -6.1683,  -6.1093,  -6.0920,  ...,  -5.5364,  -5.4399,  -3.5172],\n",
      "         [ -7.2318,  -7.2292,  -6.9103,  ...,  -7.4434,  -6.4438,  -3.3093],\n",
      "         [ -1.0042,  -1.6150,  -1.3455,  ...,   0.4061,  -2.2896,  -4.2813],\n",
      "         ...,\n",
      "         [ -7.0649,  -7.0441,  -7.1452,  ...,  -6.7819,  -6.8524,  -3.2673],\n",
      "         [ -6.4498,  -6.4931,  -6.5008,  ...,  -6.7046,  -5.9118,  -2.8734],\n",
      "         [ -6.1385,  -6.2964,  -6.2524,  ...,  -6.5116,  -6.1523,  -3.2510]],\n",
      "\n",
      "        [[-11.2185, -11.7316, -11.2202,  ..., -10.0372, -10.7809,  -9.0493],\n",
      "         [-11.4748, -11.6544, -11.7557,  ...,  -8.9142,  -9.3131, -10.5956],\n",
      "         [ -5.0119,  -5.2299,  -5.0419,  ...,  -6.2521,  -7.2840,  -3.5152],\n",
      "         ...,\n",
      "         [ -4.7797,  -5.0614,  -4.7989,  ...,  -5.3858,  -6.7243,  -4.5800],\n",
      "         [ -5.4034,  -5.6696,  -5.4195,  ...,  -6.3336,  -7.2134,  -6.1968],\n",
      "         [ -5.4233,  -5.5892,  -5.3533,  ...,  -6.0437,  -6.9711,  -4.7136]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3367,  -6.2841,  -6.3068,  ...,  -5.6575,  -5.6329,  -3.6782],\n",
      "         [ -7.7914,  -7.7169,  -7.8490,  ...,  -8.0346,  -7.8326,  -4.7220],\n",
      "         [ -8.9723,  -9.2137,  -9.0598,  ...,  -9.2230,  -8.2239,  -6.1605],\n",
      "         ...,\n",
      "         [ -6.1004,  -6.0633,  -6.1865,  ...,  -6.3023,  -6.3865,  -3.6411],\n",
      "         [ -6.2680,  -6.1375,  -6.1824,  ...,  -6.7026,  -6.4142,  -3.9643],\n",
      "         [ -6.2958,  -6.1952,  -6.2957,  ...,  -6.7805,  -6.4326,  -4.6329]],\n",
      "\n",
      "        [[ -6.7204,  -6.6701,  -6.6494,  ...,  -6.0857,  -5.8927,  -3.8558],\n",
      "         [-11.3355, -11.2724, -11.4051,  ..., -10.0586,  -9.2555,  -8.5415],\n",
      "         [-12.3596, -12.0836, -11.7492,  ..., -10.3152,  -9.6177,  -8.3771],\n",
      "         ...,\n",
      "         [-12.9002, -12.7617, -12.7816,  ..., -12.3816, -11.2956,  -9.4639],\n",
      "         [ -8.9624,  -8.8257,  -9.1314,  ...,  -8.2728,  -7.9916,  -4.6473],\n",
      "         [-14.8049, -14.3553, -14.6208,  ..., -12.2805, -13.1946, -12.0166]],\n",
      "\n",
      "        [[ -6.6141,  -6.5747,  -6.5770,  ...,  -5.9976,  -5.9406,  -3.5215],\n",
      "         [ -8.2246,  -8.1966,  -8.0746,  ...,  -7.8774,  -7.3379,  -4.1294],\n",
      "         [-13.0579, -13.1150, -13.0568,  ..., -12.4467, -11.6350,  -8.6607],\n",
      "         ...,\n",
      "         [ -6.8160,  -6.9403,  -7.0195,  ...,  -6.9994,  -6.5987,  -3.7672],\n",
      "         [ -6.4762,  -6.4341,  -6.6404,  ...,  -6.3300,  -4.6240,  -4.6623],\n",
      "         [ -5.9807,  -5.8825,  -6.0367,  ...,  -5.9985,  -5.7324,  -2.6945]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.2675957679748535\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6090, grad_fn=<NllLossBackward0>), logits=tensor([[[-11.0789, -11.1446, -11.2973,  ..., -10.8560, -10.3219, -10.0438],\n",
      "         [-11.9045, -12.0948, -12.1731,  ..., -10.8126, -11.5159,  -8.9577],\n",
      "         [ -5.6934,  -5.7419,  -5.6456,  ...,  -6.0184,  -6.8508,  -6.3701],\n",
      "         ...,\n",
      "         [ -5.5621,  -5.7042,  -5.3062,  ...,  -4.9667,  -6.3638,  -5.9999],\n",
      "         [ -5.6420,  -5.5702,  -5.3919,  ...,  -6.3762,  -6.7003,  -5.8951],\n",
      "         [ -5.1606,  -5.3957,  -4.9868,  ...,  -4.8216,  -6.2939,  -4.6023]],\n",
      "\n",
      "        [[ -6.4174,  -6.3434,  -6.3992,  ...,  -5.7220,  -5.9120,  -3.8745],\n",
      "         [ -6.3183,  -6.1807,  -6.1865,  ...,  -6.3725,  -6.2575,  -4.8495],\n",
      "         [ -5.5236,  -5.3889,  -5.5947,  ...,  -6.0316,  -6.2494,  -3.0479],\n",
      "         ...,\n",
      "         [ -5.7901,  -5.4660,  -5.6878,  ...,  -5.7687,  -5.9022,  -3.8407],\n",
      "         [ -5.5596,  -5.3476,  -5.5516,  ...,  -5.3159,  -5.8208,  -4.0329],\n",
      "         [ -6.5584,  -6.2721,  -6.4900,  ...,  -6.1263,  -6.6499,  -5.2684]],\n",
      "\n",
      "        [[ -6.8616,  -6.9346,  -6.8654,  ...,  -6.2940,  -6.2128,  -4.3850],\n",
      "         [ -8.5831,  -8.5233,  -8.3532,  ...,  -7.4400,  -7.3243,  -4.6239],\n",
      "         [ -5.5004,  -5.3687,  -5.3117,  ...,  -4.2992,  -5.2924,  -1.7890],\n",
      "         ...,\n",
      "         [ -8.1794,  -8.2674,  -8.3131,  ...,  -7.6390,  -7.6768,  -5.5256],\n",
      "         [ -8.0019,  -8.0525,  -8.2059,  ...,  -7.5269,  -7.4809,  -4.9730],\n",
      "         [ -7.8783,  -7.8828,  -7.9784,  ...,  -7.6082,  -7.3714,  -5.1601]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-10.5285, -10.9367, -10.8411,  ...,  -8.6973, -10.6107,  -8.0283],\n",
      "         [-11.7312, -11.9032, -11.7964,  ..., -10.4367, -10.2577, -10.0264],\n",
      "         [ -5.5406,  -5.7607,  -5.7374,  ...,  -5.4229,  -7.5105,  -4.5982],\n",
      "         ...,\n",
      "         [ -6.3066,  -6.3422,  -6.4335,  ...,  -5.7938,  -7.3908,  -4.7923],\n",
      "         [ -6.0007,  -6.1334,  -6.1143,  ...,  -5.4095,  -6.8509,  -5.8267],\n",
      "         [ -5.1754,  -5.2564,  -5.3390,  ...,  -5.0120,  -7.1326,  -4.4209]],\n",
      "\n",
      "        [[ -7.7397,  -7.6858,  -7.7082,  ...,  -7.0060,  -6.9326,  -4.8492],\n",
      "         [ -9.0695,  -8.1128,  -8.3553,  ...,  -6.0722,  -6.3009, -11.7446],\n",
      "         [ -5.8472,  -5.8973,  -5.9086,  ...,  -6.6401,  -7.6148,  -3.8884],\n",
      "         ...,\n",
      "         [ -6.5304,  -6.5061,  -6.5132,  ...,  -7.0768,  -7.6204,  -5.5512],\n",
      "         [ -5.5310,  -5.5328,  -5.5013,  ...,  -5.9636,  -6.7790,  -4.7025],\n",
      "         [ -6.2085,  -6.2520,  -6.2320,  ...,  -6.8951,  -7.4672,  -4.5508]],\n",
      "\n",
      "        [[ -6.7017,  -6.6738,  -6.6987,  ...,  -6.1716,  -5.9789,  -3.9904],\n",
      "         [ -7.8889,  -7.9433,  -7.9891,  ...,  -8.0001,  -7.2002,  -6.8353],\n",
      "         [ -8.8583,  -8.6375,  -8.9758,  ...,  -8.0292,  -8.4241,  -5.2778],\n",
      "         ...,\n",
      "         [ -2.3108,  -2.2669,  -2.4484,  ...,  -2.7863,  -3.5228,  -6.2853],\n",
      "         [ -4.3849,  -4.0679,  -4.2536,  ...,  -4.2978,  -5.8096,  -5.4315],\n",
      "         [-12.6950, -12.8533, -12.7089,  ..., -10.2069, -10.3118,  -8.1144]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6089574098587036\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6907, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9543,  -6.8995,  -6.9199,  ...,  -6.3179,  -6.4763,  -4.6684],\n",
      "         [ -9.7014,  -9.4510,  -9.8467,  ...,  -9.1727,  -7.6784,  -6.8759],\n",
      "         [ -3.0744,  -3.0296,  -3.2036,  ...,  -3.5809,  -1.9446,  -8.2857],\n",
      "         ...,\n",
      "         [ -6.4820,  -6.4468,  -6.6117,  ...,  -6.4591,  -6.6961,  -6.2118],\n",
      "         [ -6.0955,  -5.9503,  -6.1056,  ...,  -5.6737,  -6.1674,  -5.6867],\n",
      "         [ -6.0394,  -5.9140,  -6.1742,  ...,  -5.6662,  -6.2516,  -5.3900]],\n",
      "\n",
      "        [[ -6.8225,  -6.8079,  -6.7946,  ...,  -6.3519,  -6.1676,  -4.2857],\n",
      "         [ -7.7270,  -8.1576,  -7.8997,  ...,  -7.8108,  -6.9704,  -9.7354],\n",
      "         [ -1.9084,  -2.0883,  -2.0357,  ...,  -3.5063,  -3.3045,  -5.8300],\n",
      "         ...,\n",
      "         [ -6.5225,  -6.3448,  -6.5847,  ...,  -7.5579,  -6.4374,  -5.5873],\n",
      "         [ -8.1373,  -8.2188,  -8.2689,  ...,  -7.8806,  -7.4517,  -5.1569],\n",
      "         [ -3.9090,  -3.7470,  -3.9134,  ...,  -5.0956,  -4.5467,  -3.6440]],\n",
      "\n",
      "        [[ -6.7995,  -6.7122,  -6.7947,  ...,  -6.0611,  -6.3362,  -3.6817],\n",
      "         [ -7.6779,  -7.4495,  -7.5605,  ...,  -7.4227,  -7.6061,  -3.0501],\n",
      "         [ -6.4437,  -6.3422,  -6.2943,  ...,  -6.0094,  -6.1586,  -3.6968],\n",
      "         ...,\n",
      "         [ -6.5844,  -6.3544,  -6.4210,  ...,  -6.6039,  -6.3192,  -2.5515],\n",
      "         [ -5.9163,  -5.7141,  -5.8394,  ...,  -5.8741,  -5.8684,  -3.2885],\n",
      "         [ -6.0760,  -5.8715,  -6.0183,  ...,  -5.9549,  -6.0571,  -2.4308]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-15.2937, -15.4711, -15.5202,  ..., -14.2614, -15.0607,  -8.3621],\n",
      "         [-12.7006, -12.3458, -12.3431,  ...,  -9.9447,  -9.7864,  -8.4837],\n",
      "         [ -5.0810,  -5.2823,  -5.2295,  ...,  -5.6455,  -7.5473,  -4.8652],\n",
      "         ...,\n",
      "         [ -4.5043,  -4.6835,  -4.7686,  ...,  -4.2327,  -7.0183,  -4.3718],\n",
      "         [ -5.4929,  -5.4756,  -5.5413,  ...,  -5.3873,  -7.2937,  -4.7102],\n",
      "         [ -5.0665,  -5.2101,  -5.2206,  ...,  -5.1225,  -7.1955,  -5.4848]],\n",
      "\n",
      "        [[ -6.6503,  -6.6386,  -6.6355,  ...,  -6.0275,  -5.7431,  -4.3691],\n",
      "         [ -6.8239,  -6.8889,  -6.9951,  ...,  -6.4587,  -6.1846,  -6.8339],\n",
      "         [ -6.5764,  -6.2807,  -6.5893,  ...,  -5.6229,  -6.3616,  -7.8566],\n",
      "         ...,\n",
      "         [ -6.3455,  -6.3976,  -6.4274,  ...,  -5.9088,  -5.4001,  -6.4808],\n",
      "         [ -5.9332,  -5.8983,  -6.0130,  ...,  -4.9451,  -5.6552,  -7.4099],\n",
      "         [ -6.5033,  -6.6156,  -6.5699,  ...,  -6.3023,  -5.5502,  -6.8822]],\n",
      "\n",
      "        [[ -7.0302,  -7.0427,  -7.0646,  ...,  -6.4523,  -6.3119,  -4.6354],\n",
      "         [ -4.8559,  -4.7905,  -5.1972,  ...,  -3.9415,  -5.6982,  -4.8043],\n",
      "         [ -4.9098,  -4.9947,  -5.0648,  ...,  -4.6442,  -4.2900,  -2.9919],\n",
      "         ...,\n",
      "         [ -7.0768,  -7.4344,  -7.3505,  ...,  -7.1186,  -7.1535,  -3.3230],\n",
      "         [ -4.1878,  -4.3262,  -4.6237,  ...,  -4.2347,  -3.8448,  -0.6868],\n",
      "         [-13.1189, -13.0694, -12.9923,  ..., -11.5705, -12.5425, -13.1053]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.69065523147583\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2177, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.2611,  -9.1404,  -9.2258,  ...,  -8.4440,  -8.2686,  -5.9575],\n",
      "         [-10.6814, -10.6930, -10.9647,  ..., -10.8944, -11.6858,  -9.3773],\n",
      "         [-10.6833, -11.2377, -10.8814,  ...,  -7.8615,  -9.4153,  -2.6292],\n",
      "         ...,\n",
      "         [ -5.4643,  -5.4412,  -5.1794,  ...,  -2.0791,  -5.4518,  -6.0354],\n",
      "         [ -7.5810,  -7.4825,  -7.4846,  ...,  -6.7333,  -8.1016,  -5.1619],\n",
      "         [ -7.5951,  -7.6574,  -7.6371,  ...,  -5.9938,  -7.9636,  -6.3035]],\n",
      "\n",
      "        [[ -6.7436,  -6.7196,  -6.6689,  ...,  -5.9520,  -5.7228,  -3.7883],\n",
      "         [ -6.7090,  -6.8680,  -6.5487,  ...,  -6.9461,  -6.3486,  -5.3600],\n",
      "         [ -6.4114,  -6.3118,  -6.1284,  ...,  -6.1818,  -5.5021,  -6.8922],\n",
      "         ...,\n",
      "         [ -7.9790,  -8.0112,  -8.0347,  ...,  -7.2260,  -5.7376,  -5.2869],\n",
      "         [ -8.0080,  -8.0307,  -7.9480,  ...,  -7.5886,  -5.3617,  -6.0763],\n",
      "         [ -7.6549,  -7.6951,  -7.7938,  ...,  -7.2906,  -5.2922,  -5.5162]],\n",
      "\n",
      "        [[ -6.9741,  -6.9101,  -6.8725,  ...,  -6.2330,  -5.9986,  -4.4813],\n",
      "         [ -9.3769,  -9.2721,  -9.4545,  ...,  -9.2085,  -9.0491, -10.0407],\n",
      "         [ -8.9282,  -8.2286,  -8.9472,  ...,  -8.1881,  -6.8433,  -8.7126],\n",
      "         ...,\n",
      "         [ -7.5856,  -7.5743,  -7.4887,  ...,  -6.4816,  -6.0788,  -8.5170],\n",
      "         [ -6.7345,  -6.9110,  -6.5789,  ...,  -5.2734,  -5.4166,  -8.5243],\n",
      "         [ -8.7498,  -8.7587,  -8.5592,  ...,  -6.6116,  -6.6894, -11.4783]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8106,  -6.7659,  -6.7499,  ...,  -6.3930,  -6.0824,  -3.8017],\n",
      "         [ -8.7362,  -8.4700,  -8.7990,  ...,  -7.9423,  -8.8512,  -8.6893],\n",
      "         [ -9.0755,  -8.6744,  -8.9051,  ...,  -9.2001,  -7.2475,  -9.5190],\n",
      "         ...,\n",
      "         [ -6.5791,  -6.7582,  -6.3950,  ...,  -6.2975,  -6.4393,  -8.6453],\n",
      "         [-10.4513, -10.8903, -10.9184,  ...,  -9.2105, -10.0286,  -8.8724],\n",
      "         [-12.1918, -12.3982, -12.4631,  ..., -11.8697, -10.7197,  -9.5076]],\n",
      "\n",
      "        [[ -7.0775,  -7.0789,  -7.0727,  ...,  -6.2474,  -6.1875,  -4.0471],\n",
      "         [-12.0022, -11.5994, -11.4017,  ...,  -9.1461, -11.2288,  -8.9504],\n",
      "         [ -4.9994,  -5.0776,  -5.0471,  ...,  -5.3036,  -6.8397,  -3.9697],\n",
      "         ...,\n",
      "         [ -5.5249,  -5.5371,  -5.4740,  ...,  -5.5171,  -6.7899,  -4.5560],\n",
      "         [ -5.0801,  -5.0261,  -4.9327,  ...,  -5.0151,  -6.5309,  -4.2873],\n",
      "         [ -5.6270,  -5.6650,  -5.5678,  ...,  -5.5488,  -7.1764,  -4.3076]],\n",
      "\n",
      "        [[ -6.7715,  -6.7994,  -6.7907,  ...,  -6.1601,  -6.1170,  -4.0986],\n",
      "         [-11.0430, -10.7075, -10.9816,  ...,  -9.7481,  -9.1520, -13.5714],\n",
      "         [ -4.7018,  -4.7346,  -4.8023,  ...,  -3.7374,  -5.4108,  -5.8880],\n",
      "         ...,\n",
      "         [ -4.7367,  -5.0066,  -4.7063,  ...,  -3.4146,  -4.6315,  -4.7601],\n",
      "         [ -5.6098,  -5.5796,  -5.7467,  ...,  -4.8684,  -5.5952,  -4.0546],\n",
      "         [-13.3695, -12.8063, -12.5731,  ..., -10.2208, -11.5361,  -7.6664]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.2176949977874756\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0346, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7370,  -6.7173,  -6.7278,  ...,  -6.1897,  -5.9997,  -4.2805],\n",
      "         [-12.5821, -12.9038, -12.8198,  ..., -11.6710, -10.8114, -10.6840],\n",
      "         [ -9.4793,  -9.4086,  -9.2755,  ...,  -9.8267,  -5.8249, -10.7362],\n",
      "         ...,\n",
      "         [-12.2569, -12.6077, -12.5710,  ..., -12.7172,  -8.5565, -10.5043],\n",
      "         [ -8.4715,  -8.6922,  -8.6235,  ...,  -8.5537,  -8.3822,  -8.9444],\n",
      "         [-13.8440, -13.2693, -13.7556,  ..., -11.2009, -12.3449,  -7.5564]],\n",
      "\n",
      "        [[ -6.9180,  -6.8671,  -6.9182,  ...,  -6.3828,  -6.2563,  -4.1941],\n",
      "         [ -7.5560,  -7.5344,  -7.5288,  ...,  -7.2152,  -7.2058,  -2.9269],\n",
      "         [ -2.0701,  -2.0459,  -2.0630,  ...,  -2.5613,  -2.5279,  -1.5156],\n",
      "         ...,\n",
      "         [ -7.8497,  -7.6878,  -7.9094,  ...,  -8.2705,  -7.7697,  -7.0654],\n",
      "         [ -7.8081,  -7.6616,  -7.8872,  ...,  -8.5314,  -7.5761,  -6.8642],\n",
      "         [ -7.2343,  -7.1895,  -7.3316,  ...,  -8.2384,  -7.0215,  -6.8292]],\n",
      "\n",
      "        [[ -6.9152,  -6.8320,  -6.8556,  ...,  -6.3002,  -6.2061,  -4.1729],\n",
      "         [ -8.7876,  -8.6333,  -8.6543,  ...,  -9.0745,  -8.3999,  -5.7773],\n",
      "         [ -8.4910,  -8.3929,  -8.4129,  ...,  -8.2421,  -8.0155,  -6.4933],\n",
      "         ...,\n",
      "         [ -6.7244,  -6.4918,  -6.6028,  ...,  -6.4512,  -6.5385,  -3.7225],\n",
      "         [ -6.0136,  -5.8154,  -5.9035,  ...,  -6.1984,  -6.1820,  -3.7597],\n",
      "         [ -6.0267,  -5.8310,  -5.8950,  ...,  -6.2233,  -6.0993,  -3.5350]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-10.0307, -10.0467, -10.1331,  ...,  -8.3424,  -8.9324,  -5.0006],\n",
      "         [-13.2400, -12.7176, -12.7882,  ..., -10.0737, -10.5974, -11.8252],\n",
      "         [ -5.6224,  -5.8496,  -5.9714,  ...,  -6.3133,  -8.0610,  -4.4450],\n",
      "         ...,\n",
      "         [ -5.8742,  -6.0456,  -6.1936,  ...,  -5.7299,  -7.7802,  -3.8594],\n",
      "         [ -6.3929,  -6.5166,  -6.6270,  ...,  -6.2849,  -8.2334,  -4.0810],\n",
      "         [ -6.2277,  -6.3937,  -6.4345,  ...,  -6.0956,  -7.4597,  -3.1111]],\n",
      "\n",
      "        [[ -7.0031,  -6.9410,  -6.9485,  ...,  -6.1423,  -6.3755,  -4.3021],\n",
      "         [-11.3708, -11.0619, -11.5157,  ..., -10.3573,  -9.9677,  -7.3365],\n",
      "         [ -7.7232,  -7.5745,  -7.9617,  ...,  -7.4337,  -7.0183,  -6.9703],\n",
      "         ...,\n",
      "         [ -9.7650,  -9.8423,  -9.9765,  ...,  -9.6167,  -8.9193, -11.1317],\n",
      "         [-11.2977, -11.3918, -11.4024,  ..., -11.1544, -10.2304, -10.6927],\n",
      "         [-13.1566, -12.8000, -12.6270,  ..., -10.5673, -12.0411,  -7.3521]],\n",
      "\n",
      "        [[-12.2107, -12.1706, -12.4604,  ...,  -9.7211, -11.2433,  -7.0048],\n",
      "         [-11.4219, -11.7155, -11.1059,  ...,  -8.0879,  -8.3442,  -9.2792],\n",
      "         [ -5.3279,  -5.4772,  -5.5263,  ...,  -6.1682,  -7.8254,  -4.6375],\n",
      "         ...,\n",
      "         [ -5.7406,  -5.9587,  -5.9171,  ...,  -5.8517,  -7.5667,  -5.0896],\n",
      "         [ -4.3987,  -4.7865,  -4.5087,  ...,  -5.6194,  -5.9621,  -4.4568],\n",
      "         [ -4.8237,  -5.0954,  -4.8870,  ...,  -4.6851,  -6.9275,  -2.9638]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.034566640853882\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0113, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7447,  -6.7369,  -6.6907,  ...,  -6.3027,  -5.8823,  -4.3510],\n",
      "         [ -6.0856,  -6.1163,  -6.3151,  ...,  -5.5991,  -4.6763,  -6.3355],\n",
      "         [-14.0276, -13.6004, -13.8249,  ..., -11.6743, -11.2438, -11.6243],\n",
      "         ...,\n",
      "         [-10.4036, -10.6576, -10.5798,  ..., -10.1995,  -7.4837, -12.4750],\n",
      "         [-15.2318, -15.6176, -15.4951,  ..., -12.5893, -12.5316, -13.1179],\n",
      "         [-12.9326, -12.7296, -12.9427,  ..., -10.6244, -10.0603,  -8.9975]],\n",
      "\n",
      "        [[ -6.8482,  -7.1011,  -6.9857,  ...,  -6.7165,  -6.3371,  -5.2179],\n",
      "         [-13.5162, -13.7919, -13.8737,  ..., -13.2996, -11.3681, -10.4417],\n",
      "         [ -7.7496,  -8.1054,  -7.9853,  ...,  -6.9810,  -6.8701,  -6.7618],\n",
      "         ...,\n",
      "         [ -4.5848,  -4.8491,  -4.8365,  ...,  -5.5860,  -5.1065,  -5.4452],\n",
      "         [ -5.5445,  -5.7254,  -5.8155,  ...,  -6.6183,  -6.6546,  -5.0703],\n",
      "         [-13.7614, -13.7151, -13.6749,  ..., -12.1500, -13.4026, -12.0771]],\n",
      "\n",
      "        [[ -7.8039,  -7.6991,  -7.7594,  ...,  -6.7809,  -6.9420,  -4.7755],\n",
      "         [-11.5915, -11.1409, -11.3063,  ...,  -9.5354,  -9.1184,  -9.6798],\n",
      "         [ -5.0517,  -5.1143,  -5.1575,  ...,  -5.4219,  -7.0948,  -3.6630],\n",
      "         ...,\n",
      "         [ -5.5651,  -5.6326,  -5.5481,  ...,  -5.4482,  -7.2148,  -5.2295],\n",
      "         [ -5.0521,  -5.1206,  -5.1619,  ...,  -5.2809,  -7.2850,  -3.5662],\n",
      "         [ -6.0677,  -6.0878,  -6.0431,  ...,  -6.0864,  -7.5405,  -5.0833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.6556,  -9.6442,  -9.6516,  ...,  -9.9920,  -9.1104,  -8.3116],\n",
      "         [ -9.6605,  -9.1871,  -9.0087,  ...,  -9.6952,  -8.0756, -11.7973],\n",
      "         [ -6.8020,  -6.7713,  -6.9748,  ...,  -7.7533,  -7.9053,  -5.9467],\n",
      "         ...,\n",
      "         [ -6.5500,  -6.4792,  -6.4915,  ...,  -6.7388,  -7.1472,  -7.1667],\n",
      "         [ -6.8288,  -6.8385,  -6.8555,  ...,  -6.9185,  -7.1953,  -7.4622],\n",
      "         [ -7.1269,  -7.1523,  -7.2477,  ...,  -7.1976,  -7.3924,  -6.5636]],\n",
      "\n",
      "        [[ -6.9894,  -6.9121,  -6.9648,  ...,  -6.2392,  -6.1242,  -3.5446],\n",
      "         [ -7.1090,  -7.2756,  -7.4680,  ...,  -6.9083,  -7.0167,  -5.2751],\n",
      "         [ -8.2734,  -8.5542,  -8.3548,  ...,  -7.7168,  -7.2023,  -3.9188],\n",
      "         ...,\n",
      "         [ -7.3282,  -7.2981,  -7.2378,  ...,  -7.1107,  -6.6991,  -3.4990],\n",
      "         [ -7.5995,  -7.4297,  -7.3728,  ...,  -7.3513,  -6.2588,  -3.2471],\n",
      "         [ -7.7056,  -7.5414,  -7.5331,  ...,  -7.2617,  -6.8393,  -3.1776]],\n",
      "\n",
      "        [[ -6.5091,  -6.4891,  -6.4977,  ...,  -5.8610,  -5.6657,  -3.9140],\n",
      "         [ -6.9189,  -6.6050,  -6.6720,  ...,  -2.7834,  -5.7338,  -6.0799],\n",
      "         [ -5.5036,  -5.5853,  -5.6285,  ...,  -5.9201,  -7.4510,  -3.6249],\n",
      "         ...,\n",
      "         [ -5.8000,  -5.9242,  -5.9146,  ...,  -5.9368,  -6.7417,  -5.2412],\n",
      "         [ -5.7107,  -5.8593,  -5.7715,  ...,  -5.8425,  -7.2277,  -5.2530],\n",
      "         [ -5.7342,  -5.9772,  -5.8478,  ...,  -6.4100,  -7.1473,  -5.4340]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.0112547874450684\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9627, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7317,  -6.6807,  -6.6381,  ...,  -6.3506,  -6.0593,  -3.6858],\n",
      "         [-12.9130, -12.5252, -12.7909,  ...,  -9.9203,  -9.8149, -10.8195],\n",
      "         [ -6.1014,  -6.2433,  -6.4253,  ...,  -7.1250,  -7.1426,  -5.8931],\n",
      "         ...,\n",
      "         [ -5.9865,  -6.0750,  -6.0484,  ...,  -6.3673,  -6.5843,  -5.1762],\n",
      "         [ -7.0268,  -7.0844,  -7.1282,  ...,  -7.2605,  -7.7713,  -5.8114],\n",
      "         [ -6.3184,  -6.3588,  -6.4264,  ...,  -6.7099,  -6.4384,  -5.0307]],\n",
      "\n",
      "        [[ -8.4166,  -8.3860,  -8.4793,  ...,  -7.3018,  -7.4988,  -4.8864],\n",
      "         [ -9.8322,  -9.7812,  -9.8416,  ...,  -7.6053,  -8.9777,  -9.1835],\n",
      "         [ -5.4206,  -5.5657,  -5.5263,  ...,  -6.7521,  -7.6682,  -3.8669],\n",
      "         ...,\n",
      "         [ -5.3253,  -5.5831,  -5.5175,  ...,  -6.3224,  -7.3625,  -4.0564],\n",
      "         [ -4.7872,  -4.9572,  -4.9037,  ...,  -5.6193,  -6.6851,  -2.6800],\n",
      "         [ -5.1612,  -5.4061,  -5.4964,  ...,  -6.1553,  -7.2521,  -3.1394]],\n",
      "\n",
      "        [[ -7.0228,  -6.9177,  -6.9673,  ...,  -6.1776,  -6.3166,  -4.1346],\n",
      "         [ -8.1660,  -7.7623,  -7.7124,  ...,  -6.8959,  -6.1956,  -9.5753],\n",
      "         [ -8.1042,  -7.7573,  -7.8657,  ...,  -6.4761,  -6.1528,  -4.2729],\n",
      "         ...,\n",
      "         [ -7.4851,  -7.2128,  -7.3125,  ...,  -7.0746,  -7.0817,  -4.9060],\n",
      "         [ -6.7543,  -6.5027,  -6.5703,  ...,  -5.9573,  -6.1696,  -4.3404],\n",
      "         [ -7.6444,  -7.3238,  -7.3852,  ...,  -6.9779,  -6.5970,  -5.9360]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2315,  -7.2574,  -7.2094,  ...,  -6.4502,  -6.5781,  -4.7252],\n",
      "         [ -8.2550,  -8.3751,  -8.5054,  ...,  -8.1955,  -7.8341,  -9.5664],\n",
      "         [ -6.7671,  -6.8527,  -7.0687,  ...,  -8.0799,  -6.5309,  -7.1697],\n",
      "         ...,\n",
      "         [-16.2841, -15.8587, -16.1417,  ..., -13.5407, -13.6910, -11.5946],\n",
      "         [-14.9560, -14.7721, -14.8021,  ..., -11.4958, -12.4351, -10.3991],\n",
      "         [ -7.6700,  -7.6731,  -7.8674,  ...,  -7.9866,  -7.8965,  -5.7056]],\n",
      "\n",
      "        [[ -7.0427,  -6.9918,  -7.0095,  ...,  -6.2145,  -6.2023,  -4.2677],\n",
      "         [-12.0095, -11.6492, -11.4163,  ...,  -9.0345,  -9.7933,  -8.9016],\n",
      "         [ -6.1614,  -6.1381,  -6.1059,  ...,  -6.3566,  -7.6912,  -5.0591],\n",
      "         ...,\n",
      "         [ -5.9674,  -6.0617,  -5.9410,  ...,  -5.6811,  -7.0198,  -4.3880],\n",
      "         [ -5.9775,  -5.9601,  -5.9908,  ...,  -6.3684,  -7.2906,  -4.4705],\n",
      "         [ -5.9762,  -5.9177,  -5.7935,  ...,  -5.8631,  -7.0787,  -5.1633]],\n",
      "\n",
      "        [[ -6.2997,  -6.2265,  -6.2384,  ...,  -5.6760,  -5.4669,  -3.7532],\n",
      "         [-12.2748, -11.9059, -12.1166,  ...,  -7.8541,  -9.7379,  -8.8509],\n",
      "         [ -5.6788,  -5.8541,  -5.9282,  ...,  -5.8854,  -7.2796,  -4.3027],\n",
      "         ...,\n",
      "         [ -5.6275,  -5.8275,  -5.8220,  ...,  -6.1855,  -6.8759,  -3.8246],\n",
      "         [ -5.7673,  -5.8853,  -5.9835,  ...,  -6.0027,  -7.4806,  -3.8745],\n",
      "         [ -5.1817,  -5.3348,  -5.3002,  ...,  -5.2588,  -6.8963,  -3.5612]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.962743878364563\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3473, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6698,  -6.6607,  -6.6749,  ...,  -5.9568,  -5.8092,  -3.8652],\n",
      "         [-11.2525, -10.9599, -10.9551,  ...,  -9.2300,  -9.4222,  -9.1077],\n",
      "         [ -5.4252,  -5.4253,  -5.4361,  ...,  -5.7493,  -7.0785,  -4.3080],\n",
      "         ...,\n",
      "         [ -5.9426,  -5.8094,  -5.8493,  ...,  -5.7251,  -7.1836,  -4.6024],\n",
      "         [ -6.2898,  -6.2187,  -6.1463,  ...,  -5.7013,  -7.3385,  -4.1431],\n",
      "         [ -6.3181,  -6.3144,  -6.3144,  ...,  -5.8419,  -7.2636,  -5.0367]],\n",
      "\n",
      "        [[ -8.4715,  -8.4108,  -8.4303,  ...,  -7.6028,  -8.2096,  -4.7037],\n",
      "         [-11.3268, -11.1792, -11.4083,  ...,  -8.9423,  -8.7963, -10.4699],\n",
      "         [ -5.4476,  -5.3122,  -5.3640,  ...,  -5.6558,  -7.5266,  -4.1458],\n",
      "         ...,\n",
      "         [ -5.3247,  -5.1707,  -5.1337,  ...,  -5.3641,  -6.6335,  -5.2339],\n",
      "         [ -5.2249,  -5.0677,  -5.0768,  ...,  -5.0644,  -6.6701,  -4.2008],\n",
      "         [ -5.5236,  -5.4617,  -5.3559,  ...,  -5.1536,  -6.0921,  -5.3254]],\n",
      "\n",
      "        [[ -7.1420,  -7.1173,  -7.0406,  ...,  -6.3824,  -5.9423,  -4.9601],\n",
      "         [-13.7637, -14.0372, -13.9775,  ..., -12.1158, -10.3726, -13.3629],\n",
      "         [ -5.0713,  -5.2044,  -5.1510,  ...,  -3.9519,  -3.5045, -11.1917],\n",
      "         ...,\n",
      "         [ -6.4377,  -6.8402,  -6.5624,  ...,  -6.8317,  -5.2697,  -8.1175],\n",
      "         [ -6.8979,  -7.2341,  -7.1630,  ...,  -7.3029,  -6.3971,  -6.9665],\n",
      "         [ -7.4424,  -7.8632,  -7.6316,  ...,  -7.9547,  -6.6716,  -6.9367]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5831,  -6.5477,  -6.5623,  ...,  -5.8728,  -5.6512,  -3.8964],\n",
      "         [-11.2334, -10.9256, -10.9410,  ...,  -8.0661, -10.1732,  -9.4703],\n",
      "         [ -6.2718,  -6.4215,  -6.4121,  ...,  -6.8897,  -7.2965,  -4.7496],\n",
      "         ...,\n",
      "         [ -6.7478,  -6.8478,  -6.8809,  ...,  -6.3016,  -7.3000,  -4.4519],\n",
      "         [ -6.7338,  -6.7484,  -6.6837,  ...,  -6.7226,  -7.1942,  -4.9298],\n",
      "         [ -5.9219,  -6.0111,  -5.9357,  ...,  -6.1730,  -7.1744,  -4.1012]],\n",
      "\n",
      "        [[ -7.1417,  -7.1339,  -7.1071,  ...,  -6.6497,  -6.2851,  -4.4333],\n",
      "         [ -8.5389,  -8.4393,  -8.4279,  ...,  -8.2822,  -7.8190,  -7.2072],\n",
      "         [-13.1267, -13.1984, -13.0773,  ..., -11.6118, -10.9932,  -7.8571],\n",
      "         ...,\n",
      "         [ -8.1408,  -8.3615,  -7.9099,  ...,  -9.1245,  -7.4333,  -7.5900],\n",
      "         [ -7.5846,  -7.5540,  -7.5840,  ...,  -7.8093,  -6.4959,  -5.3753],\n",
      "         [ -8.1839,  -8.2129,  -8.2855,  ...,  -8.4174,  -7.0489,  -5.8918]],\n",
      "\n",
      "        [[ -6.8518,  -6.8283,  -6.7980,  ...,  -6.0590,  -5.9458,  -4.0579],\n",
      "         [ -7.5055,  -7.5255,  -7.5257,  ...,  -6.7866,  -5.4324,  -5.8193],\n",
      "         [-10.9007, -10.6680, -10.6234,  ...,  -9.6868,  -9.1959,  -7.3481],\n",
      "         ...,\n",
      "         [-11.2675, -11.2889, -11.2414,  ...,  -9.3413,  -9.1743,  -7.6013],\n",
      "         [ -6.3054,  -6.5939,  -6.4131,  ...,  -6.0182,  -5.3913,  -5.4240],\n",
      "         [ -8.0682,  -8.0869,  -7.9564,  ...,  -7.5464,  -6.5408,  -6.3415]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.347275495529175\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6150, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2015,  -7.1762,  -7.1533,  ...,  -6.1725,  -6.2760,  -4.3386],\n",
      "         [ -8.2203,  -8.1076,  -8.1417,  ...,  -9.3671,  -8.7479,  -6.9758],\n",
      "         [ -1.2122,  -1.4151,  -0.9251,  ...,  -2.9025,  -1.4998,  -1.4738],\n",
      "         ...,\n",
      "         [ -8.8040,  -8.9969,  -8.8366,  ...,  -9.6918,  -8.6674,  -8.0681],\n",
      "         [ -7.9451,  -8.0602,  -7.9021,  ...,  -8.6664,  -8.3758,  -6.7844],\n",
      "         [ -6.3501,  -6.4787,  -6.3131,  ...,  -7.0240,  -8.0002,  -5.3353]],\n",
      "\n",
      "        [[ -7.2363,  -7.2867,  -7.2603,  ...,  -6.3395,  -6.8637,  -4.4956],\n",
      "         [ -8.0777,  -7.9669,  -8.5134,  ...,  -8.2843,  -8.0758,  -7.4565],\n",
      "         [-11.8024, -11.7379, -12.0366,  ..., -10.5075, -10.2888,  -8.7679],\n",
      "         ...,\n",
      "         [ -6.7882,  -6.9927,  -6.9708,  ...,  -6.7718,  -6.6436,  -5.1615],\n",
      "         [ -7.6445,  -7.6557,  -7.6036,  ...,  -7.8843,  -8.7194,  -2.3749],\n",
      "         [ -7.1570,  -7.2041,  -7.1998,  ...,  -7.7245,  -7.4835,  -5.5077]],\n",
      "\n",
      "        [[ -7.0687,  -7.1793,  -7.0078,  ...,  -6.1471,  -6.7875,  -4.6194],\n",
      "         [-11.0603, -10.6702, -10.6672,  ...,  -8.9752,  -9.3361,  -8.7087],\n",
      "         [ -5.2652,  -5.3701,  -5.3554,  ...,  -4.9472,  -7.1700,  -4.6772],\n",
      "         ...,\n",
      "         [ -5.1115,  -5.1939,  -5.0882,  ...,  -4.6391,  -6.3612,  -3.8988],\n",
      "         [ -5.2631,  -5.1978,  -5.1306,  ...,  -4.5316,  -6.1754,  -4.4212],\n",
      "         [ -5.3359,  -5.3089,  -5.2507,  ...,  -5.2367,  -6.5639,  -5.4879]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5957,  -6.7387,  -6.6950,  ...,  -6.1725,  -5.8240,  -4.3975],\n",
      "         [ -7.6581,  -8.3497,  -8.2456,  ...,  -7.6265,  -6.3246,  -4.0745],\n",
      "         [ -5.8057,  -5.9006,  -5.9708,  ...,  -6.9557,  -5.8750,  -1.8143],\n",
      "         ...,\n",
      "         [ -8.1828,  -8.3049,  -8.4752,  ...,  -5.2261,  -6.3855, -10.1806],\n",
      "         [ -3.6005,  -3.5721,  -3.7054,  ...,  -2.7127,  -2.1143,  -3.3783],\n",
      "         [-12.1309, -12.3008, -12.5727,  ..., -10.5571,  -9.4573,  -8.9706]],\n",
      "\n",
      "        [[ -7.1054,  -7.1443,  -7.1031,  ...,  -6.7591,  -6.2956,  -4.5674],\n",
      "         [ -7.7377,  -7.8944,  -7.9272,  ...,  -9.2365,  -6.4690,  -8.1785],\n",
      "         [ -7.4410,  -7.9359,  -7.5148,  ...,  -7.7782,  -7.1948,  -4.0619],\n",
      "         ...,\n",
      "         [ -9.7273, -10.0831,  -9.4637,  ...,  -8.7993,  -7.3402,  -8.5123],\n",
      "         [ -8.7617,  -8.8218,  -8.1723,  ...,  -8.8769,  -7.0450,  -6.5047],\n",
      "         [-14.3465, -14.4891, -14.5093,  ..., -13.2552, -11.8249, -10.2304]],\n",
      "\n",
      "        [[ -9.0688,  -8.9463,  -9.0230,  ...,  -7.8302,  -8.3081,  -5.3510],\n",
      "         [-11.4769, -11.1430, -10.9126,  ...,  -8.1179,  -9.6364,  -7.5379],\n",
      "         [ -6.4451,  -6.4389,  -6.4575,  ...,  -7.2346,  -8.0291,  -5.9141],\n",
      "         ...,\n",
      "         [ -6.7610,  -6.7399,  -6.8164,  ...,  -7.2622,  -8.4921,  -5.5834],\n",
      "         [ -6.9763,  -7.0260,  -6.9565,  ...,  -7.3459,  -8.3883,  -5.0221],\n",
      "         [ -6.6149,  -6.5083,  -6.4880,  ...,  -6.5879,  -7.9291,  -5.4376]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6149648427963257\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6663, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9565,  -6.8778,  -6.9633,  ...,  -6.1810,  -6.3819,  -3.7727],\n",
      "         [ -9.9394,  -9.6407,  -9.7237,  ...,  -9.6391,  -9.6502,  -6.7608],\n",
      "         [ -7.0371,  -7.2952,  -7.1559,  ...,  -6.8166,  -7.0152,  -6.9442],\n",
      "         ...,\n",
      "         [ -6.1704,  -6.0914,  -6.2162,  ...,  -5.6605,  -6.4787,  -4.5939],\n",
      "         [ -6.1623,  -6.0433,  -6.2012,  ...,  -5.4762,  -6.9861,  -4.2385],\n",
      "         [ -6.5647,  -6.6506,  -6.6648,  ...,  -6.3323,  -6.2136,  -4.9328]],\n",
      "\n",
      "        [[ -7.8361,  -7.7257,  -7.7602,  ...,  -6.7256,  -6.9196,  -4.4878],\n",
      "         [-12.7581, -12.8392, -12.4527,  ..., -10.7520, -10.9612,  -8.9135],\n",
      "         [ -5.7469,  -5.8029,  -5.7790,  ...,  -6.5855,  -7.8900,  -6.0846],\n",
      "         ...,\n",
      "         [ -6.0274,  -6.0958,  -6.0662,  ...,  -5.4822,  -7.6022,  -4.6066],\n",
      "         [ -6.2021,  -6.1495,  -6.1435,  ...,  -6.2587,  -7.5777,  -4.9573],\n",
      "         [ -5.9474,  -5.9099,  -5.8695,  ...,  -5.5882,  -6.8664,  -5.4165]],\n",
      "\n",
      "        [[-12.9277, -12.8249, -12.9030,  ..., -11.1480, -12.1412,  -7.1608],\n",
      "         [ -9.8520,  -9.4737,  -9.7808,  ...,  -6.5317,  -8.1318,  -7.8034],\n",
      "         [ -5.5840,  -5.8459,  -5.7030,  ...,  -6.3723,  -8.0448,  -4.2389],\n",
      "         ...,\n",
      "         [ -5.7346,  -5.9206,  -5.7099,  ...,  -6.0104,  -7.3779,  -5.3996],\n",
      "         [ -6.1626,  -6.4104,  -6.2972,  ...,  -6.7820,  -7.8279,  -4.7351],\n",
      "         [ -6.7782,  -7.0407,  -6.9952,  ...,  -7.0095,  -8.6657,  -4.6019]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7964,  -6.7840,  -6.7649,  ...,  -6.4457,  -5.9350,  -4.7267],\n",
      "         [-12.0581, -12.4009, -12.2404,  ..., -10.4565, -10.8504, -11.2727],\n",
      "         [-10.3908, -10.3439, -10.3836,  ...,  -9.4713,  -5.8441, -10.5266],\n",
      "         ...,\n",
      "         [ -6.9587,  -7.0753,  -7.1378,  ...,  -7.6065,  -6.6463,  -8.3237],\n",
      "         [ -7.3857,  -7.5581,  -7.4537,  ...,  -7.5852,  -6.4969,  -6.7692],\n",
      "         [ -7.9678,  -7.8504,  -8.0962,  ...,  -8.4486,  -7.2230,  -7.9859]],\n",
      "\n",
      "        [[ -6.6224,  -6.6122,  -6.6309,  ...,  -6.0656,  -5.8880,  -4.2114],\n",
      "         [-11.0426, -11.5088, -11.6237,  ..., -11.1632,  -8.7175, -14.3548],\n",
      "         [ -9.4005, -10.0009,  -9.8486,  ...,  -9.6137,  -6.8720,  -9.9468],\n",
      "         ...,\n",
      "         [ -8.4593,  -8.7417,  -8.7069,  ...,  -8.1179,  -7.7826,  -6.3905],\n",
      "         [ -7.7083,  -8.0915,  -8.0211,  ...,  -7.5451,  -7.0718,  -7.3664],\n",
      "         [ -7.3178,  -7.6820,  -7.6548,  ...,  -7.3201,  -6.3747,  -7.6708]],\n",
      "\n",
      "        [[ -7.1043,  -7.1482,  -7.1188,  ...,  -6.4450,  -6.3804,  -4.4030],\n",
      "         [ -9.1691,  -9.3173,  -9.3049,  ..., -10.1549,  -9.9082,  -8.2799],\n",
      "         [ -5.1943,  -5.4725,  -5.6839,  ...,  -5.9376,  -5.4638,  -5.7843],\n",
      "         ...,\n",
      "         [ -4.3668,  -4.6720,  -5.0787,  ...,  -3.3792,  -5.5584,  -4.3484],\n",
      "         [-15.6208, -15.5721, -15.5370,  ..., -14.6228, -11.7279, -13.9850],\n",
      "         [-12.9188, -12.7720, -12.6773,  ..., -10.0475, -11.4951,  -9.9165]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6662688255310059\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7108, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3704,  -6.2556,  -6.3423,  ...,  -6.1032,  -6.0414,  -3.6042],\n",
      "         [-10.0360,  -9.7961,  -9.8182,  ..., -10.3050,  -8.9001,  -6.3638],\n",
      "         [ -7.6237,  -7.7718,  -7.7635,  ...,  -7.7903,  -7.3979,  -4.0544],\n",
      "         ...,\n",
      "         [ -6.6178,  -6.4432,  -6.5320,  ...,  -6.8621,  -6.6531,  -4.3490],\n",
      "         [ -7.1339,  -6.9907,  -7.0878,  ...,  -7.7234,  -6.7484,  -4.1434],\n",
      "         [ -6.9058,  -6.8141,  -6.9090,  ...,  -7.3224,  -6.8457,  -4.0698]],\n",
      "\n",
      "        [[ -7.0120,  -6.8993,  -6.9289,  ...,  -6.2327,  -6.0903,  -4.4825],\n",
      "         [-12.8628, -12.7248, -12.9239,  ..., -10.3512,  -9.2804,  -8.7043],\n",
      "         [ -5.6927,  -5.7213,  -5.7930,  ...,  -6.1596,  -7.4459,  -4.6612],\n",
      "         ...,\n",
      "         [ -6.2777,  -6.3722,  -6.2604,  ...,  -6.6581,  -7.1390,  -5.6327],\n",
      "         [ -6.4980,  -6.4340,  -6.5531,  ...,  -7.0383,  -7.5369,  -5.7623],\n",
      "         [ -5.7759,  -5.8532,  -5.8040,  ...,  -6.4918,  -7.4318,  -5.0593]],\n",
      "\n",
      "        [[ -5.5355,  -5.3999,  -5.5496,  ...,  -5.3805,  -4.5891,  -3.0490],\n",
      "         [-14.3418, -13.7878, -13.7469,  ..., -11.4818, -11.7870, -16.7985],\n",
      "         [ -6.2306,  -6.3453,  -6.4291,  ...,  -6.7172,  -7.6098,  -5.6386],\n",
      "         ...,\n",
      "         [ -6.2130,  -6.2316,  -6.2272,  ...,  -6.3121,  -6.8317,  -6.4483],\n",
      "         [ -6.0687,  -6.1162,  -6.1715,  ...,  -6.6895,  -6.9117,  -5.6764],\n",
      "         [ -6.8744,  -6.8458,  -6.9031,  ...,  -6.9933,  -6.9825,  -5.4833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7783,  -6.7370,  -6.7376,  ...,  -6.1214,  -5.6912,  -3.9799],\n",
      "         [ -7.7488,  -8.0219,  -8.1114,  ...,  -6.5456,  -5.4156,  -6.4119],\n",
      "         [ -4.4430,  -4.2864,  -4.7067,  ...,  -3.3609,  -3.2402,  -6.1136],\n",
      "         ...,\n",
      "         [-10.1183,  -9.9919, -10.2244,  ...,  -9.7883,  -8.1171,  -8.1799],\n",
      "         [ -8.3977,  -8.2515,  -8.6037,  ...,  -6.2501,  -6.8115,  -6.3082],\n",
      "         [-13.7360, -13.0825, -13.1452,  ..., -10.2221, -11.3751, -11.4692]],\n",
      "\n",
      "        [[ -6.9275,  -6.8895,  -6.8702,  ...,  -6.3267,  -6.0994,  -4.4140],\n",
      "         [-16.5030, -16.7641, -16.8246,  ..., -15.8156, -13.3875, -14.4293],\n",
      "         [-14.2551, -14.4177, -14.1382,  ..., -12.5801, -13.1856, -10.7125],\n",
      "         ...,\n",
      "         [ -8.3949,  -8.7537,  -8.7092,  ...,  -8.4557,  -8.6847,  -6.8179],\n",
      "         [-12.5565, -12.7269, -12.4203,  ..., -12.4002, -11.0669,  -8.1484],\n",
      "         [-14.8729, -14.9623, -14.7034,  ..., -12.2973, -12.8601, -14.0212]],\n",
      "\n",
      "        [[ -7.0807,  -7.0877,  -7.0544,  ...,  -6.4809,  -6.2470,  -4.7399],\n",
      "         [ -7.4374,  -7.3838,  -7.6393,  ...,  -7.3657,  -6.4556,  -7.8017],\n",
      "         [ -8.4798,  -8.6102,  -8.4656,  ...,  -9.8876,  -9.1989,  -7.2327],\n",
      "         ...,\n",
      "         [ -4.1959,  -4.3648,  -4.2598,  ...,  -3.6512,  -4.1707,  -5.7408],\n",
      "         [ -8.7355,  -8.8320,  -8.9096,  ...,  -8.7899,  -8.7961,  -8.2725],\n",
      "         [-11.3473, -11.3339, -11.4037,  ..., -10.5586,  -9.6090,  -8.9633]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.7107889652252197\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0364, grad_fn=<NllLossBackward0>), logits=tensor([[[-11.2051, -11.3584, -11.3061,  ..., -10.4219,  -9.5269, -10.1576],\n",
      "         [-13.5798, -13.4493, -13.1870,  ..., -12.2645, -10.6856, -15.1784],\n",
      "         [ -5.9630,  -6.2219,  -6.1030,  ...,  -6.8414,  -8.2368,  -6.0254],\n",
      "         ...,\n",
      "         [ -6.6405,  -6.7155,  -6.6517,  ...,  -7.1047,  -8.6146,  -5.4631],\n",
      "         [ -6.3181,  -6.3744,  -6.4052,  ...,  -6.6210,  -8.0744,  -5.5836],\n",
      "         [ -7.0268,  -7.1066,  -7.2312,  ...,  -7.6688,  -8.5756,  -4.9574]],\n",
      "\n",
      "        [[ -9.4236,  -9.3135,  -9.2756,  ...,  -8.7527,  -9.2577,  -6.0829],\n",
      "         [-10.3486, -10.4246, -10.4543,  ...,  -8.2276,  -8.2029,  -8.9136],\n",
      "         [ -5.6295,  -5.7010,  -5.6675,  ...,  -6.2205,  -7.4376,  -5.8739],\n",
      "         ...,\n",
      "         [ -6.6281,  -6.7025,  -6.8104,  ...,  -7.3462,  -8.2701,  -7.1808],\n",
      "         [ -5.9003,  -5.9684,  -5.8720,  ...,  -5.9212,  -6.9404,  -6.7366],\n",
      "         [ -6.0341,  -6.1374,  -6.1007,  ...,  -6.5400,  -7.4947,  -5.5857]],\n",
      "\n",
      "        [[ -6.9410,  -6.9089,  -6.9025,  ...,  -6.3340,  -6.0291,  -4.5944],\n",
      "         [ -9.9591, -10.3214, -10.2921,  ..., -10.6621,  -9.6864,  -9.3079],\n",
      "         [ -6.7253,  -6.9328,  -7.1416,  ...,  -6.4117,  -5.4754,  -6.7445],\n",
      "         ...,\n",
      "         [ -7.2185,  -7.6263,  -7.4985,  ...,  -6.5464,  -7.9136,  -8.3961],\n",
      "         [ -8.8508,  -9.7050,  -9.4759,  ...,  -8.9917,  -7.5380,  -9.8971],\n",
      "         [-12.6258, -12.3531, -12.4330,  ..., -10.7747, -11.0790,  -9.3856]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4597,  -6.4357,  -6.3978,  ...,  -5.8522,  -5.3457,  -4.3364],\n",
      "         [-13.4912, -14.1892, -14.0058,  ..., -11.9395, -11.1494, -13.8510],\n",
      "         [ -3.4411,  -3.9706,  -3.8664,  ...,  -3.6916,  -4.5147,  -4.3812],\n",
      "         ...,\n",
      "         [ -5.4037,  -5.6595,  -5.6786,  ...,  -4.7551,  -5.4016,  -5.7780],\n",
      "         [ -5.2896,  -5.6409,  -5.5956,  ...,  -4.1781,  -5.1484,  -6.6340],\n",
      "         [ -5.7924,  -5.9964,  -6.0030,  ...,  -5.5261,  -5.5987,  -6.4175]],\n",
      "\n",
      "        [[ -6.5811,  -6.5652,  -6.5756,  ...,  -6.0938,  -5.9035,  -4.0951],\n",
      "         [-10.6250, -10.6290, -10.8684,  ..., -11.5836, -10.9657,  -8.6867],\n",
      "         [-13.0573, -13.1509, -13.2290,  ..., -14.1577, -13.7362, -10.9131],\n",
      "         ...,\n",
      "         [-10.7896, -11.2621, -11.1214,  ...,  -9.1503,  -8.2619, -12.3414],\n",
      "         [ -8.2543,  -8.1695,  -7.8514,  ...,  -8.4308,  -8.0799,  -8.1187],\n",
      "         [-14.0608, -13.8795, -13.9824,  ..., -12.7181, -11.0824,  -8.6787]],\n",
      "\n",
      "        [[ -7.3113,  -7.2899,  -7.2647,  ...,  -6.6696,  -6.2797,  -4.8297],\n",
      "         [-10.4062, -10.2451, -10.3004,  ...,  -9.8157,  -9.5270,  -9.1355],\n",
      "         [ -7.0778,  -7.2084,  -7.1212,  ...,  -8.0061,  -6.6707,  -7.3578],\n",
      "         ...,\n",
      "         [-12.6618, -12.7702, -12.8145,  ..., -11.8930,  -9.7942, -11.4609],\n",
      "         [ -9.3633,  -9.3259,  -9.5219,  ...,  -8.4157,  -7.2472, -10.8138],\n",
      "         [-14.3256, -13.5743, -13.7392,  ..., -11.4029, -11.4501, -10.8721]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.03637433052063\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.8965, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3816,  -6.2745,  -6.2873,  ...,  -5.7630,  -5.7016,  -3.6618],\n",
      "         [ -7.6544,  -7.5920,  -7.5202,  ...,  -7.7317,  -7.8952,  -3.3980],\n",
      "         [ -7.4950,  -7.4091,  -7.3498,  ...,  -7.8026,  -6.7023,  -5.2181],\n",
      "         ...,\n",
      "         [ -6.5296,  -6.3609,  -6.4526,  ...,  -6.3962,  -6.4616,  -3.6262],\n",
      "         [ -6.1208,  -5.9346,  -6.0145,  ...,  -5.8992,  -6.0955,  -2.8098],\n",
      "         [ -6.4397,  -6.2695,  -6.3579,  ...,  -6.4457,  -6.5523,  -3.3176]],\n",
      "\n",
      "        [[ -6.9254,  -6.8863,  -6.9012,  ...,  -6.1257,  -6.0607,  -4.1176],\n",
      "         [-13.1435, -12.2835, -12.8860,  ...,  -8.3653, -10.4974,  -9.9964],\n",
      "         [ -6.1984,  -6.1597,  -6.1982,  ...,  -6.4195,  -7.8198,  -3.8292],\n",
      "         ...,\n",
      "         [ -6.8991,  -6.9648,  -6.8804,  ...,  -7.0127,  -8.3233,  -4.7013],\n",
      "         [ -6.4279,  -6.4891,  -6.4563,  ...,  -6.5192,  -7.7644,  -5.1293],\n",
      "         [ -6.6862,  -6.7416,  -6.6238,  ...,  -6.7470,  -7.5882,  -5.0322]],\n",
      "\n",
      "        [[ -6.3040,  -6.2568,  -6.3244,  ...,  -5.7099,  -5.7557,  -3.4154],\n",
      "         [ -8.1871,  -8.3290,  -8.1908,  ...,  -8.1940,  -8.2287,  -4.1799],\n",
      "         [ -7.6022,  -7.5832,  -7.3920,  ...,  -7.7883,  -7.3383,  -4.3722],\n",
      "         ...,\n",
      "         [ -6.7589,  -6.7036,  -6.7463,  ...,  -6.7709,  -6.8164,  -3.1462],\n",
      "         [ -6.9956,  -6.9579,  -7.0270,  ...,  -7.1991,  -6.8728,  -3.7822],\n",
      "         [ -5.7103,  -5.5601,  -5.6988,  ...,  -5.7677,  -6.0105,  -3.4115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7010,  -6.6628,  -6.6555,  ...,  -6.0969,  -6.0557,  -4.0675],\n",
      "         [-15.9739, -15.6468, -15.7155,  ..., -15.7888, -15.6068, -12.2689],\n",
      "         [ -6.1083,  -5.8796,  -5.9631,  ...,  -6.9580,  -7.0077,  -6.8706],\n",
      "         ...,\n",
      "         [ -6.9349,  -6.8293,  -6.6747,  ...,  -7.6362,  -6.6940,  -6.0185],\n",
      "         [ -5.9929,  -5.7981,  -5.5677,  ...,  -5.9934,  -4.6848,  -4.9969],\n",
      "         [ -7.8862,  -7.7314,  -7.6590,  ...,  -8.3750,  -7.6180,  -5.5548]],\n",
      "\n",
      "        [[ -6.6649,  -6.6304,  -6.6559,  ...,  -5.8503,  -5.7901,  -3.5477],\n",
      "         [ -6.4143,  -6.4346,  -6.5179,  ...,  -7.0174,  -7.0575,  -1.6750],\n",
      "         [ -7.0053,  -7.1317,  -7.0696,  ...,  -7.0236,  -6.8673,  -2.6963],\n",
      "         ...,\n",
      "         [ -6.8548,  -6.7280,  -6.7580,  ...,  -6.5066,  -6.4197,  -1.8293],\n",
      "         [ -6.3177,  -6.1700,  -6.2209,  ...,  -6.4587,  -6.3487,  -2.6324],\n",
      "         [ -6.2412,  -6.1481,  -6.2251,  ...,  -6.1681,  -5.9222,  -2.8103]],\n",
      "\n",
      "        [[ -6.7167,  -6.6231,  -6.6604,  ...,  -5.9726,  -5.9295,  -4.1062],\n",
      "         [ -8.7382,  -8.7913,  -8.9889,  ...,  -9.0234,  -8.5588,  -5.5997],\n",
      "         [ -8.2361,  -8.1228,  -8.3991,  ...,  -8.0604,  -8.3919,  -5.2371],\n",
      "         ...,\n",
      "         [ -6.8180,  -6.5757,  -6.6811,  ...,  -6.9084,  -6.8764,  -4.2873],\n",
      "         [ -6.4366,  -6.2696,  -6.3256,  ...,  -6.1151,  -6.3721,  -3.5233],\n",
      "         [ -6.3691,  -6.1492,  -6.2343,  ...,  -6.2435,  -6.2095,  -2.8882]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 0.896467924118042\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1939, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0415,  -7.1879,  -7.1244,  ...,  -6.7016,  -6.3521,  -5.1665],\n",
      "         [ -2.3771,  -2.8546,  -2.8307,  ...,  -2.4705,  -1.1673,  -4.0238],\n",
      "         [-11.8585, -11.7937, -11.9701,  ..., -12.5982,  -9.5584,  -9.7314],\n",
      "         ...,\n",
      "         [ -8.8837,  -8.8105,  -8.7194,  ...,  -8.9171,  -5.7940, -11.9257],\n",
      "         [ -5.0080,  -5.1218,  -5.0454,  ...,  -5.4530,  -3.9846,  -8.4306],\n",
      "         [-11.9217, -11.7725, -11.9459,  ...,  -9.3899,  -9.9320, -10.4289]],\n",
      "\n",
      "        [[ -6.9386,  -7.0103,  -6.9133,  ...,  -6.7688,  -6.5535,  -5.0663],\n",
      "         [-14.1906, -14.0521, -13.8570,  ..., -12.8761,  -9.8695, -13.3555],\n",
      "         [-10.4060, -10.1725, -10.1450,  ..., -10.2424,  -8.9827, -10.9685],\n",
      "         ...,\n",
      "         [-13.8126, -13.8830, -13.7273,  ..., -11.0400, -10.0128, -16.6229],\n",
      "         [ -8.2839,  -8.0670,  -8.5191,  ...,  -7.2244,  -6.8653,  -8.3547],\n",
      "         [-12.1167, -12.0783, -11.8002,  ...,  -9.2039, -11.2245, -11.2059]],\n",
      "\n",
      "        [[-10.1106, -10.1904, -10.0646,  ...,  -8.6556, -10.3809,  -6.2320],\n",
      "         [-12.3226, -12.3816, -12.4590,  ..., -10.4844, -10.4633, -10.9624],\n",
      "         [ -4.8146,  -5.0881,  -5.0230,  ...,  -6.4427,  -7.1594,  -4.4526],\n",
      "         ...,\n",
      "         [ -6.0152,  -6.1169,  -6.1675,  ...,  -7.1260,  -8.3104,  -4.9535],\n",
      "         [ -5.8398,  -5.9879,  -5.7963,  ...,  -6.6239,  -7.1107,  -5.4110],\n",
      "         [ -7.1579,  -7.2966,  -7.2247,  ...,  -7.0404,  -7.8230,  -6.7009]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6107,  -6.5818,  -6.5940,  ...,  -5.8753,  -5.6599,  -3.9277],\n",
      "         [ -7.2774,  -6.9330,  -6.8707,  ...,  -6.9660,  -6.8882,  -5.9806],\n",
      "         [-13.4053, -13.5448, -13.3160,  ..., -10.9265, -12.3325, -10.9060],\n",
      "         ...,\n",
      "         [ -5.3712,  -5.4225,  -5.3768,  ...,  -5.8076,  -6.2047,  -4.2721],\n",
      "         [ -4.6527,  -4.7577,  -4.7203,  ...,  -4.9022,  -5.2757,  -3.1483],\n",
      "         [ -4.5765,  -4.7527,  -4.6382,  ...,  -4.9590,  -5.6201,  -3.2734]],\n",
      "\n",
      "        [[ -5.9186,  -5.8541,  -5.9604,  ...,  -5.9692,  -6.0731,  -2.5893],\n",
      "         [-11.2716, -10.6065, -10.8084,  ...,  -8.3814,  -8.7173,  -7.2250],\n",
      "         [ -5.7239,  -5.8242,  -5.7497,  ...,  -5.9632,  -6.9730,  -3.0016],\n",
      "         ...,\n",
      "         [ -6.0172,  -5.9852,  -5.8842,  ...,  -6.0433,  -7.6310,  -3.1573],\n",
      "         [ -6.0624,  -6.1514,  -6.1038,  ...,  -6.0890,  -7.0723,  -3.5836],\n",
      "         [ -6.1523,  -6.1536,  -6.1379,  ...,  -6.2304,  -6.4951,  -3.7144]],\n",
      "\n",
      "        [[ -7.1085,  -7.1273,  -7.0805,  ...,  -6.6011,  -6.2155,  -4.9402],\n",
      "         [-14.5265, -14.3563, -14.6727,  ..., -13.1627, -11.8963, -16.3087],\n",
      "         [ -4.8682,  -5.1788,  -5.2958,  ...,  -8.3431,  -5.4424,  -4.8903],\n",
      "         ...,\n",
      "         [ -5.4320,  -5.5594,  -5.5774,  ...,  -5.5997,  -4.2660,  -7.8677],\n",
      "         [ -7.6321,  -7.9781,  -7.8276,  ...,  -7.5489,  -7.0751,  -6.7790],\n",
      "         [ -6.6364,  -6.9203,  -6.8580,  ...,  -6.1970,  -5.8597,  -6.3425]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.193889856338501\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9856, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9312,  -6.9389,  -6.9272,  ...,  -6.4266,  -6.0670,  -4.6172],\n",
      "         [-14.0051, -13.9806, -14.0496,  ..., -14.0417, -11.1908, -10.5907],\n",
      "         [ -4.2405,  -4.2993,  -4.5916,  ...,  -4.0496,  -3.3783,  -5.4836],\n",
      "         ...,\n",
      "         [-13.3958, -13.0486, -13.3383,  ..., -10.6816, -11.8307,  -9.9132],\n",
      "         [-12.7428, -12.8258, -13.0427,  ..., -12.9746, -11.7593,  -7.9034],\n",
      "         [-12.2462, -11.9657, -12.0778,  ..., -10.0087, -10.9622,  -8.1907]],\n",
      "\n",
      "        [[ -6.6241,  -6.6018,  -6.6248,  ...,  -5.8453,  -6.0384,  -3.7104],\n",
      "         [ -8.6981,  -8.3513,  -8.6430,  ...,  -8.4811,  -8.2035,  -5.8057],\n",
      "         [ -9.9181,  -9.9250, -10.0682,  ...,  -8.9792,  -7.7771,  -8.9115],\n",
      "         ...,\n",
      "         [ -5.9859,  -5.7941,  -5.9400,  ...,  -5.7871,  -6.0103,  -3.8073],\n",
      "         [ -6.1928,  -5.9960,  -6.1930,  ...,  -5.9965,  -6.1683,  -3.3570],\n",
      "         [ -6.6175,  -6.4536,  -6.6719,  ...,  -6.3958,  -6.6247,  -3.3928]],\n",
      "\n",
      "        [[ -6.5007,  -6.5225,  -6.5130,  ...,  -6.0475,  -5.9009,  -4.3060],\n",
      "         [ -4.9973,  -4.9514,  -5.2163,  ...,  -6.4063,  -5.8775,  -5.9109],\n",
      "         [ -8.3111,  -7.9507,  -8.4966,  ...,  -9.4933,  -7.7202,  -8.7446],\n",
      "         ...,\n",
      "         [ -5.5003,  -5.5761,  -5.6613,  ...,  -6.5930,  -6.1345,  -5.6044],\n",
      "         [ -7.2714,  -7.2471,  -7.3790,  ...,  -7.5991,  -7.2288,  -8.6965],\n",
      "         [ -7.5861,  -7.6113,  -7.6663,  ...,  -7.9178,  -7.3053,  -7.4833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7778,  -6.7912,  -6.7538,  ...,  -6.1678,  -6.2293,  -4.2375],\n",
      "         [ -6.8098,  -6.5861,  -7.0571,  ...,  -7.5691,  -6.7871,  -8.7599],\n",
      "         [ -2.1681,  -2.3087,  -2.2896,  ...,  -3.3711,  -4.7167,  -4.6965],\n",
      "         ...,\n",
      "         [ -5.8106,  -5.8180,  -5.8337,  ...,  -5.2556,  -5.9260,  -6.4630],\n",
      "         [ -4.1244,  -3.8339,  -3.9884,  ...,  -3.6189,  -3.9820,  -7.6348],\n",
      "         [ -6.1977,  -6.1659,  -6.1773,  ...,  -6.1140,  -6.3536,  -5.9904]],\n",
      "\n",
      "        [[ -6.3990,  -6.3482,  -6.3660,  ...,  -5.8175,  -5.5833,  -3.8005],\n",
      "         [ -8.5965,  -8.4862,  -8.4728,  ...,  -8.6667,  -8.7018,  -4.3874],\n",
      "         [ -7.2744,  -7.4034,  -7.2955,  ...,  -7.7449,  -7.2211,  -6.1220],\n",
      "         ...,\n",
      "         [ -6.2306,  -6.1754,  -6.1737,  ...,  -6.5984,  -6.0308,  -3.0339],\n",
      "         [ -6.0524,  -5.9588,  -5.9611,  ...,  -6.6341,  -6.2367,  -4.0694],\n",
      "         [ -6.9124,  -6.7612,  -6.8308,  ...,  -7.0560,  -7.0837,  -3.5455]],\n",
      "\n",
      "        [[ -6.8308,  -6.8930,  -6.8446,  ...,  -6.1893,  -6.0582,  -4.2673],\n",
      "         [-14.6635, -14.3908, -14.7081,  ..., -14.1298, -11.8220, -15.3214],\n",
      "         [ -8.5418,  -9.0987,  -9.1972,  ...,  -9.8483,  -8.6883, -11.2602],\n",
      "         ...,\n",
      "         [ -7.2540,  -7.4286,  -7.3367,  ...,  -7.5989,  -7.4121,  -3.8228],\n",
      "         [ -8.3897,  -8.4542,  -8.6441,  ...,  -8.8907,  -7.7806,  -7.7571],\n",
      "         [-12.2379, -11.8098, -12.2339,  ..., -10.0524,  -9.2396,  -9.6283]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.9856340885162354\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1951, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.1777,  -8.0460,  -8.1297,  ...,  -7.2170,  -7.2565,  -4.8470],\n",
      "         [-11.7386, -11.1859, -11.3958,  ...,  -8.7760, -10.0201,  -9.5629],\n",
      "         [ -5.9976,  -6.2042,  -6.2317,  ...,  -6.2873,  -7.9940,  -5.2005],\n",
      "         ...,\n",
      "         [ -6.5700,  -6.7920,  -6.7224,  ...,  -6.4291,  -7.6204,  -5.4211],\n",
      "         [ -6.4876,  -6.6631,  -6.6022,  ...,  -6.4741,  -8.1656,  -6.9723],\n",
      "         [ -6.6285,  -6.7671,  -6.6665,  ...,  -6.7197,  -8.2895,  -7.4841]],\n",
      "\n",
      "        [[ -7.3652,  -7.4452,  -7.3616,  ...,  -6.6227,  -6.4845,  -4.9780],\n",
      "         [ -6.1057,  -6.2341,  -6.3906,  ...,  -6.8695,  -5.4982,  -7.1028],\n",
      "         [-11.3774, -11.5456, -11.6340,  ...,  -9.8686, -11.0231, -11.1377],\n",
      "         ...,\n",
      "         [-10.5065, -10.8086, -11.0201,  ...,  -9.6513,  -9.9608,  -9.7764],\n",
      "         [-11.9896, -11.9906, -12.1258,  ..., -10.8851, -10.2741,  -8.9596],\n",
      "         [-13.0046, -12.9352, -13.1420,  ..., -12.1656,  -8.9301,  -7.6860]],\n",
      "\n",
      "        [[ -7.0113,  -6.9364,  -6.9462,  ...,  -6.2808,  -6.0640,  -4.1947],\n",
      "         [-12.9405, -12.8512, -12.7786,  ..., -12.4529, -11.4502,  -6.1898],\n",
      "         [ -6.9378,  -7.6039,  -7.1012,  ...,  -7.7949,  -6.2574,  -6.4830],\n",
      "         ...,\n",
      "         [ -8.0325,  -8.1891,  -8.2165,  ...,  -7.7590,  -7.0428,  -5.1243],\n",
      "         [ -8.0629,  -8.2348,  -8.2399,  ...,  -7.8930,  -7.4262,  -5.2688],\n",
      "         [ -8.2224,  -8.3917,  -8.3230,  ...,  -7.9920,  -7.5782,  -5.6967]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2777,  -6.2194,  -6.2012,  ...,  -5.5792,  -5.6095,  -3.7728],\n",
      "         [ -7.4388,  -7.2097,  -7.4113,  ...,  -8.2924,  -7.2666,  -5.4033],\n",
      "         [ -5.1585,  -5.1744,  -5.4981,  ...,  -5.7638,  -6.2039,  -3.8743],\n",
      "         ...,\n",
      "         [ -5.9487,  -5.8037,  -5.8889,  ...,  -6.0567,  -6.0251,  -4.1182],\n",
      "         [ -6.4108,  -6.3389,  -6.3917,  ...,  -6.6145,  -6.6283,  -4.0644],\n",
      "         [ -5.7531,  -5.6196,  -5.7887,  ...,  -5.8914,  -6.0406,  -3.1985]],\n",
      "\n",
      "        [[ -6.6385,  -6.8369,  -6.4222,  ...,  -6.5132,  -6.7496,  -5.4335],\n",
      "         [-10.6008, -10.4387, -10.4956,  ...,  -8.8795, -10.2493,  -7.5077],\n",
      "         [ -5.4001,  -5.4478,  -5.2570,  ...,  -5.6433,  -6.8253,  -4.3396],\n",
      "         ...,\n",
      "         [ -5.0555,  -5.1955,  -5.0408,  ...,  -5.3543,  -6.2672,  -4.6330],\n",
      "         [ -5.8775,  -5.8940,  -5.7549,  ...,  -6.2091,  -7.0471,  -5.6179],\n",
      "         [ -5.2749,  -5.3120,  -5.0914,  ...,  -5.2989,  -6.4037,  -4.4361]],\n",
      "\n",
      "        [[ -7.6651,  -7.6673,  -7.5985,  ...,  -6.8665,  -6.8248,  -3.8820],\n",
      "         [-15.5956, -15.2092, -15.4742,  ..., -14.0858, -14.1808,  -7.4199],\n",
      "         [ -7.9779,  -7.9304,  -8.0598,  ...,  -7.0444,  -6.9196,  -6.9735],\n",
      "         ...,\n",
      "         [ -8.2867,  -8.2966,  -8.3082,  ...,  -7.4249,  -7.4131,  -5.5429],\n",
      "         [ -6.6940,  -6.3224,  -6.5826,  ...,  -6.4287,  -5.8164,  -3.8612],\n",
      "         [ -8.2386,  -8.1289,  -8.2224,  ...,  -7.8968,  -7.6774,  -5.0252]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.1951255798339844\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6907, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2787,  -6.2390,  -6.2621,  ...,  -5.6148,  -5.4876,  -3.8180],\n",
      "         [-12.4418, -12.1486, -12.2990,  ...,  -9.2442, -10.2451, -11.2183],\n",
      "         [ -6.2011,  -6.3336,  -6.3666,  ...,  -6.3376,  -7.4990,  -5.1574],\n",
      "         ...,\n",
      "         [ -6.6188,  -6.7524,  -6.6679,  ...,  -6.5583,  -7.7713,  -5.3430],\n",
      "         [ -6.4329,  -6.4784,  -6.5149,  ...,  -6.4538,  -7.4769,  -5.1032],\n",
      "         [ -6.9330,  -6.9736,  -6.8882,  ...,  -6.8523,  -8.1597,  -5.6831]],\n",
      "\n",
      "        [[ -6.5102,  -6.4272,  -6.4733,  ...,  -5.7241,  -5.7924,  -3.6915],\n",
      "         [ -8.5178,  -8.2444,  -8.5713,  ...,  -8.1876,  -8.2591,  -6.3717],\n",
      "         [ -5.7450,  -5.6411,  -5.8472,  ...,  -5.6640,  -5.9468,  -4.0922],\n",
      "         ...,\n",
      "         [ -6.8669,  -6.5759,  -6.7554,  ...,  -6.3792,  -6.7625,  -3.9570],\n",
      "         [ -6.0745,  -5.9690,  -6.1271,  ...,  -5.8674,  -6.2036,  -3.8065],\n",
      "         [ -6.4370,  -6.3157,  -6.3304,  ...,  -5.8384,  -6.8365,  -3.2071]],\n",
      "\n",
      "        [[ -6.8827,  -6.8400,  -6.8442,  ...,  -6.2431,  -5.9554,  -4.1498],\n",
      "         [-16.1260, -16.2992, -16.3751,  ..., -13.4423, -13.8355, -14.7396],\n",
      "         [-17.9263, -17.9574, -17.9994,  ..., -14.8669, -14.4332, -14.4543],\n",
      "         ...,\n",
      "         [ -7.5723,  -7.5857,  -7.7117,  ...,  -6.7429,  -6.8784,  -6.3884],\n",
      "         [ -7.8865,  -7.8719,  -7.9651,  ...,  -7.2129,  -7.5374,  -6.3598],\n",
      "         [ -8.3221,  -8.2641,  -8.4985,  ...,  -7.5533,  -7.2936,  -7.1232]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7281,  -6.6733,  -6.7067,  ...,  -6.0097,  -5.8394,  -3.9915],\n",
      "         [ -8.8961,  -9.0257,  -8.9940,  ...,  -8.0364,  -7.7541,  -9.5566],\n",
      "         [ -5.2950,  -4.8168,  -4.9888,  ...,  -4.8780,  -4.1039,  -6.1481],\n",
      "         ...,\n",
      "         [ -8.7128,  -8.6919,  -8.7368,  ...,  -8.0743,  -7.9250,  -6.0709],\n",
      "         [ -8.1814,  -8.1960,  -8.1975,  ...,  -7.9486,  -7.7864,  -7.6342],\n",
      "         [ -7.9221,  -7.8131,  -7.8445,  ...,  -7.5516,  -7.2109,  -6.6456]],\n",
      "\n",
      "        [[ -6.4054,  -6.4420,  -6.3946,  ...,  -6.2422,  -6.0773,  -3.6192],\n",
      "         [ -9.1653,  -9.4957,  -9.3652,  ...,  -9.7380,  -6.8689, -11.3641],\n",
      "         [ -7.9105,  -7.5473,  -7.6939,  ...,  -7.3546,  -5.7291,  -7.1632],\n",
      "         ...,\n",
      "         [-11.2014, -11.4548, -11.0010,  ...,  -9.6822,  -7.7043, -10.3075],\n",
      "         [ -4.1474,  -4.5245,  -4.5943,  ...,  -4.3246,  -4.9949,  -2.5581],\n",
      "         [-11.8495, -11.7085, -11.3652,  ..., -10.7910, -11.1226,  -9.3510]],\n",
      "\n",
      "        [[ -7.0813,  -7.0763,  -7.0443,  ...,  -6.2861,  -6.0849,  -4.2084],\n",
      "         [-14.2942, -14.2286, -13.9731,  ..., -14.0808, -12.0469, -12.8494],\n",
      "         [-12.6861, -12.6192, -12.4175,  ...,  -9.9519, -10.6243, -14.3043],\n",
      "         ...,\n",
      "         [ -6.6692,  -6.7344,  -6.8690,  ...,  -5.7108,  -6.2280,  -5.3045],\n",
      "         [ -7.0273,  -6.9901,  -7.0063,  ...,  -6.7011,  -7.2097,  -5.0035],\n",
      "         [ -6.1240,  -6.2025,  -6.2674,  ...,  -5.6642,  -5.5416,  -4.9091]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.690738558769226\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4041, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4610,  -6.3947,  -6.4619,  ...,  -5.8588,  -5.8583,  -3.8285],\n",
      "         [ -8.9745,  -8.8647,  -9.1173,  ...,  -9.6158,  -9.3053,  -7.1763],\n",
      "         [ -8.8030,  -9.0057,  -9.3731,  ...,  -8.7861,  -8.4574,  -6.4339],\n",
      "         ...,\n",
      "         [ -6.6225,  -6.3995,  -6.5725,  ...,  -6.2591,  -6.6249,  -4.2221],\n",
      "         [ -6.6098,  -6.4559,  -6.6437,  ...,  -6.5924,  -6.7942,  -4.0917],\n",
      "         [ -6.4102,  -6.1743,  -6.4113,  ...,  -6.3929,  -6.6801,  -4.6419]],\n",
      "\n",
      "        [[ -6.5756,  -6.5139,  -6.5463,  ...,  -5.9652,  -5.8428,  -4.0347],\n",
      "         [ -5.4318,  -5.4346,  -5.4476,  ...,  -6.1905,  -6.0337,  -3.3974],\n",
      "         [ -6.8716,  -7.3811,  -6.8805,  ...,  -5.8456,  -6.3694,  -7.6624],\n",
      "         ...,\n",
      "         [ -6.3180,  -6.3535,  -6.3096,  ...,  -6.4478,  -6.2534,  -4.0004],\n",
      "         [ -6.3279,  -6.3025,  -6.3145,  ...,  -6.1659,  -6.1209,  -3.3823],\n",
      "         [ -6.7731,  -6.7309,  -6.7437,  ...,  -6.6157,  -6.1596,  -4.2851]],\n",
      "\n",
      "        [[ -7.3151,  -7.2096,  -7.2331,  ...,  -6.4050,  -6.4028,  -4.4214],\n",
      "         [-13.6428, -13.2504, -13.3314,  ..., -10.7432, -10.8579,  -8.1751],\n",
      "         [ -5.1469,  -5.4183,  -5.3408,  ...,  -5.9090,  -7.1153,  -5.5493],\n",
      "         ...,\n",
      "         [ -5.5874,  -5.7977,  -5.6757,  ...,  -6.2596,  -6.5300,  -6.0782],\n",
      "         [ -5.5483,  -5.6920,  -5.5519,  ...,  -6.3825,  -7.1608,  -5.7280],\n",
      "         [ -6.0385,  -6.1610,  -6.1091,  ...,  -6.1821,  -6.7325,  -5.5722]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.0566,  -8.1198,  -8.1035,  ...,  -7.0716,  -7.3268,  -4.8071],\n",
      "         [-11.1198, -11.3203, -11.2034,  ...,  -8.6913, -10.4295,  -6.7155],\n",
      "         [ -5.8458,  -6.2934,  -6.2241,  ...,  -6.0686,  -7.3974,  -4.2560],\n",
      "         ...,\n",
      "         [ -5.4975,  -5.7505,  -5.6585,  ...,  -5.9599,  -7.1389,  -4.2324],\n",
      "         [ -6.2594,  -6.4630,  -6.3607,  ...,  -6.2319,  -7.4761,  -5.8623],\n",
      "         [ -5.9804,  -6.1691,  -6.0675,  ...,  -6.1195,  -7.3000,  -4.5068]],\n",
      "\n",
      "        [[ -9.8217,  -9.8576,  -9.8643,  ...,  -9.0749,  -9.6704,  -6.2733],\n",
      "         [-10.9053, -10.7730, -10.9653,  ...,  -8.3465,  -8.2182,  -7.0370],\n",
      "         [ -5.7490,  -5.8972,  -5.7701,  ...,  -6.5234,  -7.0216,  -5.5019],\n",
      "         ...,\n",
      "         [ -5.9684,  -6.1715,  -5.9556,  ...,  -6.5325,  -6.7896,  -5.3856],\n",
      "         [ -5.0556,  -5.1425,  -4.9743,  ...,  -5.5057,  -6.5191,  -4.6976],\n",
      "         [ -5.5615,  -5.6869,  -5.5637,  ...,  -6.4699,  -6.6349,  -5.5964]],\n",
      "\n",
      "        [[ -5.6055,  -5.9183,  -5.8283,  ...,  -6.2310,  -5.6923,  -4.9310],\n",
      "         [-10.7484, -10.1996, -10.2293,  ...,  -7.2290,  -8.8380,  -9.7942],\n",
      "         [ -5.6420,  -5.6690,  -5.6768,  ...,  -6.1130,  -6.3239,  -6.1031],\n",
      "         ...,\n",
      "         [ -6.6321,  -6.6495,  -6.7047,  ...,  -6.7893,  -7.1831,  -6.0541],\n",
      "         [ -6.6427,  -6.8160,  -6.7054,  ...,  -7.4183,  -7.2871,  -5.9972],\n",
      "         [ -6.2998,  -6.4352,  -6.4458,  ...,  -7.1180,  -6.8840,  -5.7967]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.4041433334350586\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0067, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9389,  -6.9735,  -6.8984,  ...,  -6.1585,  -5.8835,  -4.2377],\n",
      "         [ -6.3163,  -6.3207,  -6.4876,  ...,  -6.3385,  -5.3763,  -6.6495],\n",
      "         [ -2.3775,  -2.3719,  -2.2017,  ...,  -3.6021,  -2.1346,  -2.8309],\n",
      "         ...,\n",
      "         [ -5.3875,  -5.7229,  -5.2465,  ...,  -5.5475,  -4.5015,  -6.2755],\n",
      "         [ -1.9866,  -1.7614,  -1.8177,  ...,  -3.4346,  -0.9783,  -2.9121],\n",
      "         [-14.0952, -13.8364, -14.1775,  ..., -10.4511, -10.7225, -11.5553]],\n",
      "\n",
      "        [[ -6.7417,  -6.7316,  -6.7432,  ...,  -6.0911,  -5.7728,  -4.1655],\n",
      "         [-13.3030, -13.8081, -13.6785,  ..., -12.0057, -10.9743,  -9.8494],\n",
      "         [ -8.8643,  -9.1343,  -9.1958,  ...,  -7.7058,  -7.3405,  -6.4701],\n",
      "         ...,\n",
      "         [ -6.3502,  -6.5685,  -6.5159,  ...,  -6.3565,  -6.2416,  -5.6128],\n",
      "         [ -6.6626,  -6.8414,  -6.8788,  ...,  -6.6600,  -6.7582,  -6.1143],\n",
      "         [ -7.1242,  -7.2970,  -7.2282,  ...,  -6.8358,  -6.8725,  -5.5594]],\n",
      "\n",
      "        [[ -7.4455,  -7.4341,  -7.4134,  ...,  -6.9361,  -6.6526,  -4.5128],\n",
      "         [ -6.4056,  -6.7985,  -6.7175,  ...,  -6.6129,  -7.5187,  -7.5158],\n",
      "         [ -9.6144,  -9.3499,  -9.2813,  ...,  -8.5683,  -5.5212, -10.9128],\n",
      "         ...,\n",
      "         [ -8.1685,  -8.1509,  -8.1512,  ...,  -8.1477,  -7.1386,  -7.0718],\n",
      "         [ -6.1731,  -6.2657,  -6.1846,  ...,  -7.1543,  -5.7598,  -6.5385],\n",
      "         [ -7.7744,  -7.8212,  -7.9830,  ...,  -8.4250,  -7.5437,  -7.1284]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1491,  -7.1381,  -7.1111,  ...,  -6.7680,  -6.4497,  -4.1998],\n",
      "         [-10.1902, -10.4092, -10.2506,  ...,  -9.8231,  -8.5389, -10.9374],\n",
      "         [-12.5786, -12.3915, -12.2141,  ..., -13.0740,  -9.7320, -12.0072],\n",
      "         ...,\n",
      "         [ -6.0821,  -6.2156,  -6.1193,  ...,  -5.2729,  -6.0688,  -6.9882],\n",
      "         [ -5.9995,  -6.0760,  -6.0705,  ...,  -5.3525,  -5.5115,  -6.4046],\n",
      "         [-11.4100, -11.7232, -11.6730,  ..., -11.9587, -10.2911, -10.7443]],\n",
      "\n",
      "        [[-13.4815, -13.2031, -13.5412,  ..., -11.3803, -12.5419,  -8.2448],\n",
      "         [-11.3146, -11.4857, -11.1114,  ..., -10.1062, -10.4918,  -6.4796],\n",
      "         [ -6.3509,  -6.4747,  -6.5334,  ...,  -7.5958,  -8.3640,  -5.2290],\n",
      "         ...,\n",
      "         [ -6.6400,  -6.7155,  -6.9402,  ...,  -7.5260,  -8.6374,  -6.0265],\n",
      "         [ -7.1836,  -7.2464,  -7.1924,  ...,  -8.0221,  -8.1991,  -6.4949],\n",
      "         [ -7.6103,  -7.6207,  -7.7487,  ...,  -8.2659,  -8.3981,  -6.8981]],\n",
      "\n",
      "        [[ -6.9697,  -7.0106,  -6.9748,  ...,  -6.2979,  -6.2935,  -4.4798],\n",
      "         [-14.1379, -14.3488, -14.4598,  ..., -15.0219, -11.4602, -10.9998],\n",
      "         [-16.1281, -16.7004, -16.5382,  ..., -17.4723, -13.3830,  -7.3603],\n",
      "         ...,\n",
      "         [-10.1441, -10.2278, -10.0691,  ...,  -9.8732,  -9.3242,  -7.0586],\n",
      "         [ -8.0758,  -8.6014,  -8.5178,  ...,  -8.5021,  -8.1824,  -4.8305],\n",
      "         [-15.9220, -15.3553, -15.7063,  ..., -14.5710, -13.1930, -12.4043]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.0066967010498047\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.5389, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0583,  -7.0286,  -7.0420,  ...,  -6.4223,  -6.2722,  -4.0813],\n",
      "         [-12.7379, -12.4207, -13.2128,  ..., -12.3826, -13.0131, -12.3937],\n",
      "         [ -5.7848,  -5.8665,  -5.6522,  ...,  -4.8182,  -5.0737,  -6.6840],\n",
      "         ...,\n",
      "         [ -6.7178,  -6.8443,  -7.1579,  ...,  -6.0697,  -6.2462,  -7.8559],\n",
      "         [ -7.2343,  -7.4832,  -7.6446,  ...,  -7.0446,  -6.6640,  -7.1951],\n",
      "         [ -6.8879,  -7.0261,  -7.2205,  ...,  -6.1140,  -5.8861,  -6.4898]],\n",
      "\n",
      "        [[ -6.6381,  -6.5816,  -6.6569,  ...,  -5.9940,  -6.0777,  -3.8869],\n",
      "         [ -5.6777,  -5.6073,  -5.8264,  ...,  -5.8262,  -6.1555,  -2.3879],\n",
      "         [ -8.2966,  -8.1891,  -8.3052,  ...,  -8.5628,  -7.3340,  -4.4814],\n",
      "         ...,\n",
      "         [ -5.4297,  -5.3173,  -5.4021,  ...,  -5.5092,  -5.7113,  -3.1125],\n",
      "         [ -5.9674,  -5.7816,  -5.8009,  ...,  -5.7179,  -6.2723,  -4.2834],\n",
      "         [ -5.9254,  -5.7273,  -5.8646,  ...,  -6.0257,  -5.9820,  -3.5114]],\n",
      "\n",
      "        [[ -6.8106,  -6.7483,  -6.8317,  ...,  -6.1125,  -6.0750,  -3.3342],\n",
      "         [ -8.4545,  -8.3091,  -8.7330,  ...,  -8.2421,  -8.3437,  -5.7827],\n",
      "         [ -6.9373,  -7.1160,  -7.4527,  ...,  -7.0065,  -6.4900,  -6.5022],\n",
      "         ...,\n",
      "         [ -6.5052,  -6.4132,  -6.6027,  ...,  -6.4644,  -6.8836,  -4.0209],\n",
      "         [ -6.3403,  -6.1643,  -6.3760,  ...,  -6.1578,  -6.3752,  -2.9001],\n",
      "         [ -6.3036,  -6.3028,  -6.4564,  ...,  -6.4977,  -6.4736,  -3.0682]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7496,  -6.7408,  -6.7295,  ...,  -6.2505,  -6.0415,  -4.8512],\n",
      "         [-11.4230, -11.4386, -11.6893,  ..., -10.5831, -10.1341, -11.4564],\n",
      "         [-14.3487, -14.6248, -14.7274,  ..., -13.5101, -11.1370, -11.3200],\n",
      "         ...,\n",
      "         [ -8.0755,  -8.2920,  -8.3835,  ...,  -8.4480,  -7.3382,  -6.1172],\n",
      "         [ -7.9551,  -8.2449,  -8.2937,  ...,  -8.6653,  -7.8392,  -6.0635],\n",
      "         [ -7.6313,  -7.8760,  -7.9062,  ...,  -8.2186,  -7.3559,  -5.4832]],\n",
      "\n",
      "        [[ -6.3645,  -6.3189,  -6.3502,  ...,  -5.6561,  -5.4869,  -3.7762],\n",
      "         [-13.1969, -12.7914, -12.8732,  ..., -11.3949, -11.2564,  -9.3481],\n",
      "         [ -5.8611,  -5.9278,  -5.9514,  ...,  -5.8056,  -6.8837,  -4.7178],\n",
      "         ...,\n",
      "         [ -6.1245,  -6.1866,  -6.1910,  ...,  -6.1054,  -7.1064,  -4.8175],\n",
      "         [ -5.4585,  -5.5198,  -5.5276,  ...,  -5.2837,  -6.5891,  -4.7288],\n",
      "         [ -6.4040,  -6.3899,  -6.5295,  ...,  -6.0301,  -7.1071,  -5.2621]],\n",
      "\n",
      "        [[ -7.4349,  -7.4013,  -7.4624,  ...,  -6.9216,  -6.6067,  -3.7304],\n",
      "         [-14.9690, -15.2191, -15.1297,  ..., -12.1076, -11.0992, -13.3808],\n",
      "         [-13.8603, -13.9211, -13.7308,  ..., -11.6410, -11.9363, -13.5121],\n",
      "         ...,\n",
      "         [-12.8611, -12.5573, -12.9965,  ..., -11.4893, -12.6693, -13.3945],\n",
      "         [ -7.6836,  -7.8705,  -7.9344,  ...,  -6.8678,  -7.9965,  -5.1605],\n",
      "         [-12.1943, -11.9087, -12.2344,  ...,  -9.0488, -11.4523, -10.3754]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.5389420986175537\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.9256, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7891,  -6.7357,  -6.7640,  ...,  -6.0538,  -5.9914,  -3.9852],\n",
      "         [-11.8625, -11.8747, -11.3955,  ...,  -7.8827, -10.8889,  -6.4980],\n",
      "         [ -5.5725,  -5.7865,  -5.7735,  ...,  -5.9650,  -7.1677,  -4.0543],\n",
      "         ...,\n",
      "         [ -6.2470,  -6.3637,  -6.3923,  ...,  -6.0625,  -8.0822,  -4.5811],\n",
      "         [ -6.6088,  -6.8041,  -6.7183,  ...,  -6.8220,  -7.8275,  -4.5888],\n",
      "         [ -6.8309,  -6.9399,  -6.9128,  ...,  -7.1295,  -7.5205,  -4.5344]],\n",
      "\n",
      "        [[ -7.2356,  -7.2072,  -7.1763,  ...,  -6.3722,  -6.6584,  -3.7875],\n",
      "         [-10.8215, -10.3150, -10.3958,  ...,  -9.6171,  -7.6877,  -8.7200],\n",
      "         [ -5.9547,  -6.1558,  -6.0950,  ...,  -6.0388,  -6.8800,  -3.6847],\n",
      "         ...,\n",
      "         [ -7.6493,  -7.6686,  -7.7020,  ...,  -7.5660,  -7.7841,  -5.7454],\n",
      "         [ -7.0045,  -6.9311,  -7.0947,  ...,  -6.8378,  -7.9328,  -4.0180],\n",
      "         [ -6.7857,  -6.8960,  -6.7904,  ...,  -6.7801,  -7.2172,  -4.2207]],\n",
      "\n",
      "        [[ -6.4825,  -6.4327,  -6.4341,  ...,  -5.7244,  -5.6069,  -3.7692],\n",
      "         [-10.5757, -10.6344, -10.3257,  ...,  -7.5795,  -9.0803,  -8.2158],\n",
      "         [ -5.6725,  -5.8148,  -5.7684,  ...,  -5.8536,  -7.2610,  -4.5981],\n",
      "         ...,\n",
      "         [ -5.9925,  -6.1664,  -6.0870,  ...,  -5.7722,  -7.1215,  -4.9637],\n",
      "         [ -5.7291,  -5.8745,  -5.8149,  ...,  -5.8318,  -6.8544,  -4.5347],\n",
      "         [ -5.5262,  -5.6845,  -5.6440,  ...,  -5.3282,  -6.8074,  -3.7433]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-10.3985, -10.5093, -10.4977,  ...,  -9.0480,  -9.6797,  -6.6579],\n",
      "         [ -9.8344,  -9.7692,  -9.9944,  ...,  -7.3766,  -7.5285,  -7.0633],\n",
      "         [ -5.3148,  -5.4220,  -5.5165,  ...,  -5.4241,  -7.4197,  -6.2571],\n",
      "         ...,\n",
      "         [ -6.2956,  -6.3360,  -6.3589,  ...,  -5.2159,  -7.6798,  -7.1893],\n",
      "         [ -6.3681,  -6.3285,  -6.4032,  ...,  -5.8733,  -7.5971,  -6.5787],\n",
      "         [ -5.6739,  -5.5483,  -5.6144,  ...,  -4.5110,  -6.4356,  -5.6997]],\n",
      "\n",
      "        [[ -7.1818,  -7.2097,  -7.1524,  ...,  -6.5279,  -6.2422,  -4.7157],\n",
      "         [-13.9455, -13.9097, -13.7035,  ..., -12.6099, -10.5013, -10.8782],\n",
      "         [ -7.3640,  -7.3406,  -7.5598,  ...,  -6.6991,  -6.0346,  -6.7585],\n",
      "         ...,\n",
      "         [-15.8333, -15.6835, -15.4419,  ..., -12.9879, -12.1639, -13.7326],\n",
      "         [-10.3517, -11.2987, -10.8342,  ..., -10.9711,  -9.2710, -12.2753],\n",
      "         [-14.8109, -14.2102, -14.6280,  ..., -12.5043, -10.8413, -10.0067]],\n",
      "\n",
      "        [[ -8.0444,  -7.9414,  -7.9966,  ...,  -6.9200,  -7.2214,  -4.7396],\n",
      "         [-12.5170, -12.0856, -11.9819,  ...,  -9.1837, -10.3577,  -8.8520],\n",
      "         [ -6.8531,  -6.7857,  -6.7406,  ...,  -7.0176,  -7.8474,  -5.3989],\n",
      "         ...,\n",
      "         [ -7.1226,  -7.0587,  -7.0694,  ...,  -7.0357,  -8.3651,  -5.5471],\n",
      "         [ -6.7526,  -6.7022,  -6.7124,  ...,  -6.6566,  -7.8401,  -5.1823],\n",
      "         [ -6.4615,  -6.4028,  -6.3202,  ...,  -6.3729,  -7.0117,  -4.5386]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.9256067276000977\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9091, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4343,  -7.3396,  -7.2908,  ...,  -6.6834,  -6.6849,  -3.7895],\n",
      "         [ -8.5426,  -8.4607,  -8.6767,  ...,  -8.6624,  -8.5781,  -4.7260],\n",
      "         [ -6.6715,  -6.7587,  -6.9107,  ...,  -7.2299,  -6.1640,  -4.0497],\n",
      "         ...,\n",
      "         [ -5.8021,  -5.6201,  -5.7521,  ...,  -5.6729,  -5.4645,  -2.3163],\n",
      "         [ -6.2615,  -5.9135,  -6.1425,  ...,  -5.9809,  -5.9892,  -1.7858],\n",
      "         [ -6.6003,  -6.4197,  -6.5830,  ...,  -6.9056,  -6.6930,  -2.3540]],\n",
      "\n",
      "        [[ -7.1494,  -7.1103,  -7.1497,  ...,  -6.2659,  -6.3444,  -4.2918],\n",
      "         [-13.7721, -13.5978, -13.5819,  ..., -10.8452, -11.3592,  -9.1042],\n",
      "         [ -5.9117,  -6.0258,  -6.0936,  ...,  -6.3015,  -7.1546,  -5.2795],\n",
      "         ...,\n",
      "         [ -5.6549,  -5.7215,  -5.7733,  ...,  -6.1218,  -7.0182,  -2.8012],\n",
      "         [ -5.5851,  -5.7306,  -5.6209,  ...,  -6.0108,  -6.9198,  -5.6478],\n",
      "         [ -6.1286,  -6.3534,  -6.1858,  ...,  -6.4629,  -7.2719,  -5.9849]],\n",
      "\n",
      "        [[ -6.9466,  -7.0985,  -7.0087,  ...,  -6.6849,  -6.2257,  -4.8805],\n",
      "         [-12.6465, -12.3496, -12.5302,  ..., -12.9141, -10.6049, -11.9142],\n",
      "         [ -6.3844,  -6.8409,  -6.8043,  ...,  -7.5948,  -6.2683,  -8.0458],\n",
      "         ...,\n",
      "         [ -7.5435,  -7.7349,  -7.4900,  ...,  -7.3672,  -6.7491,  -3.9107],\n",
      "         [ -2.9465,  -3.0784,  -3.2003,  ...,  -2.9811,  -3.1951,  -0.9650],\n",
      "         [-13.5864, -13.8093, -13.4318,  ..., -11.7284, -13.0013, -11.3443]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0698,  -6.9805,  -7.0220,  ...,  -6.3557,  -6.2679,  -4.2178],\n",
      "         [-13.9918, -13.3800, -13.6977,  ..., -12.4141, -11.6786, -10.9004],\n",
      "         [ -5.8530,  -5.9086,  -6.0191,  ...,  -6.3520,  -7.5794,  -4.9768],\n",
      "         ...,\n",
      "         [ -6.5264,  -6.4845,  -6.5916,  ...,  -7.1750,  -7.8701,  -5.5305],\n",
      "         [ -5.9341,  -5.9665,  -6.0995,  ...,  -6.3010,  -7.0822,  -4.6069],\n",
      "         [ -6.4875,  -6.4236,  -6.5788,  ...,  -6.6346,  -7.2496,  -4.4031]],\n",
      "\n",
      "        [[ -8.5196,  -8.4962,  -8.4008,  ...,  -7.6242,  -7.0174,  -5.2167],\n",
      "         [-17.2333, -17.0278, -17.2825,  ..., -14.7106, -12.7566, -13.6814],\n",
      "         [ -8.6833,  -8.5985,  -8.9946,  ...,  -8.4035,  -5.2883,  -6.3406],\n",
      "         ...,\n",
      "         [ -8.6874,  -8.6693,  -8.6757,  ...,  -8.5305,  -7.3225,  -8.7240],\n",
      "         [ -8.1435,  -8.1929,  -8.3271,  ...,  -8.2728,  -6.5135,  -7.8142],\n",
      "         [ -8.1485,  -8.3611,  -8.2982,  ...,  -7.9105,  -6.2717,  -7.6791]],\n",
      "\n",
      "        [[ -7.2927,  -7.2959,  -7.1933,  ...,  -6.6915,  -6.4023,  -5.2606],\n",
      "         [-10.7110, -10.5924, -10.5661,  ...,  -9.8281,  -8.3205, -11.0965],\n",
      "         [-13.3080, -13.6030, -13.2507,  ..., -10.3681, -10.5227, -12.0343],\n",
      "         ...,\n",
      "         [ -7.9342,  -8.0165,  -8.0042,  ...,  -6.9911,  -7.7692,  -5.6484],\n",
      "         [ -7.9069,  -8.0171,  -7.9858,  ...,  -7.1874,  -7.2845,  -5.8769],\n",
      "         [ -7.9817,  -8.1164,  -8.0305,  ...,  -7.0985,  -7.5488,  -6.1311]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.9090790748596191\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5837, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.0301,  -5.9814,  -6.0258,  ...,  -5.5445,  -5.6572,  -3.1943],\n",
      "         [ -8.9080,  -8.7771,  -9.0165,  ...,  -9.1116,  -9.7007,  -5.3141],\n",
      "         [ -9.4844,  -9.6515,  -9.8589,  ...,  -9.5806,  -9.6497,  -5.7247],\n",
      "         ...,\n",
      "         [ -6.3226,  -6.1627,  -6.3907,  ...,  -6.4146,  -6.4044,  -2.8549],\n",
      "         [ -6.8310,  -6.7426,  -6.9356,  ...,  -6.7773,  -6.6484,  -3.7964],\n",
      "         [ -7.1510,  -7.0954,  -7.2757,  ...,  -7.4872,  -7.1823,  -3.5620]],\n",
      "\n",
      "        [[-13.0176, -12.8114, -12.7652,  ..., -11.8067, -12.8883,  -8.2997],\n",
      "         [-12.8134, -12.3137, -12.5071,  ...,  -8.8457, -10.7802,  -9.4682],\n",
      "         [ -6.0910,  -6.3449,  -6.2528,  ...,  -6.5245,  -6.7541,  -4.1838],\n",
      "         ...,\n",
      "         [ -7.0036,  -7.1622,  -7.0211,  ...,  -7.7219,  -8.2125,  -5.7591],\n",
      "         [ -6.8826,  -7.1249,  -6.8687,  ...,  -7.4191,  -7.5483,  -6.0439],\n",
      "         [ -7.2119,  -7.2340,  -7.1539,  ...,  -7.9966,  -7.7171,  -5.7630]],\n",
      "\n",
      "        [[ -6.9500,  -6.9089,  -6.9080,  ...,  -6.2743,  -6.2778,  -4.0663],\n",
      "         [ -8.5634,  -8.4178,  -8.5647,  ...,  -8.2822,  -8.5125,  -5.8980],\n",
      "         [ -7.7157,  -7.7070,  -7.8453,  ...,  -7.4252,  -7.0246,  -4.8460],\n",
      "         ...,\n",
      "         [ -5.6803,  -5.4208,  -5.5809,  ...,  -5.8460,  -5.6745,  -2.8879],\n",
      "         [ -6.1983,  -6.1087,  -6.2668,  ...,  -6.4678,  -6.6039,  -3.4105],\n",
      "         [ -6.1707,  -6.0792,  -6.2501,  ...,  -6.6742,  -6.3296,  -3.1482]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2789,  -7.3129,  -7.2901,  ...,  -6.8153,  -6.4452,  -4.3972],\n",
      "         [ -9.8165,  -9.6917,  -9.7602,  ...,  -8.5556,  -8.5608,  -7.5323],\n",
      "         [ -7.2327,  -7.8563,  -7.8052,  ...,  -8.1948,  -5.5456,  -5.1002],\n",
      "         ...,\n",
      "         [ -6.0828,  -5.9141,  -5.7081,  ...,  -3.6672,  -5.1177,  -6.3301],\n",
      "         [-11.1152, -10.9575, -10.6941,  ..., -11.0309,  -9.2037,  -8.5066],\n",
      "         [-12.0625, -12.1865, -12.6609,  ..., -10.2471,  -9.6975, -12.0558]],\n",
      "\n",
      "        [[ -6.8342,  -6.8214,  -6.8274,  ...,  -6.0535,  -5.8900,  -3.9159],\n",
      "         [-11.7108, -11.8426, -11.6697,  ..., -10.9496,  -8.9834,  -8.1955],\n",
      "         [ -8.2473,  -8.4785,  -8.5142,  ...,  -7.5874,  -6.7561,  -6.6780],\n",
      "         ...,\n",
      "         [ -8.1081,  -8.0435,  -7.8574,  ...,  -6.7418,  -6.7097,  -5.0435],\n",
      "         [-14.1434, -14.1612, -14.4052,  ..., -13.0185, -10.4836,  -9.3231],\n",
      "         [ -9.8564, -10.0344,  -9.6002,  ...,  -8.5226,  -7.5434,  -7.0110]],\n",
      "\n",
      "        [[ -7.0906,  -7.0682,  -7.1182,  ...,  -6.4452,  -6.4200,  -4.0105],\n",
      "         [ -8.8985,  -8.6813,  -8.4350,  ...,  -9.4993,  -8.1166,  -7.7576],\n",
      "         [-14.1921, -14.8102, -14.4673,  ..., -15.5298, -11.4871, -10.6314],\n",
      "         ...,\n",
      "         [ -6.6777,  -6.5638,  -6.3683,  ...,  -6.9420,  -6.4589,  -7.8725],\n",
      "         [ -7.6980,  -7.7683,  -7.7311,  ...,  -7.8613,  -5.6416,  -6.2445],\n",
      "         [-12.0952, -12.1469, -11.6655,  ..., -11.7979, -12.4340,  -9.5069]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.5836739540100098\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5081, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5348,  -6.5261,  -6.5744,  ...,  -5.7085,  -5.8384,  -3.1577],\n",
      "         [ -8.6798,  -8.3189,  -8.5548,  ...,  -8.9529,  -8.6697,  -3.5582],\n",
      "         [-10.1904, -10.3963, -10.7013,  ...,  -9.7777,  -9.3384,  -6.7569],\n",
      "         ...,\n",
      "         [ -6.9976,  -6.6903,  -6.9923,  ...,  -6.7245,  -7.2486,  -2.5939],\n",
      "         [ -6.4931,  -6.1982,  -6.4592,  ...,  -6.1652,  -6.5434,  -1.4648],\n",
      "         [ -6.2985,  -5.9017,  -6.3657,  ...,  -6.1006,  -5.9212,  -0.4775]],\n",
      "\n",
      "        [[ -7.6094,  -7.6005,  -7.5353,  ...,  -6.7580,  -6.7625,  -4.5220],\n",
      "         [ -8.4302,  -8.7874,  -8.5216,  ...,  -8.2640,  -8.0457,  -7.5564],\n",
      "         [ -4.9906,  -5.2945,  -5.3555,  ...,  -4.6927,  -4.1876,  -2.6532],\n",
      "         ...,\n",
      "         [ -9.1769,  -9.1787,  -9.2988,  ...,  -9.4107,  -8.7858,  -5.3972],\n",
      "         [ -9.5809,  -9.5995,  -9.6545,  ...,  -9.3040,  -8.5179,  -5.8421],\n",
      "         [ -9.3217,  -9.4503,  -9.4387,  ...,  -9.6212,  -8.2190,  -5.6105]],\n",
      "\n",
      "        [[ -7.0836,  -7.0640,  -7.0413,  ...,  -6.4705,  -6.2920,  -4.4676],\n",
      "         [-12.6325, -12.5649, -12.1747,  ..., -11.7125, -10.3055, -10.9686],\n",
      "         [-10.7946, -10.4525, -10.5137,  ..., -10.1267,  -8.9045,  -8.4096],\n",
      "         ...,\n",
      "         [ -8.4399,  -8.6783,  -8.5854,  ...,  -9.2748,  -7.2916,  -8.3047],\n",
      "         [ -8.2984,  -8.4379,  -8.4247,  ...,  -9.3106,  -7.7739,  -9.5020],\n",
      "         [ -7.7984,  -8.0145,  -8.0057,  ...,  -8.2825,  -6.2012,  -7.6881]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7848,  -6.7252,  -6.7272,  ...,  -6.1090,  -5.9283,  -3.9878],\n",
      "         [ -4.0755,  -4.0530,  -4.0860,  ...,  -4.6915,  -4.1002,  -3.4273],\n",
      "         [ -9.6196,  -9.6178,  -9.4300,  ...,  -8.4064,  -7.2803,  -7.8993],\n",
      "         ...,\n",
      "         [ -7.0504,  -6.8204,  -6.9513,  ...,  -7.8204,  -6.3053,  -7.8649],\n",
      "         [ -7.5788,  -7.3485,  -7.5638,  ...,  -8.1610,  -6.9585,  -7.5861],\n",
      "         [ -7.9872,  -7.7675,  -7.9365,  ...,  -8.2836,  -7.3614,  -6.4614]],\n",
      "\n",
      "        [[ -9.6725,  -9.7917,  -9.6173,  ...,  -8.5237,  -8.8239,  -7.9352],\n",
      "         [-13.4317, -13.1262, -13.1552,  ..., -11.7041, -11.9381,  -8.3387],\n",
      "         [ -5.0283,  -5.0795,  -5.1097,  ...,  -5.1001,  -6.7096,  -4.4695],\n",
      "         ...,\n",
      "         [ -5.6147,  -5.6410,  -5.5083,  ...,  -5.8944,  -6.2916,  -5.3800],\n",
      "         [ -6.0231,  -5.9853,  -6.0128,  ...,  -6.2280,  -6.6082,  -5.7369],\n",
      "         [ -6.2234,  -6.1479,  -6.0683,  ...,  -6.0331,  -5.9584,  -6.8572]],\n",
      "\n",
      "        [[ -6.4920,  -6.4224,  -6.4566,  ...,  -5.6929,  -5.6327,  -3.9838],\n",
      "         [-12.5616, -12.1002, -12.1500,  ..., -10.0982, -10.9363, -10.3556],\n",
      "         [ -6.6367,  -6.7226,  -6.7255,  ...,  -6.2312,  -8.2708,  -5.8651],\n",
      "         ...,\n",
      "         [ -6.9908,  -7.2454,  -7.2732,  ...,  -7.0924,  -8.6803,  -5.2252],\n",
      "         [ -5.6425,  -5.8997,  -5.8398,  ...,  -5.7259,  -7.3941,  -4.8152],\n",
      "         [ -6.7131,  -6.9578,  -6.8085,  ...,  -6.6671,  -8.0017,  -5.4285]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.508147954940796\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6475, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6435,  -6.6148,  -6.6054,  ...,  -5.6742,  -5.5716,  -3.6900],\n",
      "         [-12.3750, -12.3991, -12.6363,  ..., -11.3754, -10.3882,  -7.9546],\n",
      "         [-11.0946, -11.5857, -11.3920,  ..., -10.4866, -10.1956,  -9.0039],\n",
      "         ...,\n",
      "         [ -7.0382,  -7.2795,  -6.8826,  ...,  -6.9819,  -5.7692,  -5.0862],\n",
      "         [ -6.2596,  -6.5582,  -6.2403,  ...,  -5.9902,  -5.5618,  -4.6960],\n",
      "         [ -7.9156,  -8.0763,  -7.6209,  ...,  -7.0492,  -5.9983,  -4.3726]],\n",
      "\n",
      "        [[-10.0262,  -9.8553,  -9.8672,  ...,  -8.3785,  -9.0454,  -5.8180],\n",
      "         [-12.0845, -11.7440, -11.8597,  ..., -10.6040, -10.6862,  -8.6244],\n",
      "         [ -5.3136,  -5.4276,  -5.5192,  ...,  -5.4500,  -7.5707,  -4.3691],\n",
      "         ...,\n",
      "         [ -5.6794,  -5.7618,  -5.6642,  ...,  -5.5227,  -7.6033,  -6.0158],\n",
      "         [ -6.5869,  -6.6628,  -6.6503,  ...,  -6.6464,  -7.0024,  -5.9582],\n",
      "         [ -6.3498,  -6.4902,  -6.3739,  ...,  -6.2734,  -7.1920,  -6.1872]],\n",
      "\n",
      "        [[ -6.5380,  -6.4933,  -6.5256,  ...,  -5.7375,  -5.6422,  -3.8586],\n",
      "         [-11.6389, -11.2680, -11.6050,  ...,  -7.8073, -10.2216,  -9.1590],\n",
      "         [ -6.8859,  -7.0323,  -7.0926,  ...,  -6.7952,  -8.4357,  -4.8320],\n",
      "         ...,\n",
      "         [ -6.9174,  -6.9555,  -7.0997,  ...,  -7.1224,  -8.4113,  -4.4962],\n",
      "         [ -6.8178,  -6.7456,  -6.8473,  ...,  -6.5178,  -7.7184,  -6.2433],\n",
      "         [ -7.2596,  -7.2470,  -7.3418,  ...,  -7.0604,  -8.2257,  -5.6867]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4732,  -7.4526,  -7.4139,  ...,  -6.7842,  -6.4933,  -4.0994],\n",
      "         [ -6.8187,  -7.1622,  -6.7380,  ...,  -6.4885,  -6.5477,  -5.2425],\n",
      "         [-12.0637, -11.8429, -12.1858,  ..., -10.2444,  -9.3505, -10.1136],\n",
      "         ...,\n",
      "         [ -9.1313,  -8.9948,  -9.1972,  ...,  -8.0437,  -7.4043,  -7.9893],\n",
      "         [ -8.1319,  -8.0524,  -8.2263,  ...,  -7.2895,  -6.7430,  -7.1160],\n",
      "         [ -8.9446,  -8.9832,  -8.8941,  ...,  -8.3693,  -7.2712,  -7.2281]],\n",
      "\n",
      "        [[ -6.7410,  -6.7592,  -6.7050,  ...,  -5.9786,  -5.8896,  -4.1888],\n",
      "         [ -6.5439,  -6.8988,  -6.5735,  ...,  -6.8025,  -7.3551,  -5.1145],\n",
      "         [ -4.5357,  -4.5981,  -5.0968,  ...,  -4.5227,  -5.0338,  -3.6090],\n",
      "         ...,\n",
      "         [ -7.1050,  -7.2467,  -7.3162,  ...,  -7.6517,  -7.2915,  -7.2727],\n",
      "         [ -7.2543,  -7.3386,  -7.4394,  ...,  -7.7671,  -7.1134,  -7.1474],\n",
      "         [ -7.5715,  -7.7035,  -7.7543,  ...,  -8.1114,  -7.5030,  -6.8794]],\n",
      "\n",
      "        [[ -6.8848,  -6.8578,  -6.8467,  ...,  -6.2236,  -5.9427,  -4.4014],\n",
      "         [ -7.5396,  -7.7612,  -7.6671,  ...,  -7.9683,  -7.2572,  -6.7462],\n",
      "         [ -7.7354,  -7.4018,  -7.8008,  ...,  -7.5764,  -6.3656,  -7.3925],\n",
      "         ...,\n",
      "         [ -8.4470,  -8.4071,  -8.4788,  ...,  -9.1579,  -8.2421,  -7.8058],\n",
      "         [ -9.0425,  -9.0268,  -9.0945,  ...,  -9.6371,  -7.9501,  -7.9959],\n",
      "         [ -8.4547,  -8.4644,  -8.5703,  ...,  -9.1094,  -7.6545,  -7.7632]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.6475197076797485\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5774, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3493,  -7.3021,  -7.2272,  ...,  -6.6692,  -6.5320,  -4.3706],\n",
      "         [-13.0629, -13.1148, -13.3238,  ..., -10.7270, -10.3843, -10.5022],\n",
      "         [ -8.4071,  -8.4537,  -8.5604,  ...,  -9.2091,  -5.7263,  -6.3216],\n",
      "         ...,\n",
      "         [-10.8696, -10.9887, -10.6201,  ..., -10.9786,  -8.4422,  -8.3604],\n",
      "         [-12.0767, -11.9024, -11.5336,  ..., -10.7035,  -9.7133,  -6.1541],\n",
      "         [-13.4818, -13.1131, -13.7600,  ..., -10.8718, -11.6139,  -9.8558]],\n",
      "\n",
      "        [[ -8.7725,  -8.6171,  -8.7728,  ...,  -8.0326,  -8.4829,  -3.9580],\n",
      "         [-11.6793, -11.6112, -11.4536,  ...,  -7.6862,  -9.3458,  -8.6903],\n",
      "         [ -5.7672,  -5.8367,  -5.9866,  ...,  -6.2105,  -7.6362,  -4.5474],\n",
      "         ...,\n",
      "         [ -5.6389,  -5.5282,  -5.6267,  ...,  -6.1111,  -7.4944,  -4.7923],\n",
      "         [ -5.9769,  -5.9305,  -6.0255,  ...,  -5.7860,  -7.4877,  -5.4919],\n",
      "         [ -6.1939,  -6.1839,  -6.1991,  ...,  -5.9783,  -7.3233,  -5.7864]],\n",
      "\n",
      "        [[ -7.8958,  -7.8509,  -7.8675,  ...,  -7.4392,  -6.9535,  -5.0107],\n",
      "         [-10.5122, -10.9465, -10.9079,  ...,  -9.8576,  -6.8343, -11.8024],\n",
      "         [-10.5471, -10.5476, -10.5823,  ...,  -9.3673,  -6.5709, -11.1596],\n",
      "         ...,\n",
      "         [ -9.3207,  -9.3551,  -9.4466,  ...,  -8.4873,  -7.4379,  -8.5108],\n",
      "         [ -8.9834,  -9.2366,  -9.1326,  ...,  -7.9947,  -7.1878,  -7.5110],\n",
      "         [ -9.7017,  -9.7938,  -9.7837,  ...,  -9.2654,  -7.9870,  -8.5433]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5770,  -6.5479,  -6.5521,  ...,  -5.9058,  -5.6990,  -3.9186],\n",
      "         [-12.1080, -11.3343, -11.5802,  ...,  -9.2240, -10.9696, -10.2381],\n",
      "         [ -6.3968,  -6.4767,  -6.5521,  ...,  -6.5973,  -7.8415,  -5.2155],\n",
      "         ...,\n",
      "         [ -6.4837,  -6.6109,  -6.5326,  ...,  -6.1510,  -7.2922,  -5.3294],\n",
      "         [ -6.2040,  -6.3263,  -6.2792,  ...,  -6.2716,  -7.7527,  -5.0780],\n",
      "         [ -6.3267,  -6.4045,  -6.4559,  ...,  -6.2520,  -7.4711,  -4.5245]],\n",
      "\n",
      "        [[ -6.6240,  -6.5679,  -6.6621,  ...,  -5.7437,  -6.0169,  -2.3222],\n",
      "         [ -7.8439,  -7.5730,  -7.7630,  ...,  -8.0005,  -7.7980,  -3.3321],\n",
      "         [ -8.2357,  -8.0410,  -8.1505,  ...,  -8.3215,  -7.8654,  -3.0464],\n",
      "         ...,\n",
      "         [ -6.0539,  -5.9126,  -6.1129,  ...,  -5.8654,  -6.2004,  -1.5802],\n",
      "         [ -6.4971,  -6.2704,  -6.4415,  ...,  -6.0924,  -6.5903,  -0.9808],\n",
      "         [ -6.0105,  -5.8036,  -5.9321,  ...,  -5.7875,  -6.0695,  -0.5448]],\n",
      "\n",
      "        [[ -6.8981,  -6.8783,  -6.8093,  ...,  -6.3383,  -6.1988,  -4.3630],\n",
      "         [ -7.0631,  -7.2811,  -7.2707,  ...,  -6.6933,  -6.6962,  -6.6032],\n",
      "         [-13.1317, -13.0725, -13.2395,  ..., -12.7822, -10.4491, -10.6938],\n",
      "         ...,\n",
      "         [-10.9686, -11.3469, -11.2205,  ..., -10.4983, -10.0021, -11.9339],\n",
      "         [ -8.9853,  -9.5905,  -9.5433,  ...,  -9.9587,  -9.9862,  -7.9811],\n",
      "         [-14.1407, -13.7946, -13.9892,  ..., -10.9620, -11.1061, -10.8029]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.5774359703063965\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1042, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5301,  -6.5143,  -6.5333,  ...,  -5.8922,  -5.6760,  -3.9027],\n",
      "         [ -9.7551,  -9.4046,  -9.7109,  ...,  -7.1747,  -7.5306,  -9.3185],\n",
      "         [ -6.9381,  -7.0173,  -6.9587,  ...,  -7.3024,  -7.8137,  -5.5219],\n",
      "         ...,\n",
      "         [ -7.0919,  -7.0391,  -7.1240,  ...,  -7.8140,  -7.2380,  -5.7220],\n",
      "         [ -6.7670,  -6.8183,  -6.7835,  ...,  -7.2955,  -7.3662,  -4.9720],\n",
      "         [ -6.8101,  -6.9084,  -6.8015,  ...,  -7.1983,  -7.3059,  -5.2223]],\n",
      "\n",
      "        [[ -6.9551,  -6.9634,  -6.9065,  ...,  -6.2117,  -6.0002,  -3.9248],\n",
      "         [-16.3236, -16.0074, -16.2362,  ..., -15.3845, -13.4816, -13.6571],\n",
      "         [-12.5797, -12.8507, -12.3278,  ...,  -9.7265, -11.0946, -12.6792],\n",
      "         ...,\n",
      "         [-13.7862, -14.2950, -13.8740,  ..., -11.3414, -10.2535, -14.5742],\n",
      "         [ -9.6706,  -9.9742,  -9.9196,  ...,  -7.4285,  -6.3786, -10.1504],\n",
      "         [-11.8318, -11.8250, -12.2413,  ...,  -9.8926,  -9.5704,  -5.7078]],\n",
      "\n",
      "        [[ -6.3631,  -6.3307,  -6.3573,  ...,  -5.6895,  -5.5056,  -3.8536],\n",
      "         [-14.3745, -13.8299, -14.0979,  ..., -12.0023, -12.1004, -11.0415],\n",
      "         [ -6.7604,  -6.7573,  -6.7940,  ...,  -7.2186,  -8.0496,  -6.2755],\n",
      "         ...,\n",
      "         [ -6.5981,  -6.6542,  -6.6491,  ...,  -7.3034,  -7.3165,  -6.1325],\n",
      "         [ -6.5421,  -6.5161,  -6.5608,  ...,  -7.4939,  -7.0854,  -6.7789],\n",
      "         [ -6.1387,  -6.2438,  -6.0948,  ...,  -6.0524,  -6.9509,  -5.5486]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0369,  -7.0315,  -6.9966,  ...,  -6.1433,  -6.0529,  -4.2828],\n",
      "         [-11.6713, -11.6731, -11.4972,  ...,  -8.4277,  -9.8564,  -9.8749],\n",
      "         [ -6.7273,  -6.8518,  -6.9498,  ...,  -6.6919,  -8.7052,  -4.6690],\n",
      "         ...,\n",
      "         [ -6.0837,  -6.2376,  -6.1760,  ...,  -6.6393,  -8.2090,  -5.1595],\n",
      "         [ -6.5958,  -6.5899,  -6.6685,  ...,  -7.2244,  -8.0243,  -5.4440],\n",
      "         [ -6.9830,  -7.1452,  -7.1388,  ...,  -7.1119,  -8.5949,  -4.9323]],\n",
      "\n",
      "        [[ -7.0670,  -7.0100,  -7.0273,  ...,  -6.2438,  -6.2320,  -4.0278],\n",
      "         [-10.8080, -10.2672, -10.6826,  ...,  -6.6953,  -9.5664,  -9.5669],\n",
      "         [ -6.3670,  -6.4382,  -6.4434,  ...,  -5.9366,  -6.8613,  -5.0442],\n",
      "         ...,\n",
      "         [ -5.7226,  -5.6119,  -5.8449,  ...,  -5.4291,  -6.4224,  -3.3523],\n",
      "         [ -5.8269,  -5.8805,  -5.9445,  ...,  -5.7607,  -6.5009,  -4.0426],\n",
      "         [ -6.4964,  -6.5106,  -6.5442,  ...,  -5.9007,  -6.4827,  -4.4839]],\n",
      "\n",
      "        [[ -6.4557,  -6.4283,  -6.4694,  ...,  -5.8748,  -5.9718,  -3.4959],\n",
      "         [ -7.7393,  -7.5256,  -7.7004,  ...,  -8.2392,  -7.6833,  -4.3423],\n",
      "         [ -5.6786,  -5.7831,  -5.7396,  ...,  -5.9187,  -5.9055,  -4.0377],\n",
      "         ...,\n",
      "         [ -5.5889,  -5.5001,  -5.6762,  ...,  -5.4803,  -5.4578,  -2.0967],\n",
      "         [ -6.0068,  -5.8671,  -5.9850,  ...,  -5.9889,  -5.7841,  -3.3054],\n",
      "         [ -6.1816,  -6.1521,  -6.2852,  ...,  -6.4267,  -6.5413,  -3.0918]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.104185104370117\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4313, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2432,  -7.2719,  -7.2625,  ...,  -6.7471,  -6.3940,  -4.8175],\n",
      "         [ -7.5944,  -7.5506,  -7.7624,  ...,  -6.7999,  -7.5880,  -4.7387],\n",
      "         [ -7.3667,  -7.3341,  -7.4666,  ...,  -7.0967,  -7.5027,  -7.1264],\n",
      "         ...,\n",
      "         [-11.6446, -11.8343, -11.9541,  ...,  -9.8847,  -9.9004, -11.4566],\n",
      "         [-12.0870, -12.1595, -12.5619,  ..., -12.0744, -11.4058, -11.8857],\n",
      "         [-13.5860, -12.8472, -13.3646,  ..., -10.6580, -11.7409, -10.3477]],\n",
      "\n",
      "        [[ -6.5838,  -6.5213,  -6.5708,  ...,  -5.9102,  -5.9365,  -3.6717],\n",
      "         [ -8.8997,  -8.7800,  -8.9951,  ...,  -9.8796,  -8.9642,  -4.9668],\n",
      "         [ -6.4933,  -6.5507,  -6.7300,  ...,  -7.4478,  -7.6163,  -3.4873],\n",
      "         ...,\n",
      "         [ -6.0800,  -6.0006,  -6.1531,  ...,  -6.0823,  -6.1735,  -3.0545],\n",
      "         [ -6.1224,  -6.0254,  -6.1796,  ...,  -6.1992,  -5.8570,  -2.9625],\n",
      "         [ -6.1781,  -6.1602,  -6.3739,  ...,  -6.6261,  -6.3121,  -3.1281]],\n",
      "\n",
      "        [[ -7.3385,  -7.3343,  -7.2895,  ...,  -6.7880,  -6.5650,  -4.1722],\n",
      "         [-16.9772, -16.7973, -16.7952,  ..., -15.6240, -13.7974, -11.3467],\n",
      "         [ -6.4037,  -6.3237,  -6.5743,  ...,  -6.8883,  -6.7014,  -4.5150],\n",
      "         ...,\n",
      "         [ -7.9111,  -8.4095,  -8.2400,  ...,  -8.2538,  -7.0257,  -6.3054],\n",
      "         [ -9.1068,  -9.2627,  -9.1822,  ...,  -7.4254,  -8.6764,  -6.7427],\n",
      "         [-14.8137, -14.9281, -14.8514,  ..., -12.6678, -11.7878,  -9.3791]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8925,  -6.9024,  -6.8772,  ...,  -6.2003,  -6.2589,  -4.3248],\n",
      "         [-15.5002, -15.7085, -15.9023,  ..., -12.4030, -13.6491, -14.8507],\n",
      "         [-11.8955, -11.6787, -12.1893,  ..., -10.4310, -11.5728, -11.8061],\n",
      "         ...,\n",
      "         [ -8.4984,  -8.6923,  -8.8828,  ...,  -9.7035, -10.0393, -10.6483],\n",
      "         [ -8.5589,  -8.4454,  -8.6612,  ...,  -7.8483,  -6.9934,  -7.8746],\n",
      "         [-12.4076, -12.3266, -12.6819,  ...,  -9.7431, -11.3527,  -7.8417]],\n",
      "\n",
      "        [[ -6.5282,  -6.4726,  -6.4889,  ...,  -5.8405,  -5.6747,  -3.7136],\n",
      "         [ -8.7624,  -8.7426,  -8.8468,  ...,  -9.5658,  -8.6682,  -5.0895],\n",
      "         [ -7.4615,  -7.0691,  -7.7015,  ...,  -7.2636,  -7.4530,  -6.1645],\n",
      "         ...,\n",
      "         [ -6.2264,  -6.1326,  -6.2902,  ...,  -6.3768,  -6.4795,  -2.8513],\n",
      "         [ -6.3885,  -6.2995,  -6.4999,  ...,  -6.4279,  -6.5701,  -2.9041],\n",
      "         [ -6.0016,  -5.9129,  -6.0567,  ...,  -5.9335,  -6.0562,  -2.8451]],\n",
      "\n",
      "        [[ -7.1620,  -7.0873,  -7.1169,  ...,  -5.8437,  -6.4107,  -4.5728],\n",
      "         [ -7.8632,  -7.5463,  -7.8029,  ...,  -6.0783,  -6.2428,  -6.6792],\n",
      "         [ -5.6630,  -5.7650,  -5.7975,  ...,  -5.8724,  -7.9161,  -4.0618],\n",
      "         ...,\n",
      "         [ -5.4904,  -5.6289,  -5.4660,  ...,  -5.6856,  -7.1708,  -5.0271],\n",
      "         [ -5.6427,  -5.7717,  -5.7445,  ...,  -5.7214,  -7.1238,  -4.5125],\n",
      "         [ -6.7962,  -6.8379,  -6.8391,  ...,  -6.6212,  -7.8336,  -5.9999]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.431299924850464\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8251, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2578,  -7.2021,  -7.1897,  ...,  -6.3978,  -6.3975,  -4.0373],\n",
      "         [ -6.8771,  -6.7992,  -6.8500,  ...,  -7.4930,  -6.1101,  -6.4385],\n",
      "         [ -5.3409,  -5.4844,  -5.3114,  ...,  -5.4175,  -4.2455,  -3.1146],\n",
      "         ...,\n",
      "         [ -8.5002,  -8.3394,  -8.4670,  ...,  -7.7638,  -8.4076,  -6.1292],\n",
      "         [ -7.6316,  -7.5817,  -7.4883,  ...,  -7.5548,  -7.3325,  -3.5090],\n",
      "         [-15.2047, -15.1298, -15.1264,  ..., -13.5554, -13.1598, -11.8998]],\n",
      "\n",
      "        [[ -7.0286,  -7.1113,  -7.0418,  ...,  -6.2683,  -6.2632,  -4.5372],\n",
      "         [ -7.0112,  -7.0309,  -7.0418,  ...,  -5.8450,  -5.9590,  -6.1511],\n",
      "         [ -6.6808,  -6.4610,  -6.8292,  ...,  -5.7609,  -5.8787,  -4.2009],\n",
      "         ...,\n",
      "         [ -8.7964,  -8.9580,  -9.1745,  ...,  -7.6456,  -8.0684,  -5.8966],\n",
      "         [ -5.0042,  -4.9433,  -4.9847,  ...,  -3.5412,  -4.5490,  -4.5266],\n",
      "         [ -8.9354,  -8.8849,  -9.1621,  ...,  -8.0049,  -8.0904,  -6.4202]],\n",
      "\n",
      "        [[ -6.6641,  -6.6393,  -6.6404,  ...,  -6.0431,  -5.8371,  -4.1527],\n",
      "         [-11.6851, -11.9023, -12.2160,  ..., -12.1936,  -9.9780, -10.1283],\n",
      "         [-13.8021, -13.5362, -13.7997,  ..., -12.1943, -11.5975, -11.5779],\n",
      "         ...,\n",
      "         [ -7.0270,  -7.1821,  -7.0694,  ...,  -6.8700,  -6.3662,  -6.9124],\n",
      "         [ -4.5630,  -4.4465,  -4.5731,  ...,  -4.8518,  -5.4656,  -4.5575],\n",
      "         [ -7.2097,  -7.3589,  -7.3649,  ...,  -6.8815,  -6.7525,  -6.2071]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9348,  -6.9393,  -6.8948,  ...,  -6.4134,  -6.1056,  -4.2964],\n",
      "         [-10.3295, -10.3669, -10.2265,  ..., -10.7277,  -8.5456,  -8.5068],\n",
      "         [ -9.6157,  -9.5040,  -9.6266,  ...,  -9.3637,  -9.3280,  -9.3041],\n",
      "         ...,\n",
      "         [ -2.2498,  -2.2719,  -2.3658,  ...,  -3.3003,  -2.3622,  -4.2478],\n",
      "         [-11.1195, -11.8828, -11.2340,  ..., -11.4358,  -9.6738, -10.3026],\n",
      "         [-14.4688, -13.9842, -14.1217,  ..., -11.7139, -12.4321, -11.6159]],\n",
      "\n",
      "        [[ -7.3836,  -7.3582,  -7.3227,  ...,  -6.3701,  -6.3112,  -4.5967],\n",
      "         [-12.4115, -12.1100, -12.4438,  ...,  -9.0703, -11.2319,  -8.4953],\n",
      "         [ -6.0797,  -6.2034,  -6.2199,  ...,  -6.3254,  -7.5220,  -4.1175],\n",
      "         ...,\n",
      "         [ -5.9865,  -5.9883,  -5.9318,  ...,  -5.8465,  -7.1488,  -4.5474],\n",
      "         [ -6.4097,  -6.4916,  -6.4372,  ...,  -6.3838,  -7.6697,  -5.1754],\n",
      "         [ -6.0453,  -6.0538,  -5.9718,  ...,  -6.5209,  -7.0236,  -5.4050]],\n",
      "\n",
      "        [[ -6.4886,  -6.4238,  -6.4456,  ...,  -5.8231,  -5.7978,  -3.5826],\n",
      "         [ -8.2884,  -7.8919,  -8.2846,  ...,  -8.8053,  -8.8868,  -4.9149],\n",
      "         [ -7.8551,  -7.5689,  -7.8020,  ...,  -7.4132,  -8.5949,  -5.0312],\n",
      "         ...,\n",
      "         [ -6.0165,  -5.8663,  -5.9843,  ...,  -5.9644,  -6.1482,  -2.6987],\n",
      "         [ -5.4667,  -5.3414,  -5.5004,  ...,  -5.7796,  -5.7312,  -2.0846],\n",
      "         [ -6.0751,  -5.8071,  -5.9971,  ...,  -6.1662,  -6.4646,  -2.8063]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.8250720500946045\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0869, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9531,  -6.9069,  -6.9015,  ...,  -6.1710,  -5.9597,  -3.9596],\n",
      "         [ -8.7912,  -8.8440,  -9.1195,  ...,  -8.4735,  -8.3654,  -2.8834],\n",
      "         [ -5.6986,  -5.9384,  -5.6865,  ...,  -7.1335,  -6.1546,  -2.7996],\n",
      "         ...,\n",
      "         [ -8.2302,  -8.1827,  -8.2796,  ...,  -8.5632,  -8.1378,  -3.3407],\n",
      "         [ -9.0839,  -9.0077,  -9.1199,  ...,  -9.3301,  -8.5806,  -4.4082],\n",
      "         [ -8.8499,  -8.7680,  -8.8543,  ...,  -9.3950,  -8.3753,  -4.5768]],\n",
      "\n",
      "        [[ -6.7226,  -6.6869,  -6.7490,  ...,  -6.0262,  -5.8098,  -3.9220],\n",
      "         [-11.6054, -11.6140, -11.5131,  ...,  -8.5175, -10.1415,  -7.3434],\n",
      "         [ -5.9225,  -6.1697,  -6.1308,  ...,  -6.0502,  -7.6641,  -4.5409],\n",
      "         ...,\n",
      "         [ -6.8151,  -7.0221,  -6.9418,  ...,  -6.8768,  -7.9376,  -4.9160],\n",
      "         [ -6.5005,  -6.5672,  -6.6056,  ...,  -6.7375,  -7.8179,  -4.4040],\n",
      "         [ -6.8475,  -6.8918,  -6.8972,  ...,  -6.5788,  -7.5799,  -5.1336]],\n",
      "\n",
      "        [[ -7.0476,  -7.0631,  -7.0361,  ...,  -6.5335,  -6.2426,  -4.2573],\n",
      "         [-13.8696, -13.8635, -13.7492,  ..., -11.6879, -11.7060, -10.9165],\n",
      "         [ -6.4448,  -6.6466,  -6.3271,  ...,  -5.7785,  -5.0454,  -4.4963],\n",
      "         ...,\n",
      "         [ -7.5004,  -7.5387,  -7.6185,  ...,  -7.3670,  -7.2750,  -7.2308],\n",
      "         [ -7.0766,  -7.0450,  -7.1064,  ...,  -6.7505,  -7.0854,  -6.3801],\n",
      "         [ -7.3748,  -7.3454,  -7.4429,  ...,  -7.3922,  -7.3614,  -5.2825]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.8184,  -8.7327,  -8.7150,  ...,  -7.6321,  -8.0011,  -4.9107],\n",
      "         [-11.0306, -11.1228, -11.6926,  ...,  -8.2339,  -7.7640, -11.3389],\n",
      "         [ -5.1649,  -5.4083,  -5.4387,  ...,  -6.0106,  -7.2329,  -3.9103],\n",
      "         ...,\n",
      "         [ -5.7950,  -5.8700,  -5.8492,  ...,  -6.0226,  -7.0889,  -4.2486],\n",
      "         [ -5.3457,  -5.5359,  -5.4728,  ...,  -6.0202,  -6.4919,  -4.7331],\n",
      "         [ -5.8944,  -6.0172,  -6.0721,  ...,  -6.8340,  -7.0532,  -5.5158]],\n",
      "\n",
      "        [[ -7.2397,  -7.2417,  -7.2356,  ...,  -6.4978,  -6.4362,  -4.1772],\n",
      "         [ -9.0924,  -9.5292,  -9.4657,  ...,  -9.2599, -10.6002,  -6.4860],\n",
      "         [-11.1841, -11.6262, -11.6721,  ..., -11.7953, -10.7905,  -9.0598],\n",
      "         ...,\n",
      "         [ -6.3065,  -6.5527,  -6.3139,  ...,  -5.3821,  -6.9169,  -5.9379],\n",
      "         [ -8.5831,  -8.6491,  -8.6371,  ...,  -9.1140,  -8.9328,  -6.5043],\n",
      "         [ -7.8543,  -7.7416,  -7.8763,  ...,  -8.3611,  -7.6428,  -4.2909]],\n",
      "\n",
      "        [[ -7.1371,  -7.1251,  -7.1239,  ...,  -6.5373,  -6.3645,  -4.6779],\n",
      "         [-13.6528, -13.5738, -13.8954,  ..., -13.0076, -12.9222, -12.7038],\n",
      "         [ -9.0727,  -8.8746,  -9.0555,  ...,  -9.4889, -10.5191,  -9.8489],\n",
      "         ...,\n",
      "         [-11.0292, -11.1497, -11.3597,  ..., -10.8165,  -7.8837,  -9.7150],\n",
      "         [ -4.5251,  -4.5712,  -4.6555,  ...,  -5.0618,  -4.5908,  -2.7375],\n",
      "         [-11.3103, -11.3274, -11.5526,  ..., -10.0692,  -9.4330,  -7.8217]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.0868630409240723\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.0890, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1033,  -7.0690,  -7.0829,  ...,  -6.2896,  -6.2073,  -4.1499],\n",
      "         [-12.4695, -12.4082, -12.8158,  ..., -11.0982, -11.2538, -16.5693],\n",
      "         [ -3.5136,  -3.2440,  -3.1912,  ...,  -4.0066,  -4.0098,  -0.6802],\n",
      "         ...,\n",
      "         [ -6.9324,  -6.8604,  -6.9567,  ...,  -7.3395,  -6.3955,  -5.3860],\n",
      "         [ -6.6067,  -6.5891,  -6.6378,  ...,  -7.1719,  -5.9229,  -5.1846],\n",
      "         [ -7.6616,  -7.6515,  -7.6360,  ...,  -8.1175,  -6.7979,  -5.7482]],\n",
      "\n",
      "        [[ -6.6278,  -6.5440,  -6.5680,  ...,  -5.8698,  -6.1445,  -3.7230],\n",
      "         [ -8.3025,  -8.1883,  -8.3456,  ...,  -8.7823,  -8.6633,  -4.4155],\n",
      "         [ -9.2316,  -9.2115,  -9.2702,  ...,  -8.9785,  -8.1674,  -7.2206],\n",
      "         ...,\n",
      "         [ -6.3345,  -6.1481,  -6.3194,  ...,  -5.8862,  -5.9545,  -3.9759],\n",
      "         [ -5.3905,  -5.3288,  -5.4855,  ...,  -5.3549,  -5.3780,  -2.9614],\n",
      "         [ -6.7420,  -6.6831,  -6.8630,  ...,  -7.0426,  -6.6090,  -4.0538]],\n",
      "\n",
      "        [[ -6.5134,  -6.5011,  -6.5844,  ...,  -5.7400,  -5.7391,  -4.6737],\n",
      "         [ -4.6220,  -4.6715,  -4.8175,  ...,  -5.5821,  -4.5523,  -5.4611],\n",
      "         [-14.7732, -14.2640, -14.4532,  ..., -11.8760, -11.9242,  -9.6844],\n",
      "         ...,\n",
      "         [ -5.9753,  -5.9601,  -6.1206,  ...,  -5.8817,  -5.2733,  -5.0376],\n",
      "         [ -5.2228,  -5.1360,  -5.2860,  ...,  -5.4640,  -4.9643,  -4.0253],\n",
      "         [ -4.9197,  -4.7887,  -4.8552,  ...,  -4.9622,  -4.8764,  -4.2639]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4952,  -6.4828,  -6.4648,  ...,  -5.8424,  -5.6726,  -3.7223],\n",
      "         [-10.6449, -10.6746, -10.6858,  ...,  -9.6317,  -9.0462, -13.4584],\n",
      "         [ -8.5456,  -8.4948,  -8.5155,  ...,  -7.6040,  -6.6105,  -4.3496],\n",
      "         ...,\n",
      "         [ -5.8545,  -5.7883,  -5.7074,  ...,  -5.8239,  -6.0848,  -3.6518],\n",
      "         [ -4.6603,  -4.7099,  -4.7414,  ...,  -5.3412,  -5.1024,  -3.8941],\n",
      "         [ -6.8448,  -6.6128,  -6.7272,  ...,  -6.0581,  -6.5826,  -5.2195]],\n",
      "\n",
      "        [[ -7.5635,  -7.5436,  -7.5538,  ...,  -6.9209,  -6.9911,  -4.4887],\n",
      "         [-11.9557, -12.0292, -12.1464,  ..., -10.5953, -10.8301,  -8.5243],\n",
      "         [ -5.8390,  -5.9069,  -5.9626,  ...,  -6.4433,  -7.5630,  -3.8942],\n",
      "         ...,\n",
      "         [ -7.4539,  -7.5487,  -7.4096,  ...,  -7.4120,  -7.6530,  -5.8459],\n",
      "         [ -6.1659,  -6.2246,  -6.1244,  ...,  -6.1087,  -7.1283,  -5.0137],\n",
      "         [ -5.7477,  -5.8826,  -5.8188,  ...,  -6.1918,  -6.6365,  -4.6444]],\n",
      "\n",
      "        [[ -6.4151,  -6.3225,  -6.3295,  ...,  -5.8606,  -5.8157,  -3.4103],\n",
      "         [ -9.4841,  -9.1785,  -9.4784,  ..., -10.5263,  -9.4357,  -4.8667],\n",
      "         [ -6.7359,  -6.5026,  -6.5417,  ...,  -7.5512,  -6.8355,  -2.8143],\n",
      "         ...,\n",
      "         [ -6.3625,  -6.2416,  -6.4388,  ...,  -6.7654,  -6.7786,  -2.3333],\n",
      "         [ -5.7504,  -5.5887,  -5.7436,  ...,  -5.9098,  -5.9490,  -1.7892],\n",
      "         [ -6.0349,  -5.8533,  -5.9760,  ...,  -6.6793,  -6.1126,  -2.1440]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 3.089024782180786\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8472, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8124,  -6.7580,  -6.7975,  ...,  -6.0090,  -6.1199,  -3.7854],\n",
      "         [ -8.6064,  -8.4339,  -8.5753,  ...,  -8.6457,  -9.5078,  -3.8053],\n",
      "         [ -7.2746,  -7.1716,  -7.2887,  ...,  -7.0897,  -8.1008,  -2.9812],\n",
      "         ...,\n",
      "         [ -6.0086,  -5.8988,  -6.0547,  ...,  -5.9789,  -6.4352,  -2.1710],\n",
      "         [ -5.9407,  -5.8243,  -5.9558,  ...,  -5.9304,  -6.4298,  -1.9877],\n",
      "         [ -6.1146,  -5.9565,  -6.1199,  ...,  -6.0809,  -6.4676,  -2.1211]],\n",
      "\n",
      "        [[ -6.7491,  -6.7485,  -6.7585,  ...,  -6.2684,  -5.9841,  -4.0890],\n",
      "         [-13.0193, -13.0923, -13.2595,  ..., -12.6397,  -9.9640, -14.3408],\n",
      "         [ -5.1611,  -5.6452,  -5.5144,  ...,  -5.2339,  -4.3425,  -8.8192],\n",
      "         ...,\n",
      "         [-10.8393, -10.8091, -10.9317,  ...,  -9.9577,  -9.7050, -10.6823],\n",
      "         [-16.5923, -16.6749, -17.0553,  ..., -15.7668, -14.3644, -14.1890],\n",
      "         [-13.8407, -13.0518, -13.3715,  ...,  -9.5481, -12.1793, -11.3815]],\n",
      "\n",
      "        [[ -8.8666,  -8.7455,  -8.8776,  ...,  -7.8068,  -8.1218,  -5.3819],\n",
      "         [-10.1804,  -9.8483,  -9.8791,  ...,  -7.1668,  -8.5661,  -8.9331],\n",
      "         [ -5.5664,  -5.8521,  -5.8085,  ...,  -5.6171,  -7.5845,  -4.5932],\n",
      "         ...,\n",
      "         [ -6.3217,  -6.4239,  -6.4848,  ...,  -6.4435,  -7.4666,  -4.3173],\n",
      "         [ -5.2881,  -5.3453,  -5.4317,  ...,  -5.5613,  -7.0766,  -4.0659],\n",
      "         [ -5.7964,  -5.9734,  -5.8340,  ...,  -6.0451,  -7.1290,  -5.3971]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5992,  -6.5727,  -6.5960,  ...,  -6.0376,  -5.8273,  -4.0605],\n",
      "         [-13.6064, -13.8946, -13.7084,  ..., -12.7495, -12.6278, -14.1295],\n",
      "         [-13.1711, -13.8360, -13.7289,  ..., -12.5298, -12.5511, -11.3949],\n",
      "         ...,\n",
      "         [ -5.5587,  -5.6573,  -5.5525,  ...,  -5.4417,  -5.9779,  -2.7089],\n",
      "         [ -9.0414,  -9.3574,  -8.8497,  ...,  -8.5045,  -9.6404,  -8.3426],\n",
      "         [-14.1414, -13.7053, -13.9099,  ..., -11.7875, -11.6551, -10.6255]],\n",
      "\n",
      "        [[ -6.5116,  -6.4411,  -6.4767,  ...,  -5.7668,  -5.7799,  -3.5157],\n",
      "         [ -5.9292,  -5.7340,  -5.9693,  ...,  -6.3593,  -6.3922,  -2.7704],\n",
      "         [ -7.5870,  -7.6475,  -7.7327,  ...,  -8.9248,  -7.3183,  -4.5321],\n",
      "         ...,\n",
      "         [ -6.5024,  -6.3776,  -6.5314,  ...,  -6.9089,  -6.3423,  -2.8545],\n",
      "         [ -6.3897,  -6.2227,  -6.3869,  ...,  -6.8469,  -6.1202,  -2.6857],\n",
      "         [ -6.1552,  -6.0802,  -6.2978,  ...,  -6.6938,  -6.4296,  -2.9828]],\n",
      "\n",
      "        [[ -6.6549,  -6.5933,  -6.5898,  ...,  -5.9657,  -5.8079,  -3.9709],\n",
      "         [ -4.0408,  -3.9734,  -4.1703,  ...,  -3.6461,  -4.4107,  -6.7084],\n",
      "         [-11.2212, -11.7459, -11.6973,  ...,  -9.3811,  -9.2430, -10.9018],\n",
      "         ...,\n",
      "         [ -4.2544,  -4.4036,  -4.4158,  ...,  -4.1299,  -4.7287,  -5.6079],\n",
      "         [ -5.7748,  -5.9241,  -5.8987,  ...,  -5.8154,  -5.5742,  -5.9771],\n",
      "         [ -5.6805,  -5.8990,  -5.7810,  ...,  -5.9632,  -5.5451,  -6.1752]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.847172260284424\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5147, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6965,  -6.6324,  -6.6594,  ...,  -6.0453,  -5.8442,  -3.9115],\n",
      "         [ -7.9733,  -7.9527,  -7.6042,  ...,  -8.0693,  -7.9205,  -5.8451],\n",
      "         [ -7.4211,  -7.5001,  -7.3093,  ...,  -7.6327,  -7.4168,  -5.0789],\n",
      "         ...,\n",
      "         [ -6.5849,  -6.4310,  -6.4345,  ...,  -6.2610,  -6.6446,  -3.6285],\n",
      "         [ -6.0924,  -6.0164,  -5.8970,  ...,  -6.0043,  -6.3040,  -2.6722],\n",
      "         [ -5.9662,  -5.8949,  -5.8673,  ...,  -6.3503,  -6.5672,  -3.4172]],\n",
      "\n",
      "        [[ -6.2708,  -6.2301,  -6.2580,  ...,  -5.6511,  -5.4819,  -3.7497],\n",
      "         [-12.5079, -12.3248, -12.5166,  ...,  -8.8780, -10.0424,  -8.4654],\n",
      "         [ -6.5773,  -6.5901,  -6.5632,  ...,  -6.4291,  -7.6154,  -4.9507],\n",
      "         ...,\n",
      "         [ -6.5027,  -6.5925,  -6.6259,  ...,  -6.2656,  -7.0253,  -5.1030],\n",
      "         [ -6.8537,  -6.7861,  -6.8560,  ...,  -7.3942,  -7.1258,  -5.4780],\n",
      "         [ -7.0159,  -7.0436,  -7.0969,  ...,  -6.8147,  -7.4737,  -5.8654]],\n",
      "\n",
      "        [[ -6.8784,  -6.8367,  -6.8832,  ...,  -6.1131,  -6.1857,  -4.3702],\n",
      "         [-13.0321, -13.4220, -12.9835,  ..., -11.4276, -11.3328,  -9.1340],\n",
      "         [ -6.0192,  -5.9120,  -5.9770,  ...,  -6.5435,  -7.0361,  -6.1450],\n",
      "         ...,\n",
      "         [ -6.9497,  -6.8171,  -6.8976,  ...,  -6.8593,  -7.5642,  -5.2329],\n",
      "         [ -6.3726,  -6.3240,  -6.3917,  ...,  -6.9629,  -6.9282,  -6.3335],\n",
      "         [ -6.7767,  -6.6480,  -6.7164,  ...,  -6.9879,  -6.6223,  -5.8046]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1546,  -7.1044,  -7.1424,  ...,  -6.3110,  -6.2863,  -4.2375],\n",
      "         [ -9.6104,  -9.4258,  -9.5409,  ...,  -8.2791,  -7.3871,  -7.4817],\n",
      "         [ -5.6219,  -5.6750,  -5.6173,  ...,  -6.1731,  -7.3226,  -4.7284],\n",
      "         ...,\n",
      "         [ -5.4588,  -5.5163,  -5.4465,  ...,  -5.8456,  -7.0359,  -4.6796],\n",
      "         [ -5.4562,  -5.5718,  -5.5368,  ...,  -6.1166,  -7.3195,  -4.3665],\n",
      "         [ -6.0628,  -6.1074,  -6.0872,  ...,  -6.3063,  -7.3588,  -4.3421]],\n",
      "\n",
      "        [[ -6.6257,  -6.5814,  -6.6280,  ...,  -5.7855,  -6.0667,  -3.7937],\n",
      "         [-14.9313, -14.5689, -14.4844,  ..., -11.4511, -13.0829, -11.9955],\n",
      "         [ -5.6474,  -5.8389,  -5.8128,  ...,  -6.0237,  -7.1376,  -5.3622],\n",
      "         ...,\n",
      "         [ -5.8892,  -5.9573,  -6.0160,  ...,  -6.1609,  -6.9033,  -5.4038],\n",
      "         [ -6.4571,  -6.4910,  -6.5244,  ...,  -6.8330,  -7.2128,  -4.8215],\n",
      "         [ -5.7640,  -5.8904,  -5.8128,  ...,  -6.4278,  -6.8501,  -5.0042]],\n",
      "\n",
      "        [[ -6.8416,  -6.7872,  -6.8042,  ...,  -6.1757,  -5.9903,  -4.1681],\n",
      "         [ -3.8219,  -3.7657,  -3.5298,  ...,  -2.8682,  -3.5015,  -2.6156],\n",
      "         [ -8.4328,  -9.0830,  -8.4654,  ...,  -7.4576,  -6.4651,  -5.6327],\n",
      "         ...,\n",
      "         [ -7.0167,  -7.0883,  -6.9044,  ...,  -7.4786,  -5.8105,  -5.8656],\n",
      "         [ -7.4942,  -7.5666,  -7.2999,  ...,  -7.6973,  -5.6383,  -5.6188],\n",
      "         [ -7.7156,  -7.6867,  -7.6459,  ...,  -7.9333,  -6.6960,  -4.8483]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.5147218704223633\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5569, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2509,  -7.2465,  -7.2068,  ...,  -6.3130,  -6.3414,  -4.4489],\n",
      "         [-10.4937, -11.1357, -10.9127,  ..., -10.0936, -10.1748,  -5.5916],\n",
      "         [ -8.4216,  -8.4151,  -8.3682,  ...,  -7.0940,  -6.3217,  -3.8882],\n",
      "         ...,\n",
      "         [ -8.4443,  -8.3941,  -8.3936,  ...,  -8.1835,  -7.1283,  -7.0091],\n",
      "         [ -8.2746,  -8.3818,  -8.3673,  ...,  -8.1722,  -6.9666,  -6.6283],\n",
      "         [ -9.0754,  -9.1583,  -9.2437,  ...,  -9.1040,  -7.7969,  -6.5457]],\n",
      "\n",
      "        [[ -6.6056,  -6.5200,  -6.5418,  ...,  -5.9008,  -5.9341,  -4.0110],\n",
      "         [ -6.9314,  -6.7331,  -6.7575,  ...,  -6.9638,  -7.5677,  -3.0289],\n",
      "         [ -8.0312,  -7.8231,  -7.7125,  ...,  -7.6806,  -7.1805,  -6.3336],\n",
      "         ...,\n",
      "         [ -5.3581,  -5.2237,  -5.2803,  ...,  -5.7105,  -5.3500,  -3.1868],\n",
      "         [ -5.4923,  -5.3522,  -5.3984,  ...,  -5.3890,  -5.3758,  -2.7646],\n",
      "         [ -5.4047,  -5.3096,  -5.3533,  ...,  -5.3638,  -5.5617,  -2.4549]],\n",
      "\n",
      "        [[ -6.4539,  -6.3680,  -6.4274,  ...,  -5.7114,  -5.5403,  -3.9950],\n",
      "         [-11.4672, -11.3032, -11.5763,  ...,  -8.3723,  -8.8616, -10.8791],\n",
      "         [ -5.5730,  -5.6289,  -5.6279,  ...,  -6.0903,  -7.2041,  -4.2094],\n",
      "         ...,\n",
      "         [ -6.7562,  -6.7877,  -6.8447,  ...,  -7.0463,  -8.0469,  -4.7616],\n",
      "         [ -6.0530,  -6.1229,  -5.9506,  ...,  -6.2439,  -7.3104,  -4.8307],\n",
      "         [ -6.2218,  -6.3110,  -6.3023,  ...,  -6.3948,  -7.4654,  -4.5842]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6961,  -7.7753,  -7.7823,  ...,  -6.5277,  -7.1107,  -4.0866],\n",
      "         [ -9.3072,  -9.1055,  -9.4162,  ...,  -8.1102,  -8.6735,  -6.4868],\n",
      "         [ -6.2772,  -6.6365,  -6.6428,  ...,  -6.2572,  -7.9420,  -4.5622],\n",
      "         ...,\n",
      "         [ -6.1522,  -6.3221,  -6.2008,  ...,  -6.1934,  -7.5646,  -6.3254],\n",
      "         [ -6.2064,  -6.2562,  -6.2834,  ...,  -6.2528,  -6.9705,  -4.8249],\n",
      "         [ -6.5608,  -6.6816,  -6.4866,  ...,  -6.3663,  -7.1762,  -5.6381]],\n",
      "\n",
      "        [[ -7.1476,  -7.0920,  -7.1318,  ...,  -6.2087,  -6.2562,  -4.1362],\n",
      "         [-12.6900, -12.2045, -12.4209,  ..., -12.1480, -10.3324,  -7.7394],\n",
      "         [ -6.0241,  -6.0145,  -6.0729,  ...,  -6.6394,  -7.3221,  -4.7405],\n",
      "         ...,\n",
      "         [ -6.2540,  -6.2812,  -6.3488,  ...,  -6.3176,  -7.0418,  -5.1642],\n",
      "         [ -6.1101,  -6.1483,  -6.1429,  ...,  -6.4165,  -7.5103,  -5.2258],\n",
      "         [ -6.0844,  -6.0453,  -6.0850,  ...,  -6.0958,  -6.8681,  -5.2325]],\n",
      "\n",
      "        [[ -7.5492,  -7.5767,  -7.5452,  ...,  -6.8662,  -6.8690,  -4.7106],\n",
      "         [ -8.2649,  -8.1836,  -8.2618,  ...,  -7.6934,  -8.5738,  -6.9069],\n",
      "         [ -7.8551,  -7.9074,  -7.7100,  ...,  -7.8213,  -5.6479,  -8.8945],\n",
      "         ...,\n",
      "         [ -7.0231,  -7.5594,  -7.5395,  ...,  -8.0840,  -7.4858,  -6.6438],\n",
      "         [ -6.2143,  -6.6603,  -6.4671,  ...,  -6.8523,  -6.1020,  -6.2199],\n",
      "         [ -7.1984,  -7.3935,  -7.3888,  ...,  -8.3569,  -7.8116,  -6.0759]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.5569260120391846\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7943, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.7748,  -7.7852,  -7.8187,  ...,  -6.5483,  -6.9517,  -4.3694],\n",
      "         [-13.3049, -12.8684, -13.0168,  ...,  -9.4378, -10.2290, -11.8885],\n",
      "         [ -5.0030,  -5.0928,  -5.2068,  ...,  -5.1339,  -6.7834,  -4.4016],\n",
      "         ...,\n",
      "         [ -4.5354,  -4.7062,  -4.5756,  ...,  -5.0657,  -5.4912,  -4.5249],\n",
      "         [ -5.0944,  -5.2389,  -5.0928,  ...,  -5.4543,  -6.2873,  -4.9031],\n",
      "         [ -4.6009,  -4.7474,  -4.5549,  ...,  -4.6881,  -5.8002,  -4.7099]],\n",
      "\n",
      "        [[ -6.9369,  -6.8913,  -6.8840,  ...,  -6.2823,  -6.0373,  -4.3617],\n",
      "         [ -9.9692,  -9.7949, -10.0363,  ...,  -9.2712,  -7.7176,  -9.0374],\n",
      "         [ -4.1014,  -4.0836,  -4.3537,  ...,  -3.7441,  -3.9633,  -5.1092],\n",
      "         ...,\n",
      "         [ -7.6197,  -7.8418,  -7.6062,  ...,  -7.5521,  -5.9657,  -6.1973],\n",
      "         [ -6.6163,  -6.6487,  -6.5906,  ...,  -6.8315,  -5.1673,  -5.7999],\n",
      "         [ -7.1140,  -7.3569,  -7.2288,  ...,  -6.9537,  -5.3766,  -6.4136]],\n",
      "\n",
      "        [[ -6.8214,  -6.8220,  -6.8365,  ...,  -6.2136,  -5.9987,  -4.0171],\n",
      "         [ -6.9651,  -6.9407,  -7.1189,  ...,  -6.2031,  -5.1852,  -7.5156],\n",
      "         [ -3.1795,  -3.6210,  -2.9973,  ...,  -1.8108,  -2.2819,  -5.1361],\n",
      "         ...,\n",
      "         [ -2.3858,  -2.7758,  -2.3027,  ...,  -0.5341,  -2.5627,  -2.9768],\n",
      "         [ -6.8583,  -6.9066,  -6.9425,  ...,  -7.2723,  -6.6423,  -5.5220],\n",
      "         [-13.4155, -13.2739, -13.4040,  ..., -11.2432, -11.9076,  -9.2374]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4533,  -6.4684,  -6.4778,  ...,  -5.8873,  -6.1189,  -3.8713],\n",
      "         [-12.2067, -12.5174, -12.4346,  ..., -11.9811, -10.5213, -10.4793],\n",
      "         [-11.6794, -11.3827, -11.7373,  ..., -10.6402, -11.0443,  -9.8239],\n",
      "         ...,\n",
      "         [ -7.7791,  -7.9077,  -7.8825,  ...,  -8.4576,  -7.8112,  -5.9503],\n",
      "         [ -8.0220,  -8.1978,  -8.1742,  ...,  -8.3056,  -7.3365,  -4.1833],\n",
      "         [ -7.6983,  -7.8462,  -7.9026,  ...,  -8.1995,  -6.9188,  -4.3381]],\n",
      "\n",
      "        [[ -7.0079,  -6.9704,  -6.9739,  ...,  -6.3831,  -6.4002,  -4.2397],\n",
      "         [-12.9020, -12.9909, -12.9332,  ..., -12.1888, -11.4730,  -9.6009],\n",
      "         [-12.8283, -13.1085, -13.1514,  ..., -11.2370, -10.6097, -10.2996],\n",
      "         ...,\n",
      "         [ -6.0724,  -6.7521,  -6.2777,  ...,  -6.1839,  -6.0340,  -5.2807],\n",
      "         [ -7.3953,  -7.4643,  -7.3807,  ...,  -8.7060,  -8.0903,  -7.7996],\n",
      "         [ -5.4716,  -5.6127,  -5.5547,  ...,  -6.3418,  -6.0939,  -7.7355]],\n",
      "\n",
      "        [[ -6.3801,  -6.3215,  -6.3600,  ...,  -5.6048,  -5.9260,  -3.0536],\n",
      "         [ -9.2037,  -9.0246,  -9.1861,  ...,  -9.3511,  -9.2294,  -4.5765],\n",
      "         [ -9.4673,  -9.4250,  -9.7795,  ...,  -9.3432,  -8.8215,  -5.7844],\n",
      "         ...,\n",
      "         [ -6.5837,  -6.3465,  -6.5699,  ...,  -6.5795,  -6.5577,  -3.1999],\n",
      "         [ -6.1938,  -6.1143,  -6.2283,  ...,  -6.1250,  -6.2907,  -3.1905],\n",
      "         [ -6.1495,  -5.9841,  -6.1791,  ...,  -5.7643,  -6.3510,  -2.9754]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 1.7943181991577148\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4652, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2898,  -7.2866,  -7.2988,  ...,  -6.5106,  -6.8863,  -4.0995],\n",
      "         [-11.8053, -11.6411, -11.5887,  ...,  -8.8893,  -9.7073, -11.1856],\n",
      "         [ -6.3706,  -6.2979,  -6.4412,  ...,  -6.7046,  -8.2358,  -3.3913],\n",
      "         ...,\n",
      "         [ -7.1044,  -7.0031,  -7.0693,  ...,  -6.7831,  -8.0005,  -5.1182],\n",
      "         [ -5.8479,  -5.8437,  -5.9330,  ...,  -6.6068,  -7.9395,  -3.6099],\n",
      "         [ -6.6422,  -6.6478,  -6.6363,  ...,  -6.4799,  -7.2745,  -4.6663]],\n",
      "\n",
      "        [[ -7.2473,  -7.1571,  -7.1949,  ...,  -6.4563,  -6.3497,  -4.0788],\n",
      "         [-13.9779, -13.8311, -13.6880,  ..., -13.0785, -12.7236,  -9.4198],\n",
      "         [ -5.6136,  -5.6195,  -5.6179,  ...,  -5.7797,  -7.0837,  -4.4661],\n",
      "         ...,\n",
      "         [ -5.6129,  -5.6958,  -5.6317,  ...,  -5.6106,  -6.6061,  -4.5144],\n",
      "         [ -5.3197,  -5.3002,  -5.2959,  ...,  -5.5317,  -6.7554,  -5.0153],\n",
      "         [ -5.6786,  -5.7448,  -5.6506,  ...,  -5.7814,  -6.5574,  -4.4952]],\n",
      "\n",
      "        [[ -6.8703,  -6.8405,  -6.8137,  ...,  -6.2357,  -6.0666,  -3.9630],\n",
      "         [-15.2147, -15.3226, -15.0619,  ..., -13.6833, -12.6380, -12.9817],\n",
      "         [-11.8054, -11.5945, -11.8368,  ...,  -8.2341,  -9.6219, -15.1282],\n",
      "         ...,\n",
      "         [ -8.3893,  -8.5334,  -7.8015,  ...,  -6.4587,  -8.3818,  -8.8086],\n",
      "         [ -7.1010,  -7.2052,  -7.0971,  ...,  -5.6124,  -6.8640,  -6.8631],\n",
      "         [ -7.0560,  -7.2178,  -7.0567,  ...,  -6.0042,  -6.8367,  -5.7182]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7213,  -6.7024,  -6.7231,  ...,  -5.9845,  -5.7659,  -3.9264],\n",
      "         [-11.6058, -10.9541, -11.3934,  ...,  -7.7493, -10.2369,  -6.2683],\n",
      "         [ -5.7530,  -5.8628,  -5.9239,  ...,  -5.6682,  -7.2518,  -4.6040],\n",
      "         ...,\n",
      "         [ -6.6076,  -6.6700,  -6.5995,  ...,  -6.5144,  -7.4207,  -5.6368],\n",
      "         [ -5.5393,  -5.6214,  -5.5753,  ...,  -5.1480,  -6.8924,  -4.7601],\n",
      "         [ -5.8644,  -5.8708,  -5.8543,  ...,  -5.4683,  -6.7176,  -5.3277]],\n",
      "\n",
      "        [[ -7.0860,  -7.0396,  -7.0373,  ...,  -6.3596,  -6.2492,  -4.2017],\n",
      "         [ -8.0444,  -7.9737,  -7.9894,  ...,  -7.9114,  -7.3259,  -6.7308],\n",
      "         [ -7.1922,  -7.2353,  -7.3589,  ...,  -6.9829,  -6.1696,  -7.6412],\n",
      "         ...,\n",
      "         [ -7.3847,  -7.4783,  -7.5103,  ...,  -7.1852,  -6.6534,  -5.6619],\n",
      "         [-16.9597, -17.0041, -16.8918,  ..., -13.9382, -13.6880, -14.9529],\n",
      "         [-16.0749, -15.5354, -16.2060,  ..., -13.7856, -13.7009, -12.1782]],\n",
      "\n",
      "        [[ -6.9355,  -6.8526,  -6.8226,  ...,  -6.0827,  -6.0379,  -3.6102],\n",
      "         [-12.9559, -12.4837, -12.9285,  ...,  -9.6817,  -9.7882,  -8.7191],\n",
      "         [ -5.5206,  -5.6279,  -5.4312,  ...,  -5.2427,  -3.8545,  -7.0142],\n",
      "         ...,\n",
      "         [ -4.6417,  -4.7146,  -4.6694,  ...,  -3.6882,  -3.5126,  -4.4905],\n",
      "         [ -2.8253,  -2.8923,  -2.8689,  ...,  -2.2471,  -2.0294,  -3.8525],\n",
      "         [ -5.7581,  -5.8393,  -5.7457,  ...,  -4.4927,  -4.3886,  -4.5105]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 0, Loss: 2.4652199745178223\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3027, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7727,  -6.8256,  -6.8035,  ...,  -6.1494,  -6.0018,  -3.9383],\n",
      "         [ -6.6902,  -6.8730,  -7.0592,  ...,  -7.4373,  -6.4940,  -5.6595],\n",
      "         [ -6.3410,  -6.4273,  -6.4004,  ...,  -6.2523,  -6.3076,  -5.2166],\n",
      "         ...,\n",
      "         [-11.1677, -11.4904, -11.2411,  ...,  -9.8919,  -9.9414, -14.3736],\n",
      "         [-10.0003,  -9.9617, -10.1142,  ...,  -8.9976, -10.0376, -11.6867],\n",
      "         [-13.0944, -12.9112, -12.9475,  ...,  -9.5645, -11.2021,  -8.6173]],\n",
      "\n",
      "        [[ -7.4326,  -7.5000,  -7.4449,  ...,  -6.9982,  -6.4142,  -4.2585],\n",
      "         [-13.7175, -14.0824, -13.6770,  ..., -10.2556, -11.5724,  -9.5306],\n",
      "         [ -8.2707,  -8.6015,  -8.5624,  ...,  -8.2516,  -7.2444,  -7.3873],\n",
      "         ...,\n",
      "         [ -9.6130,  -9.9913,  -9.9334,  ..., -10.1802,  -9.0020,  -6.3855],\n",
      "         [ -8.0009,  -8.5439,  -8.3717,  ...,  -8.0622,  -6.8513,  -6.3452],\n",
      "         [-12.0426, -11.8590, -12.2520,  ..., -10.6453, -10.7236,  -9.8978]],\n",
      "\n",
      "        [[ -6.7804,  -6.7304,  -6.7054,  ...,  -6.1998,  -5.9828,  -4.1225],\n",
      "         [ -7.0752,  -6.9630,  -7.1259,  ...,  -6.5471,  -5.7638,  -8.6407],\n",
      "         [ -6.9484,  -6.8617,  -6.7452,  ...,  -6.5793,  -6.1128,  -8.1282],\n",
      "         ...,\n",
      "         [ -8.5287,  -8.6303,  -8.4938,  ...,  -8.7631,  -7.8056,  -9.1802],\n",
      "         [-10.0097, -10.4423,  -9.9046,  ...,  -8.6404,  -9.8423,  -9.4349],\n",
      "         [ -7.9420,  -8.0310,  -7.9483,  ...,  -8.3120,  -7.3297,  -8.3476]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5869,  -6.5835,  -6.5962,  ...,  -5.9150,  -5.6929,  -3.8070],\n",
      "         [-13.6745, -13.7525, -14.0159,  ..., -12.9857, -11.2731,  -9.8946],\n",
      "         [-14.6685, -14.4963, -14.6519,  ..., -11.9561, -11.0732,  -9.2794],\n",
      "         ...,\n",
      "         [ -7.1673,  -7.4168,  -7.3476,  ...,  -7.0793,  -6.6431,  -2.2995],\n",
      "         [ -7.5272,  -7.6847,  -7.5762,  ...,  -7.3228,  -7.0564,  -3.6517],\n",
      "         [ -7.7581,  -8.0300,  -7.9519,  ...,  -7.4930,  -6.8154,  -3.5869]],\n",
      "\n",
      "        [[ -7.0289,  -7.0101,  -7.0006,  ...,  -6.3216,  -6.0621,  -4.2561],\n",
      "         [-11.5328, -11.4738, -11.4530,  ..., -11.0453, -10.4314,  -7.6039],\n",
      "         [-13.5677, -13.9899, -14.1067,  ..., -12.3834, -10.1579, -12.2229],\n",
      "         ...,\n",
      "         [ -6.3420,  -6.3823,  -6.2605,  ...,  -6.0318,  -5.4123,  -4.9565],\n",
      "         [ -6.7931,  -6.8814,  -6.7605,  ...,  -6.8339,  -5.7966,  -4.7004],\n",
      "         [ -5.8842,  -5.9493,  -5.7578,  ...,  -6.0042,  -4.8577,  -4.5773]],\n",
      "\n",
      "        [[ -6.7788,  -6.7471,  -6.7062,  ...,  -6.0850,  -6.1069,  -4.2536],\n",
      "         [-11.3398, -11.3042, -11.6390,  ..., -11.3788, -11.0409, -10.7073],\n",
      "         [-11.7271, -11.9427, -12.1789,  ..., -10.5977, -12.1340,  -9.2400],\n",
      "         ...,\n",
      "         [ -8.1044,  -8.1201,  -8.0669,  ...,  -8.3466,  -6.6340,  -6.9956],\n",
      "         [ -6.7710,  -6.7637,  -6.6808,  ...,  -7.1053,  -5.4966,  -7.5384],\n",
      "         [ -8.5911,  -8.4050,  -8.4542,  ...,  -8.6995,  -6.9810,  -7.7801]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.302748441696167\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.7769, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2242,  -7.1831,  -7.2120,  ...,  -6.4864,  -6.4142,  -4.3468],\n",
      "         [-12.9817, -12.9707, -12.8214,  ..., -10.2776, -10.0356, -11.3409],\n",
      "         [ -5.6665,  -5.8012,  -5.8186,  ...,  -6.6093,  -7.8522,  -4.0830],\n",
      "         ...,\n",
      "         [ -5.8738,  -5.9290,  -5.8654,  ...,  -5.8501,  -7.4963,  -5.7650],\n",
      "         [ -5.7194,  -5.8690,  -5.7372,  ...,  -5.9378,  -7.3509,  -4.0438],\n",
      "         [ -5.4845,  -5.5966,  -5.5415,  ...,  -5.9272,  -7.3053,  -5.8774]],\n",
      "\n",
      "        [[ -6.5200,  -6.4584,  -6.4668,  ...,  -5.7910,  -5.5638,  -3.8812],\n",
      "         [ -7.1357,  -6.8827,  -7.1626,  ...,  -4.4363,  -6.8414,  -4.0657],\n",
      "         [ -6.5679,  -6.5892,  -6.6129,  ...,  -6.7609,  -7.3826,  -5.2372],\n",
      "         ...,\n",
      "         [ -6.3886,  -6.3640,  -6.3625,  ...,  -6.1575,  -7.1032,  -4.5953],\n",
      "         [ -7.5777,  -7.5910,  -7.5666,  ...,  -7.5871,  -7.9149,  -6.0994],\n",
      "         [ -6.9400,  -6.9567,  -6.9990,  ...,  -6.9688,  -7.4248,  -5.6080]],\n",
      "\n",
      "        [[ -6.8685,  -6.8206,  -6.8248,  ...,  -6.0767,  -5.9178,  -4.2257],\n",
      "         [ -9.5999,  -9.2546,  -9.4825,  ...,  -7.2655,  -7.8348,  -9.0850],\n",
      "         [ -4.9274,  -4.9183,  -4.8949,  ...,  -5.5297,  -6.7966,  -4.3831],\n",
      "         ...,\n",
      "         [ -6.4827,  -6.4521,  -6.4260,  ...,  -6.5601,  -7.2852,  -5.4544],\n",
      "         [ -5.4852,  -5.5123,  -5.4840,  ...,  -5.4781,  -6.5151,  -4.5795],\n",
      "         [ -5.2890,  -5.2182,  -5.2097,  ...,  -5.6203,  -6.6218,  -4.7703]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1187,  -7.0948,  -7.1056,  ...,  -6.3117,  -6.1549,  -4.2124],\n",
      "         [-12.5252, -12.4099, -12.6756,  ..., -10.9568, -10.4248,  -9.3094],\n",
      "         [ -5.4171,  -5.4850,  -5.4347,  ...,  -5.5708,  -6.9628,  -3.4923],\n",
      "         ...,\n",
      "         [ -5.3628,  -5.5067,  -5.3539,  ...,  -5.4645,  -6.5817,  -4.8677],\n",
      "         [ -5.4754,  -5.5293,  -5.4169,  ...,  -5.6026,  -6.4322,  -4.4200],\n",
      "         [ -5.9241,  -6.0179,  -5.8988,  ...,  -6.0383,  -6.9146,  -4.4873]],\n",
      "\n",
      "        [[ -7.3820,  -7.3812,  -7.3875,  ...,  -6.8139,  -6.4793,  -4.4617],\n",
      "         [ -8.4893,  -8.4656,  -8.6735,  ...,  -7.4431,  -7.3068,  -8.4447],\n",
      "         [-11.3998, -11.3085, -10.3270,  ...,  -9.5930, -10.8398,  -5.4640],\n",
      "         ...,\n",
      "         [ -4.4780,  -4.7714,  -4.3767,  ...,  -5.4109,  -2.7717,  -5.8090],\n",
      "         [ -5.6829,  -6.0416,  -5.8102,  ...,  -5.9874,  -4.8104,  -5.1398],\n",
      "         [ -4.9040,  -5.0679,  -4.8981,  ...,  -5.2771,  -3.7442,  -4.2241]],\n",
      "\n",
      "        [[ -6.4748,  -6.4227,  -6.4713,  ...,  -5.7589,  -5.7458,  -3.7527],\n",
      "         [-10.9223, -10.6958, -11.0265,  ..., -10.9365, -10.5775,  -7.5490],\n",
      "         [-10.2067, -10.0769, -10.2920,  ...,  -9.8677,  -8.2246,  -7.8382],\n",
      "         ...,\n",
      "         [ -6.1583,  -6.0794,  -6.2622,  ...,  -6.1615,  -6.0522,  -4.1439],\n",
      "         [ -6.5140,  -6.2775,  -6.4453,  ...,  -6.5640,  -6.2314,  -4.4678],\n",
      "         [ -6.8093,  -6.6152,  -6.7968,  ...,  -6.6805,  -6.7528,  -4.3137]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.7769137024879456\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2015, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0506,  -6.9820,  -7.0275,  ...,  -6.1295,  -6.1892,  -4.0447],\n",
      "         [-12.4981, -11.9295, -12.0226,  ..., -10.6342, -10.8528,  -8.0835],\n",
      "         [ -4.9289,  -4.9695,  -4.9007,  ...,  -5.6120,  -7.1163,  -2.9228],\n",
      "         ...,\n",
      "         [ -6.0061,  -6.0658,  -6.0801,  ...,  -6.2973,  -7.6041,  -5.0244],\n",
      "         [ -6.3806,  -6.3962,  -6.3444,  ...,  -7.0330,  -7.6756,  -5.4619],\n",
      "         [ -5.8820,  -5.9661,  -5.7794,  ...,  -6.2948,  -7.2890,  -5.6280]],\n",
      "\n",
      "        [[ -6.8161,  -6.7961,  -6.7586,  ...,  -6.2552,  -5.9645,  -4.2795],\n",
      "         [ -5.2727,  -5.3434,  -5.3101,  ...,  -5.7052,  -4.2923,  -5.8726],\n",
      "         [-10.5951, -11.1266, -10.4127,  ..., -10.6911,  -8.5034, -10.2647],\n",
      "         ...,\n",
      "         [ -6.0511,  -6.2167,  -6.1121,  ...,  -5.3336,  -5.6756,  -5.5186],\n",
      "         [ -6.0766,  -6.2835,  -6.2030,  ...,  -5.9798,  -5.8939,  -5.7445],\n",
      "         [ -6.0806,  -6.2896,  -6.2104,  ...,  -5.6006,  -5.8454,  -4.9706]],\n",
      "\n",
      "        [[ -6.4862,  -6.4545,  -6.5667,  ...,  -5.8303,  -5.9481,  -3.2364],\n",
      "         [ -5.5586,  -5.4766,  -5.7359,  ...,  -6.0039,  -5.9413,  -2.2911],\n",
      "         [ -8.1080,  -8.1547,  -8.1905,  ...,  -8.0095,  -8.5039,  -3.4593],\n",
      "         ...,\n",
      "         [ -5.5545,  -5.4858,  -5.5817,  ...,  -5.6193,  -5.9105,  -1.8850],\n",
      "         [ -5.4005,  -5.1501,  -5.3135,  ...,  -5.6793,  -5.5906,  -2.4222],\n",
      "         [ -5.9990,  -5.8408,  -5.9354,  ...,  -6.0662,  -6.0146,  -2.0928]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8706,  -6.8186,  -6.8084,  ...,  -6.0396,  -6.0689,  -4.1312],\n",
      "         [ -8.8510,  -8.6221,  -8.7060,  ...,  -9.3469,  -7.1141,  -9.8033],\n",
      "         [ -3.0737,  -2.9360,  -2.9478,  ...,  -2.6967,  -3.7535,  -1.2689],\n",
      "         ...,\n",
      "         [ -6.8733,  -6.8784,  -6.8056,  ...,  -6.4010,  -6.2257,  -5.0071],\n",
      "         [ -6.1331,  -6.0769,  -6.0383,  ...,  -5.5517,  -5.8826,  -4.9032],\n",
      "         [ -6.4987,  -6.5889,  -6.5367,  ...,  -6.1024,  -5.9869,  -4.8906]],\n",
      "\n",
      "        [[ -6.8469,  -6.7959,  -6.7989,  ...,  -6.2177,  -5.9779,  -4.2611],\n",
      "         [-14.0478, -14.4869, -14.2977,  ..., -12.8923, -11.6361, -12.1090],\n",
      "         [-10.9984, -11.2130, -10.8282,  ..., -12.5054,  -9.1363, -12.2810],\n",
      "         ...,\n",
      "         [ -7.7005,  -7.7022,  -7.5792,  ...,  -6.9941,  -6.6214,  -7.7326],\n",
      "         [ -7.2675,  -7.5483,  -7.3090,  ...,  -7.1325,  -7.5110,  -5.0640],\n",
      "         [-14.1011, -13.8206, -13.8407,  ..., -11.9542, -12.4493,  -7.7571]],\n",
      "\n",
      "        [[ -6.5710,  -6.5166,  -6.5244,  ...,  -5.8907,  -5.6442,  -3.8775],\n",
      "         [-13.4342, -13.1729, -13.0877,  ..., -10.9032, -11.1584, -12.1222],\n",
      "         [ -5.4442,  -5.6065,  -5.5017,  ...,  -5.6899,  -6.7581,  -3.6576],\n",
      "         ...,\n",
      "         [ -6.1643,  -6.2766,  -6.2078,  ...,  -6.2171,  -6.8300,  -5.7728],\n",
      "         [ -5.7013,  -5.8133,  -5.7455,  ...,  -5.2615,  -6.9040,  -4.5305],\n",
      "         [ -5.9934,  -6.0522,  -5.9885,  ...,  -5.8937,  -6.9508,  -4.8342]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.2015186548233032\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1795, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6633,  -6.6482,  -6.6427,  ...,  -6.0222,  -5.8616,  -3.9009],\n",
      "         [ -7.9160,  -8.3345,  -7.9745,  ...,  -7.3491,  -6.3022,  -5.4146],\n",
      "         [ -8.1828,  -8.5887,  -8.3146,  ...,  -8.1071,  -7.6910, -10.2287],\n",
      "         ...,\n",
      "         [ -7.3191,  -7.4040,  -7.5673,  ...,  -6.4837,  -7.0928,  -7.4857],\n",
      "         [ -7.6271,  -7.8640,  -7.9256,  ...,  -6.8656,  -7.0237,  -6.8919],\n",
      "         [-15.3166, -14.8825, -15.0529,  ..., -12.4098, -12.6117, -11.0634]],\n",
      "\n",
      "        [[ -8.7064,  -8.7851,  -8.8088,  ...,  -7.6962,  -7.6687,  -5.4769],\n",
      "         [-13.0802, -12.8568, -12.5223,  ..., -10.4796,  -9.2308,  -9.4714],\n",
      "         [ -5.1203,  -5.1503,  -5.2290,  ...,  -5.3545,  -6.9553,  -4.5072],\n",
      "         ...,\n",
      "         [ -5.4038,  -5.4248,  -5.3723,  ...,  -5.3111,  -6.6095,  -5.5880],\n",
      "         [ -5.3057,  -5.2818,  -5.2391,  ...,  -5.2361,  -6.1092,  -5.7223],\n",
      "         [ -5.0307,  -5.0461,  -5.0573,  ...,  -4.9476,  -6.5503,  -5.3171]],\n",
      "\n",
      "        [[ -7.4024,  -7.4423,  -7.3986,  ...,  -6.9613,  -6.7272,  -4.3282],\n",
      "         [ -7.7803,  -7.4850,  -7.7001,  ...,  -7.9942,  -9.0502,  -6.3769],\n",
      "         [ -9.6545,  -9.6717,  -9.6199,  ...,  -9.0093,  -8.2628, -10.3131],\n",
      "         ...,\n",
      "         [ -8.1153,  -8.2490,  -8.1258,  ...,  -7.7621,  -8.4598,  -6.5824],\n",
      "         [ -7.0767,  -7.1760,  -6.9191,  ...,  -7.3405,  -7.2079,  -9.0260],\n",
      "         [ -8.7171,  -8.8240,  -8.7123,  ...,  -8.0404,  -8.2939,  -7.3971]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7856,  -6.7349,  -6.7282,  ...,  -6.0715,  -5.8499,  -4.3111],\n",
      "         [-10.0118, -10.1911,  -9.9918,  ...,  -9.3496,  -8.6631,  -8.4103],\n",
      "         [ -3.4296,  -3.5151,  -3.6228,  ...,  -3.3063,  -3.6378,  -5.8087],\n",
      "         ...,\n",
      "         [ -5.2591,  -5.3868,  -5.2068,  ...,  -5.5739,  -4.7600,  -6.5709],\n",
      "         [ -6.0364,  -6.1620,  -5.9506,  ...,  -5.6192,  -5.4602,  -6.1002],\n",
      "         [ -6.3650,  -6.4495,  -6.4139,  ...,  -6.6103,  -6.4303,  -5.5623]],\n",
      "\n",
      "        [[ -6.7853,  -6.7522,  -6.7591,  ...,  -6.0629,  -5.8620,  -3.9896],\n",
      "         [ -8.8891,  -9.0150,  -9.1752,  ...,  -8.0159,  -8.7328,  -3.2215],\n",
      "         [ -5.4116,  -5.6304,  -5.4478,  ...,  -6.2440,  -6.0456,  -3.4265],\n",
      "         ...,\n",
      "         [ -7.7362,  -7.6643,  -7.5442,  ...,  -7.6612,  -7.0974,  -5.2475],\n",
      "         [ -7.6738,  -7.6915,  -7.5895,  ...,  -7.7050,  -7.2000,  -4.6715],\n",
      "         [ -7.7611,  -7.8446,  -7.7581,  ...,  -7.8083,  -7.2632,  -5.0628]],\n",
      "\n",
      "        [[ -6.4726,  -6.4068,  -6.4082,  ...,  -5.7341,  -5.6370,  -3.6927],\n",
      "         [ -6.8383,  -6.7110,  -6.7668,  ...,  -7.6462,  -7.9760,  -2.7738],\n",
      "         [ -7.7484,  -7.5960,  -7.7987,  ...,  -8.6379,  -8.4511,  -5.0807],\n",
      "         ...,\n",
      "         [ -5.3468,  -5.2204,  -5.3657,  ...,  -5.7131,  -6.3999,  -0.6617],\n",
      "         [ -5.2014,  -5.1354,  -5.2921,  ...,  -5.4410,  -5.9982,  -0.9088],\n",
      "         [ -5.3292,  -5.3158,  -5.4027,  ...,  -5.6714,  -6.1320,  -1.3412]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.179452419281006\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0513, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2387,  -7.2403,  -7.2063,  ...,  -6.6197,  -6.4387,  -4.3976],\n",
      "         [ -9.4860,  -9.5473,  -9.6057,  ..., -10.2659,  -9.8214,  -6.6302],\n",
      "         [-11.5941, -11.5322, -11.4534,  ..., -10.4006,  -9.7737, -11.8162],\n",
      "         ...,\n",
      "         [ -5.9800,  -5.7214,  -5.9325,  ...,  -4.8218,  -6.2638,  -4.2448],\n",
      "         [-16.6154, -16.7146, -17.0317,  ..., -15.5734, -14.1210, -11.0709],\n",
      "         [-14.2587, -13.9939, -13.9756,  ..., -10.4377, -11.3281, -10.6248]],\n",
      "\n",
      "        [[ -7.4707,  -7.4483,  -7.4494,  ...,  -6.8366,  -6.5875,  -4.4713],\n",
      "         [-12.9732, -13.0298, -13.0963,  ..., -13.2486, -12.1343, -11.4066],\n",
      "         [ -1.4736,  -2.0285,  -1.7461,  ...,  -0.8576,  -2.4234,  -4.1271],\n",
      "         ...,\n",
      "         [-12.9203, -12.9246, -12.6327,  ..., -11.0196, -10.1507, -13.3077],\n",
      "         [ -7.8339,  -7.9984,  -7.9211,  ...,  -7.9035,  -6.6293,  -7.8783],\n",
      "         [-14.7684, -14.3093, -14.5224,  ..., -12.1559, -11.5973, -11.9049]],\n",
      "\n",
      "        [[ -6.5721,  -6.5126,  -6.5336,  ...,  -5.7271,  -5.8174,  -3.6700],\n",
      "         [ -7.6596,  -7.5489,  -7.6044,  ...,  -6.9387,  -6.9936,  -4.6700],\n",
      "         [ -5.0226,  -5.1128,  -5.0458,  ...,  -3.9984,  -6.0040,  -4.2869],\n",
      "         ...,\n",
      "         [ -5.7792,  -5.7373,  -5.5918,  ...,  -4.7820,  -5.9237,  -3.2479],\n",
      "         [ -5.7973,  -5.7552,  -5.7745,  ...,  -4.9323,  -5.9969,  -3.6631],\n",
      "         [ -6.0475,  -5.9936,  -5.9605,  ...,  -5.4051,  -6.3251,  -3.5035]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9951,  -6.9578,  -6.9991,  ...,  -6.3204,  -6.1722,  -4.3735],\n",
      "         [ -7.2558,  -7.2472,  -7.2130,  ...,  -7.1096,  -6.5357,  -6.6403],\n",
      "         [ -7.0690,  -7.0625,  -7.2885,  ...,  -7.5753,  -6.7885,  -7.2020],\n",
      "         ...,\n",
      "         [ -6.7951,  -7.0055,  -6.8304,  ...,  -5.9329,  -7.2200,  -5.8898],\n",
      "         [ -6.8924,  -7.1533,  -6.9536,  ...,  -5.0533,  -6.2939,  -6.9399],\n",
      "         [-14.3560, -13.9562, -14.2263,  ..., -12.9336, -11.1837,  -9.0760]],\n",
      "\n",
      "        [[ -6.9533,  -6.9600,  -6.8983,  ...,  -6.2880,  -5.9683,  -4.1507],\n",
      "         [-15.3416, -15.1048, -15.3179,  ..., -13.8658, -12.8461, -13.8905],\n",
      "         [ -8.7363,  -8.8267,  -8.8626,  ...,  -8.9682,  -8.2401,  -6.4572],\n",
      "         ...,\n",
      "         [  0.1309,  -0.1569,   0.1670,  ...,  -0.7082,   0.5116,  -1.2483],\n",
      "         [-13.7049, -13.6288, -13.6383,  ..., -11.9372,  -9.8914,  -8.1342],\n",
      "         [-13.3899, -13.0524, -13.1445,  ..., -11.5584, -10.3705,  -9.8332]],\n",
      "\n",
      "        [[ -7.6433,  -7.5729,  -7.6508,  ...,  -7.5639,  -8.2315,  -3.7368],\n",
      "         [-12.8894, -12.5648, -13.0394,  ..., -11.3893, -11.5211, -10.2793],\n",
      "         [ -5.6578,  -5.7247,  -5.6791,  ...,  -5.8676,  -6.8471,  -4.8265],\n",
      "         ...,\n",
      "         [ -5.9138,  -5.9865,  -5.8249,  ...,  -6.4679,  -6.8662,  -4.8899],\n",
      "         [ -5.8091,  -5.8368,  -5.6844,  ...,  -6.1900,  -6.2702,  -5.0826],\n",
      "         [ -6.1106,  -6.1713,  -6.1219,  ...,  -6.3735,  -6.8902,  -5.1281]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.051346778869629\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5995, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5846,  -6.5263,  -6.5548,  ...,  -5.8021,  -5.7529,  -4.0926],\n",
      "         [ -7.5354,  -7.4691,  -7.4339,  ...,  -7.1127,  -7.0320,  -4.6659],\n",
      "         [ -5.2428,  -5.4612,  -5.2799,  ...,  -5.2955,  -6.8592,  -4.5310],\n",
      "         ...,\n",
      "         [ -5.5152,  -5.6960,  -5.5088,  ...,  -5.1543,  -6.8228,  -4.9331],\n",
      "         [ -5.1970,  -5.3882,  -5.3525,  ...,  -5.4878,  -6.6543,  -3.9341],\n",
      "         [ -6.2841,  -6.4498,  -6.3376,  ...,  -5.8986,  -7.2098,  -4.8041]],\n",
      "\n",
      "        [[ -7.0702,  -7.0809,  -7.0426,  ...,  -6.3976,  -6.1481,  -4.2801],\n",
      "         [-13.6995, -13.5120, -13.6185,  ..., -11.6670, -11.1446, -11.9754],\n",
      "         [-10.3858, -10.6943, -10.2505,  ...,  -9.9831,  -8.3869, -15.7555],\n",
      "         ...,\n",
      "         [ -6.5955,  -6.7057,  -6.5752,  ...,  -5.5300,  -6.4444,  -5.9836],\n",
      "         [ -6.6581,  -6.8353,  -6.7270,  ...,  -5.9565,  -6.0601,  -5.9706],\n",
      "         [ -5.2870,  -5.3663,  -5.3038,  ...,  -5.0365,  -5.0757,  -5.7470]],\n",
      "\n",
      "        [[ -7.0274,  -7.0204,  -6.9405,  ...,  -6.2363,  -6.3700,  -4.1154],\n",
      "         [ -6.5302,  -6.8375,  -6.5975,  ...,  -5.5616,  -5.7665,  -5.6025],\n",
      "         [-13.6576, -13.5486, -13.6663,  ..., -11.2143, -10.7937, -10.8916],\n",
      "         ...,\n",
      "         [ -1.0874,  -1.7330,  -1.4582,  ...,  -0.7172,  -1.3103,  -5.3478],\n",
      "         [ -4.9119,  -5.3162,  -5.1478,  ...,  -5.4429,  -5.1651,  -6.9121],\n",
      "         [ -6.6368,  -6.8346,  -6.7663,  ...,  -6.7207,  -6.2922,  -8.2741]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8686,  -6.8434,  -6.8445,  ...,  -6.1156,  -6.1336,  -4.1623],\n",
      "         [ -9.6757,  -9.8163,  -9.7487,  ..., -10.3800,  -9.6417,  -3.9245],\n",
      "         [-12.6395, -12.8250, -12.5221,  ..., -13.2222, -11.6793,  -9.0387],\n",
      "         ...,\n",
      "         [ -7.0548,  -7.2766,  -7.0408,  ...,  -6.7403,  -5.6395,  -5.5366],\n",
      "         [ -6.3230,  -6.3715,  -6.0013,  ...,  -7.1605,  -6.4165,  -5.5585],\n",
      "         [ -7.5165,  -7.6472,  -7.4914,  ...,  -7.9515,  -7.3784,  -6.3553]],\n",
      "\n",
      "        [[ -6.7287,  -6.7692,  -6.7467,  ...,  -6.1746,  -6.3682,  -3.7933],\n",
      "         [ -7.5461,  -7.7926,  -7.6659,  ...,  -8.4832,  -7.5921,  -6.1400],\n",
      "         [ -6.9404,  -7.0214,  -6.8058,  ...,  -7.4853,  -6.9410,  -5.2764],\n",
      "         ...,\n",
      "         [ -8.0437,  -8.2955,  -8.2986,  ...,  -8.5292,  -7.0801,  -7.0252],\n",
      "         [ -7.7986,  -7.9513,  -7.8897,  ...,  -8.1594,  -6.8074,  -6.0909],\n",
      "         [ -7.6607,  -7.9048,  -7.8145,  ...,  -7.7697,  -6.5552,  -6.3148]],\n",
      "\n",
      "        [[ -6.6820,  -6.6149,  -6.6111,  ...,  -6.0484,  -6.0633,  -3.9274],\n",
      "         [ -7.1408,  -7.2101,  -7.0287,  ...,  -7.9457,  -6.1320,  -5.7466],\n",
      "         [-12.3015, -12.7846, -11.9714,  ..., -10.3617,  -8.9708, -14.8834],\n",
      "         ...,\n",
      "         [ -5.7245,  -5.9469,  -5.6508,  ...,  -5.6672,  -5.9881,  -3.9973],\n",
      "         [ -6.9491,  -7.2466,  -7.1158,  ...,  -6.2669,  -7.6480,  -5.3291],\n",
      "         [ -7.6034,  -7.7162,  -7.8873,  ...,  -7.3864,  -7.8343,  -6.2160]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.599470615386963\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6657, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4288,  -6.3958,  -6.4102,  ...,  -5.6993,  -5.5721,  -3.5468],\n",
      "         [ -8.0994,  -7.8195,  -7.8835,  ...,  -8.0115,  -8.3510,  -6.7329],\n",
      "         [ -5.9579,  -6.0357,  -5.8965,  ...,  -5.6206,  -6.1722,  -5.3240],\n",
      "         ...,\n",
      "         [ -5.5164,  -5.4278,  -5.3695,  ...,  -5.2488,  -5.7820,  -3.6626],\n",
      "         [ -6.0002,  -5.9113,  -5.9072,  ...,  -5.8454,  -6.4017,  -3.8981],\n",
      "         [ -4.9493,  -4.7845,  -4.9449,  ...,  -4.4887,  -5.5422,  -3.4597]],\n",
      "\n",
      "        [[ -7.1271,  -7.1228,  -7.1339,  ...,  -6.2545,  -6.3146,  -4.2342],\n",
      "         [-13.3178, -13.2497, -13.2372,  ..., -10.6361, -10.4299, -10.6183],\n",
      "         [ -6.8219,  -6.8074,  -6.8659,  ...,  -6.7028,  -8.2275,  -4.0444],\n",
      "         ...,\n",
      "         [ -6.3360,  -6.3559,  -6.2031,  ...,  -6.1025,  -7.0844,  -3.9829],\n",
      "         [ -6.5848,  -6.7459,  -6.6228,  ...,  -6.6763,  -7.9626,  -5.1307],\n",
      "         [ -6.6503,  -6.6577,  -6.4582,  ...,  -5.7571,  -7.0955,  -4.2537]],\n",
      "\n",
      "        [[ -6.7209,  -6.6662,  -6.7043,  ...,  -5.9078,  -6.0211,  -3.8294],\n",
      "         [ -8.6645,  -8.4256,  -8.5560,  ...,  -8.6435,  -8.4969,  -4.7376],\n",
      "         [ -7.7023,  -7.4235,  -7.5351,  ...,  -7.7630,  -6.5699,  -5.9775],\n",
      "         ...,\n",
      "         [ -5.8518,  -5.7255,  -5.7390,  ...,  -5.9776,  -6.2667,  -2.9486],\n",
      "         [ -5.9408,  -5.8646,  -5.9092,  ...,  -5.9019,  -6.0927,  -3.1352],\n",
      "         [ -6.3426,  -6.1696,  -6.2485,  ...,  -6.2724,  -6.6725,  -2.9080]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4749,  -6.4332,  -6.4488,  ...,  -5.7181,  -5.5558,  -3.8881],\n",
      "         [-12.4133, -12.0082, -12.1561,  ...,  -9.7004,  -9.3591,  -9.3180],\n",
      "         [ -5.4550,  -5.5315,  -5.5171,  ...,  -5.9179,  -7.3470,  -5.0690],\n",
      "         ...,\n",
      "         [ -6.1471,  -6.1670,  -6.0853,  ...,  -6.3707,  -7.3720,  -4.9064],\n",
      "         [ -5.6581,  -5.7007,  -5.6729,  ...,  -6.0636,  -6.7953,  -4.4951],\n",
      "         [ -6.8091,  -6.8659,  -6.8507,  ...,  -6.9841,  -7.8143,  -4.6333]],\n",
      "\n",
      "        [[ -6.8026,  -6.7375,  -6.7390,  ...,  -6.0193,  -5.7985,  -4.0217],\n",
      "         [ -5.3119,  -5.1619,  -5.2697,  ...,  -4.5638,  -6.8399,  -3.4030],\n",
      "         [-14.9935, -15.3812, -15.4088,  ..., -14.3101, -13.8878,  -9.0369],\n",
      "         ...,\n",
      "         [ -6.8005,  -6.8866,  -6.9720,  ...,  -6.1850,  -6.4203,  -5.0928],\n",
      "         [ -7.3449,  -7.5358,  -7.7595,  ...,  -7.0007,  -7.2494,  -4.1200],\n",
      "         [ -6.8871,  -6.9858,  -7.1981,  ...,  -6.3171,  -7.1883,  -4.1026]],\n",
      "\n",
      "        [[ -7.0334,  -7.0260,  -6.9720,  ...,  -6.4417,  -6.2142,  -4.5246],\n",
      "         [ -7.2108,  -7.1420,  -6.9964,  ...,  -6.3234,  -6.8488,  -8.9200],\n",
      "         [-10.1713,  -9.9711,  -9.7173,  ...,  -9.3349, -10.1056,  -7.9349],\n",
      "         ...,\n",
      "         [-14.3462, -14.4702, -14.0342,  ..., -13.4889, -12.5476, -13.1673],\n",
      "         [-10.9795, -10.6076, -10.4417,  ...,  -9.2478,  -9.7151, -10.4308],\n",
      "         [-13.1510, -12.9418, -13.3649,  ..., -10.2146, -10.5075,  -9.0300]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.665748119354248\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0541, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9619,  -6.9138,  -6.9064,  ...,  -6.1441,  -5.9352,  -4.0274],\n",
      "         [ -9.8787,  -9.8664,  -9.4031,  ...,  -9.6253,  -8.7410,  -9.3840],\n",
      "         [-10.8866, -10.5083, -10.6567,  ...,  -8.1419,  -8.5379,  -9.1819],\n",
      "         ...,\n",
      "         [ -7.1862,  -7.2702,  -6.8948,  ...,  -7.7171,  -6.8294,  -5.0902],\n",
      "         [ -8.7133,  -8.4311,  -8.4683,  ...,  -6.5400,  -7.0068,  -7.8042],\n",
      "         [ -7.5073,  -7.5105,  -7.4014,  ...,  -8.0235,  -7.1725,  -4.8405]],\n",
      "\n",
      "        [[ -7.6502,  -7.5982,  -7.6035,  ...,  -7.1162,  -7.0267,  -4.4577],\n",
      "         [-11.3773, -11.1560, -11.1899,  ...,  -7.8662,  -8.2862, -10.5382],\n",
      "         [ -4.8219,  -4.6943,  -4.8264,  ...,  -5.2900,  -6.2292,  -4.2225],\n",
      "         ...,\n",
      "         [ -5.1370,  -5.0785,  -5.0906,  ...,  -5.0279,  -6.3979,  -4.2781],\n",
      "         [ -6.3007,  -6.2139,  -6.1872,  ...,  -6.3518,  -7.0577,  -5.3654],\n",
      "         [ -5.9641,  -5.8473,  -6.0141,  ...,  -5.8381,  -6.8079,  -4.5305]],\n",
      "\n",
      "        [[ -6.7350,  -6.6851,  -6.7114,  ...,  -5.8901,  -5.8316,  -3.8139],\n",
      "         [ -7.7705,  -7.7754,  -7.8285,  ...,  -7.5700,  -7.9477,  -4.9361],\n",
      "         [ -2.7359,  -2.7326,  -2.8206,  ...,  -3.4446,  -3.0422,  -3.5643],\n",
      "         ...,\n",
      "         [ -7.7879,  -7.7448,  -7.7913,  ...,  -7.5309,  -7.8859,  -5.8474],\n",
      "         [ -6.9363,  -6.8330,  -6.8805,  ...,  -6.7626,  -7.4478,  -5.4846],\n",
      "         [ -7.9637,  -7.9658,  -8.0511,  ...,  -7.6976,  -8.1577,  -6.3833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6293,  -6.5819,  -6.5987,  ...,  -5.8726,  -5.7106,  -4.1468],\n",
      "         [ -9.2764,  -8.9601,  -8.6855,  ...,  -7.5813,  -6.8982,  -8.7288],\n",
      "         [ -5.2740,  -5.3503,  -5.0661,  ...,  -5.8822,  -4.2307,  -5.8681],\n",
      "         ...,\n",
      "         [ -1.8308,  -2.0477,  -1.8138,  ...,  -2.3929,  -1.3912,  -4.6888],\n",
      "         [ -6.3250,  -6.4140,  -6.2804,  ...,  -7.0741,  -5.8463,  -6.4914],\n",
      "         [ -6.4858,  -6.5250,  -6.4737,  ...,  -6.8858,  -6.3756,  -6.7017]],\n",
      "\n",
      "        [[ -7.2190,  -7.1684,  -7.1759,  ...,  -6.4404,  -6.2266,  -4.4907],\n",
      "         [-14.3060, -13.8054, -13.8099,  ..., -10.4949, -12.1772, -11.4166],\n",
      "         [ -4.2948,  -4.3599,  -4.2233,  ...,  -4.4568,  -6.0075,  -3.4953],\n",
      "         ...,\n",
      "         [ -5.3688,  -5.3385,  -5.2208,  ...,  -5.6204,  -5.8877,  -4.2180],\n",
      "         [ -4.7777,  -4.7352,  -4.6436,  ...,  -4.9619,  -6.0364,  -3.7437],\n",
      "         [ -5.2221,  -5.2234,  -5.2305,  ...,  -5.4473,  -5.9462,  -3.2806]],\n",
      "\n",
      "        [[ -6.5832,  -6.5339,  -6.5661,  ...,  -5.8604,  -5.7551,  -3.9027],\n",
      "         [-11.8806, -11.4165, -11.8303,  ...,  -8.5627, -10.4434, -11.1185],\n",
      "         [ -5.4187,  -5.5445,  -5.5064,  ...,  -5.7777,  -7.3548,  -4.8170],\n",
      "         ...,\n",
      "         [ -5.2671,  -5.4086,  -5.2985,  ...,  -5.5004,  -6.7449,  -5.0358],\n",
      "         [ -6.0672,  -6.2330,  -6.1151,  ...,  -6.0827,  -7.1671,  -4.9724],\n",
      "         [ -5.8799,  -6.0911,  -5.9416,  ...,  -6.2629,  -7.6028,  -5.1909]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.054131507873535\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8580, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7562,  -6.6854,  -6.7116,  ...,  -6.0841,  -5.8067,  -4.0082],\n",
      "         [ -8.4871,  -8.5157,  -8.6049,  ...,  -6.7506,  -8.0097,  -7.7938],\n",
      "         [-10.1040, -10.2281, -10.2581,  ...,  -9.6106, -10.2637,  -6.8433],\n",
      "         ...,\n",
      "         [ -7.6357,  -7.4656,  -7.2912,  ...,  -5.9256,  -4.9648,  -8.1677],\n",
      "         [ -7.2008,  -7.4779,  -7.2202,  ...,  -6.8916,  -6.5717,  -3.7048],\n",
      "         [ -8.2746,  -8.1684,  -8.1754,  ...,  -7.2465,  -7.3538,  -6.9988]],\n",
      "\n",
      "        [[ -7.3303,  -7.3540,  -7.3076,  ...,  -6.9144,  -6.5097,  -4.7263],\n",
      "         [ -8.9368,  -9.1728,  -8.2991,  ...,  -8.8166,  -6.9036, -11.9054],\n",
      "         [ -3.4119,  -3.5020,  -3.3346,  ...,  -4.0387,  -2.7743,  -5.7447],\n",
      "         ...,\n",
      "         [ -5.4171,  -5.6138,  -5.3569,  ...,  -5.1981,  -4.7565,  -6.4001],\n",
      "         [ -5.8339,  -5.8758,  -6.0119,  ...,  -5.9096,  -5.3123,  -6.4880],\n",
      "         [ -5.9751,  -6.2521,  -6.0284,  ...,  -6.3713,  -5.6504,  -6.8212]],\n",
      "\n",
      "        [[ -6.9399,  -6.8516,  -6.8568,  ...,  -6.2616,  -6.0283,  -4.1837],\n",
      "         [ -8.0042,  -7.6615,  -7.9107,  ...,  -7.0303,  -8.2058,  -4.1500],\n",
      "         [ -8.2516,  -9.0280,  -9.2560,  ...,  -8.7815,  -9.0431,  -8.9768],\n",
      "         ...,\n",
      "         [ -6.6290,  -6.5150,  -6.6894,  ...,  -5.7845,  -6.7618,  -3.9998],\n",
      "         [ -6.5824,  -6.5153,  -6.5860,  ...,  -5.7702,  -6.6284,  -3.5635],\n",
      "         [ -6.1655,  -6.2098,  -6.2711,  ...,  -5.7140,  -6.5016,  -4.7532]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0717,  -7.0286,  -7.0747,  ...,  -6.3135,  -6.1930,  -4.1157],\n",
      "         [-15.9567, -15.6364, -15.7332,  ..., -13.7186, -13.4124, -16.3112],\n",
      "         [ -7.8175,  -7.8060,  -7.8337,  ...,  -6.7001,  -8.1405,  -7.9885],\n",
      "         ...,\n",
      "         [ -7.4628,  -7.7074,  -7.8460,  ...,  -8.0134,  -8.2478,  -7.2440],\n",
      "         [ -7.3148,  -7.4402,  -7.5584,  ...,  -7.2323,  -7.5859,  -6.8381],\n",
      "         [ -7.9140,  -8.0005,  -8.1773,  ...,  -7.9966,  -8.1131,  -6.7562]],\n",
      "\n",
      "        [[ -6.6799,  -6.5996,  -6.6351,  ...,  -5.8535,  -5.7847,  -4.0142],\n",
      "         [-10.4540, -10.4346, -10.4103,  ...,  -9.5346,  -8.0371,  -9.2486],\n",
      "         [ -5.7978,  -5.8527,  -5.8573,  ...,  -6.1289,  -6.7704,  -6.1324],\n",
      "         ...,\n",
      "         [ -4.5613,  -4.5636,  -4.5339,  ...,  -4.4980,  -5.6952,  -4.5149],\n",
      "         [ -5.0776,  -5.2288,  -5.2015,  ...,  -5.1513,  -6.7232,  -4.3847],\n",
      "         [ -6.2650,  -6.3260,  -6.2681,  ...,  -6.0551,  -6.9298,  -6.1750]],\n",
      "\n",
      "        [[ -7.7843,  -7.7799,  -7.7226,  ...,  -7.0593,  -6.8645,  -4.2786],\n",
      "         [-15.8802, -15.3971, -15.7921,  ..., -13.6502, -12.2433, -12.5034],\n",
      "         [-17.6709, -17.3503, -17.3545,  ..., -15.1782, -12.3748, -13.7587],\n",
      "         ...,\n",
      "         [ -5.7579,  -6.1199,  -5.9563,  ...,  -6.9906,  -6.0893,  -4.8021],\n",
      "         [-15.2215, -14.9594, -15.1789,  ..., -11.9552, -13.6491, -10.3645],\n",
      "         [-14.4744, -14.3325, -14.4094,  ..., -11.9503, -11.8702,  -9.4939]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.858020544052124\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7008, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6333,  -6.6000,  -6.5870,  ...,  -5.9684,  -5.6758,  -4.0451],\n",
      "         [-12.5222, -12.0370, -12.4929,  ...,  -9.9357, -10.3205, -10.2588],\n",
      "         [ -5.7488,  -5.9297,  -5.8844,  ...,  -6.1943,  -7.4539,  -4.9518],\n",
      "         ...,\n",
      "         [ -5.9244,  -6.0184,  -5.9854,  ...,  -6.1566,  -7.0688,  -5.0136],\n",
      "         [ -6.0310,  -6.2855,  -6.1752,  ...,  -6.3707,  -7.5235,  -4.5839],\n",
      "         [ -5.6414,  -5.9031,  -5.8046,  ...,  -5.8312,  -7.0322,  -4.5579]],\n",
      "\n",
      "        [[ -7.0076,  -6.9488,  -6.9265,  ...,  -6.2940,  -6.2217,  -4.5245],\n",
      "         [-11.2978, -11.2711, -11.3862,  ..., -10.0421, -10.1213,  -8.1934],\n",
      "         [-12.9798, -12.8684, -12.5789,  ..., -10.5350,  -9.7262, -13.3365],\n",
      "         ...,\n",
      "         [-13.0503, -13.0571, -12.7182,  ..., -10.9102,  -9.8427,  -7.8266],\n",
      "         [-13.3909, -13.3595, -13.0145,  ..., -11.1069, -10.9935,  -9.0326],\n",
      "         [-14.6864, -14.3098, -14.4591,  ..., -12.3130, -12.4203, -10.2073]],\n",
      "\n",
      "        [[ -7.7720,  -7.6427,  -7.6130,  ...,  -6.9923,  -7.0132,  -4.9896],\n",
      "         [-11.3240, -11.4619, -11.4657,  ..., -10.1802,  -9.1978,  -9.5100],\n",
      "         [ -5.8041,  -5.8141,  -5.7511,  ...,  -6.5241,  -7.0028,  -3.5877],\n",
      "         ...,\n",
      "         [ -6.5086,  -6.5871,  -6.4091,  ...,  -6.7792,  -6.7011,  -5.4222],\n",
      "         [ -6.3783,  -6.3654,  -6.3127,  ...,  -7.1262,  -7.2627,  -4.8178],\n",
      "         [ -6.1742,  -6.2062,  -6.1432,  ...,  -6.7666,  -7.2189,  -4.8506]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0259,  -7.0474,  -7.0245,  ...,  -6.2740,  -6.1642,  -4.2721],\n",
      "         [-14.5488, -14.3241, -14.5045,  ..., -13.4665, -11.6020, -13.4893],\n",
      "         [ -9.8036, -10.2425, -10.3360,  ...,  -8.7053,  -7.4071, -10.0556],\n",
      "         ...,\n",
      "         [ -6.5066,  -6.6099,  -6.6892,  ...,  -6.7537,  -5.9536,  -6.4163],\n",
      "         [ -6.0074,  -6.1420,  -6.1884,  ...,  -6.2732,  -4.9781,  -5.6542],\n",
      "         [-13.8405, -13.5929, -13.8836,  ..., -11.3172, -10.7145,  -9.6813]],\n",
      "\n",
      "        [[ -7.1520,  -7.1987,  -7.1645,  ...,  -6.4017,  -6.4056,  -4.5061],\n",
      "         [ -8.4063,  -8.4692,  -8.4093,  ...,  -8.3847,  -7.4677,  -4.5258],\n",
      "         [ -1.5662,  -1.7408,  -1.6497,  ...,  -1.3907,  -2.5322,   0.1472],\n",
      "         ...,\n",
      "         [ -7.3016,  -7.3868,  -7.5735,  ...,  -7.1228,  -6.5103,  -7.1674],\n",
      "         [ -4.3541,  -4.5834,  -4.6705,  ...,  -3.6944,  -3.4359,  -4.1803],\n",
      "         [ -7.8382,  -7.9112,  -7.9924,  ...,  -7.5193,  -6.5353,  -6.6209]],\n",
      "\n",
      "        [[ -6.5199,  -6.4921,  -6.5083,  ...,  -5.6698,  -5.6858,  -3.6646],\n",
      "         [-11.6713, -11.6606, -11.3823,  ...,  -9.1090,  -9.1587,  -8.8038],\n",
      "         [ -5.4662,  -5.4849,  -5.3712,  ...,  -5.2994,  -6.8913,  -3.7161],\n",
      "         ...,\n",
      "         [ -5.6498,  -5.6695,  -5.4879,  ...,  -5.3639,  -7.0714,  -4.0637],\n",
      "         [ -5.9666,  -6.0656,  -5.8918,  ...,  -6.2156,  -6.8780,  -4.6094],\n",
      "         [ -5.6522,  -5.6797,  -5.4605,  ...,  -5.3263,  -7.0590,  -3.5933]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.7008466720581055\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.0004, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8859,  -6.8636,  -6.8569,  ...,  -6.2695,  -6.0607,  -4.2289],\n",
      "         [ -7.0318,  -7.2858,  -7.0146,  ...,  -5.9676,  -5.9103,  -6.6072],\n",
      "         [ -8.1723,  -8.5202,  -8.2020,  ...,  -9.0121,  -8.0001,  -5.9520],\n",
      "         ...,\n",
      "         [ -8.6147,  -8.6017,  -8.3146,  ...,  -9.3923,  -7.8644,  -7.2535],\n",
      "         [ -6.2580,  -6.2187,  -6.2450,  ...,  -6.1934,  -4.8272,  -3.1849],\n",
      "         [-15.0261, -14.7077, -14.6741,  ..., -12.0875, -13.2584, -11.9275]],\n",
      "\n",
      "        [[ -6.6956,  -6.6343,  -6.6506,  ...,  -6.1315,  -5.9965,  -3.9312],\n",
      "         [ -7.1377,  -7.0055,  -7.3433,  ...,  -8.3856,  -7.1786,  -8.0029],\n",
      "         [-12.4961, -12.9575, -12.6564,  ..., -11.4376, -11.7565, -14.8409],\n",
      "         ...,\n",
      "         [-13.7923, -13.9732, -13.9628,  ..., -12.8162, -11.8143, -13.0763],\n",
      "         [ -6.8965,  -7.2444,  -7.0508,  ...,  -5.5961,  -6.9184,  -6.6610],\n",
      "         [-13.7141, -13.2558, -13.5030,  ..., -11.9670, -10.8909,  -9.3894]],\n",
      "\n",
      "        [[ -6.5218,  -6.4354,  -6.4222,  ...,  -5.7834,  -5.5850,  -3.8823],\n",
      "         [ -8.4357,  -8.3031,  -8.1134,  ...,  -8.5680,  -8.7366,  -6.5762],\n",
      "         [ -8.3758,  -8.2394,  -8.0857,  ...,  -8.8485,  -8.3983,  -9.1182],\n",
      "         ...,\n",
      "         [ -5.6773,  -5.5879,  -5.5789,  ...,  -5.9205,  -6.2647,  -4.0477],\n",
      "         [ -5.7432,  -5.6316,  -5.6478,  ...,  -5.9695,  -5.8660,  -4.3861],\n",
      "         [ -5.4848,  -5.4317,  -5.4514,  ...,  -5.7066,  -6.3210,  -3.7856]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2804,  -6.2139,  -6.2620,  ...,  -5.6192,  -5.4022,  -3.6295],\n",
      "         [ -9.9004,  -9.8393,  -9.8006,  ...,  -7.4610,  -7.6250,  -6.4123],\n",
      "         [ -6.0587,  -6.1354,  -6.0738,  ...,  -6.2188,  -7.1675,  -5.2513],\n",
      "         ...,\n",
      "         [ -5.9796,  -6.0230,  -6.0356,  ...,  -6.3720,  -6.7342,  -5.4982],\n",
      "         [ -5.6661,  -5.8578,  -5.7109,  ...,  -5.8508,  -6.9011,  -4.8846],\n",
      "         [ -6.7411,  -6.8663,  -6.7875,  ...,  -6.7495,  -7.4647,  -5.4955]],\n",
      "\n",
      "        [[ -6.7437,  -6.6858,  -6.7589,  ...,  -6.0501,  -5.9605,  -3.9657],\n",
      "         [-12.1891, -12.0364, -11.9314,  ...,  -8.6891, -10.7594, -10.8841],\n",
      "         [ -6.5261,  -6.7380,  -6.6110,  ...,  -6.5772,  -7.8170,  -4.3934],\n",
      "         ...,\n",
      "         [ -6.6899,  -6.6755,  -6.6359,  ...,  -5.9741,  -7.3575,  -4.2659],\n",
      "         [ -7.2619,  -7.3857,  -7.2551,  ...,  -6.8728,  -7.6893,  -4.7884],\n",
      "         [ -7.0861,  -7.1823,  -7.0960,  ...,  -6.6049,  -7.8954,  -4.6604]],\n",
      "\n",
      "        [[ -6.6529,  -6.6261,  -6.6500,  ...,  -5.9171,  -5.8373,  -3.8611],\n",
      "         [ -5.6659,  -5.5751,  -5.7758,  ...,  -5.6708,  -6.2701,  -3.5937],\n",
      "         [ -5.9545,  -6.0407,  -5.9081,  ...,  -6.1087,  -6.7241,  -2.3980],\n",
      "         ...,\n",
      "         [ -5.4836,  -5.4348,  -5.4938,  ...,  -5.6133,  -6.0031,  -2.8612],\n",
      "         [ -5.7241,  -5.6023,  -5.7801,  ...,  -5.3921,  -6.5211,  -2.3458],\n",
      "         [ -5.8513,  -5.5788,  -5.8137,  ...,  -5.7422,  -6.5001,  -3.4821]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 3.000392198562622\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3312, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5437,  -7.5607,  -7.5407,  ...,  -7.0422,  -6.4111,  -4.7786],\n",
      "         [-11.2574, -11.2073, -11.0101,  ..., -10.4956,  -8.0324, -11.2058],\n",
      "         [ -9.1922,  -9.0193,  -9.2726,  ...,  -9.8161,  -6.6168, -11.3090],\n",
      "         ...,\n",
      "         [ -9.4567,  -9.1682,  -9.3953,  ...,  -7.2622,  -6.8583,  -9.2396],\n",
      "         [ -9.5454,  -9.9081,  -9.3533,  ...,  -8.2915,  -7.2110,  -9.5370],\n",
      "         [-12.3869, -12.1134, -12.1275,  ...,  -9.8022,  -9.6301,  -8.6153]],\n",
      "\n",
      "        [[ -6.5479,  -6.4990,  -6.5217,  ...,  -5.7276,  -5.6962,  -3.6783],\n",
      "         [ -5.6440,  -5.4694,  -5.6414,  ...,  -5.7129,  -5.8576,  -3.3827],\n",
      "         [ -7.8151,  -7.8450,  -7.7750,  ...,  -7.4308,  -7.4892,  -2.6736],\n",
      "         ...,\n",
      "         [ -6.0209,  -5.9132,  -6.1079,  ...,  -5.6817,  -6.0004,  -3.8750],\n",
      "         [ -6.2316,  -6.0614,  -6.1956,  ...,  -6.1902,  -6.0132,  -4.3371],\n",
      "         [ -6.3128,  -6.1977,  -6.3877,  ...,  -6.0317,  -5.8318,  -3.6833]],\n",
      "\n",
      "        [[ -6.6201,  -6.5915,  -6.6120,  ...,  -5.8577,  -5.7486,  -3.9672],\n",
      "         [-12.7721, -12.6004, -12.3902,  ...,  -8.9068, -10.5691,  -9.6994],\n",
      "         [ -5.6775,  -5.8569,  -5.8323,  ...,  -5.9757,  -7.2308,  -3.7970],\n",
      "         ...,\n",
      "         [ -6.1978,  -6.2769,  -6.1880,  ...,  -6.5210,  -6.9166,  -5.3903],\n",
      "         [ -5.4873,  -5.6278,  -5.5564,  ...,  -5.4839,  -6.2830,  -5.2308],\n",
      "         [ -6.0062,  -6.1429,  -6.0741,  ...,  -6.1572,  -7.0731,  -4.5866]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2623,  -7.2791,  -7.2176,  ...,  -6.3869,  -6.2043,  -3.5315],\n",
      "         [-14.5480, -14.8302, -14.4724,  ..., -12.4648, -10.9378,  -8.0289],\n",
      "         [-13.8499, -14.2445, -14.0647,  ..., -13.0377, -11.1714,  -8.3144],\n",
      "         ...,\n",
      "         [ -7.2099,  -7.4592,  -7.0693,  ...,  -6.4532,  -6.4977,  -6.2026],\n",
      "         [ -8.1653,  -8.3546,  -8.0411,  ...,  -7.9339,  -7.5193,  -6.0874],\n",
      "         [ -7.6417,  -7.5237,  -7.5402,  ...,  -6.1095,  -6.0210,  -7.9857]],\n",
      "\n",
      "        [[ -6.6972,  -6.6752,  -6.6985,  ...,  -5.9159,  -5.9220,  -4.0933],\n",
      "         [-13.4336, -13.2794, -13.1264,  ..., -10.3834, -10.8581, -11.8077],\n",
      "         [ -5.5803,  -5.5954,  -5.5012,  ...,  -5.5948,  -6.7674,  -4.9750],\n",
      "         ...,\n",
      "         [ -5.6785,  -5.7769,  -5.6383,  ...,  -5.8787,  -6.3428,  -4.9986],\n",
      "         [ -5.5806,  -5.6712,  -5.5641,  ...,  -5.5657,  -6.5823,  -4.6330],\n",
      "         [ -5.0677,  -5.1008,  -4.9967,  ...,  -5.0509,  -5.9387,  -5.4390]],\n",
      "\n",
      "        [[ -6.8811,  -6.8445,  -6.8655,  ...,  -6.3451,  -5.9746,  -4.4248],\n",
      "         [ -9.8488, -10.1199, -10.1767,  ...,  -8.4180,  -9.3265,  -8.4983],\n",
      "         [ -5.8031,  -5.8170,  -5.7729,  ...,  -5.8656,  -6.5634,  -4.9642],\n",
      "         ...,\n",
      "         [ -6.2185,  -6.3153,  -6.2959,  ...,  -6.5939,  -6.6385,  -5.1989],\n",
      "         [ -6.0925,  -6.2100,  -6.2735,  ...,  -6.3870,  -6.8152,  -5.3504],\n",
      "         [ -5.7436,  -5.7502,  -5.7077,  ...,  -5.9643,  -6.3915,  -5.0246]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.3311965465545654\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0809, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2905,  -6.2464,  -6.2555,  ...,  -5.6597,  -5.3844,  -3.7481],\n",
      "         [-10.8750, -10.5721, -10.5928,  ...,  -7.9919,  -9.6852,  -6.9754],\n",
      "         [ -5.8348,  -5.9503,  -5.9710,  ...,  -5.9459,  -6.8686,  -3.8716],\n",
      "         ...,\n",
      "         [ -6.0335,  -6.1296,  -6.0289,  ...,  -5.6640,  -6.7305,  -5.2444],\n",
      "         [ -5.0563,  -5.1152,  -5.1020,  ...,  -4.6418,  -6.4066,  -4.4812],\n",
      "         [ -6.4841,  -6.4895,  -6.5018,  ...,  -6.1603,  -7.0571,  -5.6445]],\n",
      "\n",
      "        [[ -6.9601,  -7.0942,  -6.9416,  ...,  -6.3293,  -6.0457,  -5.0443],\n",
      "         [-13.7172, -13.6617, -13.8281,  ..., -11.3223,  -8.5717, -15.7942],\n",
      "         [ -9.5135,  -9.6577,  -9.2262,  ...,  -7.1725,  -6.5286,  -7.4482],\n",
      "         ...,\n",
      "         [-13.5965, -13.8789, -14.0148,  ..., -12.5976, -11.0277,  -8.3988],\n",
      "         [ -6.8183,  -6.7368,  -6.7264,  ...,  -5.6036,  -5.2684,  -5.2877],\n",
      "         [ -6.6468,  -6.7935,  -6.7858,  ...,  -6.2251,  -5.8287,  -6.0814]],\n",
      "\n",
      "        [[ -6.7438,  -6.7463,  -6.7171,  ...,  -6.2418,  -5.8945,  -4.5865],\n",
      "         [ -8.1776,  -8.6358,  -8.3992,  ...,  -8.5362,  -8.9968,  -6.3154],\n",
      "         [ -9.7987,  -9.6266, -10.0448,  ...,  -9.7417,  -7.6942, -11.3152],\n",
      "         ...,\n",
      "         [ -5.5798,  -5.6840,  -5.7471,  ...,  -4.4486,  -6.0265, -10.2972],\n",
      "         [ -5.6071,  -5.6631,  -5.7713,  ...,  -4.1563,  -6.1376,  -9.3916],\n",
      "         [ -6.0089,  -5.8111,  -6.0878,  ...,  -6.0471,  -5.1335,  -5.4123]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8829,  -6.9155,  -6.8339,  ...,  -6.0003,  -6.0440,  -3.9445],\n",
      "         [-12.0458, -11.9496, -12.1233,  ..., -11.5165, -10.7495, -10.2934],\n",
      "         [-11.1753, -11.0968, -11.0521,  ..., -10.8853, -10.0107,  -8.3704],\n",
      "         ...,\n",
      "         [-15.7257, -15.6588, -15.6497,  ..., -13.1436, -12.5297, -14.1137],\n",
      "         [-11.6796, -11.8452, -11.5139,  ..., -10.3391,  -8.6717,  -8.8957],\n",
      "         [-13.8188, -13.3154, -13.4347,  ..., -10.7728, -11.0184,  -8.8408]],\n",
      "\n",
      "        [[ -6.7067,  -6.7458,  -6.7040,  ...,  -6.1266,  -5.9826,  -4.0686],\n",
      "         [-11.3723, -11.2857, -11.2874,  ..., -10.3812, -11.2550,  -8.2782],\n",
      "         [ -5.1954,  -5.4467,  -5.4614,  ...,  -4.5606,  -5.4532,  -4.7013],\n",
      "         ...,\n",
      "         [ -9.4386,  -9.3447,  -9.5706,  ...,  -8.0943,  -9.0761,  -5.4463],\n",
      "         [ -7.9147,  -8.2489,  -7.8244,  ...,  -6.9097,  -7.6254,  -8.7426],\n",
      "         [-13.3375, -13.0091, -13.3415,  ..., -10.3695, -11.1777,  -9.8611]],\n",
      "\n",
      "        [[ -7.0639,  -7.0366,  -7.0303,  ...,  -6.2307,  -6.1744,  -3.9579],\n",
      "         [-14.3577, -14.3363, -14.4382,  ..., -13.5514, -10.6582,  -7.5330],\n",
      "         [-11.7992, -11.8448, -12.1407,  ..., -10.6066,  -9.6180,  -7.0377],\n",
      "         ...,\n",
      "         [ -9.0610,  -8.9922,  -9.2794,  ...,  -9.8493,  -6.9690, -11.5131],\n",
      "         [-11.7666, -12.0144, -12.2120,  ...,  -9.8866, -10.0792, -10.6663],\n",
      "         [-12.2171, -11.6749, -12.0292,  ...,  -8.5452,  -9.6104,  -6.9992]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0809450149536133\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(5.3067, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6959,  -6.6707,  -6.6738,  ...,  -5.8456,  -5.8170,  -4.1151],\n",
      "         [ -9.3727,  -9.3719,  -9.3215,  ...,  -6.7731,  -9.6325,  -7.9269],\n",
      "         [ -4.6612,  -4.8103,  -4.6628,  ...,  -5.0448,  -6.5668,  -4.9171],\n",
      "         ...,\n",
      "         [ -5.2720,  -5.3901,  -5.2841,  ...,  -5.1446,  -6.4085,  -4.9119],\n",
      "         [ -5.2331,  -5.3625,  -5.2504,  ...,  -5.6624,  -6.7521,  -3.7315],\n",
      "         [ -5.7657,  -5.8587,  -5.7199,  ...,  -5.9784,  -6.9693,  -4.8807]],\n",
      "\n",
      "        [[ -6.5895,  -6.5386,  -6.5747,  ...,  -6.3877,  -6.1902,  -3.3630],\n",
      "         [ -9.3575,  -9.0739,  -9.4090,  ...,  -6.7952,  -6.5895,  -9.3565],\n",
      "         [ -6.5615,  -6.5871,  -6.5214,  ...,  -7.1965,  -7.2987,  -3.1934],\n",
      "         ...,\n",
      "         [ -5.6229,  -5.5397,  -5.6367,  ...,  -5.6882,  -5.8167,  -3.0443],\n",
      "         [ -6.7555,  -6.6985,  -6.6468,  ...,  -6.9856,  -6.8085,  -3.8430],\n",
      "         [ -6.5176,  -6.5632,  -6.4518,  ...,  -6.7857,  -6.4713,  -4.1250]],\n",
      "\n",
      "        [[ -6.1463,  -6.0790,  -6.0910,  ...,  -5.4817,  -5.2888,  -3.7859],\n",
      "         [-11.1676, -10.6687, -10.4889,  ...,  -8.8357,  -7.8316,  -9.4615],\n",
      "         [ -5.5073,  -5.5887,  -5.5769,  ...,  -5.7471,  -6.8711,  -4.1693],\n",
      "         ...,\n",
      "         [ -6.1477,  -6.2617,  -6.1249,  ...,  -6.3961,  -6.7788,  -5.3621],\n",
      "         [ -6.8573,  -6.8464,  -6.9002,  ...,  -6.9683,  -7.3578,  -5.7095],\n",
      "         [ -6.4533,  -6.5287,  -6.4994,  ...,  -6.5151,  -6.9251,  -6.1577]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0319,  -6.9922,  -7.0113,  ...,  -6.1323,  -6.1568,  -4.2035],\n",
      "         [-10.9848, -10.3485, -10.4544,  ...,  -8.3191,  -9.3457,  -7.4974],\n",
      "         [ -5.3282,  -5.2108,  -5.1953,  ...,  -5.5959,  -6.8939,  -3.6302],\n",
      "         ...,\n",
      "         [ -6.0457,  -6.0081,  -5.8602,  ...,  -6.0381,  -7.3827,  -4.4521],\n",
      "         [ -6.4029,  -6.4440,  -6.4531,  ...,  -6.7589,  -8.1306,  -4.1786],\n",
      "         [ -5.7624,  -5.7467,  -5.6599,  ...,  -5.6708,  -7.1870,  -3.9909]],\n",
      "\n",
      "        [[ -6.6325,  -6.5919,  -6.5893,  ...,  -6.0910,  -5.6479,  -4.0924],\n",
      "         [ -6.9215,  -6.8755,  -7.3050,  ...,  -6.4160,  -6.3044,  -4.1722],\n",
      "         [ -7.1975,  -7.0583,  -7.2857,  ...,  -5.2353,  -6.5427,  -5.0963],\n",
      "         ...,\n",
      "         [ -6.1402,  -6.1795,  -5.9956,  ...,  -6.5087,  -5.8050,  -4.6116],\n",
      "         [ -6.9557,  -7.0732,  -6.9104,  ...,  -6.9559,  -6.4114,  -4.5479],\n",
      "         [ -7.1551,  -7.3495,  -7.0814,  ...,  -7.4823,  -6.7549,  -4.6272]],\n",
      "\n",
      "        [[ -6.7395,  -6.7135,  -6.7316,  ...,  -6.1606,  -5.8641,  -4.1091],\n",
      "         [ -6.1479,  -6.1647,  -6.0189,  ...,  -6.3047,  -6.5618,  -4.0656],\n",
      "         [ -6.3539,  -6.4842,  -6.3535,  ...,  -6.5389,  -6.6220,  -3.5851],\n",
      "         ...,\n",
      "         [ -5.9616,  -5.9900,  -5.8795,  ...,  -6.2735,  -6.5709,  -3.9449],\n",
      "         [ -6.0177,  -6.0258,  -5.9733,  ...,  -6.3336,  -6.0105,  -3.5873],\n",
      "         [ -6.4814,  -6.4463,  -6.3278,  ...,  -6.4642,  -6.5561,  -4.1285]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 5.306699275970459\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0336, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2564,  -7.2794,  -7.2660,  ...,  -6.3433,  -6.5166,  -3.9767],\n",
      "         [-15.3529, -14.9618, -14.7383,  ..., -12.4366, -13.9053, -12.1958],\n",
      "         [ -5.5148,  -5.5557,  -5.5587,  ...,  -5.7814,  -7.1167,  -3.6155],\n",
      "         ...,\n",
      "         [ -5.5264,  -5.7874,  -5.6286,  ...,  -5.9385,  -7.0521,  -5.4418],\n",
      "         [ -5.6658,  -5.7950,  -5.6091,  ...,  -5.9259,  -6.5147,  -4.4310],\n",
      "         [ -5.7622,  -5.7515,  -5.6796,  ...,  -6.1159,  -7.5723,  -5.6890]],\n",
      "\n",
      "        [[ -6.4614,  -6.4281,  -6.4446,  ...,  -5.8413,  -5.6247,  -3.8820],\n",
      "         [ -8.6895,  -8.5438,  -8.6631,  ...,  -8.4519,  -6.4617,  -5.7296],\n",
      "         [ -5.3122,  -5.1252,  -4.9921,  ...,  -5.5101,  -4.5184,  -3.3706],\n",
      "         ...,\n",
      "         [ -6.5033,  -6.4736,  -6.4796,  ...,  -6.5193,  -6.1551,  -4.9257],\n",
      "         [ -6.5296,  -6.4756,  -6.5195,  ...,  -6.3125,  -6.1978,  -4.1711],\n",
      "         [ -6.6690,  -6.6779,  -6.6752,  ...,  -6.6787,  -6.3415,  -3.5415]],\n",
      "\n",
      "        [[ -6.8498,  -6.8282,  -6.8435,  ...,  -5.9917,  -6.0777,  -4.0820],\n",
      "         [-12.8177, -12.6012, -12.5654,  ...,  -9.1209, -10.7089,  -8.1725],\n",
      "         [ -5.6355,  -5.7888,  -5.8013,  ...,  -5.9872,  -7.6885,  -3.6053],\n",
      "         ...,\n",
      "         [ -6.4554,  -6.4952,  -6.4653,  ...,  -6.4619,  -7.1352,  -4.3988],\n",
      "         [ -6.4050,  -6.5286,  -6.4870,  ...,  -6.5142,  -6.9406,  -4.9182],\n",
      "         [ -6.3861,  -6.5636,  -6.3926,  ...,  -6.4173,  -7.1889,  -4.5108]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1905,  -7.1626,  -7.1521,  ...,  -6.4678,  -6.2139,  -4.2325],\n",
      "         [-10.6339, -10.7614, -10.7129,  ...,  -9.0411, -10.2617,  -9.7178],\n",
      "         [ -9.3407,  -9.3669,  -9.5931,  ...,  -8.5755,  -9.0308,  -9.5680],\n",
      "         ...,\n",
      "         [ -8.7823,  -8.8430,  -8.3364,  ...,  -7.6031,  -8.4739,  -6.5517],\n",
      "         [ -7.8900,  -7.8423,  -7.8076,  ...,  -6.5657,  -6.5998,  -6.2494],\n",
      "         [-14.0369, -13.7418, -14.1840,  ..., -11.4314, -11.5577, -10.8270]],\n",
      "\n",
      "        [[ -7.3301,  -7.2881,  -7.2800,  ...,  -6.7570,  -6.4272,  -4.6189],\n",
      "         [ -8.0346,  -8.2886,  -7.6656,  ...,  -8.9855,  -7.6499, -11.9653],\n",
      "         [-10.1911, -10.0093, -10.0280,  ...,  -9.6248,  -8.3208, -11.3412],\n",
      "         ...,\n",
      "         [ -6.8575,  -7.0751,  -7.0142,  ...,  -7.1598,  -5.4639,  -5.2526],\n",
      "         [ -7.1862,  -7.3656,  -7.2738,  ...,  -7.2306,  -5.7916,  -6.4812],\n",
      "         [ -7.4150,  -7.5826,  -7.5106,  ...,  -7.4278,  -6.1248,  -6.7880]],\n",
      "\n",
      "        [[ -6.6935,  -6.7171,  -6.6617,  ...,  -6.0188,  -6.0851,  -4.3714],\n",
      "         [-12.2283, -11.9076, -12.4204,  ..., -12.3887, -10.0311, -14.7124],\n",
      "         [ -7.7127,  -8.1485,  -8.3374,  ...,  -7.8038,  -6.7196, -11.8987],\n",
      "         ...,\n",
      "         [ -6.1843,  -6.2886,  -5.9757,  ...,  -5.2581,  -5.6318,  -9.7611],\n",
      "         [-10.5123, -10.4127, -10.6248,  ...,  -8.1606, -10.8229,  -7.7633],\n",
      "         [-12.5880, -13.0841, -13.0760,  ..., -10.0952, -10.6266,  -7.5518]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0335686206817627\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9323, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8759,  -6.8545,  -6.8265,  ...,  -6.3733,  -6.1844,  -3.7276],\n",
      "         [-11.3636, -11.6304, -11.3706,  ..., -11.2760,  -9.4121,  -9.1099],\n",
      "         [ -6.0531,  -6.4192,  -6.1112,  ...,  -6.1063,  -4.0283,  -7.7873],\n",
      "         ...,\n",
      "         [ -7.7992,  -8.2052,  -7.7692,  ...,  -7.7448,  -9.4547,  -7.6789],\n",
      "         [-12.2357, -12.0371, -12.2627,  ...,  -9.6870, -10.3995,  -9.2549],\n",
      "         [-12.6680, -12.6394, -12.6311,  ..., -11.3359, -12.0547,  -9.5849]],\n",
      "\n",
      "        [[ -6.8449,  -6.8421,  -6.8915,  ...,  -6.2145,  -5.9444,  -3.9713],\n",
      "         [ -9.7122,  -9.2914,  -9.6141,  ...,  -6.5098,  -7.3959,  -6.3753],\n",
      "         [ -5.9380,  -5.9852,  -5.9879,  ...,  -6.4614,  -7.6718,  -3.7200],\n",
      "         ...,\n",
      "         [ -6.6402,  -6.7418,  -6.5921,  ...,  -6.4869,  -7.7336,  -4.5961],\n",
      "         [ -6.3620,  -6.3964,  -6.3168,  ...,  -6.2935,  -7.5322,  -4.7134],\n",
      "         [ -6.2020,  -6.2624,  -6.2658,  ...,  -6.4248,  -7.1272,  -4.5568]],\n",
      "\n",
      "        [[ -6.8929,  -6.8956,  -6.8751,  ...,  -6.3293,  -6.0492,  -4.0074],\n",
      "         [ -4.7692,  -4.6747,  -4.3623,  ...,  -4.3104,  -6.3753,  -2.8744],\n",
      "         [ -4.1411,  -4.5909,  -4.3412,  ...,  -4.2041,  -5.0344,  -6.4305],\n",
      "         ...,\n",
      "         [ -7.7537,  -7.8073,  -7.7977,  ...,  -7.7757,  -6.6268,  -8.0816],\n",
      "         [ -6.5468,  -6.6199,  -6.5881,  ...,  -6.5164,  -5.5214,  -6.8487],\n",
      "         [ -7.5003,  -7.5589,  -7.5913,  ...,  -7.7023,  -6.5178,  -5.6791]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0410,  -7.0576,  -7.0335,  ...,  -6.3639,  -6.1489,  -4.0815],\n",
      "         [-13.2578, -12.9873, -13.1741,  ..., -11.8500, -12.2899, -11.6164],\n",
      "         [ -9.1646,  -9.5662,  -9.0600,  ...,  -9.4584, -11.2834,  -9.0513],\n",
      "         ...,\n",
      "         [-14.0929, -14.1743, -13.6295,  ..., -12.5824, -13.0449, -14.5853],\n",
      "         [ -7.1328,  -7.0976,  -7.0863,  ...,  -6.4646,  -7.1591,  -5.5364],\n",
      "         [-13.2800, -13.1494, -13.3831,  ..., -10.8840, -10.8487, -10.3341]],\n",
      "\n",
      "        [[ -6.4937,  -6.4841,  -6.4267,  ...,  -6.0066,  -5.6637,  -3.8692],\n",
      "         [ -9.4952,  -9.6853,  -9.5672,  ...,  -8.3360,  -9.4710, -11.8762],\n",
      "         [ -8.4255,  -8.4576,  -8.4735,  ...,  -8.2532,  -4.6173,  -5.0895],\n",
      "         ...,\n",
      "         [ -5.1516,  -5.5538,  -4.9092,  ...,  -5.9068,  -4.7293,  -5.6517],\n",
      "         [-15.7595, -15.8867, -15.7216,  ..., -12.9617, -11.8973, -12.7267],\n",
      "         [-15.2079, -15.1478, -15.0607,  ..., -13.2697, -12.8590, -10.9616]],\n",
      "\n",
      "        [[ -7.1045,  -7.1154,  -7.0647,  ...,  -6.3620,  -6.1935,  -4.3077],\n",
      "         [-11.9213, -12.1201, -12.0552,  ..., -10.9364, -10.8943, -11.0264],\n",
      "         [ -3.3422,  -3.9299,  -3.5152,  ...,  -3.0385,  -3.1694,  -4.7317],\n",
      "         ...,\n",
      "         [ -2.3722,  -2.3299,  -2.5188,  ...,  -2.6030,  -2.8040,   2.7015],\n",
      "         [-14.8939, -14.5876, -14.9800,  ..., -11.5813, -10.9229, -10.0512],\n",
      "         [-13.6501, -13.5769, -13.7815,  ..., -11.7438, -11.8276,  -6.2206]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.9322911500930786\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2845, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4148,  -6.3651,  -6.3822,  ...,  -5.6847,  -5.5731,  -3.6396],\n",
      "         [ -9.2441,  -9.0210,  -8.8310,  ...,  -8.8986,  -9.6883,  -6.2043],\n",
      "         [-12.7390, -13.2544, -12.9836,  ..., -12.4257, -11.1284,  -9.5210],\n",
      "         ...,\n",
      "         [ -6.1856,  -6.0382,  -6.0766,  ...,  -6.0630,  -6.1818,  -3.5430],\n",
      "         [ -6.5718,  -6.4732,  -6.6766,  ...,  -6.3783,  -6.5450,  -3.2842],\n",
      "         [ -6.4133,  -6.3203,  -6.4441,  ...,  -6.1060,  -6.2417,  -3.0257]],\n",
      "\n",
      "        [[ -6.5423,  -6.5750,  -6.5103,  ...,  -5.7706,  -5.9676,  -3.5341],\n",
      "         [-14.4612, -14.7855, -14.7642,  ..., -14.6764, -12.1483, -12.1418],\n",
      "         [ -5.2373,  -5.6106,  -5.6444,  ...,  -4.7310,  -5.6046,  -6.2203],\n",
      "         ...,\n",
      "         [ -4.1665,  -4.3603,  -4.1022,  ...,  -4.0084,  -6.0425,  -2.2360],\n",
      "         [ -3.3048,  -3.5009,  -3.3092,  ...,  -3.2183,  -5.1214,  -1.6570],\n",
      "         [ -3.9714,  -4.2512,  -4.0233,  ...,  -3.7802,  -5.4942,  -1.2883]],\n",
      "\n",
      "        [[ -6.4937,  -6.4545,  -6.4726,  ...,  -5.8094,  -5.6281,  -3.8559],\n",
      "         [-11.0465, -10.5182, -10.2198,  ...,  -7.8127,  -8.7508,  -8.6018],\n",
      "         [ -5.5115,  -5.6648,  -5.6177,  ...,  -5.7051,  -6.8792,  -3.9177],\n",
      "         ...,\n",
      "         [ -5.9782,  -6.0230,  -5.9115,  ...,  -5.9207,  -6.8209,  -5.0687],\n",
      "         [ -6.4197,  -6.5029,  -6.4009,  ...,  -6.6919,  -7.0128,  -4.8174],\n",
      "         [ -5.9261,  -6.0284,  -5.9734,  ...,  -6.0565,  -6.7530,  -4.7192]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3997,  -6.3604,  -6.3757,  ...,  -5.7097,  -5.5659,  -3.7170],\n",
      "         [-11.2826, -10.5564, -10.6896,  ...,  -8.2489,  -8.4867, -11.6504],\n",
      "         [ -5.9356,  -6.0505,  -6.0760,  ...,  -6.3922,  -7.3023,  -4.8162],\n",
      "         ...,\n",
      "         [ -6.6968,  -6.9169,  -6.8618,  ...,  -6.7677,  -7.6641,  -4.7224],\n",
      "         [ -6.4322,  -6.5586,  -6.4870,  ...,  -6.6845,  -7.4567,  -5.5926],\n",
      "         [ -7.1648,  -7.2805,  -7.1866,  ...,  -6.9915,  -8.1300,  -5.3799]],\n",
      "\n",
      "        [[ -6.7285,  -6.7162,  -6.7213,  ...,  -6.1022,  -5.8630,  -3.8917],\n",
      "         [ -9.3158,  -9.6098,  -9.4257,  ..., -11.0329,  -7.3112, -10.4451],\n",
      "         [ -7.3300,  -7.4672,  -7.2431,  ...,  -6.2553,  -6.9960,  -4.7082],\n",
      "         ...,\n",
      "         [ -7.1794,  -7.2057,  -7.0409,  ...,  -6.6071,  -5.2960,  -6.6427],\n",
      "         [-15.0163, -14.9069, -14.2045,  ..., -13.1317, -11.1544, -13.0388],\n",
      "         [-12.8794, -12.5217, -12.4902,  ..., -10.1398, -10.9110,  -7.7967]],\n",
      "\n",
      "        [[ -7.0212,  -7.0301,  -7.0030,  ...,  -6.1996,  -6.0502,  -3.9340],\n",
      "         [-14.0015, -13.9290, -13.9783,  ..., -13.6086, -10.8016,  -8.5762],\n",
      "         [ -4.1488,  -4.0428,  -4.2517,  ...,  -3.5172,  -3.4101,  -3.4791],\n",
      "         ...,\n",
      "         [ -7.1262,  -7.1199,  -7.1049,  ...,  -6.1746,  -5.2945,  -6.1601],\n",
      "         [-13.9027, -13.8629, -13.8285,  ..., -11.4127,  -8.8956, -10.9839],\n",
      "         [-11.0164, -10.6365, -11.1471,  ...,  -7.9023,  -9.1643,  -6.9956]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2844974994659424\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1876, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7813,  -6.8092,  -6.8126,  ...,  -6.2767,  -6.1102,  -4.1796],\n",
      "         [-13.1489, -13.4185, -13.3272,  ..., -12.7167, -12.7745, -10.7382],\n",
      "         [ -4.6272,  -5.2565,  -5.0895,  ...,  -5.5848,  -5.3366,  -4.6385],\n",
      "         ...,\n",
      "         [ -8.1331,  -8.5033,  -7.6899,  ...,  -7.9743,  -7.1416,  -8.7234],\n",
      "         [ -7.3739,  -8.1789,  -7.7054,  ...,  -8.0550,  -8.1408,  -5.3162],\n",
      "         [-12.6234, -12.5188, -12.7945,  ..., -10.8892, -11.4839,  -9.9076]],\n",
      "\n",
      "        [[ -7.2769,  -7.2846,  -7.2603,  ...,  -6.5853,  -6.3908,  -4.2993],\n",
      "         [-14.0834, -13.7225, -13.7583,  ..., -13.4824, -11.9119, -13.3346],\n",
      "         [ -5.7811,  -5.3237,  -5.4584,  ...,  -5.5067,  -5.0439,  -6.5168],\n",
      "         ...,\n",
      "         [-10.3585, -10.4901, -10.3008,  ...,  -7.9327,  -9.3464,  -7.7874],\n",
      "         [ -5.6637,  -5.6116,  -5.4521,  ...,  -4.8112,  -4.6832,  -5.3915],\n",
      "         [-12.5900, -12.5337, -12.6467,  ...,  -9.2739,  -9.3842, -10.6894]],\n",
      "\n",
      "        [[ -6.9189,  -6.8250,  -6.8442,  ...,  -6.2385,  -5.9757,  -3.8781],\n",
      "         [ -5.7993,  -5.6872,  -5.8407,  ...,  -6.4765,  -6.6601,  -3.2367],\n",
      "         [ -8.4483,  -8.3296,  -8.4464,  ...,  -8.8345,  -8.6142,  -5.4699],\n",
      "         ...,\n",
      "         [ -6.1038,  -6.0433,  -6.1260,  ...,  -6.2461,  -6.9903,  -3.8071],\n",
      "         [ -5.6700,  -5.5077,  -5.6040,  ...,  -5.8620,  -6.7401,  -3.2156],\n",
      "         [ -5.5973,  -5.4801,  -5.6329,  ...,  -5.7854,  -6.7656,  -3.5812]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2454,  -7.2460,  -7.2581,  ...,  -6.4895,  -6.2774,  -4.1907],\n",
      "         [-12.8722, -13.0987, -13.0104,  ..., -11.7264, -11.2573,  -3.8438],\n",
      "         [ -8.7350,  -9.0338,  -8.8421,  ...,  -8.8027,  -7.9071,  -8.8207],\n",
      "         ...,\n",
      "         [-12.6481, -12.2581, -12.5701,  ...,  -9.5739, -10.0636,  -9.3051],\n",
      "         [ -7.2561,  -7.7142,  -7.2335,  ...,  -6.6637,  -6.4072,  -5.3914],\n",
      "         [ -7.4078,  -7.6571,  -7.6607,  ...,  -6.7935,  -7.0887,  -4.6397]],\n",
      "\n",
      "        [[ -7.5048,  -7.4019,  -7.4581,  ...,  -6.7026,  -6.8630,  -3.8097],\n",
      "         [-16.7288, -16.8117, -17.0147,  ..., -15.4490, -14.5897, -14.5139],\n",
      "         [ -9.4268,  -9.6793,  -9.7138,  ...,  -8.3795,  -9.3242,  -5.7947],\n",
      "         ...,\n",
      "         [ -5.8586,  -5.7947,  -5.0957,  ...,  -6.1370,  -6.2663,  -1.8658],\n",
      "         [ -4.2248,  -4.6158,  -4.2166,  ...,  -4.5424,  -4.1577,  -4.7595],\n",
      "         [-15.0559, -15.0982, -14.7411,  ..., -12.3685, -11.4573, -12.0191]],\n",
      "\n",
      "        [[ -6.5063,  -6.4652,  -6.4913,  ...,  -5.8184,  -5.6520,  -3.8653],\n",
      "         [-11.3870, -10.8282, -10.9451,  ...,  -7.7298,  -8.7782,  -8.6280],\n",
      "         [ -5.7348,  -5.9065,  -5.9071,  ...,  -5.9807,  -6.8765,  -4.6168],\n",
      "         ...,\n",
      "         [ -6.3155,  -6.3950,  -6.3680,  ...,  -6.5246,  -7.5344,  -4.7508],\n",
      "         [ -6.3650,  -6.4618,  -6.3842,  ...,  -6.2954,  -6.7159,  -5.0095],\n",
      "         [ -6.4648,  -6.4835,  -6.4329,  ...,  -6.3645,  -7.0611,  -4.6286]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.1875882148742676\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.0356, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5820,  -6.5636,  -6.5988,  ...,  -6.1729,  -5.7913,  -3.7415],\n",
      "         [ -6.5705,  -6.5651,  -6.4983,  ...,  -6.8128,  -6.2375,  -3.9382],\n",
      "         [ -8.3084,  -8.5223,  -8.3313,  ...,  -8.2485,  -7.7919,  -6.6150],\n",
      "         ...,\n",
      "         [ -6.7573,  -6.7849,  -6.7054,  ...,  -6.4955,  -6.0697,  -4.1102],\n",
      "         [ -6.9606,  -6.9774,  -6.8685,  ...,  -6.8671,  -6.6999,  -3.7671],\n",
      "         [ -6.9582,  -6.9995,  -6.9128,  ...,  -6.8299,  -6.3539,  -4.2439]],\n",
      "\n",
      "        [[ -6.7489,  -6.7081,  -6.6744,  ...,  -5.9169,  -6.0230,  -4.1419],\n",
      "         [ -7.8441,  -7.4860,  -7.7532,  ...,  -7.8060,  -7.4683,  -5.3290],\n",
      "         [ -7.6647,  -7.5473,  -7.5761,  ...,  -8.2006,  -6.9127,  -6.1040],\n",
      "         ...,\n",
      "         [ -5.2977,  -5.3547,  -5.3582,  ...,  -5.1210,  -6.1767,  -3.3865],\n",
      "         [ -5.6324,  -5.5681,  -5.7060,  ...,  -5.1156,  -5.9817,  -3.8631],\n",
      "         [ -5.4681,  -5.4415,  -5.5249,  ...,  -5.3876,  -5.7593,  -2.7816]],\n",
      "\n",
      "        [[ -7.0207,  -7.0677,  -7.0023,  ...,  -6.7132,  -6.2483,  -4.1912],\n",
      "         [ -9.4407,  -9.4636,  -9.0851,  ...,  -9.3371,  -9.0331,  -9.4138],\n",
      "         [ -6.1807,  -6.7344,  -6.2292,  ...,  -5.3194,  -5.6149,  -7.5362],\n",
      "         ...,\n",
      "         [-14.1782, -13.7206, -13.9516,  ..., -12.6245, -11.2859, -12.2594],\n",
      "         [ -9.9432, -10.0155,  -9.9704,  ...,  -9.8828,  -9.3624,  -9.5958],\n",
      "         [-11.3897, -11.2084, -11.6478,  ...,  -8.6660,  -9.4523,  -6.1670]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5857,  -6.5380,  -6.5668,  ...,  -5.8164,  -5.7266,  -3.8518],\n",
      "         [ -9.4213,  -9.0417,  -9.2568,  ...,  -8.7850,  -8.0064,  -5.7138],\n",
      "         [ -7.9983,  -7.9151,  -7.9842,  ...,  -7.3967,  -7.0152,  -7.3102],\n",
      "         ...,\n",
      "         [ -6.1085,  -6.0631,  -6.1498,  ...,  -5.7425,  -6.6030,  -3.3310],\n",
      "         [ -5.6850,  -5.6442,  -5.7430,  ...,  -5.2820,  -6.0730,  -2.6621],\n",
      "         [ -5.6254,  -5.5696,  -5.6664,  ...,  -5.6184,  -6.1216,  -1.9729]],\n",
      "\n",
      "        [[ -6.4257,  -6.3900,  -6.4193,  ...,  -5.7879,  -5.5808,  -3.7541],\n",
      "         [-11.1680, -11.2239, -11.4461,  ...,  -8.3171, -10.2967,  -8.7015],\n",
      "         [ -5.7054,  -5.7221,  -5.7901,  ...,  -6.2553,  -7.2003,  -4.7285],\n",
      "         ...,\n",
      "         [ -6.9316,  -6.9612,  -6.9334,  ...,  -7.0514,  -7.8796,  -5.2261],\n",
      "         [ -6.1082,  -6.2204,  -6.1088,  ...,  -6.4060,  -7.3081,  -5.1711],\n",
      "         [ -6.4777,  -6.5449,  -6.4856,  ...,  -6.7430,  -7.4082,  -5.3452]],\n",
      "\n",
      "        [[ -7.3196,  -7.2804,  -7.2681,  ...,  -6.6674,  -6.4150,  -4.0224],\n",
      "         [ -7.4689,  -7.6932,  -7.4966,  ...,  -6.5350,  -7.8933,  -4.0718],\n",
      "         [-12.0648, -11.7098, -11.7943,  ..., -11.7555,  -9.1776,  -6.7720],\n",
      "         ...,\n",
      "         [ -7.4380,  -7.4592,  -7.3523,  ...,  -5.0284,  -5.8253,  -5.4128],\n",
      "         [ -8.6881,  -8.8037,  -8.7285,  ...,  -7.3393,  -7.1862,  -5.7740],\n",
      "         [-14.0486, -13.6655, -13.7619,  ..., -10.8895, -10.1938, -10.9618]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 3.035637378692627\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9848, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4626,  -6.4744,  -6.4954,  ...,  -5.9234,  -5.6579,  -3.4695],\n",
      "         [-10.6842, -10.4991, -10.9397,  ..., -10.1649,  -9.2547,  -7.3087],\n",
      "         [ -6.6500,  -6.4325,  -6.2944,  ...,  -5.4808,  -4.3679,  -8.4139],\n",
      "         ...,\n",
      "         [ -7.4304,  -7.2271,  -7.3842,  ...,  -7.1263,  -7.7007,  -4.7132],\n",
      "         [ -7.1208,  -7.0508,  -7.1886,  ...,  -7.0516,  -6.8218,  -4.4506],\n",
      "         [ -6.9768,  -6.7198,  -6.9009,  ...,  -6.9704,  -6.6279,  -5.1263]],\n",
      "\n",
      "        [[ -6.7438,  -6.6737,  -6.7090,  ...,  -6.0138,  -5.9117,  -3.7656],\n",
      "         [ -9.0961,  -9.0602,  -9.1044,  ...,  -9.0068, -10.4290,  -5.3322],\n",
      "         [ -9.4759,  -9.3304,  -9.3854,  ...,  -8.9024, -10.1953,  -7.6126],\n",
      "         ...,\n",
      "         [ -5.6638,  -5.5537,  -5.6035,  ...,  -5.8675,  -6.1410,  -2.3645],\n",
      "         [ -5.8488,  -5.6897,  -5.7658,  ...,  -6.0360,  -6.4533,  -1.9834],\n",
      "         [ -5.8913,  -5.7384,  -5.8840,  ...,  -5.9245,  -6.2884,  -2.5666]],\n",
      "\n",
      "        [[ -7.6284,  -7.5636,  -7.6104,  ...,  -6.5442,  -6.8635,  -4.4044],\n",
      "         [-13.6001, -13.1912, -13.4818,  ..., -12.2461, -13.6073, -12.4407],\n",
      "         [ -6.8366,  -7.2401,  -7.2174,  ...,  -6.7111,  -9.1036,  -4.7164],\n",
      "         ...,\n",
      "         [ -6.4420,  -6.5268,  -6.4718,  ...,  -6.3870,  -8.2832,  -5.1270],\n",
      "         [ -7.2168,  -7.3089,  -7.2523,  ...,  -6.8338,  -8.6310,  -4.7762],\n",
      "         [ -6.6842,  -6.9295,  -6.8353,  ...,  -6.4755,  -8.3671,  -4.5969]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6552,  -6.6315,  -6.6960,  ...,  -6.0199,  -5.8362,  -3.8313],\n",
      "         [-10.5584, -10.3428, -10.2605,  ...,  -9.5729,  -9.6693,  -8.0762],\n",
      "         [ -6.2549,  -6.3145,  -6.1964,  ...,  -6.1931,  -7.1441,  -5.0236],\n",
      "         ...,\n",
      "         [ -6.2451,  -6.2919,  -6.1965,  ...,  -6.0923,  -6.5391,  -4.3063],\n",
      "         [ -6.5878,  -6.7147,  -6.6318,  ...,  -6.6984,  -7.3467,  -4.3433],\n",
      "         [ -6.6965,  -6.8002,  -6.5281,  ...,  -6.4935,  -7.0748,  -3.6579]],\n",
      "\n",
      "        [[ -7.2725,  -7.3577,  -7.4412,  ...,  -6.8947,  -7.2063,  -3.0789],\n",
      "         [-14.1380, -13.6509, -14.0314,  ..., -11.0468, -11.2434,  -9.8500],\n",
      "         [ -6.6343,  -6.6964,  -6.7299,  ...,  -6.4187,  -7.1026,  -3.5876],\n",
      "         ...,\n",
      "         [ -6.2863,  -6.3003,  -6.4541,  ...,  -6.3496,  -6.4053,  -3.3999],\n",
      "         [ -7.0786,  -7.2188,  -7.2469,  ...,  -6.8402,  -6.8959,  -3.7592],\n",
      "         [ -6.8351,  -7.0352,  -7.0417,  ...,  -6.6702,  -7.4296,  -3.3942]],\n",
      "\n",
      "        [[ -6.3080,  -6.2942,  -6.3364,  ...,  -5.7581,  -5.3602,  -3.7779],\n",
      "         [-12.3355, -12.0682, -12.0675,  ...,  -8.1263, -10.1185,  -9.2153],\n",
      "         [ -5.7981,  -5.8510,  -5.9051,  ...,  -6.2195,  -7.0518,  -5.1715],\n",
      "         ...,\n",
      "         [ -5.5499,  -5.6102,  -5.5802,  ...,  -5.9590,  -7.0974,  -3.9417],\n",
      "         [ -5.8069,  -5.7642,  -5.7344,  ...,  -5.9678,  -6.8247,  -4.7029],\n",
      "         [ -5.4395,  -5.4099,  -5.4000,  ...,  -5.4552,  -6.3945,  -4.4995]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.9848458766937256\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.9425, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7737,  -6.6962,  -6.6878,  ...,  -6.0963,  -6.1487,  -3.7946],\n",
      "         [ -7.9203,  -7.5579,  -7.7910,  ...,  -7.5953,  -7.3646,  -4.0559],\n",
      "         [ -6.6755,  -6.7000,  -6.4862,  ...,  -5.1873,  -6.2894,  -4.6326],\n",
      "         ...,\n",
      "         [ -5.4043,  -5.2677,  -5.2620,  ...,  -5.5112,  -5.7264,  -1.3537],\n",
      "         [ -3.0120,  -3.0973,  -2.9418,  ...,  -2.7521,  -4.8004,  -1.5480],\n",
      "         [ -5.7315,  -5.4720,  -5.6386,  ...,  -5.7990,  -5.8773,  -1.8942]],\n",
      "\n",
      "        [[ -6.6399,  -6.6007,  -6.6127,  ...,  -5.9410,  -5.7906,  -3.9618],\n",
      "         [ -9.2242,  -8.5881,  -8.8245,  ...,  -8.4691,  -9.6492,  -6.6758],\n",
      "         [-10.2684, -10.2067, -10.1251,  ...,  -9.0324,  -8.8031,  -8.0350],\n",
      "         ...,\n",
      "         [ -5.9345,  -5.7214,  -5.7638,  ...,  -5.1270,  -6.2160,  -2.7843],\n",
      "         [ -6.0929,  -5.9945,  -6.0435,  ...,  -5.7228,  -6.3657,  -2.7649],\n",
      "         [ -5.7192,  -5.6573,  -5.8045,  ...,  -5.4953,  -5.9531,  -2.7482]],\n",
      "\n",
      "        [[ -6.4164,  -6.3655,  -6.3933,  ...,  -5.7126,  -5.5532,  -3.7676],\n",
      "         [-12.8267, -12.4629, -12.7003,  ..., -10.2275, -10.2162,  -7.8125],\n",
      "         [ -6.2174,  -6.3186,  -6.3893,  ...,  -6.3436,  -7.4424,  -3.9241],\n",
      "         ...,\n",
      "         [ -7.1661,  -7.0864,  -7.0831,  ...,  -7.0210,  -7.8153,  -5.4407],\n",
      "         [ -6.0488,  -6.0650,  -6.1056,  ...,  -6.1287,  -7.1266,  -3.7413],\n",
      "         [ -5.9225,  -6.0400,  -5.9589,  ...,  -5.8730,  -6.9256,  -3.9265]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4583,  -7.4942,  -7.4398,  ...,  -6.7070,  -6.5516,  -4.1578],\n",
      "         [ -7.6498,  -7.9672,  -7.8625,  ...,  -6.9332,  -6.3378,  -6.4587],\n",
      "         [-11.8590, -11.7365, -11.4708,  ...,  -9.4769,  -9.7720, -11.1241],\n",
      "         ...,\n",
      "         [ -7.2355,  -7.5002,  -7.4791,  ...,  -7.1212,  -6.7700,  -6.8586],\n",
      "         [ -6.9732,  -7.3423,  -7.2408,  ...,  -6.1825,  -7.1067,  -6.8077],\n",
      "         [ -8.0610,  -8.3273,  -8.3006,  ...,  -7.9224,  -7.6685,  -6.0291]],\n",
      "\n",
      "        [[ -6.7316,  -6.7454,  -6.7179,  ...,  -5.9463,  -5.8150,  -4.7996],\n",
      "         [-13.9998, -14.2760, -14.2308,  ..., -12.8714, -11.4753, -13.4936],\n",
      "         [ -7.3060,  -7.3675,  -7.5933,  ...,  -7.8335,  -5.9587,  -7.4439],\n",
      "         ...,\n",
      "         [-11.3066, -11.1703, -11.0722,  ...,  -8.5978,  -8.2688,  -9.0867],\n",
      "         [ -7.5978,  -7.4105,  -7.3934,  ...,  -7.1992,  -7.5283,  -7.6004],\n",
      "         [-12.4219, -12.4042, -12.3188,  ..., -11.0353,  -9.5124,  -5.9104]],\n",
      "\n",
      "        [[-11.3480, -11.3823, -11.4112,  ..., -10.8609, -11.9842,  -7.7913],\n",
      "         [-12.8101, -13.0317, -12.7637,  ..., -11.4311,  -9.6222, -12.1198],\n",
      "         [ -5.7983,  -5.9064,  -5.8337,  ...,  -5.9765,  -7.5325,  -5.2439],\n",
      "         ...,\n",
      "         [ -5.9464,  -6.0027,  -5.8208,  ...,  -6.3719,  -7.2011,  -5.2798],\n",
      "         [ -7.0142,  -7.0757,  -6.9395,  ...,  -7.0496,  -7.8395,  -6.2320],\n",
      "         [ -5.9937,  -6.1717,  -5.9410,  ...,  -5.9299,  -7.5208,  -4.6052]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.9424759149551392\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1705, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5272,  -6.5076,  -6.5563,  ...,  -5.8437,  -5.5954,  -3.5937],\n",
      "         [ -7.6250,  -7.4355,  -7.6505,  ...,  -8.1517,  -8.3321,  -5.4590],\n",
      "         [ -7.7525,  -7.7145,  -7.8245,  ...,  -8.1849,  -6.9058,  -6.5593],\n",
      "         ...,\n",
      "         [ -6.0727,  -5.9741,  -6.0375,  ...,  -5.9319,  -6.6843,  -3.8850],\n",
      "         [ -6.1193,  -6.0028,  -6.0664,  ...,  -6.0013,  -6.5862,  -3.6998],\n",
      "         [ -5.5657,  -5.5392,  -5.6300,  ...,  -5.3770,  -5.8594,  -3.5037]],\n",
      "\n",
      "        [[ -6.3681,  -6.3155,  -6.3414,  ...,  -5.6661,  -5.5132,  -3.8429],\n",
      "         [-12.6219, -12.2931, -12.1639,  ...,  -9.3343, -10.3631, -10.3684],\n",
      "         [ -6.2055,  -6.3034,  -6.2670,  ...,  -6.0319,  -7.1667,  -4.9851],\n",
      "         ...,\n",
      "         [ -6.4230,  -6.5171,  -6.4121,  ...,  -6.2706,  -7.3451,  -4.6902],\n",
      "         [ -6.2291,  -6.2573,  -6.2183,  ...,  -6.2937,  -6.8924,  -4.8694],\n",
      "         [ -5.9958,  -6.1018,  -6.0245,  ...,  -5.8989,  -6.6896,  -5.0468]],\n",
      "\n",
      "        [[ -6.2312,  -6.1904,  -6.1780,  ...,  -5.7313,  -5.5053,  -3.5464],\n",
      "         [ -7.3095,  -7.2519,  -7.4833,  ...,  -6.8936,  -8.3929,  -1.4015],\n",
      "         [ -6.9599,  -7.0680,  -7.1624,  ...,  -7.6643,  -7.2936,  -3.8572],\n",
      "         ...,\n",
      "         [ -6.1998,  -6.1556,  -6.1285,  ...,  -5.9453,  -6.5544,  -1.9073],\n",
      "         [ -5.7398,  -5.7001,  -5.6070,  ...,  -5.7025,  -5.9756,  -1.1671],\n",
      "         [ -6.0137,  -6.0019,  -5.9899,  ...,  -6.2599,  -6.3631,  -1.9946]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7158,  -6.6742,  -6.6763,  ...,  -5.8630,  -5.8416,  -3.9528],\n",
      "         [ -7.7916,  -7.7188,  -7.7952,  ...,  -8.4018,  -8.6098,  -5.2779],\n",
      "         [ -8.3761,  -8.5203,  -8.5065,  ...,  -9.1669,  -8.1331,  -6.5881],\n",
      "         ...,\n",
      "         [ -5.9047,  -5.8688,  -6.0273,  ...,  -6.3426,  -6.3021,  -4.1741],\n",
      "         [ -5.9239,  -5.8208,  -6.0394,  ...,  -6.1598,  -6.4028,  -3.3256],\n",
      "         [ -5.7882,  -5.7462,  -5.8959,  ...,  -6.1534,  -6.1790,  -2.4656]],\n",
      "\n",
      "        [[ -6.6197,  -6.6087,  -6.6168,  ...,  -5.8303,  -5.8635,  -3.8984],\n",
      "         [ -5.1899,  -5.5823,  -5.1688,  ...,  -4.2900,  -2.2888,  -4.9977],\n",
      "         [ -3.1305,  -3.5859,  -3.4004,  ...,  -3.9848,  -3.8328,  -3.3690],\n",
      "         ...,\n",
      "         [ -5.8079,  -5.9446,  -5.9241,  ...,  -5.8281,  -5.4064,  -3.8136],\n",
      "         [ -5.3837,  -5.5417,  -5.6442,  ...,  -4.8367,  -5.5101,  -4.8986],\n",
      "         [ -5.7224,  -5.8269,  -5.9214,  ...,  -5.6628,  -5.3496,  -3.6222]],\n",
      "\n",
      "        [[ -7.3404,  -7.3397,  -7.3059,  ...,  -6.4588,  -6.4963,  -4.2823],\n",
      "         [-11.0008, -10.9102, -10.9251,  ...,  -9.1980, -10.3028, -11.4709],\n",
      "         [ -8.9819,  -8.6125,  -8.9142,  ...,  -9.5611,  -9.2746,  -7.5119],\n",
      "         ...,\n",
      "         [ -7.6220,  -7.6980,  -7.7598,  ...,  -7.5847,  -7.1288,  -6.7878],\n",
      "         [ -7.5404,  -7.6194,  -7.7079,  ...,  -7.6978,  -7.4071,  -6.5781],\n",
      "         [ -7.5299,  -7.5732,  -7.5839,  ...,  -7.5470,  -7.5542,  -5.6434]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.1704792976379395\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4681, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0268,  -7.0303,  -6.9932,  ...,  -6.3630,  -6.0659,  -4.3797],\n",
      "         [-12.8188, -12.5820, -12.7977,  ..., -12.2872, -10.5044,  -9.8086],\n",
      "         [ -3.8226,  -3.9129,  -4.0401,  ...,  -4.0466,  -3.6937,  -4.6162],\n",
      "         ...,\n",
      "         [ -7.9693,  -8.0210,  -8.1055,  ...,  -7.7472,  -7.4637,  -7.1843],\n",
      "         [ -7.2106,  -7.2207,  -7.2082,  ...,  -6.4950,  -6.4129,  -6.6458],\n",
      "         [ -6.9718,  -7.1718,  -7.2178,  ...,  -6.5920,  -6.6862,  -5.9778]],\n",
      "\n",
      "        [[ -6.7689,  -6.7169,  -6.7338,  ...,  -5.9974,  -5.9660,  -3.8950],\n",
      "         [ -8.8647,  -8.8209,  -8.8558,  ...,  -9.3621,  -9.4180,  -5.7417],\n",
      "         [ -9.4355,  -9.3577,  -9.5562,  ...,  -9.6192,  -9.1142,  -7.6755],\n",
      "         ...,\n",
      "         [ -6.0872,  -6.0626,  -6.1095,  ...,  -6.4162,  -6.2412,  -3.4198],\n",
      "         [ -5.7993,  -5.7764,  -5.8017,  ...,  -5.9133,  -5.9541,  -2.9106],\n",
      "         [ -6.3581,  -6.1739,  -6.3119,  ...,  -6.3075,  -6.5364,  -2.9367]],\n",
      "\n",
      "        [[ -6.2207,  -6.1492,  -6.1564,  ...,  -5.5504,  -5.2033,  -3.8286],\n",
      "         [ -8.7605,  -8.4532,  -8.4603,  ...,  -6.5030,  -6.1665,  -7.6127],\n",
      "         [ -6.1577,  -6.2408,  -6.2696,  ...,  -6.2218,  -7.1044,  -4.3555],\n",
      "         ...,\n",
      "         [ -7.0984,  -7.0021,  -6.9883,  ...,  -7.0989,  -7.2005,  -5.2111],\n",
      "         [ -6.3933,  -6.4499,  -6.4623,  ...,  -6.4214,  -7.0534,  -4.4933],\n",
      "         [ -6.2085,  -6.2656,  -6.2511,  ...,  -6.3703,  -7.0280,  -4.5935]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4248,  -6.4004,  -6.4099,  ...,  -5.7850,  -5.5646,  -3.8597],\n",
      "         [-10.4155, -10.0732, -10.2068,  ...,  -7.9896,  -8.5239,  -7.7395],\n",
      "         [ -6.2197,  -6.3664,  -6.3247,  ...,  -6.5985,  -7.5224,  -4.5203],\n",
      "         ...,\n",
      "         [ -6.3961,  -6.5054,  -6.4729,  ...,  -6.6471,  -7.0674,  -5.0607],\n",
      "         [ -6.0524,  -6.0544,  -6.0187,  ...,  -5.7844,  -6.8802,  -4.5323],\n",
      "         [ -5.7581,  -5.8899,  -5.7593,  ...,  -5.7942,  -6.0633,  -4.4688]],\n",
      "\n",
      "        [[ -7.2260,  -7.2015,  -7.1925,  ...,  -6.3756,  -6.2628,  -4.2479],\n",
      "         [-12.3899, -12.3061, -12.7134,  ..., -10.3425, -11.4858,  -9.6832],\n",
      "         [ -8.1710,  -8.2109,  -8.5920,  ...,  -5.8273,  -8.2653,  -6.9415],\n",
      "         ...,\n",
      "         [ -8.1985,  -8.2236,  -8.2625,  ...,  -8.3829,  -7.5224,  -6.0264],\n",
      "         [ -8.1566,  -8.2270,  -8.2066,  ...,  -8.5985,  -7.7914,  -6.0094],\n",
      "         [ -8.2911,  -8.2913,  -8.3145,  ...,  -8.3835,  -7.8640,  -6.7745]],\n",
      "\n",
      "        [[ -7.1793,  -7.1848,  -7.1626,  ...,  -6.4424,  -6.2083,  -4.3556],\n",
      "         [-15.1228, -15.0354, -15.2501,  ..., -13.1689, -12.9089, -12.8967],\n",
      "         [-11.2091, -11.2387, -10.7280,  ...,  -9.5165,  -7.8975,  -6.4557],\n",
      "         ...,\n",
      "         [ -8.1976,  -8.2042,  -8.0796,  ...,  -8.6239,  -7.5761,  -6.9404],\n",
      "         [ -7.3320,  -7.4646,  -7.3694,  ...,  -7.5321,  -6.7077,  -5.2234],\n",
      "         [ -7.7580,  -7.8392,  -7.7753,  ...,  -7.9095,  -7.2873,  -5.9652]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.4680709838867188\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9348, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1814,  -7.1755,  -7.1051,  ...,  -6.7347,  -6.4086,  -4.1151],\n",
      "         [ -7.9700,  -8.1362,  -7.9834,  ...,  -7.6774,  -6.5969,  -7.1150],\n",
      "         [-10.1555, -10.6248, -10.1661,  ...,  -9.9462,  -8.5476,  -6.1694],\n",
      "         ...,\n",
      "         [ -3.5914,  -4.0728,  -3.6817,  ...,  -4.2484,  -4.8077,  -3.0978],\n",
      "         [ -8.6139,  -8.4146,  -8.4003,  ...,  -8.4902,  -7.1167,  -5.7593],\n",
      "         [-11.4156, -10.8756, -11.1130,  ...,  -9.4087, -10.4109,  -8.1935]],\n",
      "\n",
      "        [[ -6.7048,  -6.6741,  -6.6775,  ...,  -5.8353,  -5.9872,  -3.8671],\n",
      "         [ -8.1460,  -7.9506,  -7.9111,  ...,  -8.2426,  -8.4309,  -5.4612],\n",
      "         [ -9.1473,  -9.2197,  -9.2530,  ...,  -9.2900,  -8.4106,  -5.9011],\n",
      "         ...,\n",
      "         [ -5.6749,  -5.5180,  -5.5618,  ...,  -5.6723,  -5.9426,  -2.5411],\n",
      "         [ -5.9581,  -5.9904,  -5.9587,  ...,  -5.9939,  -5.8850,  -3.3870],\n",
      "         [ -5.8704,  -5.8486,  -5.8967,  ...,  -6.1036,  -5.8198,  -2.6611]],\n",
      "\n",
      "        [[ -6.6780,  -6.6375,  -6.6627,  ...,  -5.9445,  -5.8154,  -3.9187],\n",
      "         [ -6.7984,  -6.3957,  -6.7213,  ...,  -6.9164,  -7.1352,  -4.2624],\n",
      "         [ -8.4820,  -8.2990,  -8.4554,  ...,  -9.1275,  -7.6393,  -6.4914],\n",
      "         ...,\n",
      "         [ -5.9405,  -5.8230,  -5.9348,  ...,  -5.8400,  -6.2747,  -2.1175],\n",
      "         [ -6.1050,  -6.0256,  -6.0472,  ...,  -6.2824,  -6.5157,  -2.3988],\n",
      "         [ -5.9921,  -5.7967,  -5.9427,  ...,  -6.1351,  -6.4900,  -2.2231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6242,  -6.5754,  -6.6080,  ...,  -5.8566,  -5.7956,  -3.6631],\n",
      "         [ -9.8795,  -9.8127,  -9.8336,  ..., -10.2257, -10.3015,  -6.7873],\n",
      "         [-10.6257, -10.7208, -10.7872,  ..., -10.3540,  -9.7203,  -6.4762],\n",
      "         ...,\n",
      "         [ -6.5282,  -6.4944,  -6.6100,  ...,  -6.3016,  -6.5478,  -3.7868],\n",
      "         [ -6.1995,  -6.0654,  -6.1489,  ...,  -5.7987,  -6.4300,  -3.5578],\n",
      "         [ -6.1904,  -6.1775,  -6.2820,  ...,  -6.0469,  -6.3597,  -3.3558]],\n",
      "\n",
      "        [[ -6.6828,  -6.6591,  -6.6841,  ...,  -6.0592,  -5.9396,  -3.8060],\n",
      "         [ -8.9079,  -8.8267,  -8.8667,  ...,  -9.0517,  -9.9121,  -5.4258],\n",
      "         [ -7.4578,  -7.4582,  -7.4772,  ...,  -7.6232,  -8.4921,  -4.6334],\n",
      "         ...,\n",
      "         [ -5.5790,  -5.5499,  -5.6523,  ...,  -5.6669,  -6.0695,  -2.3938],\n",
      "         [ -5.7583,  -5.7715,  -5.9150,  ...,  -6.0290,  -6.4428,  -2.2683],\n",
      "         [ -5.3181,  -5.3541,  -5.4252,  ...,  -5.6453,  -6.0362,  -1.7849]],\n",
      "\n",
      "        [[ -6.8784,  -6.8056,  -6.8649,  ...,  -6.7787,  -6.7085,  -3.8675],\n",
      "         [-10.9936, -10.6244, -11.0089,  ...,  -7.2442,  -8.9931,  -9.5567],\n",
      "         [ -6.9222,  -6.8912,  -6.9126,  ...,  -6.8655,  -7.0972,  -3.8934],\n",
      "         ...,\n",
      "         [ -7.1961,  -7.0701,  -7.1549,  ...,  -7.1639,  -7.1643,  -3.7437],\n",
      "         [ -7.2960,  -7.1681,  -7.2877,  ...,  -6.9712,  -7.5723,  -3.4199],\n",
      "         [ -7.1390,  -6.9941,  -7.0972,  ...,  -7.1275,  -7.2541,  -3.1847]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.93475341796875\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2129, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5124,  -6.4814,  -6.5205,  ...,  -5.7835,  -5.6687,  -3.7175],\n",
      "         [ -5.6540,  -5.4918,  -5.6247,  ...,  -5.3322,  -5.1762,  -3.3167],\n",
      "         [ -4.2933,  -3.7887,  -4.0172,  ...,  -3.1587,  -1.9315,  -3.7534],\n",
      "         ...,\n",
      "         [ -7.4635,  -7.5327,  -7.4753,  ...,  -7.1535,  -7.2624,  -4.1871],\n",
      "         [ -7.4027,  -7.3529,  -7.3222,  ...,  -6.8848,  -6.8521,  -3.0719],\n",
      "         [ -6.7405,  -6.6868,  -6.6655,  ...,  -5.9636,  -5.7788,  -2.3098]],\n",
      "\n",
      "        [[ -6.7996,  -6.7575,  -6.7622,  ...,  -5.9098,  -6.0052,  -3.9946],\n",
      "         [ -9.6562,  -9.7177,  -9.2907,  ...,  -8.1209,  -9.0226,  -8.1974],\n",
      "         [  0.1049,  -0.3559,  -0.1778,  ...,   0.6439,  -0.2776,   1.2296],\n",
      "         ...,\n",
      "         [ -6.4861,  -6.4622,  -6.4131,  ...,  -6.6882,  -6.4868,  -5.1301],\n",
      "         [ -6.4218,  -6.3713,  -6.2595,  ...,  -5.7387,  -6.9857,  -5.5405],\n",
      "         [ -6.1588,  -6.2140,  -6.1055,  ...,  -5.8141,  -6.4641,  -5.5916]],\n",
      "\n",
      "        [[ -6.5252,  -6.4919,  -6.5094,  ...,  -5.7998,  -5.6599,  -3.7829],\n",
      "         [-12.7466, -12.1681, -12.6106,  ..., -10.7776, -10.9206,  -5.8492],\n",
      "         [ -6.1257,  -6.1798,  -6.1998,  ...,  -6.4525,  -7.7658,  -4.5764],\n",
      "         ...,\n",
      "         [ -7.0523,  -7.0689,  -7.0470,  ...,  -7.5210,  -7.4566,  -5.9317],\n",
      "         [ -6.2327,  -6.2976,  -6.1975,  ...,  -6.0109,  -6.8987,  -4.9740],\n",
      "         [ -6.5052,  -6.5332,  -6.4854,  ...,  -6.2788,  -6.9298,  -4.4213]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8938,  -6.9129,  -6.8637,  ...,  -6.1639,  -6.1190,  -4.0278],\n",
      "         [ -7.8207,  -7.9692,  -7.7965,  ...,  -7.2762,  -8.2136,  -7.1105],\n",
      "         [-11.7919, -11.8448, -11.5495,  ..., -12.0412,  -9.7155,  -8.7873],\n",
      "         ...,\n",
      "         [ -5.6712,  -5.9752,  -5.5936,  ...,  -5.8264,  -6.6871,  -3.1111],\n",
      "         [ -8.2181,  -8.4641,  -8.3110,  ...,  -7.3890,  -7.9970,  -5.4844],\n",
      "         [-12.6797, -13.0139, -12.6070,  ..., -11.7892, -11.9524,  -7.8083]],\n",
      "\n",
      "        [[ -7.0652,  -7.0254,  -7.0345,  ...,  -6.1921,  -6.1887,  -4.1074],\n",
      "         [-12.2726, -12.2471, -12.0165,  ...,  -8.8649,  -9.2657,  -9.9104],\n",
      "         [ -5.3548,  -5.4156,  -5.4552,  ...,  -5.0508,  -6.6778,  -3.9133],\n",
      "         ...,\n",
      "         [ -5.2133,  -5.2053,  -5.1313,  ...,  -4.8879,  -6.9826,  -3.8019],\n",
      "         [ -5.4866,  -5.6500,  -5.4500,  ...,  -5.3664,  -6.6840,  -3.5752],\n",
      "         [ -5.3286,  -5.3775,  -5.4410,  ...,  -5.2751,  -7.1119,  -3.9052]],\n",
      "\n",
      "        [[ -6.6511,  -6.5929,  -6.6212,  ...,  -5.9277,  -5.8321,  -3.7786],\n",
      "         [-13.0918, -12.4867, -12.8353,  ...,  -9.3124, -11.1664,  -9.1006],\n",
      "         [ -5.8830,  -6.0083,  -5.9413,  ...,  -6.0999,  -6.9404,  -3.7851],\n",
      "         ...,\n",
      "         [ -6.1511,  -6.0691,  -6.1195,  ...,  -6.2738,  -6.4230,  -3.6749],\n",
      "         [ -6.2696,  -6.2212,  -6.2571,  ...,  -6.4702,  -6.9020,  -3.8981],\n",
      "         [ -6.5441,  -6.5533,  -6.5379,  ...,  -7.0125,  -6.8382,  -4.9045]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2129008769989014\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2984, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3826,  -7.4200,  -7.3468,  ...,  -7.0994,  -6.8330,  -4.3174],\n",
      "         [-10.1904,  -9.9872, -10.2085,  ...,  -8.7276,  -8.7567,  -8.4456],\n",
      "         [ -6.1194,  -6.1968,  -6.2630,  ...,  -5.7315,  -7.2730,  -4.7362],\n",
      "         ...,\n",
      "         [ -6.9990,  -7.1307,  -7.1106,  ...,  -6.9899,  -7.8186,  -3.7341],\n",
      "         [ -7.2777,  -7.3660,  -7.3359,  ...,  -6.9994,  -7.7988,  -4.8905],\n",
      "         [ -6.3682,  -6.4066,  -6.3251,  ...,  -6.1754,  -7.0833,  -4.4358]],\n",
      "\n",
      "        [[ -6.2028,  -6.3309,  -6.3539,  ...,  -6.3142,  -6.9289,  -2.7196],\n",
      "         [ -8.5748,  -8.0135,  -8.7288,  ...,  -7.8390,  -7.9823,  -4.6167],\n",
      "         [ -5.9311,  -6.1333,  -6.0673,  ...,  -6.0665,  -6.4365,  -4.0811],\n",
      "         ...,\n",
      "         [ -5.8538,  -6.0197,  -5.9656,  ...,  -6.1048,  -6.8179,  -2.6186],\n",
      "         [ -6.0967,  -6.1913,  -6.1481,  ...,  -6.3732,  -6.6125,  -3.5545],\n",
      "         [ -5.8367,  -5.9245,  -5.9898,  ...,  -5.9876,  -6.5882,  -2.8103]],\n",
      "\n",
      "        [[ -7.0068,  -6.9715,  -6.9620,  ...,  -6.4366,  -6.1109,  -4.2065],\n",
      "         [ -8.5170,  -8.3574,  -8.6362,  ...,  -9.8486,  -7.3819,  -2.8064],\n",
      "         [ -7.2439,  -7.5627,  -7.4600,  ...,  -7.5133,  -7.0002,  -3.2304],\n",
      "         ...,\n",
      "         [ -5.0932,  -4.9350,  -5.1903,  ...,  -5.6099,  -4.7427,  -2.1626],\n",
      "         [-15.4032, -15.5253, -15.2975,  ..., -12.7530, -10.2876, -12.7322],\n",
      "         [-14.5506, -14.3867, -14.4440,  ..., -11.5448, -12.2658,  -9.6185]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6878,  -6.6375,  -6.6700,  ...,  -5.9685,  -5.8253,  -3.7352],\n",
      "         [ -6.2573,  -6.2649,  -6.4253,  ...,  -6.5841,  -7.1530,  -2.9361],\n",
      "         [ -6.5652,  -6.6540,  -6.4858,  ...,  -6.7635,  -6.5239,  -3.6042],\n",
      "         ...,\n",
      "         [ -6.0382,  -6.0113,  -6.0961,  ...,  -6.3026,  -6.3498,  -3.3322],\n",
      "         [ -6.4751,  -6.4251,  -6.4584,  ...,  -6.2766,  -6.3281,  -3.8176],\n",
      "         [ -5.9871,  -5.9305,  -6.0224,  ...,  -5.6684,  -5.7809,  -3.7358]],\n",
      "\n",
      "        [[ -6.6103,  -6.6078,  -6.6035,  ...,  -5.9463,  -5.7408,  -3.9196],\n",
      "         [ -8.2379,  -7.9348,  -8.2473,  ...,  -7.8396,  -8.3993,  -3.8803],\n",
      "         [ -9.0208,  -8.8177,  -9.0501,  ...,  -7.9864,  -9.3702,  -3.6898],\n",
      "         ...,\n",
      "         [ -6.5142,  -6.3827,  -6.5640,  ...,  -6.3666,  -7.0486,  -2.0125],\n",
      "         [ -5.9855,  -5.9052,  -6.0016,  ...,  -5.6852,  -6.7543,  -1.4321],\n",
      "         [ -6.6071,  -6.4628,  -6.6132,  ...,  -6.0260,  -7.0986,  -2.3582]],\n",
      "\n",
      "        [[ -7.0002,  -6.9612,  -6.9951,  ...,  -6.4733,  -6.1760,  -4.1937],\n",
      "         [-13.8486, -13.9617, -14.0367,  ..., -12.8080,  -9.6592, -16.8620],\n",
      "         [-16.1303, -16.4307, -16.0852,  ..., -13.8019, -10.0214, -18.7956],\n",
      "         ...,\n",
      "         [ -5.9611,  -6.1548,  -6.0781,  ...,  -7.1522,  -5.8470,  -7.4134],\n",
      "         [ -6.2463,  -6.2841,  -6.3117,  ...,  -7.1688,  -5.7266,  -6.0171],\n",
      "         [ -7.1989,  -7.1874,  -7.2727,  ...,  -7.8795,  -6.4402,  -6.4952]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.298448324203491\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8192, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0445,  -7.0252,  -6.9213,  ...,  -6.4977,  -6.4200,  -4.0871],\n",
      "         [ -7.6432,  -7.9433,  -8.0845,  ...,  -6.9141,  -6.4299,  -5.3444],\n",
      "         [ -3.8596,  -4.0255,  -3.7774,  ...,  -3.9510,  -2.4028,  -8.1359],\n",
      "         ...,\n",
      "         [ -2.6375,  -3.4093,  -2.5329,  ...,  -4.6797,  -2.8160,  -3.6238],\n",
      "         [-12.5802, -12.9918, -12.6817,  ..., -11.9811, -10.4497,  -8.4938],\n",
      "         [-13.7937, -13.7411, -13.9104,  ..., -12.1800,  -9.9428,  -9.2450]],\n",
      "\n",
      "        [[ -7.0535,  -7.0808,  -7.0034,  ...,  -6.5274,  -6.2514,  -4.5838],\n",
      "         [-11.6350, -11.5824, -11.9503,  ..., -11.4987,  -9.8798, -11.2327],\n",
      "         [-15.5678, -16.0102, -15.6930,  ..., -13.7146, -13.0486, -15.6958],\n",
      "         ...,\n",
      "         [ -5.2775,  -5.5678,  -5.4096,  ...,  -5.4508,  -4.9926,  -5.3662],\n",
      "         [ -4.9934,  -5.2284,  -5.0038,  ...,  -4.9187,  -4.9574,  -4.4272],\n",
      "         [ -5.5995,  -5.8771,  -5.6254,  ...,  -5.8359,  -5.1368,  -4.0635]],\n",
      "\n",
      "        [[ -6.6349,  -6.6409,  -6.5900,  ...,  -6.1024,  -5.7869,  -4.1222],\n",
      "         [ -6.2678,  -6.5822,  -6.5853,  ...,  -6.9462,  -5.8473,  -7.2824],\n",
      "         [-11.9142, -11.8763, -11.9002,  ..., -11.2438, -10.0668,  -9.2582],\n",
      "         ...,\n",
      "         [ -7.6445,  -7.7451,  -7.7246,  ...,  -6.9950,  -6.6821,  -7.2954],\n",
      "         [ -5.8635,  -5.8738,  -5.8179,  ...,  -6.6577,  -5.2487,  -5.6522],\n",
      "         [ -8.0257,  -8.2001,  -8.0954,  ...,  -7.4683,  -7.1954,  -6.2032]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0741,  -7.1196,  -6.9971,  ...,  -6.4356,  -6.3690,  -4.3212],\n",
      "         [ -6.3835,  -6.3739,  -6.3893,  ...,  -7.2246,  -7.3053,  -1.8523],\n",
      "         [-11.8124, -11.8295, -11.8934,  ..., -10.7109, -10.5241,  -8.6815],\n",
      "         ...,\n",
      "         [-11.2864, -11.8083, -11.3687,  ...,  -9.1195,  -8.9571,  -7.6927],\n",
      "         [-11.5454, -12.1353, -11.4248,  ..., -10.9674,  -9.0393,  -4.2143],\n",
      "         [-14.3636, -13.8743, -14.2713,  ..., -11.0678, -12.8517,  -9.0595]],\n",
      "\n",
      "        [[ -6.8979,  -6.8539,  -6.8502,  ...,  -5.9654,  -6.2455,  -3.8664],\n",
      "         [-11.7832, -11.9843, -11.8615,  ...,  -8.9144, -11.3906,  -9.9548],\n",
      "         [ -5.1624,  -5.2309,  -5.3271,  ...,  -5.5142,  -7.3143,  -4.3350],\n",
      "         ...,\n",
      "         [ -5.5445,  -5.5792,  -5.5209,  ...,  -5.5060,  -6.7035,  -4.9941],\n",
      "         [ -5.9783,  -6.1252,  -6.0211,  ...,  -5.7061,  -6.9866,  -4.7933],\n",
      "         [ -5.6648,  -5.6604,  -5.6689,  ...,  -5.5903,  -6.8434,  -5.3188]],\n",
      "\n",
      "        [[ -6.9116,  -6.9158,  -6.8612,  ...,  -6.1933,  -6.2155,  -4.1508],\n",
      "         [-13.7603, -13.5707, -13.7505,  ..., -12.3999, -11.6012, -11.4991],\n",
      "         [-11.3204, -10.8065, -10.9950,  ...,  -9.1260,  -9.8969,  -8.6826],\n",
      "         ...,\n",
      "         [ -3.4540,  -4.0268,  -3.9720,  ...,  -4.6561,  -3.8553,  -5.0867],\n",
      "         [ -5.8918,  -6.0305,  -5.9823,  ...,  -5.6257,  -5.4436,  -2.8622],\n",
      "         [-12.1832, -11.7615, -12.1602,  ..., -10.1949,  -8.9805,  -7.5899]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8192152976989746\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4161, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.9072,  -8.8508,  -8.8201,  ...,  -7.7504,  -7.4853,  -5.2532],\n",
      "         [ -9.4074,  -9.0557,  -8.9956,  ...,  -6.0820,  -7.7899,  -7.7227],\n",
      "         [ -5.4402,  -5.5339,  -5.5035,  ...,  -5.8734,  -6.8901,  -4.2040],\n",
      "         ...,\n",
      "         [ -6.0569,  -5.9538,  -5.9573,  ...,  -6.3238,  -6.8173,  -5.2692],\n",
      "         [ -5.8759,  -5.8338,  -5.8324,  ...,  -5.9186,  -6.7948,  -4.5604],\n",
      "         [ -5.4230,  -5.4507,  -5.4489,  ...,  -6.0004,  -6.7177,  -4.5963]],\n",
      "\n",
      "        [[ -7.3197,  -7.3206,  -7.2422,  ...,  -6.5344,  -6.6694,  -4.1810],\n",
      "         [-11.3112, -11.0866, -10.8964,  ..., -10.5659, -10.1473,  -4.3821],\n",
      "         [ -9.8917,  -9.3013,  -9.0537,  ..., -10.1891,  -8.9652,  -8.6301],\n",
      "         ...,\n",
      "         [ -7.0217,  -7.0086,  -7.0567,  ...,  -5.4045,  -7.3032,  -6.6699],\n",
      "         [-14.6544, -14.4697, -14.5809,  ..., -12.1935, -13.6097, -12.4442],\n",
      "         [-11.7103, -11.8093, -11.9363,  ...,  -9.6199, -10.9666,  -6.0184]],\n",
      "\n",
      "        [[ -7.1148,  -7.0732,  -7.0804,  ...,  -6.4385,  -6.3046,  -4.6779],\n",
      "         [ -6.3673,  -6.3802,  -6.5237,  ...,  -5.8709,  -5.8303,  -4.7552],\n",
      "         [ -4.7861,  -4.7051,  -4.8684,  ...,  -4.9007,  -6.0277,  -2.1046],\n",
      "         ...,\n",
      "         [ -9.8515,  -9.8671,  -9.7082,  ...,  -9.1007, -10.8728,  -5.7489],\n",
      "         [-11.3338, -11.4166, -11.4056,  ..., -10.1932,  -9.9187,  -9.5023],\n",
      "         [-12.9569, -13.0392, -12.9984,  ..., -11.6118, -10.4657,  -8.4010]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7179,  -6.7052,  -6.7273,  ...,  -5.9631,  -5.8848,  -3.8115],\n",
      "         [ -7.2913,  -7.5603,  -7.2213,  ...,  -6.8554,  -7.5205,  -1.7837],\n",
      "         [-10.9674, -10.4365, -10.7594,  ...,  -7.5399,  -8.8653,  -8.8736],\n",
      "         ...,\n",
      "         [ -7.5329,  -7.7096,  -7.4075,  ...,  -6.3173,  -7.3501,  -1.9851],\n",
      "         [ -7.1114,  -7.3333,  -7.0823,  ...,  -6.2293,  -7.2282,  -1.9324],\n",
      "         [ -6.8059,  -6.9765,  -6.7515,  ...,  -6.6592,  -7.1933,  -3.2981]],\n",
      "\n",
      "        [[ -7.0152,  -6.9656,  -6.9743,  ...,  -6.2404,  -6.0719,  -4.2194],\n",
      "         [-10.6223, -10.6008, -10.5053,  ...,  -7.3722,  -7.1562,  -8.6274],\n",
      "         [ -6.2089,  -6.4034,  -6.3972,  ...,  -6.1582,  -7.1505,  -5.7224],\n",
      "         ...,\n",
      "         [ -6.1374,  -6.3765,  -6.2757,  ...,  -6.1684,  -6.5825,  -4.3935],\n",
      "         [ -6.5053,  -6.6473,  -6.6824,  ...,  -5.7661,  -6.7179,  -4.4223],\n",
      "         [ -6.2639,  -6.4466,  -6.4195,  ...,  -5.5321,  -6.4014,  -5.1835]],\n",
      "\n",
      "        [[ -7.3617,  -7.3524,  -7.3374,  ...,  -6.8576,  -6.5599,  -4.4574],\n",
      "         [-11.3852, -11.5738, -11.3330,  ...,  -9.4373,  -9.3267,  -8.7535],\n",
      "         [ -3.7053,  -4.1030,  -3.9267,  ...,  -2.5838,  -3.5176,  -2.8630],\n",
      "         ...,\n",
      "         [-10.3379, -10.5548, -10.0089,  ...,  -9.9719,  -8.5033,  -6.4169],\n",
      "         [ -9.8778,  -9.8065,  -9.4120,  ..., -10.6505,  -7.8360, -11.6743],\n",
      "         [-12.6460, -12.7706, -12.5838,  ..., -10.6122, -10.7948,  -7.9263]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.416078805923462\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.8677, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2380,  -7.1639,  -7.2015,  ...,  -6.3963,  -6.2574,  -4.1323],\n",
      "         [-11.9780, -11.7714, -11.5724,  ...,  -9.4714, -10.2401,  -8.8619],\n",
      "         [ -6.3464,  -6.4818,  -6.4298,  ...,  -6.5790,  -7.9049,  -3.4687],\n",
      "         ...,\n",
      "         [ -6.8775,  -6.9603,  -6.8958,  ...,  -6.2980,  -8.1606,  -3.4165],\n",
      "         [ -6.6178,  -6.8191,  -6.6914,  ...,  -6.0922,  -7.7869,  -3.7683],\n",
      "         [ -7.2126,  -7.3340,  -7.3185,  ...,  -6.7562,  -8.5301,  -2.9050]],\n",
      "\n",
      "        [[ -6.3916,  -6.3112,  -6.2871,  ...,  -5.7959,  -5.5428,  -3.3182],\n",
      "         [ -6.5621,  -6.2636,  -6.5265,  ...,  -6.9939,  -8.0549,  -3.7750],\n",
      "         [ -7.2425,  -7.2708,  -7.0324,  ...,  -8.4767,  -7.3547,  -5.7426],\n",
      "         ...,\n",
      "         [ -5.0484,  -5.0455,  -5.1496,  ...,  -5.3896,  -5.5996,  -2.2600],\n",
      "         [ -5.3199,  -5.2708,  -5.3615,  ...,  -5.5983,  -5.8651,  -1.9449],\n",
      "         [ -5.4058,  -5.4123,  -5.4645,  ...,  -5.8386,  -6.0426,  -2.1279]],\n",
      "\n",
      "        [[ -6.9528,  -6.9225,  -6.9057,  ...,  -6.3209,  -6.2858,  -3.8361],\n",
      "         [ -9.5689,  -9.6250,  -9.5458,  ...,  -9.7407,  -8.6923,  -7.0691],\n",
      "         [ -6.5888,  -6.6218,  -6.0421,  ...,  -6.5676,  -5.7894,  -2.8040],\n",
      "         ...,\n",
      "         [-12.4471, -13.1832, -12.7079,  ..., -10.2308, -11.3792,  -9.1306],\n",
      "         [ -9.8873,  -9.7178,  -9.3973,  ...,  -9.7344,  -9.3467,  -5.7744],\n",
      "         [-15.7717, -15.9788, -15.7262,  ..., -15.7644, -13.8072, -13.1371]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8227,  -6.7809,  -6.8307,  ...,  -6.1073,  -5.9829,  -4.0447],\n",
      "         [-12.6020, -12.3324, -12.2327,  ..., -10.2513, -10.0736, -11.2288],\n",
      "         [ -5.4412,  -5.6377,  -5.6506,  ...,  -5.8250,  -7.2612,  -3.7538],\n",
      "         ...,\n",
      "         [ -5.6332,  -5.7939,  -5.7113,  ...,  -5.7425,  -6.7438,  -4.4350],\n",
      "         [ -5.4368,  -5.5885,  -5.5336,  ...,  -5.4559,  -6.7719,  -4.7506],\n",
      "         [ -5.9659,  -6.1221,  -6.0532,  ...,  -5.9043,  -7.5459,  -4.2268]],\n",
      "\n",
      "        [[ -7.0388,  -7.0034,  -6.9925,  ...,  -6.3382,  -6.2711,  -3.9350],\n",
      "         [ -5.6133,  -5.6133,  -5.4851,  ...,  -6.3590,  -6.8271,  -1.4676],\n",
      "         [ -7.9903,  -7.9491,  -7.2910,  ...,  -8.7610,  -8.4570,  -2.8769],\n",
      "         ...,\n",
      "         [ -5.3267,  -5.2216,  -5.2038,  ...,  -5.2248,  -6.0940,  -0.9543],\n",
      "         [ -6.0883,  -6.0758,  -6.0133,  ...,  -5.9422,  -6.7283,  -2.0479],\n",
      "         [ -5.8097,  -5.6507,  -5.7660,  ...,  -6.0552,  -6.8026,  -2.1963]],\n",
      "\n",
      "        [[ -7.0489,  -6.9943,  -7.0145,  ...,  -6.4687,  -6.5969,  -4.2868],\n",
      "         [-10.6901, -10.5054, -11.1969,  ...,  -7.7781,  -9.7826,  -7.9921],\n",
      "         [ -6.3065,  -6.2689,  -6.2811,  ...,  -6.5879,  -7.3348,  -3.9747],\n",
      "         ...,\n",
      "         [ -6.9267,  -6.9888,  -6.8763,  ...,  -7.0754,  -7.7829,  -4.3973],\n",
      "         [ -5.8019,  -5.8672,  -5.7906,  ...,  -6.0634,  -6.7180,  -4.7223],\n",
      "         [ -6.6587,  -6.6903,  -6.7127,  ...,  -7.1697,  -7.8864,  -3.4061]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.8677213191986084\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6607, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6267,  -6.5995,  -6.6261,  ...,  -5.9678,  -6.0382,  -4.0359],\n",
      "         [ -5.6693,  -5.6641,  -5.6428,  ...,  -5.6960,  -5.8591,  -3.7177],\n",
      "         [ -9.2764,  -9.4957,  -9.3881,  ...,  -9.6301,  -8.0442,  -8.3119],\n",
      "         ...,\n",
      "         [ -6.1671,  -6.1238,  -6.1304,  ...,  -5.6507,  -6.3100,  -4.2537],\n",
      "         [ -5.9252,  -5.9182,  -5.9463,  ...,  -5.8011,  -6.1536,  -4.0790],\n",
      "         [ -6.0835,  -6.0710,  -6.0709,  ...,  -5.9058,  -6.5028,  -4.1068]],\n",
      "\n",
      "        [[ -6.6805,  -6.6750,  -6.6606,  ...,  -6.1596,  -5.9437,  -4.0394],\n",
      "         [ -8.4617,  -8.5048,  -8.6265,  ...,  -8.2337,  -8.8682,  -4.8283],\n",
      "         [-14.1429, -14.3501, -14.3529,  ..., -13.9023, -10.8363, -13.2982],\n",
      "         ...,\n",
      "         [ -7.3907,  -7.4097,  -7.4272,  ...,  -7.1127,  -7.1482,  -4.4415],\n",
      "         [ -7.5279,  -7.6569,  -7.7608,  ...,  -7.2416,  -7.5010,  -4.8693],\n",
      "         [ -7.1135,  -7.1827,  -7.2069,  ...,  -6.5264,  -6.7245,  -4.2250]],\n",
      "\n",
      "        [[ -6.6306,  -6.9802,  -6.8265,  ...,  -6.5889,  -5.6415,  -7.6807],\n",
      "         [-11.4772, -11.5838, -11.0181,  ...,  -8.9297,  -8.8296, -11.5766],\n",
      "         [ -5.6521,  -5.7142,  -5.7443,  ...,  -6.2427,  -6.9370,  -5.1513],\n",
      "         ...,\n",
      "         [ -6.0437,  -6.1616,  -6.1424,  ...,  -6.2113,  -6.8104,  -4.8478],\n",
      "         [ -5.3569,  -5.5387,  -5.5642,  ...,  -5.8600,  -6.4161,  -3.7454],\n",
      "         [ -5.6266,  -5.7974,  -5.8243,  ...,  -5.9368,  -6.9256,  -4.7106]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1521,  -7.1986,  -7.1226,  ...,  -6.4699,  -6.3610,  -4.1653],\n",
      "         [ -6.6017,  -6.6604,  -6.5361,  ...,  -5.5471,  -6.7201,  -4.6418],\n",
      "         [-10.4940, -10.3601, -10.6179,  ..., -10.9791,  -8.0780, -10.2936],\n",
      "         ...,\n",
      "         [ -4.3363,  -4.8140,  -4.4805,  ...,  -6.3930,  -5.7810,  -4.3017],\n",
      "         [ -8.5646,  -8.6437,  -8.3313,  ...,  -7.7408,  -7.8006,  -4.0442],\n",
      "         [-13.6184, -13.6286, -13.4727,  ..., -11.6264, -10.0073, -12.2736]],\n",
      "\n",
      "        [[ -6.5279,  -6.4755,  -6.5070,  ...,  -5.9131,  -5.6217,  -3.8872],\n",
      "         [ -9.7884,  -9.2176,  -9.2622,  ...,  -5.7029,  -7.7007,  -7.6653],\n",
      "         [ -5.7833,  -5.8048,  -5.8963,  ...,  -5.9264,  -7.0060,  -3.8452],\n",
      "         ...,\n",
      "         [ -6.7264,  -6.7278,  -6.7259,  ...,  -6.8209,  -7.5462,  -5.6329],\n",
      "         [ -6.8019,  -6.7519,  -6.7880,  ...,  -6.7488,  -7.2529,  -4.8645],\n",
      "         [ -6.6174,  -6.6134,  -6.6332,  ...,  -6.7283,  -7.2218,  -4.8757]],\n",
      "\n",
      "        [[ -6.7374,  -6.7185,  -6.7795,  ...,  -6.1341,  -5.9557,  -3.9902],\n",
      "         [ -8.1884,  -8.0588,  -8.0031,  ...,  -7.4439,  -7.7537,  -5.1840],\n",
      "         [ -8.0724,  -8.3544,  -8.1660,  ...,  -7.6060,  -7.0756,  -5.1005],\n",
      "         ...,\n",
      "         [ -5.9818,  -5.9546,  -5.9599,  ...,  -5.5375,  -6.5125,  -2.7473],\n",
      "         [ -6.9789,  -7.0476,  -7.0719,  ...,  -6.8586,  -7.7643,  -2.7914],\n",
      "         [ -6.3828,  -6.3913,  -6.3322,  ...,  -5.7493,  -6.8247,  -2.9753]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.6606680154800415\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8170, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6027,  -6.6073,  -6.5897,  ...,  -6.0747,  -5.9049,  -3.7056],\n",
      "         [ -5.8418,  -6.1174,  -6.1746,  ...,  -6.0745,  -5.5474,  -7.4222],\n",
      "         [ -5.8458,  -5.6200,  -5.7160,  ...,  -5.0923,  -5.7406,  -6.6944],\n",
      "         ...,\n",
      "         [ -4.4101,  -4.3454,  -4.5448,  ...,  -4.7801,  -4.3567,  -2.4967],\n",
      "         [ -6.1529,  -6.2884,  -6.0877,  ...,  -5.8754,  -5.9105,  -4.6623],\n",
      "         [-12.9472, -12.9682, -13.0899,  ..., -10.3325, -11.5475,  -8.9088]],\n",
      "\n",
      "        [[ -6.8900,  -6.8582,  -6.8845,  ...,  -6.0806,  -6.0612,  -3.9887],\n",
      "         [-11.2626, -11.0204, -11.1233,  ...,  -7.9498,  -7.7556,  -8.4300],\n",
      "         [ -7.0209,  -7.1076,  -7.0610,  ...,  -6.8061,  -7.2235,  -3.7998],\n",
      "         ...,\n",
      "         [ -7.0684,  -7.1050,  -7.1197,  ...,  -7.0752,  -7.4391,  -3.4969],\n",
      "         [ -7.2762,  -7.2695,  -7.2404,  ...,  -7.1796,  -7.6528,  -3.7744],\n",
      "         [ -7.4076,  -7.4122,  -7.3944,  ...,  -7.1073,  -7.9778,  -4.2777]],\n",
      "\n",
      "        [[ -7.5436,  -7.6149,  -7.5594,  ...,  -7.0154,  -6.7450,  -4.2868],\n",
      "         [-10.8875, -10.7198, -10.8457,  ..., -10.0429,  -9.1143,  -9.1254],\n",
      "         [ -9.4661,  -9.3535,  -9.1801,  ...,  -8.4889,  -7.9213,  -9.8121],\n",
      "         ...,\n",
      "         [-12.6822, -12.3857, -12.4706,  ...,  -9.9742, -10.2685, -10.7728],\n",
      "         [ -9.8506,  -9.7436,  -9.6853,  ...,  -9.2716,  -9.7677,  -9.2244],\n",
      "         [-11.8727, -11.7459, -11.7331,  ...,  -9.0042,  -9.2931, -10.7911]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6187,  -6.6054,  -6.6225,  ...,  -6.0848,  -5.9256,  -4.0482],\n",
      "         [ -8.1833,  -8.2274,  -8.3345,  ...,  -9.0226,  -9.3943,  -5.6370],\n",
      "         [ -7.8916,  -7.8604,  -8.0324,  ...,  -8.3899,  -8.7064,  -4.9410],\n",
      "         ...,\n",
      "         [ -5.7097,  -5.6543,  -5.7559,  ...,  -6.0115,  -6.3347,  -2.7504],\n",
      "         [ -5.8856,  -5.8586,  -6.0067,  ...,  -6.1518,  -6.3142,  -2.3340],\n",
      "         [ -5.8639,  -5.8337,  -5.8376,  ...,  -5.8510,  -6.3610,  -2.8807]],\n",
      "\n",
      "        [[ -7.0806,  -7.1306,  -7.1057,  ...,  -6.3665,  -6.2759,  -4.0089],\n",
      "         [ -4.1867,  -4.1792,  -4.0813,  ...,  -5.3257,  -5.5817,  -6.0469],\n",
      "         [-10.2317, -10.7535, -10.2663,  ...,  -9.2973, -10.0019,  -5.7841],\n",
      "         ...,\n",
      "         [ -7.3551,  -7.5461,  -7.5414,  ...,  -7.3370,  -7.7752,  -5.0608],\n",
      "         [ -7.5884,  -7.5848,  -7.5559,  ...,  -8.0394,  -7.6235,  -6.2763],\n",
      "         [ -4.8528,  -5.0759,  -5.1092,  ...,  -4.6904,  -4.1827,  -3.6851]],\n",
      "\n",
      "        [[ -7.0522,  -7.0372,  -6.9932,  ...,  -6.5788,  -6.1736,  -3.9637],\n",
      "         [-15.9674, -15.7186, -15.6182,  ..., -14.4756, -12.7413,  -9.6608],\n",
      "         [-10.6097, -10.2892, -10.4549,  ..., -10.3779,  -9.2071, -11.2775],\n",
      "         ...,\n",
      "         [-12.7121, -12.7545, -12.4399,  ..., -11.0259,  -9.3022,  -8.5872],\n",
      "         [ -9.6879, -10.0438,  -9.9051,  ...,  -7.3358,  -8.2462,  -7.0148],\n",
      "         [-14.8702, -14.8465, -14.9321,  ..., -13.4692, -12.9901,  -6.3503]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.816985845565796\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0613, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8396,  -6.8266,  -6.7884,  ...,  -6.2232,  -5.9670,  -4.1459],\n",
      "         [ -7.0456,  -7.3023,  -7.1143,  ...,  -7.0386,  -7.5688,  -6.8011],\n",
      "         [-15.6949, -16.0272, -15.8517,  ..., -14.5898, -13.3911, -12.6370],\n",
      "         ...,\n",
      "         [ -3.8847,  -4.2809,  -4.1044,  ...,  -3.3881,  -3.9038,  -4.5591],\n",
      "         [ -5.1263,  -5.0310,  -5.3626,  ...,  -5.7512,  -4.6444,  -6.3287],\n",
      "         [-12.4317, -12.3659, -12.1364,  ...,  -9.9826,  -9.5089, -10.8980]],\n",
      "\n",
      "        [[ -6.3344,  -6.3023,  -6.3648,  ...,  -5.8129,  -5.4372,  -3.7166],\n",
      "         [-12.4055, -12.2000, -12.2007,  ..., -10.6457, -10.6109, -10.7338],\n",
      "         [ -5.5426,  -5.6580,  -5.6138,  ...,  -6.0414,  -6.9358,  -4.5168],\n",
      "         ...,\n",
      "         [ -7.0046,  -7.0856,  -7.0555,  ...,  -7.1249,  -7.3137,  -5.1404],\n",
      "         [ -6.7762,  -6.8075,  -6.8040,  ...,  -6.8310,  -7.2329,  -5.2247],\n",
      "         [ -6.7345,  -6.7728,  -6.7199,  ...,  -7.1724,  -7.2289,  -5.0439]],\n",
      "\n",
      "        [[ -7.2105,  -7.2229,  -7.1812,  ...,  -6.5726,  -6.2866,  -4.9815],\n",
      "         [-13.6440, -13.3798, -13.4771,  ..., -13.1027, -11.1185, -13.1490],\n",
      "         [-10.8225, -11.0544, -10.7647,  ..., -12.0479, -10.1049,  -7.1370],\n",
      "         ...,\n",
      "         [-12.4594, -12.4115, -12.1213,  ..., -11.6556, -11.0828,  -9.9809],\n",
      "         [ -6.0527,  -6.2630,  -6.2372,  ...,  -6.1828,  -6.2174,  -6.0001],\n",
      "         [-12.9764, -12.3111, -12.8620,  ..., -11.1015, -10.7825,  -8.9599]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3371,  -7.3455,  -7.2880,  ...,  -6.5656,  -6.4484,  -3.8171],\n",
      "         [ -8.5820,  -8.4760,  -8.6577,  ...,  -7.9190,  -7.5094,  -7.0883],\n",
      "         [-11.3504, -11.0983, -11.2290,  ..., -10.8570,  -8.5273,  -6.4853],\n",
      "         ...,\n",
      "         [ -8.1198,  -8.0826,  -8.1720,  ...,  -8.1721,  -6.9150,  -5.1724],\n",
      "         [ -7.8913,  -7.7379,  -7.8342,  ...,  -7.6250,  -6.7484,  -4.5283],\n",
      "         [ -8.0221,  -8.0061,  -8.1067,  ...,  -8.3982,  -6.7942,  -4.7288]],\n",
      "\n",
      "        [[ -6.4462,  -6.4201,  -6.3733,  ...,  -5.9586,  -5.6091,  -4.0344],\n",
      "         [ -6.4649,  -6.3270,  -6.4700,  ...,  -7.1798,  -6.3454,  -6.3344],\n",
      "         [ -7.9693,  -8.6270,  -8.3196,  ...,  -7.5984,  -6.2704,  -9.8964],\n",
      "         ...,\n",
      "         [ -6.7465,  -6.8506,  -6.7504,  ...,  -6.9958,  -6.4648,  -6.1689],\n",
      "         [ -7.8361,  -8.0302,  -7.4869,  ...,  -7.8218,  -7.6371,  -3.3960],\n",
      "         [-12.8946, -12.4271, -12.4936,  ..., -10.8244, -10.6561, -10.2083]],\n",
      "\n",
      "        [[ -6.3110,  -6.2768,  -6.2819,  ...,  -5.7146,  -5.3951,  -3.8844],\n",
      "         [-11.4140, -11.1903, -11.2793,  ...,  -9.0001,  -9.7939,  -8.9897],\n",
      "         [ -5.9701,  -6.0719,  -6.0926,  ...,  -5.9770,  -6.8361,  -4.2751],\n",
      "         ...,\n",
      "         [ -6.0476,  -6.1398,  -6.1085,  ...,  -6.2300,  -6.7408,  -4.0416],\n",
      "         [ -6.3510,  -6.3946,  -6.3479,  ...,  -6.4725,  -6.9262,  -4.2045],\n",
      "         [ -6.5276,  -6.6073,  -6.4972,  ...,  -6.5909,  -6.8731,  -4.6067]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0612823963165283\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6962, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9629,  -6.9619,  -7.0229,  ...,  -6.1619,  -6.1536,  -4.1573],\n",
      "         [-12.0837, -11.9856, -11.9758,  ...,  -8.7623,  -8.7312,  -7.8452],\n",
      "         [ -5.3307,  -5.5838,  -5.6230,  ...,  -5.6376,  -6.7247,  -3.9374],\n",
      "         ...,\n",
      "         [ -6.2617,  -6.4587,  -6.3858,  ...,  -6.2618,  -7.2316,  -4.1688],\n",
      "         [ -6.2914,  -6.4072,  -6.4365,  ...,  -6.4683,  -7.3098,  -4.0829],\n",
      "         [ -6.7135,  -6.7916,  -6.6746,  ...,  -6.2029,  -7.3719,  -4.5620]],\n",
      "\n",
      "        [[ -7.4399,  -7.4373,  -7.4032,  ...,  -6.5748,  -6.3858,  -4.7514],\n",
      "         [ -4.9231,  -4.9422,  -5.1133,  ...,  -4.7800,  -4.1899,  -5.1450],\n",
      "         [-13.6867, -13.7119, -13.8002,  ..., -12.1399, -10.0947,  -8.9455],\n",
      "         ...,\n",
      "         [ -5.4971,  -5.8689,  -5.7368,  ...,  -4.6870,  -4.1395,  -5.6306],\n",
      "         [ -7.0704,  -7.1195,  -7.1563,  ...,  -6.1541,  -6.4840,  -6.4718],\n",
      "         [-15.5550, -15.2075, -15.3916,  ..., -14.1072, -12.4734, -10.4754]],\n",
      "\n",
      "        [[ -6.7796,  -6.7553,  -6.7666,  ...,  -6.0231,  -5.8043,  -3.8523],\n",
      "         [-13.6696, -13.5091, -13.5727,  ..., -11.6361, -11.0776,  -9.2201],\n",
      "         [ -4.8007,  -4.9242,  -4.9506,  ...,  -5.1328,  -6.3528,  -3.6179],\n",
      "         ...,\n",
      "         [ -5.5879,  -5.7743,  -5.6934,  ...,  -5.6226,  -6.8942,  -5.3791],\n",
      "         [ -5.8007,  -5.9089,  -5.8902,  ...,  -6.0106,  -6.8086,  -3.9931],\n",
      "         [ -6.1418,  -6.2493,  -6.1072,  ...,  -6.3433,  -7.0101,  -4.6269]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4729,  -6.4278,  -6.4470,  ...,  -5.7622,  -5.6285,  -3.7943],\n",
      "         [-10.8531, -10.6266, -10.6981,  ...,  -8.9477,  -8.4692,  -8.4323],\n",
      "         [ -5.9838,  -6.1791,  -6.1324,  ...,  -6.2107,  -6.8556,  -4.3460],\n",
      "         ...,\n",
      "         [ -7.2483,  -7.3541,  -7.3505,  ...,  -7.4305,  -7.7069,  -4.9470],\n",
      "         [ -6.9487,  -6.9770,  -7.0094,  ...,  -6.7645,  -7.2120,  -4.8936],\n",
      "         [ -6.9302,  -6.9936,  -6.9598,  ...,  -6.8290,  -7.8222,  -4.8413]],\n",
      "\n",
      "        [[ -6.9376,  -6.9354,  -6.8881,  ...,  -6.3413,  -5.9833,  -4.1695],\n",
      "         [-13.5236, -13.3692, -13.1344,  ..., -12.3028, -10.6376,  -8.9988],\n",
      "         [ -8.9118,  -8.4169,  -8.5881,  ...,  -7.4192,  -7.6287,  -8.2633],\n",
      "         ...,\n",
      "         [ -5.7471,  -5.4361,  -5.5006,  ...,  -4.7577,  -5.7758,  -4.9502],\n",
      "         [ -4.9106,  -4.7133,  -4.6208,  ...,  -4.1788,  -4.7359,  -3.9272],\n",
      "         [ -6.1500,  -5.9921,  -6.0809,  ...,  -5.5750,  -5.6959,  -5.1104]],\n",
      "\n",
      "        [[ -6.3450,  -6.2879,  -6.3035,  ...,  -5.5074,  -5.7254,  -3.6381],\n",
      "         [ -8.1330,  -8.0619,  -8.2599,  ...,  -8.1908,  -7.5891,  -3.3424],\n",
      "         [ -6.6655,  -6.8061,  -6.8845,  ...,  -7.3435,  -7.2095,  -2.5932],\n",
      "         ...,\n",
      "         [ -5.1931,  -5.2286,  -5.2124,  ...,  -4.8694,  -5.4622,  -1.7466],\n",
      "         [ -5.1594,  -5.1773,  -5.1784,  ...,  -4.8363,  -5.6508,  -1.5057],\n",
      "         [ -4.6468,  -4.5883,  -4.6135,  ...,  -4.4038,  -5.3785,  -1.5931]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.696218967437744\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9437, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9641,  -7.0054,  -6.9438,  ...,  -6.2443,  -5.9687,  -4.8405],\n",
      "         [ -5.8902,  -5.8893,  -6.1109,  ...,  -6.0001,  -5.2960,  -5.8446],\n",
      "         [ -7.9355,  -8.0375,  -7.9356,  ...,  -7.5198,  -6.0457,  -8.6783],\n",
      "         ...,\n",
      "         [ -7.3860,  -7.4727,  -7.5124,  ...,  -7.3261,  -6.7572,  -5.8078],\n",
      "         [ -7.8046,  -7.7174,  -7.7339,  ...,  -7.8582,  -7.1378,  -6.7993],\n",
      "         [ -7.2310,  -7.2630,  -7.2982,  ...,  -7.0042,  -6.3237,  -5.8264]],\n",
      "\n",
      "        [[ -7.2306,  -7.2044,  -7.1992,  ...,  -6.5231,  -6.4304,  -3.7355],\n",
      "         [-12.6058, -12.1428, -12.6518,  ..., -10.4520,  -9.0209,  -9.6310],\n",
      "         [ -7.3151,  -7.4248,  -7.3900,  ...,  -7.1035,  -7.1084,  -3.5787],\n",
      "         ...,\n",
      "         [ -6.7812,  -6.8941,  -7.0017,  ...,  -5.9179,  -6.4269,  -1.6648],\n",
      "         [ -7.2081,  -7.2693,  -7.3188,  ...,  -6.6391,  -6.6730,  -3.2781],\n",
      "         [ -6.9372,  -7.1512,  -7.0758,  ...,  -6.7180,  -6.5405,  -2.5268]],\n",
      "\n",
      "        [[ -7.4475,  -7.3994,  -7.3165,  ...,  -6.5117,  -6.1401,  -5.0342],\n",
      "         [-11.1646, -11.0432, -11.1108,  ...,  -9.9547,  -9.7491, -11.1382],\n",
      "         [-10.1077, -10.5824, -10.0101,  ...,  -9.5997,  -7.8513, -10.4031],\n",
      "         ...,\n",
      "         [ -6.5912,  -6.4634,  -6.4424,  ...,  -5.6068,  -5.3068,  -6.7981],\n",
      "         [-10.1048, -10.2260, -10.2447,  ..., -10.0922,  -7.8153,  -4.9166],\n",
      "         [-12.9783, -11.9930, -12.3926,  ...,  -9.4252,  -9.7949,  -9.2951]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3582,  -7.3357,  -7.3154,  ...,  -6.5735,  -6.4532,  -3.7239],\n",
      "         [-17.7116, -17.5540, -17.6522,  ..., -13.5527, -13.9783, -13.6473],\n",
      "         [-10.4689, -10.8356, -10.6475,  ..., -10.4390,  -9.0085, -11.0767],\n",
      "         ...,\n",
      "         [ -6.2282,  -6.2523,  -6.2943,  ...,  -6.5919,  -6.0450,  -3.7599],\n",
      "         [ -3.5898,  -3.8356,  -3.6575,  ...,  -3.3178,  -2.7788,  -3.1134],\n",
      "         [ -7.5960,  -7.6387,  -7.7651,  ...,  -7.4322,  -6.5856,  -4.6966]],\n",
      "\n",
      "        [[ -6.7822,  -6.8349,  -6.7749,  ...,  -6.2681,  -5.8690,  -4.3631],\n",
      "         [-11.3480, -11.3832, -11.3028,  ...,  -9.3897,  -9.8916,  -9.4732],\n",
      "         [ -4.8795,  -4.9410,  -4.7654,  ...,  -4.5134,  -4.1933,  -3.2920],\n",
      "         ...,\n",
      "         [-10.4045, -10.6898, -10.1210,  ...,  -7.8561,  -8.3994,  -5.7179],\n",
      "         [ -6.6231,  -6.6875,  -6.4665,  ...,  -5.2391,  -6.5005,  -3.4944],\n",
      "         [-12.3888, -11.9002, -12.1816,  ...,  -9.6307,  -9.9738,  -6.5351]],\n",
      "\n",
      "        [[ -6.7493,  -6.7149,  -6.7091,  ...,  -6.1529,  -5.9995,  -3.3746],\n",
      "         [ -9.7280,  -9.3306,  -9.7584,  ...,  -8.3626,  -6.9331,  -6.4425],\n",
      "         [ -6.8906,  -6.9237,  -6.8872,  ...,  -7.3896,  -6.8572,  -3.7682],\n",
      "         ...,\n",
      "         [ -7.0833,  -7.1343,  -7.0892,  ...,  -7.2639,  -6.8313,  -3.8007],\n",
      "         [ -7.0224,  -7.0184,  -6.9989,  ...,  -7.2206,  -6.7127,  -4.0332],\n",
      "         [ -7.3751,  -7.3634,  -7.3789,  ...,  -7.4550,  -7.1327,  -4.9521]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.943697214126587\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4495, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7688,  -6.7140,  -6.7466,  ...,  -5.9104,  -6.1194,  -3.9533],\n",
      "         [ -6.9277,  -6.5740,  -6.9045,  ...,  -5.0537,  -7.0752,  -5.8885],\n",
      "         [ -6.2769,  -6.3938,  -6.5029,  ...,  -6.2155,  -7.8221,  -4.0730],\n",
      "         ...,\n",
      "         [ -6.2851,  -6.3567,  -6.3754,  ...,  -6.1214,  -6.9513,  -4.4039],\n",
      "         [ -5.3650,  -5.4189,  -5.4934,  ...,  -5.4568,  -6.6862,  -3.9823],\n",
      "         [ -6.0675,  -6.2700,  -6.2136,  ...,  -6.3530,  -7.3218,  -4.0547]],\n",
      "\n",
      "        [[ -6.5999,  -6.5799,  -6.5779,  ...,  -5.9151,  -5.7446,  -3.8836],\n",
      "         [ -8.8719,  -8.9740,  -9.0004,  ...,  -9.3833, -10.3999,  -3.8537],\n",
      "         [ -8.4024,  -8.4783,  -8.5738,  ...,  -9.2150,  -9.8010,  -2.4699],\n",
      "         ...,\n",
      "         [ -6.0107,  -6.0100,  -6.1211,  ...,  -6.3351,  -6.7373,  -3.1565],\n",
      "         [ -5.6284,  -5.6401,  -5.7022,  ...,  -5.7595,  -5.8644,  -2.1568],\n",
      "         [ -5.7975,  -5.7738,  -5.9159,  ...,  -6.0807,  -6.2909,  -2.3057]],\n",
      "\n",
      "        [[ -6.4514,  -6.4161,  -6.4412,  ...,  -5.7755,  -5.5908,  -3.7966],\n",
      "         [ -8.6212,  -8.1032,  -8.4030,  ...,  -5.5981,  -6.3611,  -6.9058],\n",
      "         [ -5.5653,  -5.6653,  -5.6933,  ...,  -5.7558,  -6.7375,  -4.1060],\n",
      "         ...,\n",
      "         [ -6.4161,  -6.4998,  -6.5372,  ...,  -6.6156,  -7.7050,  -4.2567],\n",
      "         [ -6.5235,  -6.6217,  -6.6678,  ...,  -6.6078,  -7.5074,  -4.5225],\n",
      "         [ -5.9331,  -6.0908,  -6.0128,  ...,  -5.7390,  -6.8303,  -4.1283]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5769,  -6.5333,  -6.5511,  ...,  -5.9477,  -5.7800,  -4.1105],\n",
      "         [-11.7413, -11.2818, -11.5774,  ...,  -8.7918, -10.3740,  -7.6459],\n",
      "         [ -5.7196,  -5.8189,  -5.8957,  ...,  -6.0531,  -7.3796,  -3.0405],\n",
      "         ...,\n",
      "         [ -6.4144,  -6.5337,  -6.5144,  ...,  -6.3807,  -7.3117,  -4.4674],\n",
      "         [ -6.3785,  -6.5253,  -6.5306,  ...,  -6.4559,  -7.1227,  -4.4692],\n",
      "         [ -6.2859,  -6.3597,  -6.2770,  ...,  -6.3797,  -7.0595,  -3.7210]],\n",
      "\n",
      "        [[ -7.0511,  -7.0473,  -7.0099,  ...,  -6.3039,  -6.0467,  -4.1339],\n",
      "         [ -4.9924,  -4.9616,  -4.6390,  ...,  -3.8587,  -4.9224,  -2.8761],\n",
      "         [-13.8684, -13.6781, -13.6315,  ..., -10.9359, -10.0617,  -9.3874],\n",
      "         ...,\n",
      "         [-17.3052, -17.1902, -17.1653,  ..., -12.6906, -12.7615, -10.9849],\n",
      "         [-11.8174, -11.5655, -11.8833,  ...,  -9.6568,  -8.7948, -10.3110],\n",
      "         [-13.9664, -13.8945, -13.7559,  ..., -11.6143, -10.1189, -11.7158]],\n",
      "\n",
      "        [[ -6.9415,  -6.8728,  -6.8689,  ...,  -6.4024,  -5.8808,  -4.2263],\n",
      "         [ -7.0185,  -6.8404,  -6.9237,  ...,  -6.9742,  -6.6800,  -5.4515],\n",
      "         [ -5.4920,  -5.3833,  -5.4998,  ...,  -6.1475,  -3.4458,  -2.6817],\n",
      "         ...,\n",
      "         [-10.4557, -10.0080, -10.2654,  ...,  -7.5119,  -7.1964,  -4.5314],\n",
      "         [-11.7782, -11.4398, -11.1216,  ...,  -8.3879, -11.6041,  -7.8748],\n",
      "         [-12.3315, -11.7637, -11.6571,  ..., -11.3803,  -9.2991, -10.5291]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.449500322341919\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5127, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8055,  -6.7620,  -6.7837,  ...,  -6.1430,  -6.0246,  -3.6931],\n",
      "         [ -8.5347,  -8.3410,  -8.6440,  ...,  -8.9725,  -8.9911,  -4.0393],\n",
      "         [-11.2052, -11.4244, -11.3293,  ..., -10.8669, -10.6341,  -4.0981],\n",
      "         ...,\n",
      "         [ -5.8458,  -5.6458,  -5.8487,  ...,  -5.9816,  -6.3941,  -2.2281],\n",
      "         [ -6.2118,  -6.1876,  -6.2278,  ...,  -6.4364,  -6.5099,  -2.2883],\n",
      "         [ -6.0217,  -5.9915,  -6.0600,  ...,  -5.9539,  -6.1890,  -2.7816]],\n",
      "\n",
      "        [[ -6.6246,  -6.6271,  -6.6268,  ...,  -5.7434,  -5.9095,  -4.2394],\n",
      "         [ -9.2942,  -9.3781,  -9.3845,  ..., -10.1575,  -8.2622,  -6.4120],\n",
      "         [ -8.8248,  -8.9098,  -8.8281,  ...,  -8.7536,  -8.9200,  -8.9887],\n",
      "         ...,\n",
      "         [ -5.7716,  -5.7701,  -5.8264,  ...,  -6.0854,  -6.1154,  -4.6541],\n",
      "         [ -5.5791,  -5.6680,  -5.6909,  ...,  -5.8053,  -5.6260,  -4.4136],\n",
      "         [ -6.1694,  -6.1889,  -6.2747,  ...,  -6.5002,  -6.4152,  -5.5414]],\n",
      "\n",
      "        [[ -6.6446,  -6.6395,  -6.5863,  ...,  -5.9744,  -5.7315,  -3.7878],\n",
      "         [-10.8422, -10.5494, -10.6616,  ...,  -9.4622,  -9.1077,  -8.2804],\n",
      "         [ -4.8316,  -4.8470,  -4.8069,  ...,  -4.1869,  -4.2017,  -4.4939],\n",
      "         ...,\n",
      "         [ -6.1523,  -6.2150,  -6.2279,  ...,  -5.7677,  -6.0048,  -5.1847],\n",
      "         [ -6.6881,  -6.7868,  -6.6958,  ...,  -6.7633,  -5.8856,  -4.7817],\n",
      "         [ -6.2514,  -6.2689,  -6.2860,  ...,  -6.1264,  -5.4278,  -4.8157]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5515,  -6.5181,  -6.5340,  ...,  -5.7709,  -5.7222,  -3.7879],\n",
      "         [ -6.3941,  -5.9052,  -5.9198,  ...,  -2.8411,  -4.0129,  -5.0445],\n",
      "         [ -5.9649,  -6.0973,  -5.9926,  ...,  -5.7143,  -6.9710,  -3.4056],\n",
      "         ...,\n",
      "         [ -6.2640,  -6.3865,  -6.2757,  ...,  -5.8683,  -6.9751,  -2.8943],\n",
      "         [ -5.9188,  -5.9928,  -5.9329,  ...,  -5.7574,  -7.1598,  -2.7617],\n",
      "         [ -6.2073,  -6.3402,  -6.3107,  ...,  -5.6974,  -7.1149,  -2.7539]],\n",
      "\n",
      "        [[ -6.5313,  -6.5530,  -6.5136,  ...,  -5.9353,  -6.0522,  -3.9978],\n",
      "         [ -8.6467,  -8.3645,  -8.7670,  ...,  -7.0731,  -7.2240,  -6.0624],\n",
      "         [ -4.8294,  -4.8589,  -4.9115,  ...,  -5.2013,  -6.3599,  -3.8580],\n",
      "         ...,\n",
      "         [ -5.3121,  -5.4761,  -5.3541,  ...,  -5.5377,  -6.4590,  -4.0978],\n",
      "         [ -5.2581,  -5.2583,  -5.2979,  ...,  -5.2504,  -6.4292,  -4.8048],\n",
      "         [ -5.9569,  -6.0131,  -5.9550,  ...,  -6.0398,  -7.1853,  -4.7268]],\n",
      "\n",
      "        [[ -6.9187,  -6.8776,  -6.8721,  ...,  -6.1312,  -5.9895,  -4.2056],\n",
      "         [ -9.5487,  -9.8689,  -9.4731,  ...,  -9.4049,  -7.8190,  -5.5138],\n",
      "         [ -8.7550,  -9.2887,  -9.0675,  ...,  -8.0760, -10.7091,  -3.8244],\n",
      "         ...,\n",
      "         [ -7.9965,  -8.1872,  -7.9345,  ...,  -8.0410,  -7.7551,  -5.2982],\n",
      "         [ -7.0801,  -7.2851,  -7.0324,  ...,  -7.2120,  -6.4575,  -3.8389],\n",
      "         [ -7.1247,  -7.2707,  -7.0424,  ...,  -7.1059,  -6.4316,  -4.3094]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.512699842453003\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2198, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8680,  -6.8818,  -6.8294,  ...,  -6.3589,  -5.9679,  -4.5460],\n",
      "         [ -6.7381,  -6.9976,  -6.7172,  ...,  -5.7712,  -5.6924,  -7.8947],\n",
      "         [ -5.4627,  -5.5028,  -5.5002,  ...,  -4.6789,  -4.8163,  -4.5176],\n",
      "         ...,\n",
      "         [ -4.1602,  -4.3646,  -4.2287,  ...,  -3.4740,  -4.0209,  -5.6022],\n",
      "         [ -2.7600,  -2.9087,  -2.8765,  ...,  -2.4308,  -2.0505,  -5.2632],\n",
      "         [ -3.4505,  -3.6647,  -3.4869,  ...,  -2.8656,  -2.8136,  -4.7582]],\n",
      "\n",
      "        [[ -7.0759,  -7.0519,  -7.0132,  ...,  -6.4357,  -6.2116,  -3.8445],\n",
      "         [ -8.6234,  -8.6858,  -8.5843,  ...,  -8.4733,  -7.1090,  -4.2138],\n",
      "         [ -9.7332,  -9.6094,  -9.6481,  ..., -10.0678,  -7.5748,  -7.9553],\n",
      "         ...,\n",
      "         [ -8.9196,  -8.8067,  -8.8298,  ...,  -9.1611,  -7.3524,  -7.5464],\n",
      "         [ -7.6476,  -7.7341,  -7.6657,  ...,  -7.4148,  -6.6390,  -5.8278],\n",
      "         [-13.8627, -13.3387, -13.5999,  ..., -10.7057, -10.8294,  -9.5181]],\n",
      "\n",
      "        [[ -7.2750,  -7.1851,  -7.3212,  ...,  -6.3807,  -6.3981,  -4.4670],\n",
      "         [-11.9094, -11.6559, -11.9213,  ..., -11.3881,  -9.2523,  -8.5252],\n",
      "         [ -5.1857,  -5.3717,  -5.3924,  ...,  -5.7165,  -7.3186,  -1.7107],\n",
      "         ...,\n",
      "         [ -5.4863,  -5.6392,  -5.5731,  ...,  -6.0489,  -7.1274,  -3.9391],\n",
      "         [ -5.4728,  -5.6225,  -5.5287,  ...,  -6.1841,  -7.0187,  -2.9683],\n",
      "         [ -4.9713,  -5.2784,  -5.1406,  ...,  -5.2374,  -6.6041,  -2.5158]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0094,  -7.0339,  -6.9761,  ...,  -6.3228,  -6.2242,  -4.7198],\n",
      "         [ -5.5209,  -5.6622,  -5.6129,  ...,  -4.7711,  -3.9000,  -5.1529],\n",
      "         [ -8.3640,  -8.3076,  -8.3578,  ...,  -8.0669,  -6.5723,  -8.7736],\n",
      "         ...,\n",
      "         [-10.2748, -10.3478,  -9.6862,  ...,  -9.1691,  -7.3759,  -7.8749],\n",
      "         [ -8.7544,  -8.6765,  -8.2174,  ...,  -7.2042,  -7.2101, -10.6347],\n",
      "         [-15.8108, -15.3809, -15.5517,  ..., -13.2038, -12.9887, -10.9276]],\n",
      "\n",
      "        [[ -6.6741,  -6.6639,  -6.6651,  ...,  -6.0427,  -5.9094,  -3.9709],\n",
      "         [ -7.5710,  -7.5159,  -7.6338,  ...,  -7.9149,  -8.0473,  -3.3412],\n",
      "         [ -7.8664,  -8.1878,  -8.2648,  ...,  -7.5366,  -7.4525,  -4.1520],\n",
      "         ...,\n",
      "         [ -5.8457,  -5.7978,  -5.9070,  ...,  -6.1213,  -6.3387,  -2.7567],\n",
      "         [ -5.8229,  -5.6863,  -5.8593,  ...,  -5.8396,  -6.4987,  -3.0402],\n",
      "         [ -5.5633,  -5.4662,  -5.5886,  ...,  -5.8217,  -6.2057,  -3.0532]],\n",
      "\n",
      "        [[ -6.6065,  -6.5904,  -6.5458,  ...,  -6.0940,  -5.7638,  -3.9642],\n",
      "         [ -3.9361,  -3.9312,  -3.8082,  ...,  -5.1037,  -4.3109,  -2.4811],\n",
      "         [ -1.8248,  -1.7399,  -1.7959,  ...,  -2.7205,  -1.0985,  -0.6643],\n",
      "         ...,\n",
      "         [ -8.5943,  -8.9886,  -8.9149,  ...,  -7.7120,  -7.9517,  -5.1325],\n",
      "         [ -7.7467,  -7.8452,  -7.8173,  ...,  -6.7168,  -6.0909,   1.6826],\n",
      "         [-11.5564, -11.3711, -11.7984,  ...,  -9.3442,  -9.7965,  -7.9220]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2197675704956055\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.1708, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3229,  -6.2753,  -6.2954,  ...,  -5.6822,  -5.5316,  -3.5992],\n",
      "         [-10.4355, -10.3765, -10.2933,  ...,  -8.1224,  -7.1960,  -8.6538],\n",
      "         [ -4.9077,  -5.0455,  -5.1429,  ...,  -4.9334,  -6.1492,  -4.0428],\n",
      "         ...,\n",
      "         [ -5.6920,  -5.8235,  -5.7688,  ...,  -5.7413,  -6.6528,  -4.2105],\n",
      "         [ -5.6756,  -5.7628,  -5.7819,  ...,  -5.6349,  -6.5683,  -4.1633],\n",
      "         [ -6.0436,  -6.1139,  -6.1836,  ...,  -5.9663,  -6.8049,  -4.6744]],\n",
      "\n",
      "        [[ -6.6394,  -6.5883,  -6.5791,  ...,  -5.8472,  -5.8963,  -3.9984],\n",
      "         [ -5.0528,  -4.7825,  -4.7803,  ...,  -4.0251,  -5.8830,  -2.5609],\n",
      "         [ -5.3575,  -4.9148,  -5.0540,  ...,  -4.0913,  -5.4442,  -1.5859],\n",
      "         ...,\n",
      "         [ -5.7151,  -5.5904,  -5.6949,  ...,  -5.5212,  -6.2383,  -1.4622],\n",
      "         [ -5.7319,  -5.6837,  -5.7590,  ...,  -5.4310,  -6.1498,  -0.9845],\n",
      "         [ -6.5070,  -6.3877,  -6.5255,  ...,  -6.0837,  -6.4177,  -2.3471]],\n",
      "\n",
      "        [[ -7.8951,  -7.7363,  -7.7727,  ...,  -7.0067,  -6.6676,  -4.4692],\n",
      "         [-13.6072, -13.2854, -13.3835,  ..., -10.8732, -10.8431,  -9.1609],\n",
      "         [ -5.7099,  -5.8385,  -5.8111,  ...,  -6.6097,  -7.0058,  -3.8802],\n",
      "         ...,\n",
      "         [ -6.2720,  -6.4592,  -6.3473,  ...,  -6.7018,  -6.9090,  -4.3811],\n",
      "         [ -5.7792,  -5.8461,  -5.7499,  ...,  -6.1713,  -7.0224,  -3.6094],\n",
      "         [ -5.2193,  -5.2850,  -5.1168,  ...,  -5.3911,  -6.1033,  -4.0723]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.5804,  -5.5340,  -5.5305,  ...,  -6.4458,  -7.4976,  -5.2292],\n",
      "         [-13.2953, -13.3250, -13.3238,  ..., -11.3362, -10.4762, -10.2974],\n",
      "         [ -4.6507,  -4.8650,  -4.7510,  ...,  -5.1729,  -5.9999,  -3.7865],\n",
      "         ...,\n",
      "         [ -4.4272,  -4.6959,  -4.6575,  ...,  -4.9205,  -5.7048,  -2.8304],\n",
      "         [ -4.2847,  -4.4746,  -4.2994,  ...,  -4.7135,  -5.2989,  -3.6644],\n",
      "         [ -4.9760,  -5.1016,  -5.1471,  ...,  -5.7683,  -6.0805,  -3.1714]],\n",
      "\n",
      "        [[ -6.5516,  -6.5136,  -6.5297,  ...,  -5.8422,  -5.7480,  -3.4491],\n",
      "         [ -8.1633,  -7.9718,  -8.1914,  ...,  -8.5550,  -8.9795,  -3.1613],\n",
      "         [ -7.3301,  -7.6029,  -7.5263,  ...,  -8.3343,  -8.4877,  -4.1924],\n",
      "         ...,\n",
      "         [ -5.3960,  -5.3279,  -5.4158,  ...,  -5.8212,  -6.1235,  -2.0081],\n",
      "         [ -5.1123,  -5.1280,  -5.2936,  ...,  -5.6415,  -5.9532,  -1.7472],\n",
      "         [ -5.2099,  -5.1240,  -5.2198,  ...,  -5.5251,  -5.9915,  -1.3103]],\n",
      "\n",
      "        [[ -6.6363,  -6.6178,  -6.6458,  ...,  -5.9020,  -5.7169,  -3.9756],\n",
      "         [-15.0795, -14.9181, -14.8903,  ..., -12.4175, -12.7604, -10.3499],\n",
      "         [ -4.9374,  -5.1002,  -5.0936,  ...,  -4.9730,  -6.4330,  -4.0998],\n",
      "         ...,\n",
      "         [ -5.5923,  -5.7831,  -5.6628,  ...,  -5.2982,  -7.6914,  -3.6565],\n",
      "         [ -5.2149,  -5.3275,  -5.2898,  ...,  -5.2331,  -6.6041,  -3.9264],\n",
      "         [ -5.0467,  -5.1914,  -5.1723,  ...,  -4.8980,  -6.8681,  -3.6719]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 3.1707537174224854\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5595, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4968,  -6.4592,  -6.4940,  ...,  -5.7894,  -5.6733,  -3.9841],\n",
      "         [ -9.8496,  -9.6231,  -9.8610,  ...,  -7.3115,  -8.0570,  -9.0560],\n",
      "         [ -5.8907,  -6.1315,  -6.0691,  ...,  -6.2901,  -7.3808,  -4.0497],\n",
      "         ...,\n",
      "         [ -5.1986,  -5.2507,  -5.2880,  ...,  -4.8146,  -6.1423,  -3.7030],\n",
      "         [ -6.5509,  -6.7560,  -6.6318,  ...,  -6.5912,  -7.7408,  -4.7178],\n",
      "         [ -5.5624,  -5.8022,  -5.7329,  ...,  -5.5706,  -6.9296,  -3.7451]],\n",
      "\n",
      "        [[ -6.5049,  -6.4836,  -6.4779,  ...,  -5.8804,  -5.8241,  -3.7392],\n",
      "         [-12.8876, -13.0429, -12.8097,  ..., -12.4539, -11.6423, -11.6999],\n",
      "         [ -6.5666,  -6.6691,  -6.7648,  ...,  -6.4286,  -6.9965,  -6.5324],\n",
      "         ...,\n",
      "         [ -5.8070,  -6.0746,  -5.8937,  ...,  -5.8436,  -5.9509,  -5.1420],\n",
      "         [ -6.9580,  -6.9468,  -6.9587,  ...,  -6.5303,  -6.9559,  -5.1397],\n",
      "         [ -6.4280,  -6.4531,  -6.3636,  ...,  -6.3785,  -6.0905,  -5.4299]],\n",
      "\n",
      "        [[ -7.2248,  -7.2714,  -7.2100,  ...,  -6.2534,  -6.5017,  -4.0308],\n",
      "         [-10.1181, -10.2854, -10.3088,  ..., -10.3865,  -7.6392,  -8.3649],\n",
      "         [ -7.7558,  -7.9841,  -7.4123,  ...,  -8.0848,  -7.4788,  -5.7971],\n",
      "         ...,\n",
      "         [-10.4700, -11.0524, -10.6005,  ...,  -9.9397, -10.4141, -11.0512],\n",
      "         [ -9.2326,  -9.4208,  -9.5390,  ...,  -7.8632,  -8.2691,  -8.6189],\n",
      "         [-14.1585, -14.7146, -14.2939,  ..., -12.6809, -10.8209, -11.0552]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4241,  -6.4515,  -6.3809,  ...,  -5.9378,  -5.6986,  -3.6517],\n",
      "         [-11.8942, -12.1821, -12.2567,  ..., -10.1692, -10.7758,  -9.1448],\n",
      "         [ -5.6366,  -6.0713,  -6.3066,  ...,  -6.2777,  -4.4833, -10.1189],\n",
      "         ...,\n",
      "         [ -4.8081,  -4.9687,  -5.0247,  ...,  -5.1494,  -5.1997,  -4.5355],\n",
      "         [ -6.2937,  -6.4029,  -6.5298,  ...,  -6.5258,  -6.7957,  -4.4455],\n",
      "         [ -6.7948,  -6.8478,  -6.9767,  ...,  -6.9280,  -7.0301,  -4.1996]],\n",
      "\n",
      "        [[ -7.2704,  -7.2626,  -7.2681,  ...,  -6.1449,  -6.6402,  -3.7205],\n",
      "         [ -8.8222,  -8.7666,  -8.6287,  ...,  -5.0161,  -9.0526,  -8.0730],\n",
      "         [ -5.6192,  -5.7409,  -5.6456,  ...,  -5.7337,  -7.4382,  -2.5640],\n",
      "         ...,\n",
      "         [ -6.2363,  -6.2099,  -6.1327,  ...,  -6.1704,  -7.5648,  -3.6544],\n",
      "         [ -5.8202,  -5.9419,  -5.8591,  ...,  -5.8424,  -6.7791,  -4.1773],\n",
      "         [ -5.7296,  -5.8188,  -5.7596,  ...,  -5.5248,  -6.9954,  -3.2659]],\n",
      "\n",
      "        [[ -7.3242,  -7.3433,  -7.3231,  ...,  -6.5553,  -6.7744,  -3.9476],\n",
      "         [-11.7314, -11.4010, -11.5364,  ...,  -8.1604,  -9.5073, -10.8314],\n",
      "         [ -5.7570,  -5.8815,  -5.8834,  ...,  -6.1468,  -7.0758,  -1.9411],\n",
      "         ...,\n",
      "         [ -6.4613,  -6.6942,  -6.5971,  ...,  -6.1826,  -7.6248,  -2.8642],\n",
      "         [ -5.9742,  -6.1347,  -6.0716,  ...,  -5.7530,  -7.1952,  -2.4939],\n",
      "         [ -6.4865,  -6.6507,  -6.5533,  ...,  -6.3780,  -7.0533,  -3.5114]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.5594708919525146\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9717, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0928,  -7.1369,  -7.1148,  ...,  -6.5715,  -6.2116,  -4.5039],\n",
      "         [-14.8762, -14.8017, -14.8586,  ..., -14.3381, -11.9310, -14.3838],\n",
      "         [ -5.9298,  -6.1465,  -6.4830,  ...,  -5.4563,  -4.6536,  -7.9816],\n",
      "         ...,\n",
      "         [ -3.8470,  -4.2185,  -3.9513,  ...,  -3.7414,  -2.0270,  -5.4812],\n",
      "         [ -7.6091,  -7.8198,  -7.9403,  ...,  -8.3890,  -7.3067,  -7.5644],\n",
      "         [ -4.6764,  -5.0696,  -4.8877,  ...,  -5.0877,  -3.4263,  -4.6679]],\n",
      "\n",
      "        [[ -6.9307,  -6.9152,  -6.9011,  ...,  -5.9294,  -6.1589,  -4.0539],\n",
      "         [-10.9115, -10.9020, -11.1660,  ...,  -7.1684,  -8.7450,  -8.0969],\n",
      "         [ -5.5376,  -5.7215,  -5.7745,  ...,  -5.5311,  -7.3508,  -3.2032],\n",
      "         ...,\n",
      "         [ -6.3388,  -6.5044,  -6.3499,  ...,  -5.8285,  -7.2710,  -3.4789],\n",
      "         [ -6.3345,  -6.4470,  -6.3682,  ...,  -5.6800,  -7.1495,  -3.2804],\n",
      "         [ -6.2174,  -6.3376,  -6.2373,  ...,  -5.6873,  -7.1462,  -3.1621]],\n",
      "\n",
      "        [[ -6.9524,  -6.9622,  -6.8910,  ...,  -6.4221,  -6.1442,  -4.3588],\n",
      "         [ -7.8608,  -7.8685,  -7.8714,  ...,  -7.9979,  -6.6680,  -5.5386],\n",
      "         [ -7.7938,  -7.8873,  -7.7420,  ...,  -7.4013,  -6.5738,  -6.3340],\n",
      "         ...,\n",
      "         [ -8.4539,  -8.4739,  -8.3809,  ...,  -7.3099,  -6.0543,  -4.7454],\n",
      "         [ -4.7870,  -4.7402,  -4.6787,  ...,  -4.2790,  -4.3862,  -3.6171],\n",
      "         [-12.7420, -12.3867, -12.8971,  ..., -10.4216,  -9.2038,  -8.4330]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7430,  -6.7116,  -6.7087,  ...,  -5.8972,  -5.9206,  -3.5975],\n",
      "         [ -7.0837,  -6.8589,  -7.1102,  ...,  -7.1896,  -7.5857,  -3.3465],\n",
      "         [ -7.6037,  -7.6213,  -7.6305,  ...,  -7.5650,  -8.1583,  -4.6651],\n",
      "         ...,\n",
      "         [ -5.8604,  -5.7518,  -5.8526,  ...,  -5.4442,  -6.3154,  -2.3561],\n",
      "         [ -5.6077,  -5.4911,  -5.5229,  ...,  -5.3257,  -6.4081,  -1.9940],\n",
      "         [ -5.4683,  -5.2890,  -5.4678,  ...,  -5.4522,  -6.3419,  -1.7828]],\n",
      "\n",
      "        [[ -6.8930,  -6.8397,  -6.8657,  ...,  -6.0752,  -6.1199,  -3.8396],\n",
      "         [ -8.3309,  -8.1691,  -8.4573,  ...,  -8.4191, -10.2775,  -1.3368],\n",
      "         [ -6.2676,  -6.4344,  -6.4207,  ...,  -5.7207,  -7.0750,   0.3127],\n",
      "         ...,\n",
      "         [ -6.2854,  -6.3128,  -6.2512,  ...,  -5.4665,  -6.1587,  -0.8093],\n",
      "         [ -5.9537,  -5.8399,  -5.9104,  ...,  -5.4006,  -6.2435,  -1.1495],\n",
      "         [ -5.3539,  -5.2888,  -5.3069,  ...,  -5.5630,  -5.9835,  -0.0698]],\n",
      "\n",
      "        [[ -6.5761,  -6.5583,  -6.6936,  ...,  -6.5264,  -6.5678,  -2.5447],\n",
      "         [ -8.9675,  -8.7396,  -8.9604,  ...,  -7.9049,  -7.7229,  -4.7385],\n",
      "         [ -6.1031,  -6.1065,  -6.1967,  ...,  -6.6059,  -6.3289,  -3.8099],\n",
      "         ...,\n",
      "         [ -6.4343,  -6.4464,  -6.5322,  ...,  -6.7776,  -6.8769,  -2.9350],\n",
      "         [ -6.6639,  -6.6005,  -6.6952,  ...,  -6.9480,  -6.5656,  -3.2679],\n",
      "         [ -6.4616,  -6.4930,  -6.5219,  ...,  -6.8241,  -6.7339,  -3.7041]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.9717336893081665\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7271, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8877,  -6.9260,  -6.8764,  ...,  -6.4842,  -6.1739,  -4.2543],\n",
      "         [ -4.3362,  -3.9911,  -4.1340,  ...,  -5.2164,  -3.5244,  -5.1498],\n",
      "         [-12.9255, -12.6229, -13.0388,  ...,  -9.9770, -11.2350, -10.5694],\n",
      "         ...,\n",
      "         [ -7.5780,  -7.5658,  -7.6327,  ...,  -7.8007,  -6.9009,  -5.2832],\n",
      "         [ -3.7403,  -3.5727,  -3.6550,  ...,  -3.5154,  -4.2315,  -3.3367],\n",
      "         [-12.9961, -12.6890, -12.9715,  ..., -11.6923, -11.1778, -10.5163]],\n",
      "\n",
      "        [[ -6.7183,  -6.6806,  -6.6900,  ...,  -5.9649,  -5.8601,  -4.1715],\n",
      "         [ -5.4452,  -5.3900,  -5.4758,  ...,  -5.0850,  -4.5909,  -3.5465],\n",
      "         [ -9.6261,  -9.3079,  -9.5537,  ...,  -9.2098,  -7.9701,  -5.8301],\n",
      "         ...,\n",
      "         [ -5.8629,  -5.7458,  -5.7484,  ...,  -5.3913,  -5.8453,  -5.1333],\n",
      "         [ -6.2465,  -6.1738,  -6.2061,  ...,  -5.9730,  -6.6142,  -5.0462],\n",
      "         [ -6.1422,  -6.1521,  -6.2036,  ...,  -5.9366,  -6.3994,  -5.0716]],\n",
      "\n",
      "        [[ -6.8396,  -6.8441,  -6.8001,  ...,  -6.1690,  -6.0511,  -3.9536],\n",
      "         [ -8.2988,  -8.2349,  -8.5405,  ...,  -5.2900,  -7.0828,  -9.2018],\n",
      "         [ -8.5289,  -8.3160,  -8.6048,  ...,  -7.3073,  -6.8546,  -7.2657],\n",
      "         ...,\n",
      "         [ -5.3730,  -5.0962,  -5.0064,  ...,  -4.8587,  -3.2343,  -3.4410],\n",
      "         [-12.5027, -12.2592, -12.2399,  ..., -12.2707, -10.0044,  -9.3851],\n",
      "         [-14.8887, -14.8108, -14.6795,  ..., -11.9106, -12.9846, -12.1929]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0125,  -7.0249,  -6.9342,  ...,  -6.3570,  -5.9817,  -4.4961],\n",
      "         [ -8.7362,  -8.8637,  -8.8004,  ...,  -9.3931,  -8.4771, -10.1104],\n",
      "         [ -6.5448,  -6.8072,  -6.7056,  ...,  -8.2189,  -7.5271,  -8.2989],\n",
      "         ...,\n",
      "         [ -5.4942,  -5.7313,  -5.7053,  ...,  -6.3281,  -4.4133,  -5.7549],\n",
      "         [ -5.8781,  -5.7432,  -5.8385,  ...,  -6.4033,  -4.4569,  -5.4840],\n",
      "         [-12.7760, -13.0510, -12.8856,  ..., -11.6505, -10.5387,  -6.7575]],\n",
      "\n",
      "        [[ -6.5398,  -6.4922,  -6.5072,  ...,  -5.8431,  -5.7230,  -3.8249],\n",
      "         [ -5.4877,  -5.3946,  -5.5373,  ...,  -5.0965,  -5.8281,  -2.9896],\n",
      "         [ -5.9444,  -5.7663,  -5.7186,  ...,  -6.3201,  -6.9934,  -1.6272],\n",
      "         ...,\n",
      "         [ -4.5979,  -4.6024,  -4.6570,  ...,  -4.4183,  -5.0371,  -1.1176],\n",
      "         [ -4.7355,  -4.7460,  -4.7597,  ...,  -4.3987,  -5.2299,  -1.0760],\n",
      "         [ -4.9184,  -4.7401,  -4.8910,  ...,  -4.4929,  -5.4143,  -0.8820]],\n",
      "\n",
      "        [[ -7.1698,  -7.1420,  -7.1153,  ...,  -6.5397,  -6.2632,  -4.3173],\n",
      "         [-12.7573, -13.1778, -12.7731,  ..., -12.7578, -12.0022, -10.1998],\n",
      "         [-14.6338, -14.5317, -14.4123,  ..., -12.5102, -13.1037, -12.8136],\n",
      "         ...,\n",
      "         [ -6.5332,  -6.8070,  -6.4415,  ...,  -6.5177,  -6.7974,  -6.5751],\n",
      "         [ -6.9406,  -7.1683,  -6.8486,  ...,  -6.9419,  -7.0637,  -5.4979],\n",
      "         [ -6.5428,  -6.7973,  -6.3788,  ...,  -6.5847,  -7.0649,  -5.4974]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.727128505706787\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8806, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3781,  -6.3256,  -6.3497,  ...,  -5.7145,  -5.4787,  -3.8413],\n",
      "         [ -8.6304,  -8.4071,  -8.2924,  ...,  -4.9257,  -7.6911,  -6.1333],\n",
      "         [ -6.5328,  -6.4995,  -6.5881,  ...,  -6.7668,  -7.1648,  -4.7144],\n",
      "         ...,\n",
      "         [ -5.5392,  -5.6444,  -5.6530,  ...,  -5.3572,  -6.5472,  -3.8760],\n",
      "         [ -5.5464,  -5.6781,  -5.7043,  ...,  -5.4564,  -6.5219,  -4.2437],\n",
      "         [ -6.3415,  -6.4455,  -6.4166,  ...,  -6.1286,  -7.3028,  -5.0412]],\n",
      "\n",
      "        [[ -6.5515,  -6.5004,  -6.5253,  ...,  -5.8734,  -5.6642,  -3.8168],\n",
      "         [-10.6019, -10.4550, -10.6137,  ...,  -6.8890,  -8.9790,  -8.0091],\n",
      "         [ -5.9013,  -6.0666,  -6.0392,  ...,  -6.1792,  -7.2325,  -4.3198],\n",
      "         ...,\n",
      "         [ -6.4581,  -6.5052,  -6.4217,  ...,  -6.3397,  -7.2475,  -4.9416],\n",
      "         [ -6.0979,  -6.1992,  -6.1089,  ...,  -5.9498,  -7.1490,  -4.1904],\n",
      "         [ -6.8447,  -7.0676,  -6.9695,  ...,  -6.9877,  -7.8684,  -4.7671]],\n",
      "\n",
      "        [[ -6.5700,  -6.5862,  -6.5781,  ...,  -5.9590,  -5.6761,  -3.4504],\n",
      "         [ -7.8200,  -7.9226,  -7.7949,  ...,  -7.0400,  -6.9415,  -5.8322],\n",
      "         [-11.9034, -12.0536, -12.3168,  ..., -10.4022, -10.9005, -11.3735],\n",
      "         ...,\n",
      "         [-11.6868, -12.2770, -12.2716,  ..., -10.8618, -10.1254, -12.0254],\n",
      "         [ -4.6535,  -4.7685,  -4.8756,  ...,  -5.3936,  -5.6083,  -3.6879],\n",
      "         [-14.4714, -14.5138, -14.5557,  ..., -13.3290, -13.3042,  -9.9935]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4052,  -6.3745,  -6.3796,  ...,  -5.8234,  -5.6967,  -3.5190],\n",
      "         [ -8.7386,  -8.7021,  -8.8086,  ...,  -8.0231,  -8.3390,  -9.9926],\n",
      "         [ -6.5684,  -6.5814,  -6.4815,  ...,  -4.5297,  -3.1866,  -4.8860],\n",
      "         ...,\n",
      "         [ -6.7427,  -6.6699,  -6.7415,  ...,  -6.6031,  -6.1888,  -3.2270],\n",
      "         [ -6.3947,  -6.3050,  -6.4344,  ...,  -5.9610,  -5.6459,  -3.4577],\n",
      "         [ -6.9453,  -6.8311,  -6.9732,  ...,  -6.7295,  -6.2974,  -3.6062]],\n",
      "\n",
      "        [[ -7.9177,  -7.9128,  -7.7431,  ...,  -7.4198,  -7.3056,  -5.1526],\n",
      "         [-12.2203, -12.4865, -12.4735,  ..., -10.8910, -11.6079, -10.2667],\n",
      "         [ -9.1749,  -9.1246,  -9.3412,  ...,  -7.8301,  -9.5604,  -4.4498],\n",
      "         ...,\n",
      "         [ -5.2464,  -5.3870,  -5.2352,  ...,  -5.0839,  -5.9160,  -6.0711],\n",
      "         [ -7.5747,  -7.6420,  -7.6821,  ...,  -7.4203,  -7.3952,  -6.8055],\n",
      "         [ -5.7266,  -5.8440,  -5.6268,  ...,  -5.7081,  -6.5610,  -4.2625]],\n",
      "\n",
      "        [[ -6.7239,  -6.7387,  -6.6700,  ...,  -6.0429,  -5.7711,  -3.4097],\n",
      "         [ -8.7689,  -8.7285,  -8.4268,  ...,  -7.9613,  -8.3853,  -2.2348],\n",
      "         [ -5.5278,  -5.7572,  -5.6973,  ...,  -5.7858,  -4.8628,  -0.0155],\n",
      "         ...,\n",
      "         [ -1.8180,  -1.7723,  -1.3811,  ...,  -0.9472,  -1.6863,   1.8749],\n",
      "         [ -8.4065,  -8.3998,  -7.9571,  ...,  -7.6072,  -7.4453,  -4.5889],\n",
      "         [-14.6296, -13.8090, -14.2010,  ..., -11.5370, -11.2311,  -8.7931]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8806297779083252\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6395, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4917,  -6.4610,  -6.4537,  ...,  -5.9536,  -5.7049,  -3.8942],\n",
      "         [-13.2299, -13.5622, -13.2606,  ..., -11.9103, -10.1772, -12.3889],\n",
      "         [ -8.1082,  -8.0394,  -8.2328,  ...,  -7.3554,  -7.4388,  -8.8211],\n",
      "         ...,\n",
      "         [ -6.3250,  -6.3725,  -6.3055,  ...,  -7.2919,  -5.2560,  -5.9923],\n",
      "         [ -4.7655,  -4.9306,  -4.8004,  ...,  -5.6346,  -4.5884,  -4.9402],\n",
      "         [ -6.3112,  -6.1155,  -6.3814,  ...,  -6.1260,  -5.6042,  -5.1732]],\n",
      "\n",
      "        [[ -6.9004,  -6.9388,  -6.8946,  ...,  -6.1530,  -6.1059,  -4.1267],\n",
      "         [ -5.5793,  -5.6986,  -5.7946,  ...,  -6.2641,  -5.1190,  -3.1009],\n",
      "         [-13.1362, -13.3531, -13.3324,  ..., -11.9322,  -9.7936, -11.4508],\n",
      "         ...,\n",
      "         [ -6.9115,  -7.0843,  -6.9051,  ...,  -7.5142,  -7.3847,  -4.5577],\n",
      "         [ -6.0775,  -6.1060,  -5.9688,  ...,  -6.5030,  -6.2163,  -1.9099],\n",
      "         [ -7.0871,  -7.1360,  -7.1003,  ...,  -7.1448,  -6.6601,  -4.1588]],\n",
      "\n",
      "        [[ -7.1885,  -7.2196,  -7.1947,  ...,  -6.4229,  -6.4030,  -4.0469],\n",
      "         [ -6.6831,  -6.8087,  -6.9336,  ...,  -5.4360,  -5.7290,  -4.8785],\n",
      "         [-14.2755, -14.5478, -14.6949,  ..., -12.3877, -11.2219,  -6.2612],\n",
      "         ...,\n",
      "         [ -5.7072,  -5.6854,  -5.4922,  ...,  -4.8474,  -5.1362,  -2.9020],\n",
      "         [ -1.7862,  -1.7819,  -1.6351,  ...,  -1.0736,  -0.5590,   3.0468],\n",
      "         [-11.0462, -10.7437, -11.1133,  ...,  -7.7546,  -9.1605,  -5.2207]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6381,  -6.6264,  -6.5998,  ...,  -5.8564,  -5.8784,  -4.0386],\n",
      "         [-13.4570, -13.2486, -13.5989,  ..., -10.4504, -11.3133,  -7.0885],\n",
      "         [ -4.9363,  -5.2003,  -5.1644,  ...,  -5.0461,  -6.6712,  -4.1957],\n",
      "         ...,\n",
      "         [ -5.7202,  -5.9204,  -5.8700,  ...,  -5.1954,  -7.1652,  -4.4479],\n",
      "         [ -4.7625,  -4.9741,  -4.8868,  ...,  -4.6632,  -6.4943,  -3.5678],\n",
      "         [ -5.0006,  -5.2128,  -5.1439,  ...,  -4.6740,  -6.9091,  -3.7503]],\n",
      "\n",
      "        [[ -6.7522,  -6.7187,  -6.7170,  ...,  -6.0434,  -5.9075,  -3.8592],\n",
      "         [ -6.2097,  -6.0024,  -6.1773,  ...,  -7.7703,  -7.6010,  -2.7835],\n",
      "         [ -7.2048,  -7.0771,  -7.2727,  ...,  -7.2342,  -5.7228,  -7.3757],\n",
      "         ...,\n",
      "         [ -5.8416,  -5.8251,  -5.8012,  ...,  -5.7372,  -5.8706,  -2.3468],\n",
      "         [ -5.7764,  -5.6620,  -5.7038,  ...,  -6.0900,  -6.0594,  -1.7283],\n",
      "         [ -6.6405,  -6.4705,  -6.5620,  ...,  -7.0092,  -7.1643,  -2.3991]],\n",
      "\n",
      "        [[ -6.9665,  -6.9635,  -6.9029,  ...,  -6.1238,  -6.0070,  -4.2342],\n",
      "         [-10.3059, -10.3425, -10.4695,  ...,  -8.1625,  -8.6912,  -9.5452],\n",
      "         [ -8.3834,  -8.4501,  -8.6707,  ...,  -8.0142,  -8.8237, -11.1868],\n",
      "         ...,\n",
      "         [-12.0996, -12.0915, -11.9729,  ...,  -9.0980,  -9.8611,  -9.8422],\n",
      "         [ -4.8691,  -4.9927,  -5.2913,  ...,  -2.9717,  -4.3884,  -4.5408],\n",
      "         [-13.3435, -12.9804, -13.2995,  ..., -10.5372, -11.2269,  -9.4304]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.6394927501678467\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5182, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6142,  -6.6675,  -6.6234,  ...,  -5.9470,  -5.7616,  -4.0526],\n",
      "         [ -8.0711,  -8.2114,  -7.8789,  ...,  -7.4839,  -6.6151,  -7.7081],\n",
      "         [ -1.4630,  -1.4683,  -1.6583,  ...,  -2.3415,  -0.8447,  -3.5561],\n",
      "         ...,\n",
      "         [ -5.4502,  -5.4143,  -5.5524,  ...,  -4.8009,  -4.0339,  -5.2898],\n",
      "         [ -4.8441,  -4.7796,  -4.7592,  ...,  -3.8705,  -3.6670,  -4.1600],\n",
      "         [ -5.9176,  -5.9204,  -5.9994,  ...,  -5.4973,  -4.0057,  -5.4536]],\n",
      "\n",
      "        [[ -6.4083,  -6.4010,  -6.4003,  ...,  -5.7546,  -5.5448,  -3.9070],\n",
      "         [ -9.4684,  -9.3601,  -9.2233,  ...,  -7.9847,  -8.0149,  -8.8613],\n",
      "         [ -5.5024,  -5.5143,  -5.6413,  ...,  -5.5696,  -6.5899,  -4.1944],\n",
      "         ...,\n",
      "         [ -5.5353,  -5.6114,  -5.7057,  ...,  -5.8797,  -6.2522,  -4.5555],\n",
      "         [ -6.2433,  -6.2115,  -6.3676,  ...,  -6.3918,  -6.7740,  -4.3016],\n",
      "         [ -5.4592,  -5.5694,  -5.6685,  ...,  -5.6970,  -6.3283,  -3.8757]],\n",
      "\n",
      "        [[ -6.9633,  -6.9378,  -6.9735,  ...,  -6.2324,  -6.1204,  -4.2162],\n",
      "         [-12.5350, -12.5260, -12.5250,  ...,  -9.7972, -12.5637, -10.0700],\n",
      "         [ -5.7102,  -5.9095,  -5.9629,  ...,  -6.0766,  -7.5377,  -4.4173],\n",
      "         ...,\n",
      "         [ -5.2742,  -5.3839,  -5.3747,  ...,  -5.5777,  -6.9732,  -4.7608],\n",
      "         [ -5.2185,  -5.2926,  -5.2711,  ...,  -5.3815,  -6.7144,  -5.0200],\n",
      "         [ -5.2064,  -5.2385,  -5.2706,  ...,  -5.2339,  -6.4684,  -4.2325]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6063,  -6.5582,  -6.5485,  ...,  -5.7977,  -5.4985,  -3.5794],\n",
      "         [-11.4146, -11.4277, -11.5681,  ..., -10.7551,  -9.9352,  -9.9261],\n",
      "         [-13.1752, -13.5689, -13.6379,  ..., -10.9119, -12.5244,  -8.4576],\n",
      "         ...,\n",
      "         [ -6.4132,  -6.3386,  -6.3734,  ...,  -5.9427,  -6.3723,  -3.5012],\n",
      "         [ -6.6685,  -6.5659,  -6.5983,  ...,  -6.3748,  -6.5817,  -4.7657],\n",
      "         [ -7.0573,  -7.2120,  -7.1397,  ...,  -6.7921,  -6.9805,  -5.4303]],\n",
      "\n",
      "        [[ -7.0290,  -7.0046,  -6.9953,  ...,  -6.1228,  -6.1755,  -4.1591],\n",
      "         [-11.1596, -10.6386, -10.7178,  ...,  -7.7296, -10.0239,  -9.6228],\n",
      "         [ -5.0813,  -5.2196,  -5.2953,  ...,  -5.4189,  -6.3477,  -2.7761],\n",
      "         ...,\n",
      "         [ -5.4574,  -5.6179,  -5.5841,  ...,  -5.8712,  -7.2428,  -3.3450],\n",
      "         [ -5.8258,  -5.9705,  -5.8954,  ...,  -5.6277,  -7.0373,  -3.9488],\n",
      "         [ -5.2327,  -5.4143,  -5.2628,  ...,  -5.0259,  -6.3801,  -3.0453]],\n",
      "\n",
      "        [[ -6.7691,  -6.7707,  -6.8489,  ...,  -6.1082,  -5.8671,  -3.6569],\n",
      "         [ -8.5290,  -8.4172,  -8.5853,  ...,  -8.2595,  -7.4341,  -4.9699],\n",
      "         [ -5.3390,  -5.3485,  -5.5290,  ...,  -4.8440,  -5.2675,  -2.0669],\n",
      "         ...,\n",
      "         [ -5.9125,  -5.8475,  -5.9208,  ...,  -5.6203,  -6.4943,  -2.2682],\n",
      "         [ -5.1352,  -5.1699,  -5.2802,  ...,  -5.0221,  -5.6508,  -2.0622],\n",
      "         [ -5.5079,  -5.4631,  -5.6146,  ...,  -5.5582,  -6.0391,  -2.1645]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.518228769302368\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8833, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.5361,  -8.6601,  -8.7419,  ...,  -7.4820,  -8.2026,  -4.2563],\n",
      "         [-12.0929, -11.5954, -11.6607,  ...,  -9.7575, -10.3130, -12.0332],\n",
      "         [ -4.7400,  -5.0170,  -4.9024,  ...,  -5.3491,  -7.4503,  -4.1099],\n",
      "         ...,\n",
      "         [ -4.3723,  -4.5298,  -4.5407,  ...,  -4.5344,  -6.9326,  -3.7696],\n",
      "         [ -4.5614,  -4.6497,  -4.6373,  ...,  -4.1412,  -6.4332,  -3.9715],\n",
      "         [ -5.3286,  -5.6037,  -5.5592,  ...,  -5.1441,  -7.1609,  -3.6437]],\n",
      "\n",
      "        [[ -6.4747,  -6.4244,  -6.4436,  ...,  -5.6960,  -5.6865,  -3.7326],\n",
      "         [ -8.8753,  -8.8322,  -9.0603,  ...,  -9.5599, -10.6828,  -2.9774],\n",
      "         [ -6.6539,  -6.8127,  -6.9032,  ...,  -5.6530,  -6.8760,  -1.4036],\n",
      "         ...,\n",
      "         [ -5.2130,  -5.0343,  -5.2054,  ...,  -5.2603,  -6.2076,  -1.6929],\n",
      "         [ -4.5254,  -4.4670,  -4.4734,  ...,  -4.5593,  -5.3797,  -1.5264],\n",
      "         [ -4.6798,  -4.6131,  -4.5921,  ...,  -4.7441,  -5.6317,  -0.7668]],\n",
      "\n",
      "        [[ -6.7560,  -6.8980,  -6.8124,  ...,  -6.5880,  -6.4991,  -5.3139],\n",
      "         [ -2.4906,  -2.8372,  -2.2499,  ...,  -3.9006,  -2.6898,  -3.5319],\n",
      "         [ -9.9089,  -9.3688,  -9.8339,  ...,  -8.2657,  -8.5647, -11.8651],\n",
      "         ...,\n",
      "         [ -6.9175,  -7.0976,  -6.9942,  ...,  -6.7143,  -6.6499,  -5.8643],\n",
      "         [ -7.1111,  -7.2202,  -7.2752,  ...,  -7.2403,  -7.2547,  -4.9365],\n",
      "         [ -5.5772,  -5.6935,  -5.5484,  ...,  -6.0537,  -5.0129,  -4.2541]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.8318,  -7.8354,  -7.7939,  ...,  -7.4979,  -7.0143,  -3.6681],\n",
      "         [-17.0744, -16.9163, -16.7752,  ..., -15.0924, -13.8890,  -7.4911],\n",
      "         [ -7.7545,  -7.8532,  -7.7511,  ...,  -6.4816,  -8.7194,  -6.2689],\n",
      "         ...,\n",
      "         [ -7.7537,  -7.9267,  -7.7056,  ...,  -6.2063,  -9.0957,  -6.4969],\n",
      "         [-11.2112, -11.1519, -11.0781,  ..., -10.8579, -10.6667,  -3.8602],\n",
      "         [-14.0333, -13.9029, -13.8545,  ..., -12.6258, -13.1734,  -8.0210]],\n",
      "\n",
      "        [[ -6.4383,  -6.4133,  -6.3878,  ...,  -5.6943,  -5.4528,  -3.7170],\n",
      "         [-11.6022, -10.9882, -11.2766,  ...,  -9.2520,  -8.2455,  -9.6458],\n",
      "         [ -6.4011,  -6.5578,  -6.5393,  ...,  -6.5324,  -7.6314,  -3.0895],\n",
      "         ...,\n",
      "         [ -5.6041,  -5.8209,  -5.6683,  ...,  -5.4921,  -7.1481,  -2.5411],\n",
      "         [ -5.8425,  -5.9692,  -5.9245,  ...,  -5.7666,  -6.8446,  -2.8602],\n",
      "         [ -6.3741,  -6.5918,  -6.4604,  ...,  -6.2705,  -6.6165,  -3.2887]],\n",
      "\n",
      "        [[ -6.6858,  -6.6653,  -6.6735,  ...,  -5.9929,  -5.8227,  -3.9868],\n",
      "         [ -9.0770,  -8.8922,  -9.4042,  ...,  -6.2926,  -7.9409,  -6.2009],\n",
      "         [ -5.8039,  -5.8858,  -5.9467,  ...,  -6.0339,  -6.3198,  -3.3708],\n",
      "         ...,\n",
      "         [ -6.1658,  -6.1602,  -6.2155,  ...,  -6.2263,  -6.6143,  -3.7079],\n",
      "         [ -6.1706,  -6.1668,  -6.2090,  ...,  -6.1733,  -6.3576,  -3.3024],\n",
      "         [ -6.0310,  -5.9762,  -6.0017,  ...,  -5.9060,  -6.3035,  -2.4950]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8833234310150146\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7858, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5259,  -7.5370,  -7.4645,  ...,  -6.7960,  -6.5822,  -4.3191],\n",
      "         [ -3.0760,  -3.1893,  -3.1973,  ...,  -4.0112,  -3.8451,  -2.8991],\n",
      "         [ -9.3492,  -9.4114,  -9.6742,  ...,  -9.9292,  -9.0285,  -7.4151],\n",
      "         ...,\n",
      "         [ -6.7588,  -6.8478,  -6.8360,  ...,  -6.8049,  -7.8906,  -6.1086],\n",
      "         [ -7.0856,  -7.2358,  -7.1747,  ...,  -7.6287,  -7.7407,  -5.5478],\n",
      "         [ -7.2450,  -7.3791,  -7.3648,  ...,  -7.4433,  -7.8068,  -4.9935]],\n",
      "\n",
      "        [[ -6.6560,  -6.6508,  -6.6306,  ...,  -5.9449,  -5.7098,  -4.0075],\n",
      "         [ -8.1925,  -7.4215,  -7.4537,  ...,  -5.7462,  -7.1713,  -6.5381],\n",
      "         [ -5.0667,  -5.2229,  -5.1883,  ...,  -5.2544,  -6.5379,  -3.6344],\n",
      "         ...,\n",
      "         [ -5.2928,  -5.3849,  -5.3342,  ...,  -5.3529,  -6.7102,  -3.2388],\n",
      "         [ -5.0835,  -5.1594,  -5.1329,  ...,  -5.2595,  -6.4260,  -3.7595],\n",
      "         [ -5.4498,  -5.4412,  -5.4334,  ...,  -5.8559,  -6.5471,  -4.2661]],\n",
      "\n",
      "        [[ -7.1330,  -7.1420,  -7.0537,  ...,  -6.6203,  -6.2616,  -4.4623],\n",
      "         [-13.8112, -13.4038, -13.6754,  ..., -12.9095, -12.7605, -12.4499],\n",
      "         [-14.2422, -14.3734, -14.1196,  ..., -12.3586, -12.7305, -13.9518],\n",
      "         ...,\n",
      "         [ -3.8052,  -4.0455,  -3.7342,  ...,  -3.8440,  -2.6053,  -3.2247],\n",
      "         [ -6.9365,  -7.1006,  -7.0209,  ...,  -6.2964,  -5.8496,  -4.2637],\n",
      "         [ -6.0671,  -6.1458,  -6.0631,  ...,  -5.9757,  -4.7210,  -4.5571]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8889,  -6.8460,  -6.8915,  ...,  -6.0966,  -6.1405,  -3.4489],\n",
      "         [ -8.8914,  -8.8954,  -9.3761,  ...,  -9.3620,  -9.0592,  -2.5964],\n",
      "         [ -7.3710,  -7.6180,  -7.9013,  ...,  -7.5709,  -7.7930,  -2.1790],\n",
      "         ...,\n",
      "         [ -5.2936,  -5.3766,  -5.3745,  ...,  -5.2787,  -6.5427,  -1.6091],\n",
      "         [ -4.6421,  -4.7760,  -4.6485,  ...,  -4.3722,  -6.3708,  -2.5195],\n",
      "         [ -5.2826,  -5.2353,  -5.3561,  ...,  -5.8937,  -6.0518,  -0.6679]],\n",
      "\n",
      "        [[ -6.4892,  -6.4647,  -6.4934,  ...,  -5.6906,  -5.7155,  -3.8362],\n",
      "         [ -9.0337,  -8.5002,  -8.6652,  ...,  -6.2052,  -8.1138,  -6.7946],\n",
      "         [ -5.8968,  -5.9768,  -5.8615,  ...,  -5.4275,  -6.7690,  -3.2159],\n",
      "         ...,\n",
      "         [ -5.9408,  -6.0798,  -5.9244,  ...,  -6.0380,  -7.0663,  -3.3821],\n",
      "         [ -5.8966,  -5.9877,  -5.8879,  ...,  -5.3037,  -6.8187,  -2.6555],\n",
      "         [ -6.2582,  -6.3557,  -6.3006,  ...,  -6.1018,  -6.7880,  -3.6427]],\n",
      "\n",
      "        [[ -6.5937,  -6.5648,  -6.5547,  ...,  -5.7459,  -5.8495,  -3.8129],\n",
      "         [ -9.1197,  -9.1158,  -8.9542,  ...,  -8.4059,  -8.5377,  -7.1582],\n",
      "         [ -3.9070,  -3.8351,  -3.9422,  ...,  -4.9892,  -4.8412,  -4.5092],\n",
      "         ...,\n",
      "         [ -5.7223,  -6.0544,  -6.0098,  ...,  -5.4540,  -6.2958,  -4.9625],\n",
      "         [ -6.6941,  -7.0693,  -6.9839,  ...,  -6.6360,  -7.3497,  -5.1096],\n",
      "         [ -5.4479,  -5.7686,  -5.7739,  ...,  -5.0040,  -5.5912,  -3.3714]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.7858426570892334\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8514, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2316,  -7.2079,  -7.1338,  ...,  -6.5491,  -6.4160,  -4.1688],\n",
      "         [ -7.0710,  -7.0302,  -7.1327,  ...,  -6.0931,  -6.0963,  -8.3378],\n",
      "         [ -5.4261,  -5.5939,  -5.3825,  ...,  -4.0128,  -4.5447,  -8.4111],\n",
      "         ...,\n",
      "         [ -6.2309,  -6.4374,  -5.9630,  ...,  -7.3634,  -5.7997,  -4.8473],\n",
      "         [ -2.7805,  -2.8053,  -2.9529,  ...,  -3.0451,  -2.6852,  -2.0071],\n",
      "         [-10.5821, -10.3609, -10.5357,  ...,  -7.9183,  -7.4827,  -8.0676]],\n",
      "\n",
      "        [[ -6.7939,  -6.7090,  -6.7672,  ...,  -6.0741,  -5.7449,  -3.9467],\n",
      "         [-15.4718, -15.3246, -15.3928,  ..., -14.3357, -12.8809, -12.3208],\n",
      "         [ -7.1680,  -7.3275,  -7.6089,  ...,  -7.7362,  -6.6304,  -6.1835],\n",
      "         ...,\n",
      "         [ -6.8703,  -7.0811,  -7.0112,  ...,  -6.1123,  -5.6206,  -5.6110],\n",
      "         [ -7.5228,  -7.3759,  -7.2808,  ...,  -6.8250,  -6.5957,  -3.3247],\n",
      "         [ -7.0868,  -6.9084,  -6.6876,  ...,  -6.6614,  -6.1587,  -3.3583]],\n",
      "\n",
      "        [[ -6.8057,  -6.7867,  -6.7762,  ...,  -6.0314,  -5.8397,  -4.0785],\n",
      "         [-10.3954, -10.2461, -10.3599,  ...,  -7.6365,  -8.3625,  -6.6437],\n",
      "         [ -5.9459,  -6.0543,  -6.0879,  ...,  -6.2322,  -7.2960,  -4.3721],\n",
      "         ...,\n",
      "         [ -6.4335,  -6.5168,  -6.3871,  ...,  -6.1113,  -6.5126,  -4.6042],\n",
      "         [ -5.8696,  -6.0237,  -5.9331,  ...,  -5.5808,  -6.7294,  -4.0780],\n",
      "         [ -6.0826,  -6.2069,  -6.2142,  ...,  -5.8351,  -6.9171,  -4.2441]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-11.4212, -11.6815, -11.4738,  ...,  -9.4138, -11.3489,  -9.5905],\n",
      "         [-11.6358, -11.5531, -11.7582,  ...,  -9.7631,  -9.9532, -11.5238],\n",
      "         [ -4.3131,  -4.5062,  -4.5851,  ...,  -5.1501,  -6.4590,  -2.6041],\n",
      "         ...,\n",
      "         [ -4.7171,  -4.7001,  -4.7237,  ...,  -5.2413,  -6.1729,  -3.5636],\n",
      "         [ -4.8982,  -4.9452,  -4.9743,  ...,  -5.1832,  -6.6270,  -3.1800],\n",
      "         [ -5.3594,  -5.5878,  -5.6083,  ...,  -5.3686,  -6.2286,  -4.6081]],\n",
      "\n",
      "        [[ -6.3785,  -6.3033,  -6.3322,  ...,  -5.5962,  -5.5492,  -3.7027],\n",
      "         [ -5.5802,  -5.6619,  -5.7947,  ...,  -5.8558,  -6.2985,  -2.8957],\n",
      "         [ -6.5584,  -6.4221,  -6.6623,  ...,  -7.1326,  -6.3635,  -4.9103],\n",
      "         ...,\n",
      "         [ -5.6731,  -5.5465,  -5.6210,  ...,  -5.9432,  -5.6767,  -4.0615],\n",
      "         [ -5.2948,  -5.1458,  -5.3452,  ...,  -5.4710,  -5.8985,  -2.3215],\n",
      "         [ -5.6246,  -5.5037,  -5.6060,  ...,  -5.7037,  -5.7184,  -3.1683]],\n",
      "\n",
      "        [[ -6.6939,  -6.6927,  -6.6951,  ...,  -5.9020,  -5.9208,  -4.0757],\n",
      "         [ -8.5163,  -8.1623,  -8.2998,  ...,  -8.2192,  -7.6851,  -6.5337],\n",
      "         [ -1.9865,  -2.1821,  -2.1507,  ...,  -2.6143,  -2.7604,  -2.4601],\n",
      "         ...,\n",
      "         [-10.4769, -10.5471, -10.1524,  ...,  -9.1392,  -7.8130,  -9.6124],\n",
      "         [ -8.2195,  -8.3855,  -7.7775,  ...,  -7.3573,  -7.4262, -10.9748],\n",
      "         [-13.0654, -12.6211, -12.7195,  ..., -11.4494, -10.9534,  -8.1532]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8513619899749756\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1764, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3899,  -6.3504,  -6.3843,  ...,  -5.7466,  -5.5228,  -3.8524],\n",
      "         [-16.0524, -15.4144, -15.5614,  ..., -13.4342, -12.9002, -11.1439],\n",
      "         [ -5.7301,  -5.8400,  -5.8249,  ...,  -5.8558,  -6.5536,  -4.8321],\n",
      "         ...,\n",
      "         [ -6.0623,  -6.2463,  -6.2220,  ...,  -6.2330,  -6.7891,  -4.7700],\n",
      "         [ -6.3970,  -6.4193,  -6.5234,  ...,  -6.4779,  -6.8764,  -5.3127],\n",
      "         [ -6.3739,  -6.3911,  -6.4160,  ...,  -6.3586,  -6.6441,  -5.0461]],\n",
      "\n",
      "        [[ -6.3830,  -6.3997,  -6.3811,  ...,  -5.8134,  -5.3774,  -4.3572],\n",
      "         [ -4.4236,  -4.8969,  -4.6033,  ...,  -6.1354,  -3.9892,  -7.7406],\n",
      "         [ -9.9946, -10.2095, -10.1855,  ..., -11.0119,  -8.2899,  -9.8206],\n",
      "         ...,\n",
      "         [ -9.4796,  -9.5522,  -9.1754,  ...,  -9.5932,  -5.6850, -10.5315],\n",
      "         [ -6.8534,  -7.1618,  -7.2468,  ...,  -7.6625,  -6.3745,  -7.5683],\n",
      "         [-14.2727, -14.3569, -14.3290,  ..., -12.7938, -11.9210, -10.6033]],\n",
      "\n",
      "        [[ -7.3350,  -7.3332,  -7.2822,  ...,  -6.5201,  -6.4019,  -4.2496],\n",
      "         [ -8.7316,  -8.3570,  -8.4055,  ...,  -5.7310,  -7.1374,  -9.0883],\n",
      "         [ -5.5848,  -5.6661,  -5.6994,  ...,  -5.8860,  -7.0625,  -2.7793],\n",
      "         ...,\n",
      "         [ -5.7114,  -5.8665,  -5.7471,  ...,  -6.1343,  -6.4112,  -3.3562],\n",
      "         [ -6.0212,  -6.0247,  -5.9480,  ...,  -6.0202,  -6.7309,  -3.4737],\n",
      "         [ -6.3093,  -6.4896,  -6.4018,  ...,  -6.7118,  -7.0152,  -3.1506]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7785,  -6.7857,  -6.7442,  ...,  -6.0190,  -5.9836,  -3.9591],\n",
      "         [ -2.8930,  -2.8367,  -2.7506,  ...,  -2.5644,  -3.0314,  -0.4886],\n",
      "         [-13.4391, -13.2792, -13.7264,  ..., -12.5264, -11.6407,  -2.2292],\n",
      "         ...,\n",
      "         [ -5.0020,  -5.0880,  -4.9619,  ...,  -5.3185,  -4.7912,  -2.0115],\n",
      "         [ -4.7266,  -4.8116,  -4.7221,  ...,  -5.0121,  -4.6064,  -2.3702],\n",
      "         [ -4.3452,  -4.4495,  -4.3980,  ...,  -4.9252,  -4.3571,  -1.6953]],\n",
      "\n",
      "        [[ -6.5371,  -6.5753,  -6.5717,  ...,  -5.7528,  -5.6173,  -3.8530],\n",
      "         [ -8.3285,  -8.6064,  -8.4175,  ...,  -7.4349,  -5.4662,  -6.6405],\n",
      "         [ -4.9089,  -5.1109,  -5.2885,  ...,  -5.1617,  -5.1984,  -9.7454],\n",
      "         ...,\n",
      "         [ -6.1687,  -6.1033,  -6.3361,  ...,  -6.3883,  -6.2565,  -6.1062],\n",
      "         [ -5.8029,  -5.7559,  -6.0315,  ...,  -6.3410,  -6.0058,  -6.9595],\n",
      "         [ -6.4692,  -6.4073,  -6.6192,  ...,  -6.5702,  -6.7869,  -6.3523]],\n",
      "\n",
      "        [[ -7.0465,  -7.0480,  -6.9926,  ...,  -6.3547,  -6.1287,  -4.3425],\n",
      "         [ -9.2194,  -9.5426,  -9.5522,  ...,  -7.8609,  -6.5052,  -7.7227],\n",
      "         [ -7.7398,  -8.0470,  -8.4067,  ...,  -6.8561,  -7.0548,  -8.5694],\n",
      "         ...,\n",
      "         [ -5.4392,  -5.5532,  -5.6706,  ...,  -6.0332,  -5.3406,  -4.4794],\n",
      "         [ -5.7865,  -5.9135,  -6.0264,  ...,  -5.8246,  -5.6351,  -4.3217],\n",
      "         [ -6.6044,  -6.5800,  -6.7198,  ...,  -6.9188,  -6.1795,  -4.6675]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.1764369010925293\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3824, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.8662,  -9.7588,  -9.9754,  ...,  -9.5899,  -9.7045,  -5.8326],\n",
      "         [-13.9641, -13.7280, -13.5843,  ..., -12.1792, -10.9342, -16.5589],\n",
      "         [ -5.6864,  -5.8256,  -5.8320,  ...,  -6.1343,  -6.5108,  -2.7257],\n",
      "         ...,\n",
      "         [ -6.2115,  -6.3387,  -6.2165,  ...,  -6.2119,  -6.8014,  -2.6886],\n",
      "         [ -6.8189,  -7.0395,  -6.9473,  ...,  -7.0635,  -7.5467,  -3.8305],\n",
      "         [ -6.0827,  -6.1788,  -6.1184,  ...,  -6.4425,  -6.9536,  -3.6685]],\n",
      "\n",
      "        [[ -6.6228,  -6.6069,  -6.6058,  ...,  -6.0013,  -6.0885,  -4.1021],\n",
      "         [-13.6816, -13.5303, -13.8859,  ..., -10.2271, -10.9416, -10.8838],\n",
      "         [ -5.4623,  -5.6159,  -5.5757,  ...,  -5.7957,  -6.7567,  -3.4156],\n",
      "         ...,\n",
      "         [ -5.1158,  -5.1443,  -5.1287,  ...,  -5.3409,  -6.3979,  -4.1419],\n",
      "         [ -5.2350,  -5.3835,  -5.3754,  ...,  -5.7149,  -6.8535,  -3.1061],\n",
      "         [ -5.7408,  -5.8082,  -5.8113,  ...,  -5.8664,  -6.3764,  -3.7400]],\n",
      "\n",
      "        [[ -6.4256,  -6.3696,  -6.3734,  ...,  -5.4892,  -5.6566,  -3.8222],\n",
      "         [ -8.2861,  -8.2622,  -8.5720,  ...,  -6.6984,  -7.5357,  -7.6354],\n",
      "         [ -5.7189,  -5.8120,  -5.8856,  ...,  -5.9508,  -6.5891,  -3.7643],\n",
      "         ...,\n",
      "         [ -5.6805,  -5.6135,  -5.7514,  ...,  -4.9505,  -6.6509,  -4.3336],\n",
      "         [ -5.4722,  -5.5138,  -5.5889,  ...,  -5.3183,  -6.7129,  -4.4379],\n",
      "         [ -5.8829,  -6.0480,  -5.9503,  ...,  -5.0898,  -6.5252,  -4.3826]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8959,  -6.8889,  -6.8484,  ...,  -6.1965,  -5.8191,  -4.1149],\n",
      "         [ -6.3889,  -6.8003,  -6.2045,  ...,  -6.4345,  -5.3735,  -4.6319],\n",
      "         [ -7.3262,  -7.3901,  -7.3416,  ...,  -6.6879,  -6.3213,  -6.2692],\n",
      "         ...,\n",
      "         [-11.4317, -11.6022, -10.7763,  ..., -12.0461, -11.4457,  -7.5211],\n",
      "         [-11.9298, -11.8423, -11.8618,  ..., -11.0522,  -9.8681,  -9.5433],\n",
      "         [-11.2576, -11.3077, -11.6521,  ...,  -9.4707,  -7.5499, -10.8019]],\n",
      "\n",
      "        [[ -6.7000,  -6.7443,  -6.6866,  ...,  -5.7944,  -5.7010,  -3.9855],\n",
      "         [ -8.1266,  -7.7437,  -7.9404,  ...,  -6.5725,  -6.4506,  -6.3254],\n",
      "         [ -5.3202,  -5.1198,  -5.3683,  ...,  -6.3230,  -6.0902,  -4.1448],\n",
      "         ...,\n",
      "         [ -7.7634,  -7.8551,  -7.9181,  ...,  -6.4112,  -6.1380,  -3.3715],\n",
      "         [ -7.7189,  -7.8983,  -7.7857,  ...,  -6.9031,  -6.9645,  -3.8486],\n",
      "         [ -8.5525,  -8.6150,  -8.5584,  ...,  -7.7922,  -8.2133,  -3.8032]],\n",
      "\n",
      "        [[ -6.4705,  -6.4337,  -6.4536,  ...,  -5.8343,  -5.6629,  -3.9019],\n",
      "         [-11.8827, -11.3525, -11.5078,  ...,  -8.5531,  -7.8619,  -9.0003],\n",
      "         [ -5.8954,  -5.9708,  -6.0482,  ...,  -6.2523,  -7.0978,  -3.7864],\n",
      "         ...,\n",
      "         [ -6.0848,  -6.1709,  -6.2067,  ...,  -6.1773,  -6.8148,  -3.8821],\n",
      "         [ -5.9122,  -5.8886,  -5.9231,  ...,  -6.1375,  -6.7120,  -4.1657],\n",
      "         [ -5.8475,  -5.8676,  -5.8903,  ...,  -5.9639,  -6.5204,  -3.9524]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.3824329376220703\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9517, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5901,  -6.5656,  -6.5912,  ...,  -5.9133,  -5.7326,  -3.8705],\n",
      "         [ -4.4719,  -4.3033,  -4.4664,  ...,  -5.2789,  -5.3879,  -2.3018],\n",
      "         [ -5.2099,  -5.0874,  -5.2140,  ...,  -5.9249,  -6.4573,  -1.1249],\n",
      "         ...,\n",
      "         [ -5.0072,  -4.9242,  -5.0952,  ...,  -5.4968,  -5.5758,  -2.0937],\n",
      "         [ -4.6079,  -4.4727,  -4.6086,  ...,  -5.0790,  -5.4893,  -1.5021],\n",
      "         [ -4.9812,  -4.9496,  -5.1437,  ...,  -5.8370,  -5.7425,  -2.1879]],\n",
      "\n",
      "        [[ -6.9726,  -7.0250,  -6.9699,  ...,  -6.1820,  -6.0827,  -4.4996],\n",
      "         [ -6.1577,  -6.6368,  -6.2485,  ...,  -6.8961,  -6.6391,  -4.9146],\n",
      "         [ -0.3539,  -0.9887,  -0.4915,  ...,  -0.6000,  -2.0683,  -1.1006],\n",
      "         ...,\n",
      "         [ -3.9457,  -4.0209,  -3.8539,  ...,  -3.5387,  -2.7341,  -5.0295],\n",
      "         [ -4.4217,  -4.5499,  -4.5541,  ...,  -3.7775,  -3.4526,  -5.9757],\n",
      "         [ -4.6448,  -4.7810,  -4.8186,  ...,  -4.3752,  -3.8250,  -4.8994]],\n",
      "\n",
      "        [[ -7.5975,  -7.6299,  -7.5402,  ...,  -6.5883,  -6.4397,  -3.9736],\n",
      "         [ -9.0815,  -9.1222,  -9.1394,  ...,  -8.5422,  -7.4228,  -5.9231],\n",
      "         [-13.7815, -14.0970, -13.6227,  ..., -12.6171,  -8.7904,  -9.6634],\n",
      "         ...,\n",
      "         [ -7.2852,  -7.6266,  -7.0706,  ...,  -6.2287,  -5.8074,  -4.6449],\n",
      "         [ -6.6203,  -6.8323,  -6.5011,  ...,  -5.1940,  -4.5215,  -6.0177],\n",
      "         [ -7.0816,  -7.2245,  -6.9865,  ...,  -5.4433,  -4.7491,  -5.9382]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7127,  -6.7129,  -6.6426,  ...,  -6.1875,  -5.7148,  -3.7972],\n",
      "         [-10.1302, -10.6803, -10.0499,  ...,  -9.5434, -10.7782, -10.2300],\n",
      "         [-15.1513, -15.2934, -15.0464,  ..., -13.7697, -11.6082, -12.3144],\n",
      "         ...,\n",
      "         [-10.8630, -11.0268, -10.2652,  ...,  -9.4734,  -8.0257,  -8.0044],\n",
      "         [-12.4482, -12.3181, -12.1022,  ..., -10.2976,  -7.2747,  -9.2050],\n",
      "         [-12.2076, -11.7498, -11.9555,  ...,  -8.0574,  -8.9998, -11.1906]],\n",
      "\n",
      "        [[ -7.2163,  -7.2265,  -7.1752,  ...,  -6.2789,  -6.1478,  -3.8786],\n",
      "         [ -8.0020,  -8.3867,  -7.6920,  ...,  -7.7544,  -5.6785,  -3.0369],\n",
      "         [-11.2488, -11.3632, -11.3625,  ..., -12.6680,  -9.6806,  -8.1856],\n",
      "         ...,\n",
      "         [ -5.8721,  -5.8078,  -5.5915,  ...,  -4.8157,  -7.0513,   1.3949],\n",
      "         [-14.0184, -13.5084, -13.3371,  ..., -11.9846, -11.9442,  -6.4195],\n",
      "         [-12.6220, -12.6072, -12.9351,  ..., -11.5597, -10.1943, -10.2198]],\n",
      "\n",
      "        [[ -6.4254,  -6.3886,  -6.4055,  ...,  -5.7761,  -5.5498,  -3.8296],\n",
      "         [-12.9688, -12.5030, -12.3142,  ...,  -9.0287, -10.5467,  -9.6886],\n",
      "         [ -6.2051,  -6.2368,  -6.2225,  ...,  -6.2513,  -6.6395,  -4.5856],\n",
      "         ...,\n",
      "         [ -6.3483,  -6.3472,  -6.3694,  ...,  -6.4758,  -6.6246,  -4.4282],\n",
      "         [ -6.1653,  -6.1759,  -6.1837,  ...,  -6.6542,  -6.6351,  -4.9147],\n",
      "         [ -6.1075,  -6.1154,  -6.1335,  ...,  -5.9759,  -6.3679,  -4.7724]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.951663613319397\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8129, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5686,  -6.5699,  -6.5717,  ...,  -5.8753,  -5.5405,  -4.1291],\n",
      "         [ -4.5686,  -4.5181,  -4.9463,  ...,  -4.5711,  -6.0969,  -2.5580],\n",
      "         [ -9.0529,  -9.5911,  -9.5120,  ...,  -9.3322,  -8.0867, -11.1911],\n",
      "         ...,\n",
      "         [ -3.2358,  -3.6668,  -3.4962,  ...,  -3.7184,  -4.6911,  -4.2963],\n",
      "         [ -2.9466,  -3.5401,  -3.2230,  ...,  -3.6258,  -4.6945,  -5.0986],\n",
      "         [ -6.3656,  -6.5571,  -6.5628,  ...,  -6.3688,  -6.5013,  -5.5854]],\n",
      "\n",
      "        [[ -6.5494,  -6.5019,  -6.5105,  ...,  -5.9996,  -5.5970,  -3.9393],\n",
      "         [-12.0548, -12.0309, -12.4955,  ..., -12.4352, -11.3910, -10.0009],\n",
      "         [-11.4058, -11.9036, -11.4644,  ..., -10.7335,  -8.1110, -10.0255],\n",
      "         ...,\n",
      "         [ -4.6129,  -4.7921,  -4.9870,  ...,  -4.9393,  -4.9624,  -4.5182],\n",
      "         [ -3.5379,  -3.5617,  -3.8390,  ...,  -4.4663,  -4.6585,  -3.9232],\n",
      "         [ -5.5051,  -5.6226,  -5.8255,  ...,  -5.5515,  -5.8282,  -4.8157]],\n",
      "\n",
      "        [[ -6.3811,  -6.3355,  -6.3627,  ...,  -5.6671,  -5.5805,  -3.7549],\n",
      "         [-11.9990, -12.0452, -12.0634,  ...,  -9.0828,  -9.9141,  -7.6018],\n",
      "         [ -5.2439,  -5.2678,  -5.2646,  ...,  -5.6130,  -6.6563,  -3.8732],\n",
      "         ...,\n",
      "         [ -6.3616,  -6.5618,  -6.5173,  ...,  -5.8369,  -7.4519,  -4.4042],\n",
      "         [ -5.1111,  -5.1704,  -5.1529,  ...,  -5.4421,  -6.6264,  -4.5616],\n",
      "         [ -5.8072,  -5.8764,  -5.9020,  ...,  -5.7454,  -6.8049,  -4.6619]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5069,  -6.5070,  -6.4692,  ...,  -5.8817,  -5.6872,  -3.9117],\n",
      "         [ -9.4068,  -9.6903,  -9.4321,  ...,  -8.0823,  -7.9497,  -8.7626],\n",
      "         [-14.2670, -14.7934, -14.3692,  ..., -12.4547, -11.6321, -15.0661],\n",
      "         ...,\n",
      "         [ -5.8641,  -5.8098,  -5.9288,  ...,  -6.4278,  -6.2903,  -5.3073],\n",
      "         [ -5.4768,  -5.4631,  -5.5473,  ...,  -5.3149,  -6.0804,  -5.3014],\n",
      "         [ -6.0969,  -5.9512,  -6.0968,  ...,  -6.2041,  -6.4339,  -4.9547]],\n",
      "\n",
      "        [[ -9.9381,  -9.7603,  -9.7583,  ...,  -8.4991,  -8.5865,  -4.0804],\n",
      "         [-11.3187, -11.5137, -11.2776,  ...,  -9.2147,  -9.3432,  -8.8804],\n",
      "         [ -4.5910,  -4.7944,  -4.8782,  ...,  -5.4822,  -6.6824,  -2.1381],\n",
      "         ...,\n",
      "         [ -4.7546,  -4.9161,  -4.8220,  ...,  -4.8616,  -6.1528,  -4.0814],\n",
      "         [ -4.8498,  -5.0906,  -4.9535,  ...,  -4.9834,  -6.3050,  -4.4423],\n",
      "         [ -5.6431,  -5.8794,  -5.8548,  ...,  -5.8802,  -7.3071,  -3.3154]],\n",
      "\n",
      "        [[ -6.7340,  -6.6884,  -6.6856,  ...,  -6.0315,  -5.9745,  -4.0474],\n",
      "         [-10.7138, -10.8995, -10.8944,  ...,  -9.3242,  -8.7524,  -9.7393],\n",
      "         [-11.4247, -11.6858, -11.6242,  ..., -10.2266,  -8.7979,  -8.0680],\n",
      "         ...,\n",
      "         [ -7.3162,  -7.3876,  -7.3160,  ...,  -7.5070,  -6.9830,  -5.2271],\n",
      "         [ -7.6198,  -7.8018,  -7.6738,  ...,  -7.5007,  -7.0748,  -5.8574],\n",
      "         [ -7.1100,  -7.1855,  -7.1728,  ...,  -6.9274,  -6.8002,  -5.7295]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8128854036331177\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7071, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9242,  -6.9673,  -6.9086,  ...,  -6.4046,  -6.0064,  -4.7360],\n",
      "         [ -3.3532,  -3.5148,  -3.4801,  ...,  -3.6488,  -5.5447,  -1.2089],\n",
      "         [ -8.5501,  -8.8091,  -8.6953,  ...,  -8.3994,  -7.3262,  -6.3179],\n",
      "         ...,\n",
      "         [ -8.9084,  -9.1958,  -9.0757,  ...,  -9.9975,  -8.7356,  -8.7417],\n",
      "         [ -5.2904,  -5.8650,  -5.8085,  ...,  -5.8678,  -6.3181,  -7.0592],\n",
      "         [-13.0258, -13.4043, -13.0194,  ..., -11.2985, -12.9914, -12.1501]],\n",
      "\n",
      "        [[ -6.8310,  -6.7873,  -6.7234,  ...,  -6.4316,  -6.1118,  -3.7915],\n",
      "         [ -2.7284,  -2.8217,  -2.5354,  ...,  -2.7705,  -2.3415,  -3.8777],\n",
      "         [-11.8963, -12.2104, -11.9805,  ..., -11.6893,  -8.7231, -10.4509],\n",
      "         ...,\n",
      "         [ -5.8338,  -6.0094,  -5.6347,  ...,  -5.5265,  -4.8639,  -4.1836],\n",
      "         [ -6.7719,  -6.9507,  -6.7447,  ...,  -6.6507,  -5.7285,  -5.3592],\n",
      "         [ -5.3195,  -5.6122,  -5.4012,  ...,  -5.5846,  -4.6554,  -4.4949]],\n",
      "\n",
      "        [[ -7.0558,  -7.0732,  -7.0547,  ...,  -6.4574,  -6.3706,  -4.4140],\n",
      "         [ -9.0948,  -9.4880,  -8.9972,  ..., -10.4931,  -7.3384,  -8.2585],\n",
      "         [-10.0787, -10.8679, -10.1281,  ..., -10.8754,  -8.9638,  -8.0307],\n",
      "         ...,\n",
      "         [ -8.9775,  -9.3348,  -8.8771,  ...,  -8.4014,  -7.9041,  -2.9014],\n",
      "         [ -4.0995,  -4.6846,  -4.2310,  ...,  -5.2407,  -7.2394,  -3.9418],\n",
      "         [-13.1960, -13.0430, -13.5735,  ..., -11.3598, -11.9375,  -7.2116]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2431,  -6.2038,  -6.2522,  ...,  -5.3776,  -5.4319,  -3.6327],\n",
      "         [-10.2003,  -9.6421,  -9.8107,  ...,  -6.1752,  -7.7509,  -9.2216],\n",
      "         [ -5.4600,  -5.6098,  -5.6290,  ...,  -5.4487,  -6.8618,  -3.9359],\n",
      "         ...,\n",
      "         [ -5.7746,  -5.8403,  -5.8620,  ...,  -5.8602,  -6.5685,  -4.5562],\n",
      "         [ -6.0320,  -6.1714,  -6.1299,  ...,  -6.5468,  -6.8006,  -4.9144],\n",
      "         [ -5.8560,  -5.8847,  -5.9537,  ...,  -5.6147,  -6.5607,  -3.8893]],\n",
      "\n",
      "        [[ -8.6534,  -8.6017,  -8.6486,  ...,  -7.3004,  -7.1672,  -4.8397],\n",
      "         [-10.4217, -10.1925, -10.2503,  ...,  -7.3891,  -7.9015, -11.0635],\n",
      "         [ -5.2163,  -5.3996,  -5.4520,  ...,  -5.6340,  -7.1330,  -3.4301],\n",
      "         ...,\n",
      "         [ -5.3063,  -5.3770,  -5.4270,  ...,  -5.7095,  -6.5354,  -3.7272],\n",
      "         [ -5.3104,  -5.5179,  -5.4107,  ...,  -5.4796,  -6.3099,  -4.4461],\n",
      "         [ -6.0516,  -6.1447,  -6.0589,  ...,  -5.9281,  -6.5861,  -4.0121]],\n",
      "\n",
      "        [[ -7.1375,  -7.1875,  -7.2131,  ...,  -6.5435,  -6.4771,  -4.1957],\n",
      "         [-15.1093, -15.4065, -15.0314,  ..., -12.2291, -12.5606, -12.1753],\n",
      "         [ -9.5955, -10.0306,  -9.6310,  ...,  -8.7714,  -7.5812, -13.2512],\n",
      "         ...,\n",
      "         [ -6.3807,  -6.9370,  -6.6856,  ...,  -5.9781,  -4.6958,  -6.3588],\n",
      "         [ -9.8482, -10.0634,  -9.9289,  ...,  -9.5247,  -6.4087,  -3.2957],\n",
      "         [-11.6850, -11.7167, -11.4178,  ..., -11.4360,  -9.2449,  -9.7082]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.7071362733840942\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8842, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.9115,  -7.8657,  -7.9240,  ...,  -7.1338,  -7.0753,  -4.5176],\n",
      "         [-12.3461, -12.1435, -12.5293,  ..., -10.1104,  -9.2977, -10.0232],\n",
      "         [ -5.3575,  -5.5560,  -5.4919,  ...,  -5.6018,  -6.6819,  -2.4477],\n",
      "         ...,\n",
      "         [ -5.6721,  -5.6394,  -5.6391,  ...,  -5.7430,  -6.4188,  -2.9273],\n",
      "         [ -5.7953,  -5.8262,  -5.8320,  ...,  -5.7537,  -6.8361,  -3.1349],\n",
      "         [ -6.1188,  -6.1295,  -6.1188,  ...,  -5.9890,  -6.5186,  -3.8630]],\n",
      "\n",
      "        [[ -6.3509,  -6.3187,  -6.3236,  ...,  -5.7866,  -5.4286,  -3.7548],\n",
      "         [-10.2090, -10.2308,  -9.9627,  ...,  -7.5386,  -8.1009,  -5.7522],\n",
      "         [ -5.0942,  -5.1598,  -5.1770,  ...,  -5.2463,  -6.4292,  -3.3219],\n",
      "         ...,\n",
      "         [ -5.5469,  -5.6521,  -5.5642,  ...,  -5.4389,  -6.2470,  -3.7589],\n",
      "         [ -5.5837,  -5.6685,  -5.6317,  ...,  -5.3287,  -6.3493,  -4.1594],\n",
      "         [ -5.8509,  -5.9081,  -5.8869,  ...,  -5.5700,  -6.3220,  -3.4769]],\n",
      "\n",
      "        [[ -6.2842,  -6.2726,  -6.2823,  ...,  -5.5452,  -5.5473,  -3.6765],\n",
      "         [ -7.8673,  -7.9979,  -7.7225,  ...,  -8.6866,  -8.4480,  -1.1411],\n",
      "         [ -5.3086,  -5.3232,  -5.2948,  ...,  -5.8767,  -6.2268,  -1.0919],\n",
      "         ...,\n",
      "         [ -5.2262,  -5.2372,  -5.2885,  ...,  -5.4303,  -5.5606,  -1.8186],\n",
      "         [ -5.3320,  -5.2659,  -5.3155,  ...,  -5.8219,  -5.4107,  -1.5870],\n",
      "         [ -5.8554,  -5.8092,  -5.9688,  ...,  -6.3684,  -6.0081,  -1.5887]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.8688,  -9.1195,  -8.9707,  ...,  -8.6496,  -8.8478,  -4.7695],\n",
      "         [-11.9877, -11.6581, -11.6140,  ...,  -8.6541,  -9.4644, -10.7822],\n",
      "         [ -5.6077,  -5.5046,  -5.5928,  ...,  -5.9055,  -6.6710,  -4.6471],\n",
      "         ...,\n",
      "         [ -5.4943,  -5.5159,  -5.5566,  ...,  -5.6580,  -7.0998,  -4.3988],\n",
      "         [ -6.0733,  -6.0263,  -6.1161,  ...,  -6.0792,  -6.9097,  -4.3350],\n",
      "         [ -5.6118,  -5.7741,  -5.6955,  ...,  -5.6852,  -6.6495,  -5.0378]],\n",
      "\n",
      "        [[ -7.5992,  -7.7243,  -7.5982,  ...,  -6.7631,  -6.4527,  -4.9777],\n",
      "         [ -5.5634,  -5.9949,  -5.6152,  ...,  -4.0717,  -4.7725,  -9.7797],\n",
      "         [ -6.3209,  -6.6265,  -6.6820,  ...,  -4.0617,  -4.9171,  -5.5096],\n",
      "         ...,\n",
      "         [ -4.3143,  -4.4793,  -4.3328,  ...,  -3.6516,  -4.4006,  -3.6933],\n",
      "         [ -4.5688,  -4.8880,  -4.8048,  ...,  -4.2413,  -5.2562,  -4.2550],\n",
      "         [ -5.0068,  -5.2700,  -5.1103,  ...,  -4.8136,  -5.1303,  -4.4290]],\n",
      "\n",
      "        [[ -7.1223,  -7.1048,  -7.0846,  ...,  -6.5216,  -6.3618,  -5.1296],\n",
      "         [-10.7130, -10.8461, -10.6509,  ...,  -9.1870,  -9.2983,  -9.7282],\n",
      "         [ -2.1751,  -2.0814,  -2.2702,  ...,  -0.4365,  -2.7348,  -3.6772],\n",
      "         ...,\n",
      "         [ -4.2322,  -4.7855,  -4.4279,  ...,  -4.8106,  -2.6311,  -1.6689],\n",
      "         [ -4.3278,  -4.5324,  -4.4708,  ...,  -4.9095,  -2.8842,  -4.7031],\n",
      "         [ -5.7406,  -5.9798,  -5.8324,  ...,  -6.0194,  -5.4565,  -4.9360]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8841538429260254\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2164, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5354,  -6.5413,  -6.5345,  ...,  -5.9521,  -5.7442,  -4.0749],\n",
      "         [-11.1815, -10.9240, -11.0117,  ...,  -8.5887,  -7.6942,  -9.6311],\n",
      "         [ -5.1963,  -5.3514,  -5.3332,  ...,  -5.2599,  -5.3284,  -3.5878],\n",
      "         ...,\n",
      "         [ -4.5084,  -4.6390,  -4.6909,  ...,  -4.8089,  -4.8899,  -3.4228],\n",
      "         [ -5.3146,  -5.4412,  -5.4162,  ...,  -5.5484,  -5.6151,  -3.4291],\n",
      "         [ -4.7844,  -4.8623,  -4.9390,  ...,  -5.2917,  -4.9149,  -4.0373]],\n",
      "\n",
      "        [[ -6.5357,  -6.5021,  -6.5219,  ...,  -5.9569,  -5.7624,  -3.9030],\n",
      "         [ -5.4057,  -5.4208,  -5.3771,  ...,  -5.5880,  -6.1638,  -1.8976],\n",
      "         [ -4.8853,  -4.9725,  -4.7187,  ...,  -5.0975,  -5.3544,  -0.6626],\n",
      "         ...,\n",
      "         [ -5.8228,  -5.7503,  -5.6900,  ...,  -6.2263,  -5.7784,  -2.3580],\n",
      "         [ -5.9524,  -5.8140,  -5.8146,  ...,  -6.1170,  -6.3794,  -2.1278],\n",
      "         [ -5.6012,  -5.5325,  -5.5280,  ...,  -5.8499,  -5.8710,  -1.5004]],\n",
      "\n",
      "        [[ -6.6700,  -6.6526,  -6.6462,  ...,  -6.0340,  -5.8005,  -4.0447],\n",
      "         [ -5.5588,  -5.5418,  -5.2428,  ...,  -4.7866,  -4.4442,  -5.1919],\n",
      "         [ -6.5930,  -6.5590,  -6.6069,  ...,  -5.2734,  -4.3390,  -7.0121],\n",
      "         ...,\n",
      "         [ -5.8942,  -5.8987,  -5.9386,  ...,  -5.9069,  -5.4102,  -5.8742],\n",
      "         [ -6.8260,  -6.9689,  -6.9513,  ...,  -7.0740,  -5.6305,  -6.7955],\n",
      "         [ -7.5367,  -7.6814,  -7.5322,  ...,  -7.7035,  -5.7201,  -5.6075]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5422,  -6.5053,  -6.5228,  ...,  -5.7104,  -5.6075,  -3.7734],\n",
      "         [ -7.2396,  -7.0580,  -7.3786,  ...,  -6.7245,  -6.9478,  -3.4145],\n",
      "         [ -4.1936,  -4.1186,  -4.1455,  ...,  -3.8184,  -4.1321,  -1.8897],\n",
      "         ...,\n",
      "         [ -3.9700,  -3.8004,  -3.9038,  ...,  -3.7933,  -4.4031,  -2.6813],\n",
      "         [ -4.0155,  -4.0336,  -4.0520,  ...,  -3.9315,  -4.7791,  -2.4907],\n",
      "         [ -4.1061,  -4.0194,  -4.1720,  ...,  -4.1034,  -4.7817,  -2.6994]],\n",
      "\n",
      "        [[ -6.5751,  -6.6183,  -6.5677,  ...,  -6.1220,  -5.4576,  -3.7955],\n",
      "         [ -9.9346,  -9.6658,  -9.4516,  ..., -10.2916,  -9.2654,  -3.9395],\n",
      "         [-12.1918, -12.2259, -11.9068,  ..., -12.6095, -10.1360,  -7.6322],\n",
      "         ...,\n",
      "         [ -7.9502,  -7.8773,  -7.8647,  ...,  -6.0117,  -5.3287,  -4.3128],\n",
      "         [ -2.9667,  -2.9636,  -2.8411,  ...,  -1.8654,  -1.6768,  -1.0245],\n",
      "         [-13.0098, -13.2980, -13.2249,  ..., -11.7197, -11.5123, -10.7565]],\n",
      "\n",
      "        [[ -4.4530,  -4.7510,  -4.5649,  ...,  -5.4972,  -4.1804,  -3.7389],\n",
      "         [-14.7060, -14.3226, -14.2515,  ..., -12.1509, -12.4145, -13.5721],\n",
      "         [ -5.7245,  -5.8155,  -5.8006,  ...,  -6.1694,  -6.3171,  -3.8339],\n",
      "         ...,\n",
      "         [ -5.5945,  -5.6500,  -5.6804,  ...,  -5.5151,  -5.7580,  -3.5793],\n",
      "         [ -5.9429,  -5.9995,  -6.0942,  ...,  -6.1377,  -6.5695,  -3.8936],\n",
      "         [ -5.0680,  -5.1073,  -5.2117,  ...,  -4.8153,  -5.0526,  -2.9074]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.216439962387085\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.8686, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3622,  -6.3168,  -6.3447,  ...,  -5.6191,  -5.5710,  -3.6653],\n",
      "         [ -6.5980,  -6.7142,  -6.8591,  ...,  -7.0592,  -7.7884,  -2.7892],\n",
      "         [ -8.5050,  -8.8229,  -8.7047,  ...,  -7.8600,  -8.3031,  -4.9727],\n",
      "         ...,\n",
      "         [ -5.0858,  -5.0088,  -5.1104,  ...,  -5.1309,  -5.6816,  -1.7799],\n",
      "         [ -5.5254,  -5.3905,  -5.4853,  ...,  -5.2144,  -5.9859,  -2.3748],\n",
      "         [ -5.4569,  -5.3826,  -5.5238,  ...,  -6.0132,  -6.2190,  -2.2453]],\n",
      "\n",
      "        [[ -6.9981,  -6.9691,  -6.9856,  ...,  -6.0242,  -6.0432,  -4.2505],\n",
      "         [-11.0265, -10.7558, -10.6535,  ...,  -8.5710,  -9.9332,  -8.4094],\n",
      "         [ -5.1680,  -5.3193,  -5.3776,  ...,  -5.5557,  -6.9870,  -4.1915],\n",
      "         ...,\n",
      "         [ -5.4402,  -5.6092,  -5.5702,  ...,  -5.6314,  -6.9856,  -4.8517],\n",
      "         [ -4.9076,  -5.0949,  -5.1384,  ...,  -5.0264,  -6.5539,  -3.5847],\n",
      "         [ -5.0561,  -5.1047,  -5.1556,  ...,  -5.3395,  -6.1663,  -3.1243]],\n",
      "\n",
      "        [[ -6.3364,  -6.2593,  -6.2757,  ...,  -5.7593,  -5.3959,  -3.8957],\n",
      "         [-11.8720, -11.2629, -11.5239,  ...,  -8.9886,  -8.7557, -10.6918],\n",
      "         [ -6.0960,  -6.0933,  -6.1588,  ...,  -6.1926,  -6.7612,  -4.4574],\n",
      "         ...,\n",
      "         [ -5.7554,  -5.7725,  -5.7831,  ...,  -5.8271,  -6.2663,  -4.1640],\n",
      "         [ -6.3985,  -6.3866,  -6.3932,  ...,  -6.3948,  -6.7558,  -4.6100],\n",
      "         [ -6.4749,  -6.5790,  -6.6374,  ...,  -6.3244,  -6.9740,  -4.2662]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6049,  -6.5997,  -6.5754,  ...,  -5.8314,  -5.7647,  -3.9988],\n",
      "         [-10.9766, -10.9411, -10.7327,  ...,  -8.4007,  -8.8711,  -6.8799],\n",
      "         [ -5.4480,  -5.5652,  -5.4838,  ...,  -5.2727,  -6.7991,  -3.6139],\n",
      "         ...,\n",
      "         [ -4.9444,  -5.1372,  -5.0111,  ...,  -4.6660,  -6.5773,  -3.4928],\n",
      "         [ -5.6994,  -5.8408,  -5.7501,  ...,  -6.0462,  -6.7295,  -3.5967],\n",
      "         [ -6.1369,  -6.3168,  -6.1733,  ...,  -5.7857,  -6.8702,  -3.6290]],\n",
      "\n",
      "        [[ -6.5399,  -6.5132,  -6.5594,  ...,  -5.6814,  -5.7159,  -3.6543],\n",
      "         [ -7.8108,  -7.8345,  -7.9663,  ...,  -8.5441,  -8.2306,  -1.7904],\n",
      "         [ -8.0895,  -8.2422,  -8.2098,  ...,  -7.2916,  -6.8974,  -1.1285],\n",
      "         ...,\n",
      "         [ -5.5750,  -5.4558,  -5.5971,  ...,  -5.6093,  -6.1928,  -1.6301],\n",
      "         [ -5.3751,  -5.2462,  -5.2976,  ...,  -5.5695,  -5.8547,  -1.3911],\n",
      "         [ -5.7053,  -5.5901,  -5.6569,  ...,  -5.5967,  -6.1233,  -1.9514]],\n",
      "\n",
      "        [[ -6.5424,  -6.5892,  -6.5474,  ...,  -5.8896,  -5.6992,  -4.1397],\n",
      "         [ -8.1112,  -8.3887,  -8.2092,  ...,  -7.4053,  -6.4018,  -6.1856],\n",
      "         [-10.9678, -10.9801, -10.8853,  ...,  -8.9656,  -8.3872,  -8.5575],\n",
      "         ...,\n",
      "         [ -7.0662,  -7.1835,  -7.0167,  ...,  -7.4750,  -5.5416,  -7.6763],\n",
      "         [ -6.4644,  -6.5386,  -6.3469,  ...,  -6.3536,  -4.9549,  -7.4750],\n",
      "         [ -6.6945,  -6.7550,  -6.6615,  ...,  -6.7857,  -5.0536,  -7.2678]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 3.8685543537139893\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7665, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.9237,  -9.4512,  -8.9749,  ...,  -8.4462,  -9.5038,  -5.2138],\n",
      "         [-11.0392, -10.7720, -10.7887,  ...,  -9.0018, -10.0140,  -8.8619],\n",
      "         [ -5.6474,  -5.6962,  -5.7282,  ...,  -6.2456,  -7.0232,  -3.4700],\n",
      "         ...,\n",
      "         [ -6.4915,  -6.5921,  -6.5362,  ...,  -6.8462,  -7.5971,  -3.2830],\n",
      "         [ -6.2895,  -6.4016,  -6.3093,  ...,  -6.3929,  -7.1112,  -3.8526],\n",
      "         [ -5.8070,  -5.8886,  -5.8655,  ...,  -6.0165,  -7.0322,  -2.8190]],\n",
      "\n",
      "        [[ -7.6018,  -7.5356,  -7.5277,  ...,  -6.9189,  -6.2976,  -4.2808],\n",
      "         [-15.1138, -15.2809, -15.4119,  ..., -15.4821, -13.0572, -13.3688],\n",
      "         [-10.1051, -10.3736, -10.1709,  ..., -10.3438,  -8.9914,  -8.8383],\n",
      "         ...,\n",
      "         [ -2.0814,  -2.0683,  -2.1534,  ...,  -0.4527,  -3.3016,  -1.2944],\n",
      "         [-10.7886, -10.7190, -10.5954,  ...,  -8.4901, -10.5959,  -8.5459],\n",
      "         [-11.2075, -10.5025, -11.0449,  ...,  -7.6032,  -8.4357,  -7.4003]],\n",
      "\n",
      "        [[ -7.0021,  -7.0114,  -6.9915,  ...,  -6.3380,  -5.9111,  -4.8649],\n",
      "         [-12.6910, -12.8600, -12.8456,  ..., -11.4610, -10.7707, -15.2825],\n",
      "         [ -6.7923,  -6.9670,  -6.9957,  ...,  -6.5091,  -6.3360,  -7.4595],\n",
      "         ...,\n",
      "         [ -6.8908,  -6.8552,  -6.6546,  ...,  -6.9409,  -6.4373,  -6.5158],\n",
      "         [ -5.2872,  -5.2014,  -5.1650,  ...,  -5.3711,  -4.7260,  -3.7908],\n",
      "         [ -6.6076,  -6.8433,  -6.6007,  ...,  -7.3132,  -6.8516,  -5.7176]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9633,  -6.9867,  -6.9015,  ...,  -6.6350,  -5.8255,  -4.8635],\n",
      "         [ -8.2674,  -8.3801,  -8.4137,  ...,  -8.3079,  -6.2207,  -6.6627],\n",
      "         [ -4.9683,  -5.3279,  -5.0974,  ...,  -4.6532,  -3.7688,  -5.7320],\n",
      "         ...,\n",
      "         [ -6.9808,  -7.2010,  -7.0741,  ...,  -6.8291,  -5.1050,  -5.5633],\n",
      "         [ -6.6658,  -6.8774,  -6.8042,  ...,  -6.7973,  -4.9771,  -5.1278],\n",
      "         [ -7.5036,  -7.6607,  -7.5998,  ...,  -7.7096,  -5.9947,  -5.3902]],\n",
      "\n",
      "        [[-12.2724, -12.2117, -11.7293,  ..., -10.1503, -12.7491,  -9.7840],\n",
      "         [-13.0467, -13.0996, -13.3518,  ...,  -9.6353,  -9.7712, -12.6959],\n",
      "         [ -4.9572,  -5.2206,  -5.1719,  ...,  -5.5279,  -7.4221,  -2.5577],\n",
      "         ...,\n",
      "         [ -5.5099,  -5.5038,  -5.4067,  ...,  -5.3133,  -6.3036,  -4.0877],\n",
      "         [ -4.3279,  -4.5405,  -4.5283,  ...,  -5.2166,  -6.3594,  -2.8821],\n",
      "         [ -5.4116,  -5.6414,  -5.5555,  ...,  -5.2277,  -6.6540,  -4.7244]],\n",
      "\n",
      "        [[ -6.8471,  -6.8765,  -6.9437,  ...,  -5.9686,  -5.9855,  -3.7823],\n",
      "         [ -9.2696,  -9.1359,  -9.0899,  ...,  -6.5280,  -8.8964,  -6.0222],\n",
      "         [ -5.6304,  -5.7588,  -5.7104,  ...,  -5.4354,  -6.8694,  -3.5803],\n",
      "         ...,\n",
      "         [ -5.6514,  -5.7894,  -5.7629,  ...,  -5.7695,  -6.3725,  -4.1963],\n",
      "         [ -5.5368,  -5.6617,  -5.6244,  ...,  -5.1151,  -6.1271,  -3.7754],\n",
      "         [ -5.4502,  -5.6529,  -5.6146,  ...,  -5.1426,  -6.5227,  -3.6671]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.7664684057235718\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4742, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4126,  -6.3770,  -6.3950,  ...,  -5.7660,  -5.4678,  -3.7978],\n",
      "         [-13.1886, -13.1967, -13.1589,  ..., -10.2040,  -9.2463, -11.5200],\n",
      "         [ -5.3215,  -5.3510,  -5.4289,  ...,  -5.7118,  -6.8555,  -3.8316],\n",
      "         ...,\n",
      "         [ -6.1911,  -6.2472,  -6.2612,  ...,  -6.2033,  -6.7319,  -4.9497],\n",
      "         [ -5.8374,  -5.9316,  -5.9967,  ...,  -5.6858,  -6.8653,  -3.9942],\n",
      "         [ -6.0892,  -6.1532,  -6.1630,  ...,  -6.3289,  -6.4766,  -4.1864]],\n",
      "\n",
      "        [[ -6.5314,  -6.5945,  -6.5361,  ...,  -5.9713,  -5.8846,  -4.1877],\n",
      "         [ -7.4690,  -7.8780,  -7.8046,  ...,  -8.6485,  -7.5208,  -7.2464],\n",
      "         [ -8.6709,  -8.7304,  -8.4211,  ..., -10.1552,  -5.6888,  -8.2008],\n",
      "         ...,\n",
      "         [ -5.5555,  -5.8221,  -5.7424,  ...,  -6.0163,  -7.2098,  -4.1426],\n",
      "         [ -4.6722,  -4.8461,  -4.5672,  ...,  -4.8006,  -5.1253,  -3.1083],\n",
      "         [-10.0267,  -9.6036, -10.3345,  ...,  -7.5807,  -8.2193,  -6.8150]],\n",
      "\n",
      "        [[ -7.1687,  -7.1693,  -7.1070,  ...,  -6.1530,  -6.2576,  -4.7934],\n",
      "         [ -6.8903,  -6.7735,  -6.8608,  ...,  -7.1792,  -5.8731,  -5.7694],\n",
      "         [ -7.9868,  -8.1022,  -7.7376,  ...,  -8.0915,  -6.2408,  -6.8298],\n",
      "         ...,\n",
      "         [ -5.8650,  -6.0223,  -5.9747,  ...,  -5.0419,  -5.3390,  -5.9976],\n",
      "         [ -6.6661,  -6.7237,  -6.6204,  ...,  -6.3263,  -6.4406,  -5.9961],\n",
      "         [ -7.0542,  -7.3410,  -7.1874,  ...,  -6.8555,  -6.7514,  -5.5011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3982,  -6.3586,  -6.3566,  ...,  -5.6865,  -5.4486,  -3.8674],\n",
      "         [-13.9515, -13.9707, -14.0421,  ..., -10.9503, -11.7648, -10.1672],\n",
      "         [ -5.3725,  -5.5172,  -5.5306,  ...,  -5.6030,  -7.2320,  -3.4993],\n",
      "         ...,\n",
      "         [ -5.8034,  -5.8633,  -5.7856,  ...,  -5.5195,  -6.8391,  -4.2582],\n",
      "         [ -5.1452,  -5.2076,  -5.0849,  ...,  -4.7869,  -6.5128,  -3.8753],\n",
      "         [ -5.9861,  -6.1369,  -5.9749,  ...,  -5.9557,  -6.8875,  -4.3662]],\n",
      "\n",
      "        [[ -6.4507,  -6.4401,  -6.4807,  ...,  -5.7074,  -5.6623,  -3.7368],\n",
      "         [ -8.2505,  -7.9294,  -8.0683,  ...,  -6.1710,  -7.3695,  -8.4405],\n",
      "         [ -4.9432,  -5.0484,  -5.2147,  ...,  -5.4064,  -6.4382,  -2.7330],\n",
      "         ...,\n",
      "         [ -5.7382,  -5.9453,  -5.8097,  ...,  -5.4188,  -6.4136,  -4.4464],\n",
      "         [ -5.0736,  -5.1589,  -5.1698,  ...,  -5.0792,  -5.9762,  -4.1714],\n",
      "         [ -5.2237,  -5.3072,  -5.2321,  ...,  -5.4825,  -6.1729,  -3.4982]],\n",
      "\n",
      "        [[ -6.3784,  -6.3679,  -6.3879,  ...,  -5.6558,  -5.5810,  -3.6284],\n",
      "         [ -8.6223,  -8.9054,  -8.4166,  ...,  -7.3962, -10.2292,  -4.0838],\n",
      "         [ -3.4883,  -3.9546,  -3.6062,  ...,  -4.0855,  -2.3937,  -2.2043],\n",
      "         ...,\n",
      "         [ -4.9940,  -4.9822,  -4.9379,  ...,  -4.7404,  -5.4839,  -4.4972],\n",
      "         [ -5.8376,  -5.7670,  -5.8543,  ...,  -5.4698,  -6.8572,  -3.9514],\n",
      "         [ -4.9624,  -4.9183,  -4.9454,  ...,  -4.5915,  -5.5374,  -2.5923]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.4742045402526855\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.0078, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9948,  -6.9663,  -6.9871,  ...,  -6.0982,  -5.9893,  -3.7837],\n",
      "         [-12.6375, -12.7080, -12.6842,  ...,  -9.4668,  -9.3810, -10.3907],\n",
      "         [ -5.0669,  -5.2496,  -5.2597,  ...,  -4.8133,  -6.4388,  -2.7511],\n",
      "         ...,\n",
      "         [ -5.6237,  -5.7872,  -5.7997,  ...,  -5.4495,  -6.5392,  -3.2399],\n",
      "         [ -5.0173,  -5.1624,  -5.2044,  ...,  -5.0095,  -6.4913,  -3.1850],\n",
      "         [ -5.7082,  -5.8155,  -5.7103,  ...,  -4.9638,  -6.4630,  -3.7039]],\n",
      "\n",
      "        [[ -6.5893,  -6.5513,  -6.5375,  ...,  -5.8698,  -5.7060,  -3.9073],\n",
      "         [-12.2883, -12.0050, -12.2275,  ..., -10.6987, -11.2596,  -9.1794],\n",
      "         [ -6.0979,  -6.0632,  -6.2164,  ...,  -6.1132,  -6.9247,  -4.0975],\n",
      "         ...,\n",
      "         [ -5.9175,  -5.8003,  -6.0322,  ...,  -5.5815,  -6.2684,  -2.8458],\n",
      "         [ -6.4524,  -6.4315,  -6.6003,  ...,  -6.3260,  -6.8022,  -3.8013],\n",
      "         [ -6.3101,  -6.2277,  -6.4534,  ...,  -6.1697,  -6.5674,  -3.4597]],\n",
      "\n",
      "        [[ -6.4348,  -6.4480,  -6.5147,  ...,  -5.7623,  -5.7027,  -3.4736],\n",
      "         [ -9.6745,  -9.1830,  -9.3086,  ...,  -6.3835,  -7.9109,  -7.8742],\n",
      "         [ -5.0015,  -5.1708,  -5.0833,  ...,  -5.3549,  -6.3621,  -2.9689],\n",
      "         ...,\n",
      "         [ -5.5558,  -5.6692,  -5.6238,  ...,  -5.6477,  -6.5788,  -3.3171],\n",
      "         [ -5.7289,  -5.8382,  -5.8557,  ...,  -5.4820,  -6.5159,  -3.5401],\n",
      "         [ -5.1703,  -5.2838,  -5.3165,  ...,  -5.0949,  -6.4519,  -3.0537]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.7276,  -7.7986,  -7.8459,  ...,  -6.6755,  -6.8989,  -4.6985],\n",
      "         [-11.7444, -11.5412, -11.4855,  ...,  -8.2772,  -9.8574,  -7.8698],\n",
      "         [ -4.5887,  -4.6637,  -4.7977,  ...,  -4.7945,  -6.1110,  -2.5769],\n",
      "         ...,\n",
      "         [ -5.3467,  -5.5098,  -5.4945,  ...,  -5.7178,  -6.7503,  -3.4354],\n",
      "         [ -5.5059,  -5.6793,  -5.6856,  ...,  -5.6936,  -6.5039,  -3.3489],\n",
      "         [ -4.8687,  -4.9179,  -4.9972,  ...,  -5.1139,  -6.3313,  -3.2998]],\n",
      "\n",
      "        [[ -6.4898,  -6.4519,  -6.4435,  ...,  -5.7082,  -5.6300,  -3.7084],\n",
      "         [-11.7366, -11.8031, -11.5483,  ...,  -9.3155, -11.1496,  -9.6458],\n",
      "         [ -5.0401,  -5.1892,  -5.0878,  ...,  -5.0845,  -6.5368,  -3.3806],\n",
      "         ...,\n",
      "         [ -4.8744,  -4.9209,  -4.7717,  ...,  -4.1316,  -5.8456,  -3.8043],\n",
      "         [ -5.3889,  -5.4466,  -5.3662,  ...,  -5.2554,  -6.5954,  -4.8074],\n",
      "         [ -4.8196,  -4.9138,  -4.7215,  ...,  -4.7717,  -6.0625,  -3.6860]],\n",
      "\n",
      "        [[ -6.0666,  -6.0098,  -6.0400,  ...,  -5.4798,  -5.2947,  -3.5153],\n",
      "         [ -8.8636,  -8.8915,  -8.9015,  ...,  -8.2088,  -7.7690,  -5.2234],\n",
      "         [ -2.0056,  -1.9230,  -2.1322,  ...,   0.0706,  -0.9945,  -3.3131],\n",
      "         ...,\n",
      "         [ -5.0760,  -5.0946,  -5.1574,  ...,  -5.4503,  -5.6342,  -2.0328],\n",
      "         [ -3.9381,  -4.0178,  -4.1233,  ...,  -3.8214,  -3.3681,  -2.2239],\n",
      "         [ -4.7365,  -4.7888,  -4.7178,  ...,  -4.6437,  -4.1462,  -2.3597]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.007792455609887838\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8670, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2078,  -7.1452,  -7.0864,  ...,  -7.0402,  -7.6295,  -3.4960],\n",
      "         [-13.5707, -13.3770, -13.3351,  ...,  -9.6429, -11.1687, -11.1970],\n",
      "         [ -4.5584,  -4.8361,  -4.8259,  ...,  -6.0912,  -7.1352,  -2.0917],\n",
      "         ...,\n",
      "         [ -5.2523,  -5.6555,  -5.2977,  ...,  -5.6477,  -7.0517,  -4.8823],\n",
      "         [ -4.9059,  -5.0260,  -5.0332,  ...,  -5.2741,  -6.8703,  -2.6627],\n",
      "         [ -5.6924,  -5.8849,  -5.6515,  ...,  -5.7843,  -6.8820,  -5.8345]],\n",
      "\n",
      "        [[ -6.6287,  -6.6058,  -6.6955,  ...,  -6.4840,  -6.2144,  -3.9894],\n",
      "         [-13.7064, -13.2606, -13.5406,  ..., -10.9600, -12.4744,  -8.5945],\n",
      "         [ -4.4920,  -4.5602,  -4.5981,  ...,  -4.7255,  -6.1755,  -3.0131],\n",
      "         ...,\n",
      "         [ -6.0511,  -6.1495,  -6.2147,  ...,  -5.7285,  -6.8907,  -3.2796],\n",
      "         [ -5.7036,  -5.5997,  -5.6502,  ...,  -5.9204,  -6.4724,  -4.4557],\n",
      "         [ -5.0723,  -5.1251,  -5.1230,  ...,  -5.0754,  -6.1548,  -4.0304]],\n",
      "\n",
      "        [[ -6.4917,  -6.4283,  -6.4460,  ...,  -5.7541,  -5.5385,  -3.8781],\n",
      "         [ -9.6239,  -9.4147,  -9.4367,  ...,  -8.0187,  -8.4091,  -6.5808],\n",
      "         [ -6.3317,  -6.3768,  -6.4943,  ...,  -6.1870,  -7.2139,  -2.8070],\n",
      "         ...,\n",
      "         [ -6.1030,  -6.1248,  -6.1659,  ...,  -5.9490,  -6.4061,  -3.1001],\n",
      "         [ -6.1190,  -6.1869,  -6.1573,  ...,  -6.2651,  -6.7374,  -3.3536],\n",
      "         [ -6.0629,  -6.1957,  -6.1678,  ...,  -6.2202,  -7.0799,  -2.9430]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6506,  -6.6452,  -6.6541,  ...,  -6.1218,  -5.9445,  -3.6024],\n",
      "         [ -6.8193,  -6.6507,  -6.8357,  ...,  -7.6376,  -7.3789,  -1.1160],\n",
      "         [ -6.6576,  -6.6277,  -6.9199,  ...,  -7.2222,  -7.0966,  -1.2087],\n",
      "         ...,\n",
      "         [ -5.5148,  -5.3512,  -5.5089,  ...,  -5.5192,  -5.9368,  -1.1810],\n",
      "         [ -5.6025,  -5.5296,  -5.5817,  ...,  -5.6865,  -6.6206,  -1.5274],\n",
      "         [ -5.5504,  -5.3544,  -5.5452,  ...,  -6.0584,  -6.4058,  -1.5132]],\n",
      "\n",
      "        [[ -6.4672,  -6.4320,  -6.4348,  ...,  -5.7621,  -5.6092,  -3.5547],\n",
      "         [-12.1982, -12.1541, -12.1554,  ...,  -8.7813, -10.4568,  -9.3312],\n",
      "         [ -5.2215,  -5.1902,  -5.2564,  ...,  -5.9590,  -6.5962,  -4.0657],\n",
      "         ...,\n",
      "         [ -6.0580,  -5.9506,  -6.0322,  ...,  -6.2296,  -6.9178,  -5.4340],\n",
      "         [ -6.2540,  -6.2184,  -6.2525,  ...,  -6.3545,  -7.0953,  -4.6297],\n",
      "         [ -5.9190,  -5.9708,  -5.9489,  ...,  -6.1290,  -6.4714,  -4.2153]],\n",
      "\n",
      "        [[ -6.1503,  -6.1138,  -6.0637,  ...,  -5.4911,  -5.6149,  -3.4100],\n",
      "         [ -6.9251,  -6.8628,  -7.0925,  ...,  -8.2977,  -7.9180,  -1.8906],\n",
      "         [ -6.3427,  -6.3829,  -6.4319,  ...,  -7.2082,  -7.4351,  -1.8779],\n",
      "         ...,\n",
      "         [ -5.1299,  -5.1151,  -5.1982,  ...,  -5.7588,  -6.2528,  -1.5781],\n",
      "         [ -4.8225,  -4.8587,  -4.8944,  ...,  -5.8326,  -6.2191,  -1.7646],\n",
      "         [ -4.7883,  -4.7437,  -4.7853,  ...,  -5.8901,  -5.6905,  -0.9744]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.867034912109375\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0826, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3493,  -6.2814,  -6.2925,  ...,  -5.5696,  -5.4723,  -3.4753],\n",
      "         [ -7.0359,  -7.0081,  -7.2202,  ...,  -7.8477,  -7.6929,  -1.7666],\n",
      "         [ -5.6562,  -5.4969,  -5.7408,  ...,  -6.0582,  -6.6299,  -0.4439],\n",
      "         ...,\n",
      "         [ -5.8026,  -5.6162,  -5.7473,  ...,  -6.1802,  -6.2152,  -1.7858],\n",
      "         [ -5.2589,  -5.0944,  -5.1887,  ...,  -5.4485,  -5.9510,  -1.5123],\n",
      "         [ -5.2571,  -5.0026,  -5.1842,  ...,  -5.0943,  -5.5561,  -1.4979]],\n",
      "\n",
      "        [[ -6.5774,  -6.5195,  -6.5364,  ...,  -5.8887,  -5.6471,  -3.9157],\n",
      "         [-10.8547, -10.9963, -10.5734,  ...,  -8.0608,  -8.3582, -10.3277],\n",
      "         [ -4.8384,  -4.9286,  -4.9854,  ...,  -4.9745,  -7.2144,  -1.9688],\n",
      "         ...,\n",
      "         [ -5.6704,  -5.7848,  -5.8706,  ...,  -5.7079,  -7.0581,  -2.4395],\n",
      "         [ -5.6916,  -5.7332,  -5.7912,  ...,  -5.3572,  -6.5769,  -3.5121],\n",
      "         [ -6.1732,  -6.2582,  -6.3082,  ...,  -5.8502,  -6.8631,  -3.3171]],\n",
      "\n",
      "        [[ -7.3039,  -7.1007,  -7.2241,  ...,  -6.7951,  -6.4420,  -4.2809],\n",
      "         [-11.5694, -11.4216, -11.4790,  ..., -10.6668,  -9.8500, -10.1276],\n",
      "         [ -5.3767,  -5.6509,  -5.6142,  ...,  -5.6593,  -6.1487,  -2.1715],\n",
      "         ...,\n",
      "         [ -5.5469,  -5.6033,  -5.5355,  ...,  -5.9102,  -5.8256,  -4.4361],\n",
      "         [ -5.5829,  -5.6291,  -5.7549,  ...,  -6.1414,  -6.5154,  -3.3166],\n",
      "         [ -5.3364,  -5.3392,  -5.4423,  ...,  -5.6434,  -5.9113,  -2.7902]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2892,  -6.1821,  -6.1461,  ...,  -5.6160,  -5.3592,  -3.7106],\n",
      "         [ -5.8564,  -5.8324,  -5.6920,  ...,  -6.5668,  -7.0070,  -1.0568],\n",
      "         [ -4.8057,  -4.7981,  -4.6526,  ...,  -6.0137,  -5.8031,  -0.6410],\n",
      "         ...,\n",
      "         [ -4.3234,  -4.2116,  -4.3068,  ...,  -4.9449,  -5.1753,  -1.1730],\n",
      "         [ -5.3953,  -5.2937,  -5.2888,  ...,  -5.8341,  -6.2228,  -0.8824],\n",
      "         [ -4.4893,  -4.4878,  -4.4299,  ...,  -4.9588,  -4.8913,  -0.8021]],\n",
      "\n",
      "        [[ -6.3741,  -6.3390,  -6.3415,  ...,  -5.8661,  -5.9564,  -3.2956],\n",
      "         [ -6.9264,  -6.7461,  -6.9429,  ...,  -7.0613,  -6.9148,  -1.5022],\n",
      "         [ -6.3858,  -6.4723,  -6.7324,  ...,  -7.6050,  -6.4751,  -2.4420],\n",
      "         ...,\n",
      "         [ -5.3844,  -5.2486,  -5.4158,  ...,  -5.6152,  -5.8012,  -1.0253],\n",
      "         [ -4.9047,  -4.8440,  -4.9195,  ...,  -5.4366,  -5.4936,  -1.0000],\n",
      "         [ -5.4781,  -5.4012,  -5.3905,  ...,  -5.9933,  -5.7982,  -1.5373]],\n",
      "\n",
      "        [[ -6.5494,  -6.5920,  -6.5306,  ...,  -5.9012,  -5.9313,  -4.1131],\n",
      "         [-15.6584, -15.5855, -15.6836,  ..., -14.4312, -12.2803, -13.0306],\n",
      "         [-10.9887, -11.1351, -11.5738,  ..., -12.2918,  -9.5802,  -9.6486],\n",
      "         ...,\n",
      "         [ -6.5965,  -6.7906,  -6.7092,  ...,  -6.5672,  -6.8160,  -3.7897],\n",
      "         [ -6.7410,  -6.8727,  -6.8459,  ...,  -6.4345,  -7.5222,  -4.0894],\n",
      "         [ -6.2728,  -6.3449,  -6.3450,  ...,  -5.8259,  -7.4505,  -4.4056]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.08262300491333\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5447, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3997,  -6.3868,  -6.3700,  ...,  -5.8097,  -5.4879,  -3.6499],\n",
      "         [-14.7317, -14.9860, -14.6941,  ..., -14.4263, -11.2103,  -9.6065],\n",
      "         [ -3.6440,  -4.4895,  -4.2856,  ...,  -4.9739,  -5.6457,  -2.5740],\n",
      "         ...,\n",
      "         [ -5.4588,  -5.4128,  -5.5178,  ...,  -5.0363,  -5.0524,  -1.4803],\n",
      "         [ -5.6030,  -5.6303,  -5.6858,  ...,  -5.0892,  -5.4386,  -1.7963],\n",
      "         [ -5.7855,  -5.8637,  -5.9978,  ...,  -5.6195,  -5.7703,  -2.2749]],\n",
      "\n",
      "        [[ -6.4513,  -6.4481,  -6.4143,  ...,  -5.6290,  -5.6765,  -3.6327],\n",
      "         [-10.1290, -10.3183, -10.4114,  ...,  -9.3430,  -9.0417,  -8.1402],\n",
      "         [ -6.7885,  -7.2099,  -6.6320,  ...,  -7.7374,  -5.7105,  -8.7727],\n",
      "         ...,\n",
      "         [ -6.3625,  -6.6623,  -6.4507,  ...,  -6.1280,  -5.5450,  -3.0404],\n",
      "         [ -6.0964,  -6.4593,  -6.2160,  ...,  -5.0128,  -4.6108,  -2.7799],\n",
      "         [ -5.4322,  -5.7099,  -5.5466,  ...,  -4.4728,  -3.7068,  -3.2443]],\n",
      "\n",
      "        [[ -6.6582,  -6.6336,  -6.6296,  ...,  -5.8712,  -5.9154,  -3.6149],\n",
      "         [-15.7516, -15.4191, -15.7376,  ..., -13.8101, -12.2464, -12.2631],\n",
      "         [-10.1311, -10.8367, -10.5134,  ..., -10.8342,  -8.7748, -10.0515],\n",
      "         ...,\n",
      "         [ -8.2084,  -8.2114,  -8.0508,  ...,  -8.2960,  -7.1374,  -4.8624],\n",
      "         [ -8.5470,  -8.4491,  -8.3733,  ...,  -8.7244,  -8.1681,  -5.6684],\n",
      "         [ -7.9056,  -7.9344,  -7.7817,  ...,  -8.0671,  -7.1860,  -5.4312]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4617,  -6.5326,  -6.4658,  ...,  -5.7728,  -5.6693,  -3.7394],\n",
      "         [-11.8093, -12.0343, -11.4847,  ...,  -9.8675,  -9.5775, -12.0631],\n",
      "         [ -6.4923,  -6.4327,  -6.5806,  ...,  -6.0302,  -6.7675,  -5.3377],\n",
      "         ...,\n",
      "         [ -3.2577,  -3.2126,  -3.2088,  ...,  -2.3952,  -4.0227,  -4.9157],\n",
      "         [-11.2287, -11.3016, -11.2775,  ..., -10.9911, -10.6285,  -9.8618],\n",
      "         [-16.0163, -16.2514, -16.1446,  ..., -14.7329, -13.6481,  -8.4849]],\n",
      "\n",
      "        [[ -6.7860,  -6.6961,  -6.6918,  ...,  -6.1285,  -5.6859,  -3.8619],\n",
      "         [ -5.5236,  -5.5093,  -5.5997,  ...,  -5.6372,  -4.5445,  -4.4066],\n",
      "         [-12.0761, -12.0243, -11.8807,  ..., -10.4520,  -8.3419,  -8.5256],\n",
      "         ...,\n",
      "         [-10.0185, -10.3548, -10.1874,  ...,  -9.5162,  -7.7319,  -7.7754],\n",
      "         [ -5.2738,  -5.6328,  -5.4104,  ...,  -5.8022,  -3.8182,  -3.5688],\n",
      "         [-14.2754, -14.4455, -14.6488,  ..., -12.7060, -12.2313, -10.1246]],\n",
      "\n",
      "        [[ -6.8877,  -6.7565,  -6.7932,  ...,  -6.0069,  -5.7818,  -3.5440],\n",
      "         [ -9.2103,  -9.1778,  -8.9652,  ...,  -7.8657,  -5.7404,  -3.1805],\n",
      "         [ -9.6266,  -9.7722,  -9.4558,  ...,  -8.1916,  -6.5879,  -0.8020],\n",
      "         ...,\n",
      "         [ -6.6142,  -6.7655,  -6.4481,  ...,  -4.3392,  -5.1363,  -1.4900],\n",
      "         [ -6.8015,  -6.9260,  -6.7111,  ...,  -4.7662,  -5.3147,  -2.6573],\n",
      "         [ -6.0916,  -6.1404,  -6.0153,  ...,  -4.2881,  -5.0218,  -1.8165]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.5446972846984863\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2401, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8932,  -6.9643,  -6.9583,  ...,  -6.1425,  -5.9852,  -3.8886],\n",
      "         [-13.0251, -12.9201, -12.7433,  ...,  -9.1742, -11.1789,  -8.7268],\n",
      "         [ -5.2273,  -5.3632,  -5.4339,  ...,  -5.4298,  -6.7166,  -2.4916],\n",
      "         ...,\n",
      "         [ -5.7901,  -5.9919,  -5.9070,  ...,  -5.7663,  -6.9882,  -3.3569],\n",
      "         [ -5.8133,  -5.9760,  -6.0224,  ...,  -5.9990,  -7.0756,  -2.9320],\n",
      "         [ -5.7633,  -5.8934,  -5.7834,  ...,  -5.9991,  -6.6118,  -3.4921]],\n",
      "\n",
      "        [[ -7.3754,  -7.2273,  -7.3519,  ...,  -6.4409,  -6.4324,  -4.1134],\n",
      "         [-13.1785, -12.9031, -12.9947,  ...,  -9.5365,  -9.7781, -12.2072],\n",
      "         [ -6.4565,  -6.4958,  -6.6407,  ...,  -6.8608,  -7.8785,  -4.1270],\n",
      "         ...,\n",
      "         [ -5.4778,  -5.5413,  -5.5337,  ...,  -5.9954,  -6.4279,  -3.3911],\n",
      "         [ -5.5145,  -5.7544,  -5.7850,  ...,  -6.4726,  -6.5346,  -2.8547],\n",
      "         [ -6.0282,  -6.1169,  -6.2197,  ...,  -6.4502,  -7.2299,  -4.4768]],\n",
      "\n",
      "        [[ -6.1141,  -6.0872,  -6.0785,  ...,  -5.4261,  -5.2057,  -3.5649],\n",
      "         [-13.6623, -13.4920, -13.3506,  ..., -10.1570, -10.3762, -10.4486],\n",
      "         [ -5.7950,  -5.8610,  -5.8620,  ...,  -5.7938,  -6.5062,  -3.8704],\n",
      "         ...,\n",
      "         [ -5.9703,  -5.9871,  -5.9257,  ...,  -6.0059,  -6.2337,  -4.0220],\n",
      "         [ -5.8381,  -5.8907,  -5.8627,  ...,  -6.0402,  -6.1499,  -3.7138],\n",
      "         [ -6.2297,  -6.3143,  -6.2976,  ...,  -6.2236,  -6.8225,  -3.9520]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7519,  -6.7284,  -6.7291,  ...,  -6.1283,  -5.9112,  -3.8317],\n",
      "         [ -5.4737,  -5.6137,  -5.5625,  ...,  -6.7595,  -5.4313,  -1.5226],\n",
      "         [ -6.1629,  -6.1418,  -6.1871,  ...,  -7.3257,  -6.5151,  -1.3645],\n",
      "         ...,\n",
      "         [ -5.3854,  -5.3509,  -5.4094,  ...,  -6.3017,  -5.5981,  -2.6567],\n",
      "         [ -5.3458,  -5.3995,  -5.3799,  ...,  -6.2232,  -5.6158,  -2.3140],\n",
      "         [ -5.1431,  -5.1556,  -5.1810,  ...,  -6.0200,  -5.5848,  -2.6610]],\n",
      "\n",
      "        [[ -6.6015,  -6.5609,  -6.5804,  ...,  -5.8680,  -5.7150,  -3.9158],\n",
      "         [-11.5673, -11.2005, -11.1270,  ...,  -8.8511,  -9.3215,  -9.3926],\n",
      "         [ -5.3900,  -5.5382,  -5.4726,  ...,  -5.3309,  -6.6295,  -3.2231],\n",
      "         ...,\n",
      "         [ -5.5530,  -5.6118,  -5.6488,  ...,  -5.3207,  -6.4732,  -2.5590],\n",
      "         [ -5.7929,  -5.8012,  -5.7289,  ...,  -5.5430,  -6.3140,  -3.9029],\n",
      "         [ -5.0698,  -5.1418,  -5.1948,  ...,  -5.0764,  -6.3153,  -3.0142]],\n",
      "\n",
      "        [[ -6.4701,  -6.5116,  -6.5558,  ...,  -5.7133,  -5.5843,  -3.8008],\n",
      "         [-14.2212, -14.1493, -14.0155,  ..., -10.6075, -12.2713, -10.0469],\n",
      "         [ -4.8447,  -4.9703,  -4.9968,  ...,  -4.6603,  -6.3093,  -3.1103],\n",
      "         ...,\n",
      "         [ -5.7345,  -5.8211,  -5.7590,  ...,  -5.0859,  -6.7421,  -3.5402],\n",
      "         [ -5.5043,  -5.6068,  -5.6376,  ...,  -5.0798,  -6.6443,  -3.5749],\n",
      "         [ -5.8110,  -5.9296,  -5.8748,  ...,  -5.5742,  -7.2894,  -3.4686]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2401485443115234\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2435, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7892,  -6.7663,  -6.7387,  ...,  -6.1662,  -5.6839,  -4.1438],\n",
      "         [-10.2296, -10.1414,  -9.9524,  ...,  -8.3597,  -6.8788,  -8.7709],\n",
      "         [-11.8338, -11.8509, -11.6319,  ...,  -9.7032,  -7.6785,  -8.5305],\n",
      "         ...,\n",
      "         [ -5.6694,  -5.5843,  -5.4596,  ...,  -5.3091,  -3.2476,  -4.8318],\n",
      "         [ -5.5236,  -5.2884,  -5.4666,  ...,  -5.0356,  -2.9089,  -3.4416],\n",
      "         [-11.3616, -11.1891, -11.2923,  ...,  -8.8192,  -6.4404,  -7.8898]],\n",
      "\n",
      "        [[ -9.8162, -10.1882,  -9.7735,  ...,  -7.1404,  -8.7610,  -5.8692],\n",
      "         [-13.2927, -13.3763, -13.1973,  ..., -11.8670, -12.2187, -11.4693],\n",
      "         [ -5.4464,  -5.5488,  -5.4516,  ...,  -6.1825,  -7.1941,  -2.5848],\n",
      "         ...,\n",
      "         [ -6.2249,  -6.3564,  -6.2063,  ...,  -6.6964,  -6.9950,  -3.7144],\n",
      "         [ -5.9126,  -6.0676,  -5.9529,  ...,  -6.0294,  -7.5999,  -3.5761],\n",
      "         [ -6.3151,  -6.4908,  -6.3753,  ...,  -6.5406,  -7.1891,  -2.8070]],\n",
      "\n",
      "        [[ -7.1994,  -7.1980,  -7.2098,  ...,  -6.2881,  -6.2048,  -3.5433],\n",
      "         [-11.3482, -11.5035, -11.2164,  ..., -10.2801,  -8.7876,  -9.7749],\n",
      "         [-11.5228, -11.4261, -11.3370,  ...,  -9.8690,  -9.5471,  -8.6130],\n",
      "         ...,\n",
      "         [-14.7462, -14.5981, -14.5352,  ..., -13.6711, -11.7356,  -5.5699],\n",
      "         [ -9.9508,  -9.9106, -10.1806,  ...,  -9.6453,  -8.6292,  -5.7070],\n",
      "         [-11.4724, -11.3159, -11.5092,  ..., -10.0636,  -9.7500,  -4.7574]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1075,  -7.0858,  -7.0817,  ...,  -6.1815,  -6.1949,  -4.0904],\n",
      "         [-12.9467, -12.3295, -12.4986,  ..., -10.4583, -10.8782,  -9.9191],\n",
      "         [ -6.3649,  -6.5221,  -6.4279,  ...,  -6.9625,  -7.6665,  -4.0129],\n",
      "         ...,\n",
      "         [ -5.9062,  -5.9314,  -5.9743,  ...,  -6.3879,  -6.8833,  -3.8292],\n",
      "         [ -6.4750,  -6.5470,  -6.4781,  ...,  -6.7638,  -7.5544,  -4.2416],\n",
      "         [ -6.4836,  -6.5191,  -6.4347,  ...,  -6.7151,  -7.2597,  -4.0578]],\n",
      "\n",
      "        [[ -6.7297,  -6.7021,  -6.6794,  ...,  -6.1044,  -5.8272,  -4.1849],\n",
      "         [-11.4092, -11.2358, -11.4638,  ..., -10.2480,  -8.5440, -11.9438],\n",
      "         [ -9.5664,  -9.8805,  -9.6590,  ...,  -8.2087,  -6.9295,  -7.7026],\n",
      "         ...,\n",
      "         [-10.1019, -10.6836, -10.4177,  ...,  -9.0200,  -8.8309,  -6.9101],\n",
      "         [ -8.1289,  -7.9942,  -7.9936,  ...,  -7.9440,  -7.6156,  -4.4790],\n",
      "         [-13.4158, -13.6446, -13.5770,  ..., -11.8818, -11.4623,  -8.3472]],\n",
      "\n",
      "        [[ -6.4750,  -6.4332,  -6.4280,  ...,  -5.8386,  -5.6913,  -3.5814],\n",
      "         [ -6.7194,  -6.6159,  -6.3836,  ...,  -8.3503,  -7.1186,  -2.6664],\n",
      "         [ -9.8460,  -9.8384,  -9.7931,  ..., -10.4007,  -9.4984,  -6.8490],\n",
      "         ...,\n",
      "         [ -4.4774,  -4.3572,  -4.3974,  ...,  -4.7361,  -4.8045,  -1.6574],\n",
      "         [ -5.0867,  -5.0754,  -4.9631,  ...,  -5.3741,  -5.3698,  -1.8505],\n",
      "         [ -4.9061,  -4.8464,  -4.8034,  ...,  -5.7539,  -5.0908,  -1.3909]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2435145378112793\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9909, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6319,  -6.5965,  -6.6020,  ...,  -6.0556,  -5.8760,  -3.6168],\n",
      "         [ -5.8437,  -5.7603,  -5.8646,  ...,  -6.5353,  -6.1146,  -1.2627],\n",
      "         [ -6.2820,  -6.1447,  -6.2934,  ...,  -6.8671,  -6.4068,  -2.5443],\n",
      "         ...,\n",
      "         [ -5.5876,  -5.5529,  -5.6233,  ...,  -5.6775,  -5.8475,  -1.2293],\n",
      "         [ -5.7472,  -5.6735,  -5.7780,  ...,  -6.1438,  -5.5662,  -1.8268],\n",
      "         [ -6.2570,  -6.1793,  -6.2169,  ...,  -6.4029,  -6.0549,  -1.6509]],\n",
      "\n",
      "        [[ -6.9183,  -6.9024,  -6.9159,  ...,  -6.0746,  -6.1722,  -4.4091],\n",
      "         [ -7.6279,  -7.7281,  -7.9232,  ...,  -8.1699,  -7.2888,  -7.0622],\n",
      "         [ -4.1663,  -4.4619,  -4.6639,  ...,  -4.6616,  -4.3102,  -3.9622],\n",
      "         ...,\n",
      "         [-13.0049, -13.0225, -13.0165,  ..., -11.1300, -10.3019, -10.6731],\n",
      "         [ -8.5089,  -8.6383,  -8.5501,  ...,  -9.1268,  -9.0925,  -9.1415],\n",
      "         [-13.1760, -13.8208, -13.6182,  ..., -12.2980,  -9.7403,  -6.8804]],\n",
      "\n",
      "        [[ -7.0100,  -6.9860,  -7.0285,  ...,  -6.1555,  -6.1509,  -3.5768],\n",
      "         [-13.6301, -13.6645, -13.4730,  ..., -11.8317, -11.2015,  -9.3247],\n",
      "         [ -3.9041,  -3.9435,  -3.9900,  ...,  -4.3766,  -5.9056,  -2.3675],\n",
      "         ...,\n",
      "         [ -5.2119,  -5.3335,  -5.3940,  ...,  -5.0343,  -6.4685,  -1.9032],\n",
      "         [ -4.8673,  -5.0089,  -4.9870,  ...,  -5.4332,  -6.1900,  -2.0456],\n",
      "         [ -5.4462,  -5.5368,  -5.5335,  ...,  -5.3345,  -6.5491,  -2.5417]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6337,  -6.6683,  -6.6294,  ...,  -6.0127,  -5.6871,  -4.4306],\n",
      "         [-10.3147, -10.7574, -10.4901,  ..., -10.7042,  -8.8894,  -9.6306],\n",
      "         [ -5.2360,  -5.3656,  -5.3307,  ...,  -5.9502,  -4.6607,  -4.3565],\n",
      "         ...,\n",
      "         [ -0.7123,  -0.4814,  -0.5953,  ...,   0.9212,   0.0578,  -1.2348],\n",
      "         [ -9.4662,  -9.5922,  -9.4086,  ...,  -9.4168,  -6.6902,  -4.9199],\n",
      "         [-13.5663, -13.8152, -13.9837,  ..., -10.7610, -10.4151,  -9.4324]],\n",
      "\n",
      "        [[ -6.4505,  -6.3986,  -6.4227,  ...,  -5.7638,  -5.5901,  -3.8378],\n",
      "         [-11.3619, -11.1807, -11.1191,  ...,  -9.0354,  -9.7234,  -5.8424],\n",
      "         [ -5.7242,  -5.7404,  -5.8272,  ...,  -6.0712,  -6.8917,  -3.4548],\n",
      "         ...,\n",
      "         [ -5.9768,  -6.1194,  -6.1163,  ...,  -6.0926,  -6.6542,  -3.8830],\n",
      "         [ -5.0280,  -5.1483,  -5.1545,  ...,  -4.8754,  -5.7747,  -3.4689],\n",
      "         [ -5.8857,  -5.9238,  -5.9466,  ...,  -5.7330,  -6.3987,  -3.7522]],\n",
      "\n",
      "        [[ -6.7591,  -6.7518,  -6.7128,  ...,  -6.1326,  -6.0163,  -3.9033],\n",
      "         [-12.5320, -12.0937, -12.6619,  ..., -10.7009, -10.8223,  -9.7424],\n",
      "         [ -9.7721,  -9.5397,  -9.2873,  ...,  -9.4686,  -7.9577,  -6.2333],\n",
      "         ...,\n",
      "         [ -6.4501,  -6.6951,  -6.4660,  ...,  -6.4647,  -8.0405,  -4.2386],\n",
      "         [ -7.7435,  -7.8301,  -7.6925,  ...,  -7.1645,  -7.8118,  -6.6494],\n",
      "         [-11.3243, -10.7971, -11.1081,  ...,  -9.1828, -10.5220,  -9.6189]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.9908666610717773\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7709, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.1878,  -6.1427,  -6.1751,  ...,  -5.5703,  -5.3410,  -3.6974],\n",
      "         [-13.6412, -13.5782, -13.2432,  ..., -10.0535, -10.4548,  -9.1063],\n",
      "         [ -5.3593,  -5.4934,  -5.5097,  ...,  -5.7596,  -6.5594,  -3.1726],\n",
      "         ...,\n",
      "         [ -6.0226,  -6.1100,  -6.1111,  ...,  -5.7883,  -6.8282,  -3.6359],\n",
      "         [ -5.5133,  -5.6272,  -5.6804,  ...,  -5.5443,  -6.5117,  -3.5618],\n",
      "         [ -6.0052,  -6.1253,  -6.0598,  ...,  -5.8872,  -6.5164,  -3.5161]],\n",
      "\n",
      "        [[ -6.7456,  -6.7522,  -6.7401,  ...,  -6.3960,  -5.8767,  -3.9679],\n",
      "         [-12.6538, -12.1987, -12.7561,  ..., -11.2983,  -9.7669, -12.2733],\n",
      "         [ -3.8113,  -3.6333,  -3.6928,  ...,  -3.6106,  -3.4166,  -6.3621],\n",
      "         ...,\n",
      "         [ -5.3081,  -5.4139,  -5.5133,  ...,  -4.9761,  -5.0305,  -3.5797],\n",
      "         [ -6.2325,  -6.4091,  -6.7813,  ...,  -5.3308,  -5.2639,  -7.0408],\n",
      "         [ -4.6314,  -4.8238,  -4.7618,  ...,  -4.9153,  -4.4897,  -1.7029]],\n",
      "\n",
      "        [[ -6.7353,  -6.5961,  -6.6205,  ...,  -6.1179,  -5.9105,  -4.3191],\n",
      "         [ -8.6595,  -8.3829,  -8.7791,  ...,  -7.6837,  -8.3623,  -8.9164],\n",
      "         [ -0.8294,  -0.9169,  -0.7451,  ...,  -0.0195,  -1.9090,  -1.1589],\n",
      "         ...,\n",
      "         [ -4.1190,  -4.5501,  -4.3150,  ...,  -3.0390,  -2.2320,  -2.0394],\n",
      "         [ -9.9389,  -9.9118, -10.1145,  ...,  -8.7661, -10.8251,  -3.4420],\n",
      "         [-12.9287, -12.6568, -12.6845,  ..., -10.8977, -10.0837,  -8.8111]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2453,  -7.1802,  -7.2410,  ...,  -6.0653,  -6.1566,  -4.3978],\n",
      "         [-14.4292, -14.0697, -14.0007,  ..., -10.9897, -12.2848, -11.1538],\n",
      "         [ -5.4007,  -5.6043,  -5.5851,  ...,  -5.0430,  -7.2070,  -4.0486],\n",
      "         ...,\n",
      "         [ -5.4129,  -5.3497,  -5.4002,  ...,  -4.6308,  -6.2898,  -4.5057],\n",
      "         [ -5.2585,  -5.1925,  -5.3510,  ...,  -4.7017,  -6.6302,  -3.6547],\n",
      "         [ -5.3148,  -5.2233,  -5.3531,  ...,  -4.0929,  -5.8526,  -4.2190]],\n",
      "\n",
      "        [[ -7.3172,  -7.3376,  -7.2852,  ...,  -6.7371,  -6.3719,  -4.1878],\n",
      "         [ -9.3672,  -9.4799,  -9.0602,  ...,  -7.9142,  -9.1669,  -3.7377],\n",
      "         [ -4.9993,  -5.0560,  -5.3028,  ...,  -4.8208,  -3.9848,  -2.6296],\n",
      "         ...,\n",
      "         [ -3.6260,  -3.7574,  -3.7187,  ...,  -3.2997,  -4.1446,  -3.9649],\n",
      "         [ -3.0042,  -3.2354,  -3.1900,  ...,  -2.5960,  -3.5856,  -3.7584],\n",
      "         [ -7.2695,  -7.3029,  -7.3842,  ...,  -7.0279,  -7.0004,  -5.1582]],\n",
      "\n",
      "        [[ -6.9596,  -6.9136,  -6.9294,  ...,  -6.1236,  -5.9923,  -3.7911],\n",
      "         [-11.6383, -11.7245, -11.5955,  ..., -10.0261, -10.5372,  -6.8823],\n",
      "         [ -4.7023,  -4.9583,  -4.9838,  ...,  -5.0599,  -6.8159,  -2.4929],\n",
      "         ...,\n",
      "         [ -5.2894,  -5.4060,  -5.4395,  ...,  -5.6319,  -6.5105,  -3.2068],\n",
      "         [ -4.8687,  -5.1286,  -5.0591,  ...,  -4.9859,  -6.6161,  -3.0915],\n",
      "         [ -5.7894,  -5.9951,  -6.0806,  ...,  -5.5509,  -6.8460,  -3.5473]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.770911931991577\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0763, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2141,  -6.1400,  -6.1844,  ...,  -5.7626,  -5.6539,  -3.1356],\n",
      "         [ -6.4430,  -6.3914,  -6.5403,  ...,  -7.0900,  -6.9607,  -2.8034],\n",
      "         [ -7.3040,  -7.2149,  -7.3744,  ...,  -7.9460,  -7.8444,  -2.4219],\n",
      "         ...,\n",
      "         [ -5.7256,  -5.5683,  -5.7388,  ...,  -6.1399,  -5.9816,  -2.0110],\n",
      "         [ -5.3009,  -5.1757,  -5.3833,  ...,  -5.6708,  -5.8755,  -1.2004],\n",
      "         [ -5.7963,  -5.7319,  -5.7841,  ...,  -6.1122,  -6.0048,  -1.9888]],\n",
      "\n",
      "        [[ -7.4859,  -7.5768,  -7.5040,  ...,  -7.1913,  -6.3137,  -3.9418],\n",
      "         [ -7.4422,  -7.5915,  -7.5667,  ...,  -7.9408,  -7.9656,  -8.4665],\n",
      "         [-10.2603,  -9.3018,  -9.9979,  ...,  -8.0188,  -8.5604, -10.0291],\n",
      "         ...,\n",
      "         [ -2.7672,  -2.8632,  -2.8138,  ...,  -2.7089,  -5.1776,  -1.1809],\n",
      "         [-11.0214, -11.1650, -11.2043,  ..., -11.2427, -11.6388,  -6.7719],\n",
      "         [-10.7279, -10.5954, -11.2040,  ..., -10.3723,  -9.1822,  -7.4765]],\n",
      "\n",
      "        [[ -6.9568,  -6.9530,  -6.9358,  ...,  -6.2229,  -5.9860,  -4.4514],\n",
      "         [-11.6088, -11.7187, -11.4314,  ..., -11.5533,  -9.8472, -11.6230],\n",
      "         [ -4.9187,  -4.9527,  -4.9576,  ...,  -5.4069,  -5.2583,  -5.0751],\n",
      "         ...,\n",
      "         [ -7.5470,  -7.5488,  -7.5604,  ...,  -7.6989,  -7.4391,  -7.1561],\n",
      "         [ -6.3597,  -6.6195,  -6.6194,  ...,  -6.7693,  -6.8615,  -4.6345],\n",
      "         [ -6.7811,  -6.7802,  -6.8379,  ...,  -7.2519,  -7.1399,  -5.4903]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7019,  -6.7238,  -6.7287,  ...,  -6.0513,  -5.6590,  -3.9829],\n",
      "         [-12.4862, -12.4855, -12.1771,  ..., -10.7461, -10.2492, -10.2231],\n",
      "         [ -5.5962,  -5.6761,  -5.6367,  ...,  -6.2355,  -7.1477,  -2.9453],\n",
      "         ...,\n",
      "         [ -5.9874,  -6.1208,  -6.0934,  ...,  -6.4171,  -7.1215,  -3.3151],\n",
      "         [ -5.2696,  -5.4070,  -5.3847,  ...,  -5.4241,  -6.6251,  -2.6355],\n",
      "         [ -5.7901,  -5.9367,  -5.7916,  ...,  -5.2002,  -6.8468,  -3.9687]],\n",
      "\n",
      "        [[ -6.6581,  -6.6206,  -6.6357,  ...,  -6.1386,  -5.9295,  -3.1292],\n",
      "         [ -6.0178,  -5.9937,  -6.1369,  ...,  -6.9496,  -6.0404,  -2.2609],\n",
      "         [ -7.0384,  -7.0048,  -7.2152,  ...,  -7.7164,  -6.3925,  -3.7295],\n",
      "         ...,\n",
      "         [ -5.5583,  -5.4694,  -5.6130,  ...,  -6.0407,  -5.3975,  -1.7212],\n",
      "         [ -5.5132,  -5.5034,  -5.5555,  ...,  -6.3216,  -5.2329,  -1.8194],\n",
      "         [ -5.8091,  -5.7140,  -5.8753,  ...,  -6.5888,  -5.6478,  -1.9573]],\n",
      "\n",
      "        [[ -6.7965,  -6.7846,  -6.7796,  ...,  -6.1043,  -6.0462,  -3.8068],\n",
      "         [ -5.9988,  -5.8006,  -6.0506,  ...,  -6.9151,  -6.6175,  -2.3468],\n",
      "         [ -5.6244,  -5.5712,  -5.6918,  ...,  -6.4453,  -5.7569,  -2.2071],\n",
      "         ...,\n",
      "         [ -5.4611,  -5.4077,  -5.3836,  ...,  -5.5182,  -5.7983,  -1.4739],\n",
      "         [ -6.3959,  -6.3446,  -6.4833,  ...,  -6.5491,  -6.4962,  -3.0412],\n",
      "         [ -5.5545,  -5.5112,  -5.6600,  ...,  -6.1661,  -5.6781,  -2.4381]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0762643814086914\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5559, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6884,  -6.6611,  -6.6642,  ...,  -5.9990,  -5.6814,  -3.8645],\n",
      "         [-11.3979, -11.1274, -11.3246,  ...,  -8.6268,  -9.0124, -10.7152],\n",
      "         [ -6.1512,  -6.2117,  -6.2658,  ...,  -6.0073,  -6.0937,  -2.3791],\n",
      "         ...,\n",
      "         [ -5.7571,  -5.7582,  -5.9009,  ...,  -5.4345,  -5.1452,  -1.9400],\n",
      "         [ -6.2877,  -6.1727,  -6.3995,  ...,  -5.7815,  -6.5837,  -2.2019],\n",
      "         [ -6.5645,  -6.6266,  -6.7439,  ...,  -6.3962,  -6.4302,  -1.7837]],\n",
      "\n",
      "        [[ -6.5916,  -6.5472,  -6.5765,  ...,  -5.9112,  -5.8675,  -4.0233],\n",
      "         [-11.1280, -10.9347, -10.9040,  ...,  -7.6477,  -8.6826,  -8.9822],\n",
      "         [ -5.9438,  -6.1981,  -6.1292,  ...,  -5.5939,  -7.2334,  -3.1423],\n",
      "         ...,\n",
      "         [ -5.3212,  -5.3636,  -5.3747,  ...,  -4.4458,  -6.0459,  -2.6845],\n",
      "         [ -5.8025,  -5.9489,  -5.8672,  ...,  -5.1691,  -6.7714,  -3.2123],\n",
      "         [ -5.8610,  -5.8983,  -5.9986,  ...,  -5.0523,  -6.5323,  -2.8635]],\n",
      "\n",
      "        [[ -6.8633,  -6.8551,  -6.8260,  ...,  -6.0344,  -5.9754,  -3.3857],\n",
      "         [-11.3486, -11.5843, -11.5963,  ..., -11.6238,  -9.2638,  -4.1845],\n",
      "         [ -5.7914,  -6.5490,  -5.8253,  ...,  -6.2146,  -4.3696,  -2.7133],\n",
      "         ...,\n",
      "         [ -7.9129,  -7.9400,  -7.9362,  ...,  -8.0516,  -7.0782,  -3.2328],\n",
      "         [ -7.2284,  -7.3428,  -7.2267,  ...,  -7.8574,  -6.2110,  -2.4458],\n",
      "         [ -8.3596,  -8.5159,  -8.4013,  ...,  -9.0004,  -7.1978,  -2.4098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6440,  -6.6601,  -6.5841,  ...,  -6.3097,  -5.5210,  -3.8624],\n",
      "         [ -8.9108,  -8.7653,  -9.0232,  ...,  -9.9423,  -7.0848,  -6.3399],\n",
      "         [-15.3505, -15.7008, -15.7283,  ..., -15.3147, -13.3314, -11.4532],\n",
      "         ...,\n",
      "         [ -8.8877,  -9.1153,  -9.0714,  ...,  -8.5853,  -7.9234,  -7.0723],\n",
      "         [ -6.9323,  -6.6396,  -6.5011,  ...,  -6.4537,  -6.1925,  -3.5196],\n",
      "         [-12.7104, -12.7381, -12.8847,  ..., -10.9913,  -9.5600,  -5.2598]],\n",
      "\n",
      "        [[ -7.2087,  -7.2712,  -7.1905,  ...,  -6.6042,  -6.5407,  -3.7770],\n",
      "         [-14.0188, -13.6899, -14.1172,  ..., -11.1555, -11.8149,  -9.6444],\n",
      "         [ -5.6407,  -5.8547,  -5.7553,  ...,  -5.3247,  -7.1543,  -2.1163],\n",
      "         ...,\n",
      "         [ -5.9495,  -6.1318,  -6.0220,  ...,  -5.8583,  -6.9862,  -2.3404],\n",
      "         [ -5.4901,  -5.7095,  -5.6139,  ...,  -5.9378,  -7.1615,  -1.6804],\n",
      "         [ -5.8667,  -6.1358,  -5.9697,  ...,  -5.6358,  -7.2982,  -2.9354]],\n",
      "\n",
      "        [[ -6.7646,  -6.6938,  -6.7059,  ...,  -5.7807,  -6.0358,  -4.0146],\n",
      "         [ -9.3561,  -9.2955,  -9.3476,  ...,  -7.9823,  -8.3023,  -6.7534],\n",
      "         [ -5.2834,  -5.2302,  -5.5950,  ...,  -6.3280,  -6.4626,  -4.3789],\n",
      "         ...,\n",
      "         [ -7.1447,  -7.2703,  -7.2055,  ...,  -6.4794,  -7.1706,  -3.5114],\n",
      "         [ -6.6842,  -7.0030,  -6.8610,  ...,  -6.7967,  -6.6500,  -5.9470],\n",
      "         [ -7.2686,  -7.5678,  -7.5149,  ...,  -6.6432,  -7.1236,  -5.4741]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.5559002161026\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0211, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2085,  -7.1815,  -7.2065,  ...,  -6.6795,  -6.4018,  -4.7305],\n",
      "         [ -7.7496,  -7.8250,  -7.5640,  ...,  -8.6008,  -7.6803,  -8.4060],\n",
      "         [ -9.3906,  -9.7193,  -9.6964,  ..., -10.2747,  -9.5807, -10.1371],\n",
      "         ...,\n",
      "         [ -8.7873,  -9.1660,  -9.3283,  ...,  -7.8327,  -7.7693, -10.0273],\n",
      "         [-11.9564, -11.7651, -11.5706,  ..., -11.8925,  -9.5981,  -8.0953],\n",
      "         [-12.5972, -12.5281, -12.6143,  ..., -14.0904, -11.5220,  -9.2295]],\n",
      "\n",
      "        [[ -6.6436,  -6.6392,  -6.6388,  ...,  -5.9641,  -5.6820,  -3.7174],\n",
      "         [-11.4875, -11.2756, -11.2502,  ...,  -9.5133,  -9.7608,  -9.1421],\n",
      "         [ -6.0296,  -6.1242,  -6.3447,  ...,  -6.0160,  -7.0043,  -4.3492],\n",
      "         ...,\n",
      "         [ -4.8891,  -5.0326,  -5.1047,  ...,  -4.2693,  -5.9600,  -4.0077],\n",
      "         [ -5.5919,  -5.7028,  -5.7805,  ...,  -5.4059,  -6.3712,  -3.6467],\n",
      "         [ -5.8894,  -6.0728,  -5.9813,  ...,  -5.5519,  -6.1898,  -4.1449]],\n",
      "\n",
      "        [[ -7.2465,  -7.2481,  -7.1900,  ...,  -6.6515,  -6.2898,  -4.7809],\n",
      "         [ -8.3052,  -8.4679,  -8.2074,  ...,  -7.1713,  -5.5154,  -7.2871],\n",
      "         [ -9.8561,  -9.9720,  -9.9268,  ...,  -7.1966,  -6.5621,  -9.4477],\n",
      "         ...,\n",
      "         [ -4.8284,  -5.1141,  -4.8541,  ...,  -4.5634,  -5.7097,  -1.8192],\n",
      "         [-13.1988, -13.7480, -13.5069,  ..., -12.7844, -10.6200,  -9.6302],\n",
      "         [-11.5425, -11.1625, -11.5040,  ...,  -8.9555,  -7.9954, -10.5010]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7212,  -6.6724,  -6.6869,  ...,  -6.0953,  -5.8280,  -3.9315],\n",
      "         [-12.1573, -11.5170, -11.8409,  ...,  -9.2004,  -9.4506, -10.8091],\n",
      "         [ -6.3226,  -6.3305,  -6.4014,  ...,  -6.0383,  -7.0425,  -2.3111],\n",
      "         ...,\n",
      "         [ -5.2437,  -5.2822,  -5.3244,  ...,  -5.2335,  -5.9773,  -2.6590],\n",
      "         [ -5.1245,  -5.1852,  -5.1632,  ...,  -5.0836,  -6.0987,  -2.7553],\n",
      "         [ -5.5089,  -5.5071,  -5.5898,  ...,  -5.3621,  -5.9384,  -2.5138]],\n",
      "\n",
      "        [[ -6.3417,  -6.3900,  -6.4146,  ...,  -5.8214,  -5.5329,  -3.2755],\n",
      "         [ -6.5058,  -6.4779,  -6.6122,  ...,  -7.3479,  -6.1199,  -3.4529],\n",
      "         [ -4.9979,  -4.9989,  -5.0961,  ...,  -5.3279,  -5.3202,  -1.8814],\n",
      "         ...,\n",
      "         [ -5.3444,  -5.3060,  -5.3375,  ...,  -5.6672,  -5.2265,  -1.6730],\n",
      "         [ -5.2430,  -5.1886,  -5.2308,  ...,  -5.9712,  -5.4035,  -1.9349],\n",
      "         [ -5.5271,  -5.4966,  -5.5857,  ...,  -5.8610,  -5.2581,  -1.9114]],\n",
      "\n",
      "        [[ -6.7987,  -6.6813,  -6.5218,  ...,  -6.4486,  -5.0072,  -3.5148],\n",
      "         [-13.1052, -13.0080, -12.9638,  ..., -11.1514, -10.3619,  -9.8649],\n",
      "         [ -7.1432,  -7.1196,  -7.2087,  ...,  -7.2974,  -7.2935,  -2.7993],\n",
      "         ...,\n",
      "         [ -7.7997,  -7.7780,  -7.8110,  ...,  -7.6708,  -7.6686,  -4.0599],\n",
      "         [ -7.6038,  -7.5884,  -7.6503,  ...,  -7.7573,  -7.4394,  -3.7779],\n",
      "         [ -6.8430,  -6.8093,  -6.7840,  ...,  -6.8680,  -6.6955,  -3.4167]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.0210745334625244\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4440, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.6282,  -9.8239,  -9.6299,  ...,  -9.3729,  -8.8937,  -4.8712],\n",
      "         [ -9.9203,  -9.6247,  -9.9816,  ...,  -7.9795,  -8.2492,  -8.1038],\n",
      "         [ -5.9965,  -6.0873,  -5.9811,  ...,  -6.2243,  -6.9140,  -2.2432],\n",
      "         ...,\n",
      "         [ -5.3387,  -5.4422,  -5.3212,  ...,  -5.1300,  -6.3456,  -2.8645],\n",
      "         [ -6.0534,  -6.2366,  -6.0516,  ...,  -6.0147,  -7.1816,  -2.2291],\n",
      "         [ -6.0634,  -6.2528,  -6.0533,  ...,  -5.4642,  -6.3152,  -2.6103]],\n",
      "\n",
      "        [[ -6.7512,  -6.7608,  -6.7328,  ...,  -6.0344,  -5.8711,  -3.9534],\n",
      "         [-12.0812, -11.7243, -12.0527,  ...,  -9.3300,  -9.2994, -11.7600],\n",
      "         [ -5.2038,  -5.4774,  -5.3495,  ...,  -5.7037,  -6.6196,  -2.9375],\n",
      "         ...,\n",
      "         [ -5.7810,  -5.8878,  -5.7997,  ...,  -5.9074,  -6.6984,  -3.7391],\n",
      "         [ -5.8167,  -5.9184,  -5.9699,  ...,  -5.9291,  -6.6471,  -3.3372],\n",
      "         [ -6.1895,  -6.3153,  -6.2424,  ...,  -5.9028,  -6.7176,  -3.9163]],\n",
      "\n",
      "        [[ -7.8038,  -7.8069,  -7.7249,  ...,  -7.3013,  -6.7576,  -4.0051],\n",
      "         [-14.0855, -14.6605, -14.4976,  ..., -13.9182, -11.2339,  -8.7326],\n",
      "         [ -6.8488,  -7.1456,  -7.5907,  ...,  -8.4530,  -7.8510,   1.3679],\n",
      "         ...,\n",
      "         [ -6.9467,  -7.1829,  -7.1724,  ...,  -7.5295,  -6.0595,  -4.4516],\n",
      "         [ -7.4061,  -7.5378,  -7.6652,  ...,  -7.7174,  -6.5374,  -4.6461],\n",
      "         [ -8.1183,  -8.2821,  -8.3417,  ...,  -8.4942,  -7.1229,  -4.9036]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6546,  -7.5619,  -7.5654,  ...,  -6.7746,  -6.5171,  -4.4332],\n",
      "         [ -5.3418,  -5.6950,  -5.5661,  ...,  -6.2253,  -3.2998,  -3.9564],\n",
      "         [ -6.2946,  -6.5384,  -6.3871,  ...,  -6.0453,  -5.2491,  -3.6485],\n",
      "         ...,\n",
      "         [ -6.9410,  -7.1218,  -7.0382,  ...,  -7.6728,  -5.0784,  -6.5301],\n",
      "         [ -7.1639,  -7.4318,  -7.3531,  ...,  -7.0126,  -6.2079,  -5.0227],\n",
      "         [-13.0957, -12.9615, -13.3757,  ..., -11.8472,  -9.8902, -10.3318]],\n",
      "\n",
      "        [[ -7.2877,  -7.2875,  -7.2271,  ...,  -6.6142,  -6.4088,  -4.3219],\n",
      "         [-10.9045, -10.6372, -10.9823,  ..., -10.9254,  -9.3024,  -8.0520],\n",
      "         [ -9.3870,  -8.9093,  -9.5097,  ..., -10.1200,  -8.4788,  -6.1513],\n",
      "         ...,\n",
      "         [ -3.5423,  -3.4032,  -3.3901,  ...,  -3.1163,  -4.3419,  -2.4351],\n",
      "         [ -4.7245,  -4.5933,  -4.5717,  ...,  -4.0274,  -4.9922,  -2.0517],\n",
      "         [ -5.7638,  -5.6637,  -5.7056,  ...,  -5.2406,  -5.7052,  -3.2601]],\n",
      "\n",
      "        [[ -6.7514,  -6.7298,  -6.5927,  ...,  -5.7816,  -5.7028,  -3.0721],\n",
      "         [ -8.8492,  -8.8609,  -8.6389,  ...,  -8.0648,  -7.5636,  -7.3608],\n",
      "         [-10.0316, -10.1122,  -9.3837,  ...,  -9.5660,  -8.2701,  -8.1794],\n",
      "         ...,\n",
      "         [ -8.2511,  -8.4931,  -8.0882,  ...,  -8.0739,  -4.5848,  -1.7965],\n",
      "         [ -6.6619,  -6.7921,  -6.6249,  ...,  -6.4446,  -5.5594,  -4.4464],\n",
      "         [-12.2635, -12.0553, -12.4161,  ...,  -9.8947, -10.2365,  -8.3840]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.4440321922302246\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2035, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9989,  -6.9440,  -6.9172,  ...,  -6.2412,  -6.1712,  -3.9858],\n",
      "         [ -9.1370,  -8.8516,  -8.8668,  ...,  -8.1819,  -9.6317,  -5.1138],\n",
      "         [ -7.1710,  -7.2350,  -7.4991,  ...,  -6.5362,  -6.2870,  -4.6227],\n",
      "         ...,\n",
      "         [ -6.7174,  -6.6691,  -6.7663,  ...,  -5.9605,  -6.3275,  -4.0864],\n",
      "         [ -4.9250,  -5.0279,  -4.9153,  ...,  -4.7533,  -5.2007,  -0.9025],\n",
      "         [ -6.6959,  -6.7306,  -6.9190,  ...,  -6.3894,  -6.5130,  -3.8519]],\n",
      "\n",
      "        [[ -7.5303,  -7.5032,  -7.4807,  ...,  -6.7268,  -6.5612,  -4.1298],\n",
      "         [-15.3952, -14.9489, -15.0172,  ..., -14.4904, -12.8183,  -9.8269],\n",
      "         [ -8.7261,  -8.7418,  -8.8513,  ...,  -8.9272,  -8.7096,  -5.4785],\n",
      "         ...,\n",
      "         [-13.5256, -13.5694, -13.2745,  ..., -12.5028, -10.6529, -11.0332],\n",
      "         [ -5.8364,  -5.9348,  -5.8858,  ...,  -5.9469,  -4.8643,  -1.4097],\n",
      "         [-14.7715, -14.8775, -14.6457,  ..., -12.7990, -11.0854, -11.3923]],\n",
      "\n",
      "        [[ -7.5865,  -7.7267,  -7.5971,  ...,  -6.9317,  -6.7113,  -5.2238],\n",
      "         [ -6.6450,  -7.0885,  -7.3053,  ...,  -8.5735,  -6.2477, -11.0245],\n",
      "         [ -7.3097,  -7.8771,  -7.9776,  ...,  -8.7962,  -7.7027,  -8.5726],\n",
      "         ...,\n",
      "         [ -4.4712,  -4.4488,  -4.4160,  ...,  -4.5618,  -5.2919,  -4.1663],\n",
      "         [ -4.1236,  -4.3469,  -3.9138,  ...,  -3.9853,  -2.9935,  -5.3342],\n",
      "         [ -6.6274,  -6.6502,  -6.6827,  ...,  -6.6985,  -6.1153,  -5.2091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.5209,  -7.4298,  -7.4187,  ...,  -6.5779,  -6.6079,  -4.1840],\n",
      "         [ -9.6682,  -9.9149,  -9.8963,  ...,  -9.1746,  -8.8582,  -6.6142],\n",
      "         [-14.2727, -14.0009, -13.8654,  ..., -10.4055, -11.1511,  -9.4817],\n",
      "         ...,\n",
      "         [ -6.3500,  -6.4314,  -6.2825,  ...,  -6.8799,  -5.9606,  -5.4039],\n",
      "         [ -5.3354,  -5.2549,  -5.2698,  ...,  -5.8658,  -5.8345,  -6.1949],\n",
      "         [ -7.1512,  -7.0952,  -7.0959,  ...,  -7.7493,  -6.2095,  -5.2344]],\n",
      "\n",
      "        [[ -8.8110,  -9.0917,  -8.8737,  ...,  -8.3846,  -8.5771,  -6.5852],\n",
      "         [-10.3989,  -9.8618, -10.2486,  ...,  -8.2738,  -7.6402, -11.3463],\n",
      "         [ -5.5699,  -5.6188,  -5.6253,  ...,  -6.0596,  -7.3310,  -4.1330],\n",
      "         ...,\n",
      "         [ -5.6785,  -5.7335,  -5.7116,  ...,  -5.6089,  -5.9390,  -4.1588],\n",
      "         [ -5.8804,  -5.7295,  -5.8635,  ...,  -6.0104,  -6.6673,  -5.2323],\n",
      "         [ -5.5264,  -5.5341,  -5.5442,  ...,  -6.0158,  -6.1451,  -4.1949]],\n",
      "\n",
      "        [[ -7.2062,  -7.2600,  -7.2167,  ...,  -6.6626,  -6.6818,  -4.3435],\n",
      "         [ -7.0995,  -7.2451,  -7.3022,  ...,  -6.7359,  -6.1017,  -5.5154],\n",
      "         [-10.4156, -10.1329, -10.3649,  ...,  -8.8668,  -8.1968,  -4.8674],\n",
      "         ...,\n",
      "         [-12.4227, -11.9684, -12.3480,  ...,  -9.8855,  -8.9240,  -8.5239],\n",
      "         [ -6.2658,  -6.6339,  -6.5220,  ...,  -6.4978,  -6.0351,  -6.1077],\n",
      "         [-15.8981, -16.4124, -16.3516,  ..., -15.0459, -13.9013, -11.8023]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2034976482391357\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.9271, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4398,  -6.4057,  -6.4057,  ...,  -5.7346,  -5.5424,  -3.7813],\n",
      "         [-11.2506, -11.1847, -11.2525,  ...,  -7.9520,  -9.3429,  -9.9476],\n",
      "         [ -5.8089,  -6.1026,  -6.0418,  ...,  -5.9421,  -7.0648,  -2.9199],\n",
      "         ...,\n",
      "         [ -6.2505,  -6.2946,  -6.3267,  ...,  -6.2133,  -7.2025,  -2.6324],\n",
      "         [ -5.1361,  -5.1217,  -5.1265,  ...,  -5.1426,  -6.7551,  -3.2911],\n",
      "         [ -5.4442,  -5.6025,  -5.4517,  ...,  -5.6612,  -6.4206,  -3.3254]],\n",
      "\n",
      "        [[ -6.8560,  -6.8412,  -6.8927,  ...,  -6.2926,  -6.2164,  -3.6114],\n",
      "         [ -7.0485,  -7.0326,  -7.1887,  ...,  -7.5375,  -6.6566,  -3.2950],\n",
      "         [ -6.1696,  -6.1584,  -6.3316,  ...,  -6.5248,  -5.9348,  -2.4667],\n",
      "         ...,\n",
      "         [ -5.6967,  -5.5955,  -5.7699,  ...,  -5.8275,  -5.5835,  -1.3948],\n",
      "         [ -5.9361,  -5.8667,  -5.9801,  ...,  -6.1789,  -5.4745,  -2.0523],\n",
      "         [ -5.7993,  -5.8435,  -5.9390,  ...,  -5.9018,  -5.8007,  -2.1138]],\n",
      "\n",
      "        [[ -6.5956,  -6.5556,  -6.5836,  ...,  -5.8626,  -5.7018,  -3.8335],\n",
      "         [-11.8811, -11.7852, -11.8608,  ...,  -9.7975, -10.8152,  -7.8436],\n",
      "         [ -5.8859,  -5.9263,  -5.9236,  ...,  -6.0190,  -7.0243,  -2.1617],\n",
      "         ...,\n",
      "         [ -6.2275,  -6.3104,  -6.2945,  ...,  -6.1638,  -7.0316,  -2.2651],\n",
      "         [ -6.3161,  -6.3268,  -6.4439,  ...,  -6.6468,  -6.8967,  -2.8828],\n",
      "         [ -5.8102,  -5.8894,  -5.8637,  ...,  -6.0082,  -6.4097,  -2.4872]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6424,  -6.4737,  -6.6424,  ...,  -5.6293,  -5.9006,  -3.2351],\n",
      "         [-11.8209, -11.5770, -11.9350,  ..., -10.9975,  -9.9038,  -7.1378],\n",
      "         [ -3.9735,  -4.0583,  -3.9734,  ...,  -4.5223,  -5.5370,  -2.4079],\n",
      "         ...,\n",
      "         [ -5.4037,  -5.4756,  -5.4560,  ...,  -5.0549,  -6.1610,  -3.8405],\n",
      "         [ -4.9296,  -5.0569,  -5.0254,  ...,  -5.5270,  -6.2598,  -3.3585],\n",
      "         [ -5.5821,  -5.6774,  -5.5692,  ...,  -5.2421,  -6.1563,  -3.5703]],\n",
      "\n",
      "        [[ -7.0005,  -6.9850,  -7.0038,  ...,  -6.4744,  -6.3280,  -4.2507],\n",
      "         [-12.7993, -12.4284, -13.0520,  ..., -11.8605, -11.1294, -13.9968],\n",
      "         [ -6.6133,  -6.6663,  -6.7005,  ...,  -6.9613,  -6.7553,  -4.2132],\n",
      "         ...,\n",
      "         [ -6.4835,  -6.4395,  -6.5069,  ...,  -6.9406,  -6.5409,  -5.1015],\n",
      "         [ -6.9469,  -6.9712,  -7.0551,  ...,  -6.8658,  -6.7367,  -5.2369],\n",
      "         [ -6.2711,  -6.3207,  -6.2666,  ...,  -6.3957,  -6.1523,  -4.2442]],\n",
      "\n",
      "        [[ -6.2992,  -6.3113,  -6.3260,  ...,  -6.1923,  -5.5562,  -3.6404],\n",
      "         [ -6.3888,  -6.3539,  -6.5047,  ...,  -7.2472,  -6.4100,  -2.3075],\n",
      "         [ -5.8188,  -5.7983,  -5.9180,  ...,  -7.0946,  -6.0165,  -2.8913],\n",
      "         ...,\n",
      "         [ -5.6453,  -5.5598,  -5.7626,  ...,  -5.7584,  -5.4119,  -2.2919],\n",
      "         [ -5.3998,  -5.4078,  -5.4930,  ...,  -5.8428,  -5.6208,  -2.2036],\n",
      "         [ -5.3469,  -5.2840,  -5.3786,  ...,  -5.8767,  -5.2213,  -2.4611]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.927055835723877\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.9431, grad_fn=<NllLossBackward0>), logits=tensor([[[ -5.7486,  -5.7419,  -5.6976,  ...,  -5.2420,  -5.2244,  -3.1106],\n",
      "         [-12.3261, -11.7439, -11.7432,  ..., -11.0571,  -9.3299, -11.7744],\n",
      "         [ -5.3376,  -5.4778,  -5.5637,  ...,  -5.6168,  -6.7276,  -3.0382],\n",
      "         ...,\n",
      "         [ -5.7259,  -5.9313,  -5.9240,  ...,  -5.8811,  -6.9159,  -2.5320],\n",
      "         [ -6.0140,  -6.0798,  -6.2034,  ...,  -6.3224,  -6.4994,  -4.1075],\n",
      "         [ -5.6871,  -5.9014,  -5.9161,  ...,  -5.5053,  -6.5486,  -3.4678]],\n",
      "\n",
      "        [[ -7.0539,  -7.0355,  -7.0047,  ...,  -6.2715,  -6.3291,  -3.8865],\n",
      "         [ -7.2314,  -7.3572,  -7.3623,  ...,  -8.0941,  -6.5798,  -3.9942],\n",
      "         [ -7.1643,  -7.3865,  -7.3985,  ...,  -7.8584,  -6.7859,  -3.5941],\n",
      "         ...,\n",
      "         [ -6.3692,  -6.3606,  -6.4368,  ...,  -6.2946,  -6.0145,  -2.2686],\n",
      "         [ -5.6323,  -5.6343,  -5.7274,  ...,  -5.9074,  -5.5023,  -1.0885],\n",
      "         [ -6.1019,  -6.0925,  -6.0994,  ...,  -6.3330,  -5.9263,  -1.9265]],\n",
      "\n",
      "        [[ -7.8634,  -7.8254,  -7.7711,  ...,  -6.8122,  -6.7267,  -3.7983],\n",
      "         [-13.7234, -13.9018, -13.6611,  ..., -10.6329, -10.3627,  -9.9110],\n",
      "         [ -9.1616,  -9.7208,  -9.4099,  ...,  -8.5051,  -8.3074,  -7.7408],\n",
      "         ...,\n",
      "         [ -8.6821,  -8.8289,  -8.5986,  ...,  -8.8750,  -6.9785,  -4.3627],\n",
      "         [ -7.8866,  -8.0365,  -7.8071,  ...,  -8.0631,  -6.5673,  -3.7619],\n",
      "         [ -7.9468,  -8.1057,  -7.8541,  ...,  -8.1578,  -6.9864,  -4.2374]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.9253,  -7.8584,  -7.8444,  ...,  -7.1378,  -7.0193,  -4.4928],\n",
      "         [-13.2313, -12.8516, -12.8491,  ..., -11.7553, -10.4611,  -9.8321],\n",
      "         [-10.6872, -10.3242, -10.3435,  ..., -10.2399,  -9.8889,  -5.7539],\n",
      "         ...,\n",
      "         [ -5.3525,  -5.2489,  -5.1692,  ...,  -5.1098,  -5.3214,  -5.5308],\n",
      "         [ -4.7172,  -4.6924,  -4.7273,  ...,  -4.9347,  -4.9815,  -5.0529],\n",
      "         [ -6.7309,  -6.7512,  -6.6731,  ...,  -7.0657,  -6.4885,  -4.6100]],\n",
      "\n",
      "        [[ -6.5107,  -6.4777,  -6.4983,  ...,  -5.9224,  -5.6287,  -3.8861],\n",
      "         [ -9.5982,  -8.9210,  -9.4934,  ...,  -7.6936,  -7.1080,  -9.1577],\n",
      "         [ -6.6424,  -6.7613,  -6.7393,  ...,  -6.8720,  -6.8117,  -3.5638],\n",
      "         ...,\n",
      "         [ -7.2274,  -7.4354,  -7.2511,  ...,  -7.4832,  -6.5416,  -4.6586],\n",
      "         [ -7.1603,  -7.1898,  -7.2033,  ...,  -7.5622,  -6.7973,  -4.5348],\n",
      "         [ -5.9382,  -6.0079,  -6.0125,  ...,  -5.9700,  -5.6126,  -3.1331]],\n",
      "\n",
      "        [[ -6.8529,  -6.8469,  -6.7871,  ...,  -6.0489,  -6.2272,  -3.8823],\n",
      "         [ -9.2358,  -9.1494,  -9.4476,  ...,  -8.6757,  -8.3278, -10.1864],\n",
      "         [ -6.2982,  -6.1142,  -6.6540,  ...,  -6.0242,  -6.7182,  -5.7585],\n",
      "         ...,\n",
      "         [ -5.1118,  -5.1163,  -5.2051,  ...,  -5.1714,  -5.8272,  -3.3271],\n",
      "         [ -5.4062,  -5.3626,  -5.4998,  ...,  -6.3056,  -5.7020,  -5.7693],\n",
      "         [ -4.2727,  -4.3406,  -4.3064,  ...,  -4.8501,  -4.9968,  -2.0998]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.9430533647537231\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4002, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5048,  -6.3855,  -6.3524,  ...,  -5.9273,  -5.8009,  -3.5156],\n",
      "         [ -7.0391,  -6.8974,  -6.9458,  ...,  -7.2661,  -6.5780,  -3.0192],\n",
      "         [ -5.2537,  -4.9849,  -5.0998,  ...,  -5.9748,  -5.5005,  -1.6499],\n",
      "         ...,\n",
      "         [ -5.8123,  -5.7717,  -5.7031,  ...,  -6.3067,  -5.9055,  -2.1705],\n",
      "         [ -5.5979,  -5.5166,  -5.5967,  ...,  -5.8541,  -5.8504,  -1.1424],\n",
      "         [ -5.6436,  -5.5103,  -5.6561,  ...,  -5.8882,  -5.8783,  -1.1633]],\n",
      "\n",
      "        [[ -6.7749,  -6.7599,  -6.7516,  ...,  -6.1019,  -6.0476,  -3.5569],\n",
      "         [ -6.7437,  -6.6899,  -6.7638,  ...,  -7.2625,  -6.5611,  -2.4452],\n",
      "         [ -6.7860,  -6.7426,  -6.8485,  ...,  -7.2549,  -6.4472,  -2.4990],\n",
      "         ...,\n",
      "         [ -6.2807,  -6.2895,  -6.3551,  ...,  -6.4084,  -5.9904,  -2.3009],\n",
      "         [ -5.6262,  -5.6398,  -5.7031,  ...,  -6.0096,  -5.7310,  -1.7275],\n",
      "         [ -5.6541,  -5.7601,  -5.8010,  ...,  -6.2591,  -5.4603,  -1.3597]],\n",
      "\n",
      "        [[ -7.5958,  -7.6444,  -7.5538,  ...,  -6.9355,  -6.6114,  -4.7000],\n",
      "         [-15.3491, -15.0291, -15.3143,  ..., -12.9223, -11.8372, -13.9309],\n",
      "         [ -8.9478,  -9.0910,  -9.0749,  ...,  -8.3558,  -9.9501,  -9.2575],\n",
      "         ...,\n",
      "         [ -6.1131,  -6.0606,  -6.1519,  ...,  -6.2589,  -6.4693,  -3.7589],\n",
      "         [ -5.7860,  -5.6482,  -5.6770,  ...,  -5.7790,  -6.1260,  -5.2511],\n",
      "         [ -4.3120,  -4.2164,  -4.3106,  ...,  -4.5514,  -4.3679,  -2.5739]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1623,  -7.1373,  -7.1561,  ...,  -6.5223,  -6.5158,  -3.6564],\n",
      "         [-14.3598, -14.0240, -14.1381,  ..., -12.8252, -11.6653, -10.4791],\n",
      "         [-10.1334, -10.1569, -10.1064,  ...,  -9.5424,  -8.0976,  -3.8641],\n",
      "         ...,\n",
      "         [-14.9787, -14.7957, -14.6457,  ..., -13.2590, -11.9173, -10.3089],\n",
      "         [-10.9516, -11.3680, -11.1390,  ...,  -9.9107,  -9.5606,  -4.8615],\n",
      "         [-16.2650, -16.3977, -16.3040,  ..., -15.8118, -12.7581,  -7.7439]],\n",
      "\n",
      "        [[ -7.4683,  -7.5184,  -7.4486,  ...,  -6.8576,  -6.6721,  -4.0369],\n",
      "         [-10.6809, -10.4750, -10.8197,  ...,  -9.7799,  -8.9339,  -9.3695],\n",
      "         [ -6.6393,  -6.8353,  -6.6589,  ...,  -6.9726,  -5.3576,  -5.0001],\n",
      "         ...,\n",
      "         [ -3.5911,  -3.8300,  -3.6112,  ...,  -4.2655,  -4.8012,  -5.2132],\n",
      "         [ -7.4601,  -7.5350,  -7.5778,  ...,  -7.4956,  -7.1056,  -5.1038],\n",
      "         [-15.0846, -14.5248, -15.0422,  ..., -13.8820, -12.4882, -12.3496]],\n",
      "\n",
      "        [[ -7.3515,  -7.2484,  -7.2683,  ...,  -6.5159,  -6.2597,  -4.1821],\n",
      "         [ -8.8111,  -8.7918,  -8.9296,  ...,  -7.9272,  -8.0324,  -6.8273],\n",
      "         [ -7.7170,  -7.8667,  -7.6696,  ...,  -6.5319,  -3.7692,  -4.3110],\n",
      "         ...,\n",
      "         [ -8.9990,  -9.0524,  -8.9748,  ...,  -7.0447,  -7.4603,  -8.0292],\n",
      "         [ -6.4147,  -6.5191,  -6.4713,  ...,  -5.1644,  -4.8375,  -6.0149],\n",
      "         [ -7.2897,  -7.3922,  -7.3534,  ...,  -6.6898,  -6.3399,  -5.4497]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.4001954793930054\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2895, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.0413,  -8.0144,  -7.9364,  ...,  -7.6682,  -7.1060,  -5.3310],\n",
      "         [-12.3568, -12.5352, -12.2778,  ..., -12.6054, -11.2120,  -9.5193],\n",
      "         [ -9.4089,  -9.0040,  -8.9941,  ...,  -9.3088,  -8.7568,  -9.5213],\n",
      "         ...,\n",
      "         [ -5.5893,  -5.6510,  -5.5699,  ...,  -6.7263,  -6.2930,  -6.3671],\n",
      "         [ -5.1642,  -5.3079,  -5.3799,  ...,  -6.8401,  -5.8544,  -5.0008],\n",
      "         [ -6.4214,  -6.4071,  -6.5068,  ...,  -7.4092,  -6.2219,  -5.2247]],\n",
      "\n",
      "        [[ -6.3997,  -6.3682,  -6.3796,  ...,  -5.6791,  -5.6232,  -3.7478],\n",
      "         [ -6.9924,  -7.0724,  -7.1481,  ...,  -6.8614,  -5.3216,  -6.0222],\n",
      "         [ -5.9828,  -6.0692,  -5.9311,  ...,  -4.7815,  -5.5726,  -1.4796],\n",
      "         ...,\n",
      "         [ -6.0344,  -6.0328,  -5.9479,  ...,  -5.2345,  -5.6130,  -3.1854],\n",
      "         [ -5.6439,  -5.7584,  -5.7513,  ...,  -5.1334,  -5.4328,  -1.2291],\n",
      "         [ -6.6171,  -6.7489,  -6.7267,  ...,  -5.9333,  -5.8587,  -2.5390]],\n",
      "\n",
      "        [[ -6.8170,  -6.8688,  -6.7868,  ...,  -6.2759,  -6.0390,  -4.0780],\n",
      "         [ -5.7326,  -5.9964,  -5.8834,  ...,  -7.7544,  -6.4005,  -3.5147],\n",
      "         [ -7.8228,  -7.6787,  -7.5520,  ...,  -9.0341,  -7.0534,  -3.7757],\n",
      "         ...,\n",
      "         [ -4.7751,  -4.8526,  -4.8423,  ...,  -5.0419,  -4.5640,  -2.8385],\n",
      "         [ -3.6857,  -3.6827,  -3.8438,  ...,  -4.6013,  -4.2274,  -2.2922],\n",
      "         [ -4.5808,  -4.6911,  -4.8500,  ...,  -5.1821,  -5.0837,  -2.7793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6623,  -6.6388,  -6.6343,  ...,  -5.9824,  -5.8003,  -4.0475],\n",
      "         [ -5.9541,  -5.9737,  -6.0975,  ...,  -6.3724,  -5.4038,  -4.7754],\n",
      "         [ -5.4351,  -5.6397,  -5.6865,  ...,  -5.6871,  -5.3769,  -3.9314],\n",
      "         ...,\n",
      "         [ -6.9251,  -6.9922,  -6.9058,  ...,  -7.1182,  -6.8263,  -5.3061],\n",
      "         [ -6.7315,  -6.5918,  -6.7645,  ...,  -6.4480,  -7.2734,  -6.6455],\n",
      "         [ -6.8856,  -6.9985,  -6.9273,  ...,  -7.0730,  -6.7233,  -3.5177]],\n",
      "\n",
      "        [[-10.7715, -10.6444, -10.7746,  ...,  -9.6226, -10.5095,  -7.1827],\n",
      "         [-14.9697, -14.8057, -14.6664,  ..., -13.3410, -12.2481, -14.4114],\n",
      "         [ -5.2754,  -5.3046,  -5.3540,  ...,  -5.5149,  -6.7878,  -3.4098],\n",
      "         ...,\n",
      "         [ -5.4376,  -5.3543,  -5.3030,  ...,  -4.8693,  -6.5500,  -4.7304],\n",
      "         [ -4.8524,  -4.7752,  -4.8571,  ...,  -4.6720,  -5.7959,  -4.0293],\n",
      "         [ -5.5897,  -5.6158,  -5.6149,  ...,  -5.1056,  -6.4700,  -2.4834]],\n",
      "\n",
      "        [[ -8.3308,  -8.2123,  -8.2275,  ...,  -7.2384,  -7.5046,  -4.7359],\n",
      "         [-10.8820, -10.1893, -10.7302,  ...,  -7.9973,  -9.5398,  -8.4813],\n",
      "         [ -5.7557,  -6.0272,  -6.0043,  ...,  -6.1390,  -6.7041,  -1.7218],\n",
      "         ...,\n",
      "         [ -5.8946,  -5.9167,  -6.0414,  ...,  -5.8360,  -6.7754,  -3.0860],\n",
      "         [ -4.3955,  -4.4816,  -4.5733,  ...,  -5.1328,  -5.9651,  -2.5559],\n",
      "         [ -4.9649,  -4.9254,  -4.9667,  ...,  -5.1363,  -5.9741,  -3.7343]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.289523124694824\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6959, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8745,  -6.9835,  -6.8605,  ...,  -6.5759,  -5.9243,  -4.5559],\n",
      "         [ -8.2018,  -8.3368,  -8.1189,  ...,  -9.1589,  -6.8938,  -6.4069],\n",
      "         [ -4.4567,  -4.4434,  -4.6114,  ...,  -5.0100,  -4.3707,  -6.8635],\n",
      "         ...,\n",
      "         [ -4.5529,  -4.3438,  -4.6369,  ...,  -6.4698,  -3.4371,  -5.6484],\n",
      "         [-12.2110, -12.0551, -12.1626,  ..., -12.4525, -10.1042,  -4.2873],\n",
      "         [-13.1094, -12.8176, -13.4378,  ..., -10.4730, -10.1571, -10.4026]],\n",
      "\n",
      "        [[ -7.3683,  -7.3992,  -7.3362,  ...,  -6.8336,  -6.5700,  -5.0120],\n",
      "         [-12.3224, -12.2771, -12.3514,  ..., -11.6792, -10.0998,  -8.3003],\n",
      "         [-10.6698, -10.8601, -10.7280,  ..., -10.4957, -10.5660,  -7.2344],\n",
      "         ...,\n",
      "         [-11.8375, -11.8320, -12.1244,  ..., -10.2663,  -9.2565,  -9.8631],\n",
      "         [ -6.7991,  -6.9072,  -6.9193,  ...,  -6.4545,  -6.3267,  -5.0400],\n",
      "         [-12.4959, -12.6833, -12.9671,  ..., -13.2779, -10.0819,  -9.0805]],\n",
      "\n",
      "        [[ -6.7277,  -6.7094,  -6.7782,  ...,  -6.0498,  -6.1819,  -3.7714],\n",
      "         [-11.9514, -11.5809, -11.5871,  ...,  -8.5997,  -9.0997,  -8.9956],\n",
      "         [ -5.8406,  -5.9554,  -5.9418,  ...,  -5.9087,  -6.5142,  -4.1319],\n",
      "         ...,\n",
      "         [ -6.1950,  -6.2156,  -6.1427,  ...,  -6.0789,  -6.6175,  -4.5542],\n",
      "         [ -6.1184,  -6.1478,  -6.1797,  ...,  -6.2911,  -6.5130,  -4.1155],\n",
      "         [ -5.7417,  -5.8304,  -5.7751,  ...,  -5.8109,  -6.6280,  -4.0550]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3327,  -6.4471,  -6.3263,  ...,  -5.6492,  -5.9824,  -3.0369],\n",
      "         [-10.2467,  -9.8446,  -9.8434,  ...,  -7.3760,  -8.1676,  -8.6572],\n",
      "         [ -4.5305,  -4.6255,  -4.6312,  ...,  -4.9941,  -6.1547,  -1.8319],\n",
      "         ...,\n",
      "         [ -5.2659,  -5.3343,  -5.3151,  ...,  -5.4514,  -6.6115,  -2.6112],\n",
      "         [ -5.5909,  -5.6595,  -5.5514,  ...,  -5.9521,  -6.3826,  -3.2894],\n",
      "         [ -4.7676,  -4.8560,  -4.8180,  ...,  -4.7323,  -5.4113,  -2.2400]],\n",
      "\n",
      "        [[ -6.7432,  -6.7434,  -6.7297,  ...,  -5.9226,  -5.8738,  -3.7996],\n",
      "         [-10.5994, -10.9279, -10.6091,  ...,  -8.3410,  -8.5180,  -8.1476],\n",
      "         [ -5.3846,  -5.6528,  -5.6748,  ...,  -5.7235,  -6.9990,  -3.4943],\n",
      "         ...,\n",
      "         [ -5.2817,  -5.4295,  -5.5122,  ...,  -5.4456,  -6.3677,  -3.7790],\n",
      "         [ -5.4604,  -5.6718,  -5.5274,  ...,  -5.3349,  -6.7469,  -2.7703],\n",
      "         [ -5.5042,  -5.6358,  -5.5717,  ...,  -5.1961,  -6.3100,  -2.9221]],\n",
      "\n",
      "        [[ -8.2038,  -8.3034,  -8.0702,  ...,  -7.2222,  -7.4182,  -4.4233],\n",
      "         [-15.3056, -14.8735, -15.0569,  ..., -14.1378, -12.6973, -11.4061],\n",
      "         [ -8.6467,  -8.5132,  -8.6377,  ...,  -9.6113,  -7.2626,  -3.2216],\n",
      "         ...,\n",
      "         [ -5.3821,  -5.6068,  -5.3005,  ...,  -5.8564,  -4.8637,  -2.9829],\n",
      "         [ -5.6295,  -5.9044,  -5.7051,  ...,  -6.2229,  -5.2090,  -4.6976],\n",
      "         [ -5.2680,  -5.2673,  -5.3609,  ...,  -5.3875,  -4.8201,  -5.0551]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.6959137916564941\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8656, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8033,  -6.7722,  -6.7752,  ...,  -5.9084,  -5.9569,  -3.6749],\n",
      "         [ -8.1228,  -8.1772,  -8.1417,  ...,  -7.4504,  -6.7390,  -4.3780],\n",
      "         [-10.2208, -10.2285, -10.2838,  ...,  -9.6985,  -7.9477,  -6.6045],\n",
      "         ...,\n",
      "         [ -7.6929,  -7.7112,  -7.6872,  ...,  -7.0837,  -6.7611,  -5.2301],\n",
      "         [ -7.0130,  -7.1930,  -7.0709,  ...,  -6.6329,  -6.0652,  -4.5164],\n",
      "         [ -6.6799,  -6.8968,  -6.7903,  ...,  -6.8242,  -6.4827,  -4.5611]],\n",
      "\n",
      "        [[-11.8079, -11.9644, -11.8964,  ..., -10.6464, -11.6754, -10.0601],\n",
      "         [-13.8433, -13.7795, -14.1005,  ..., -10.5271, -11.5067, -10.7835],\n",
      "         [ -4.6937,  -5.1000,  -4.9530,  ...,  -5.9346,  -7.5301,  -4.7019],\n",
      "         ...,\n",
      "         [ -5.1039,  -5.3959,  -5.1677,  ...,  -5.4195,  -6.4048,  -3.7822],\n",
      "         [ -4.9314,  -5.1938,  -4.9588,  ...,  -5.2507,  -6.5050,  -4.6824],\n",
      "         [ -4.8508,  -5.0577,  -4.8915,  ...,  -4.9381,  -6.6511,  -2.6523]],\n",
      "\n",
      "        [[ -6.9571,  -7.0130,  -6.8934,  ...,  -6.4823,  -6.0924,  -3.9535],\n",
      "         [ -9.3005,  -9.3624,  -9.6264,  ...,  -8.5751,  -7.3439,  -5.6308],\n",
      "         [-11.5560, -11.4000, -11.2078,  ..., -11.3719,  -8.7337,  -8.9074],\n",
      "         ...,\n",
      "         [ -6.9835,  -6.6233,  -7.0257,  ...,  -5.6512,  -5.9632,  -3.5483],\n",
      "         [-10.0925, -10.4332, -10.2850,  ..., -10.6420,  -9.5482,  -5.9053],\n",
      "         [-11.3925, -11.4047, -11.6554,  ..., -10.7271,  -9.5392,  -6.9475]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6264,  -6.5819,  -6.6129,  ...,  -5.9298,  -5.7767,  -4.0350],\n",
      "         [-12.4588, -12.1305, -12.6036,  ...,  -9.1294, -10.5609, -10.4364],\n",
      "         [ -4.9266,  -5.0376,  -5.1022,  ...,  -5.0695,  -6.0959,  -3.3235],\n",
      "         ...,\n",
      "         [ -4.4734,  -4.5922,  -4.5697,  ...,  -4.5219,  -5.7013,  -2.7922],\n",
      "         [ -5.2832,  -5.3264,  -5.4403,  ...,  -5.3293,  -6.1150,  -3.7613],\n",
      "         [ -5.4963,  -5.5705,  -5.5974,  ...,  -5.4275,  -6.4320,  -3.4059]],\n",
      "\n",
      "        [[ -7.8319,  -7.8626,  -7.8334,  ...,  -7.0187,  -6.6778,  -5.2807],\n",
      "         [ -5.7094,  -5.7808,  -5.8165,  ...,  -5.5548,  -5.8270,  -5.1046],\n",
      "         [ -9.2087,  -9.1196,  -8.9480,  ...,  -9.5377,  -8.1761,  -9.4973],\n",
      "         ...,\n",
      "         [-10.7681, -10.8984, -10.8009,  ..., -10.4352,  -8.5617, -10.0576],\n",
      "         [ -3.8053,  -3.9750,  -3.9637,  ...,  -5.2293,  -4.1137,  -4.4907],\n",
      "         [-14.1194, -14.1437, -14.3051,  ..., -12.7458, -11.1352,  -9.0147]],\n",
      "\n",
      "        [[ -6.7651,  -6.8050,  -6.7458,  ...,  -6.0722,  -6.1350,  -4.2827],\n",
      "         [ -9.6278,  -9.9871,  -9.9204,  ..., -10.9860,  -9.7070,  -9.5598],\n",
      "         [ -8.7271,  -8.7462,  -8.9381,  ...,  -7.7218,  -8.1840,  -3.8463],\n",
      "         ...,\n",
      "         [ -9.1738,  -9.4200,  -9.1600,  ...,  -8.5626,  -7.4872,  -6.4534],\n",
      "         [ -6.4240,  -6.4335,  -6.6592,  ...,  -6.3418,  -6.2803,  -5.3054],\n",
      "         [-13.3898, -14.0793, -13.8558,  ..., -13.6321, -10.8645, -12.3872]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8656121492385864\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3869, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8248,  -6.8675,  -6.7383,  ...,  -6.3461,  -6.2126,  -4.2483],\n",
      "         [ -6.4516,  -6.6668,  -6.3493,  ...,  -5.5657,  -6.2994,  -4.2023],\n",
      "         [-14.5501, -14.7108, -14.3658,  ..., -12.1414,  -9.9570, -14.7447],\n",
      "         ...,\n",
      "         [ -8.7419,  -8.6131,  -8.7857,  ...,  -7.6780,  -6.8612,  -7.6812],\n",
      "         [ -4.5110,  -4.8282,  -4.1416,  ...,  -5.3945,  -2.9654,  -3.2334],\n",
      "         [-11.7206, -11.5499, -11.5703,  ..., -10.7448,  -8.6441,  -7.7334]],\n",
      "\n",
      "        [[ -6.9271,  -6.9109,  -6.8765,  ...,  -6.2898,  -6.2569,  -3.5370],\n",
      "         [ -8.2243,  -8.3784,  -7.8357,  ...,  -8.9796,  -6.7460,  -6.0127],\n",
      "         [ -6.5051,  -6.9828,  -6.6660,  ...,  -6.8782,  -5.3719,  -7.4378],\n",
      "         ...,\n",
      "         [ -8.8744,  -9.1517,  -8.8868,  ...,  -7.7021,  -6.9220,  -5.8395],\n",
      "         [ -4.4416,  -4.6836,  -4.5238,  ...,  -4.5101,  -4.4004,  -3.8871],\n",
      "         [ -7.0396,  -7.6820,  -6.8748,  ...,  -7.6589,  -5.2775,  -4.3466]],\n",
      "\n",
      "        [[ -6.7935,  -6.7584,  -6.7792,  ...,  -6.0418,  -5.8397,  -3.7259],\n",
      "         [-13.1813, -13.4146, -13.5758,  ..., -10.1873, -10.6441, -12.1350],\n",
      "         [ -4.7419,  -4.8716,  -4.8840,  ...,  -5.2391,  -6.5007,  -2.1207],\n",
      "         ...,\n",
      "         [ -5.4170,  -5.4459,  -5.5209,  ...,  -5.7435,  -6.2476,  -3.0106],\n",
      "         [ -5.2529,  -5.3419,  -5.3761,  ...,  -5.3124,  -6.7703,  -3.7914],\n",
      "         [ -6.0575,  -6.1157,  -6.2798,  ...,  -5.9627,  -6.8733,  -3.3598]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5283,  -6.4998,  -6.4862,  ...,  -5.6840,  -5.5974,  -3.8072],\n",
      "         [ -6.4086,  -6.5047,  -6.6674,  ...,  -5.9856,  -7.2059,  -0.7439],\n",
      "         [ -8.4866,  -8.5156,  -8.5555,  ...,  -8.6042,  -6.0406,  -5.5577],\n",
      "         ...,\n",
      "         [ -7.3182,  -7.7470,  -7.8696,  ...,  -7.0466,  -7.0368,  -0.9246],\n",
      "         [ -6.0308,  -6.2327,  -6.0897,  ...,  -5.7110,  -5.5427,  -3.3793],\n",
      "         [ -6.9253,  -7.0468,  -6.8195,  ...,  -6.1063,  -6.2263,  -2.5582]],\n",
      "\n",
      "        [[ -7.2063,  -7.2150,  -7.1638,  ...,  -6.6809,  -6.4726,  -4.9403],\n",
      "         [-12.2604, -11.8834, -12.0189,  ..., -11.3372, -10.8665, -11.8835],\n",
      "         [ -9.7898, -10.1690, -10.0730,  ...,  -8.3752,  -7.5175,  -5.9363],\n",
      "         ...,\n",
      "         [ -3.1130,  -3.4520,  -3.0586,  ...,  -3.5517,  -2.5230,  -2.2567],\n",
      "         [ -5.5071,  -5.8005,  -5.4333,  ...,  -5.5902,  -4.7865,  -3.7426],\n",
      "         [ -5.5296,  -5.8218,  -5.4499,  ...,  -5.3219,  -5.7267,  -4.2701]],\n",
      "\n",
      "        [[-10.0408, -10.1728, -10.0371,  ...,  -9.1364,  -9.5434,  -6.4884],\n",
      "         [-15.2543, -15.1398, -15.3375,  ..., -12.6503, -14.1265, -12.1996],\n",
      "         [ -4.9968,  -5.1497,  -5.1283,  ...,  -5.2511,  -7.2137,  -2.5426],\n",
      "         ...,\n",
      "         [ -4.5843,  -4.7941,  -4.7767,  ...,  -5.3841,  -6.2317,  -2.6074],\n",
      "         [ -5.2751,  -5.4494,  -5.5170,  ...,  -5.1566,  -6.8554,  -2.8503],\n",
      "         [ -5.4430,  -5.5836,  -5.6849,  ...,  -5.4910,  -6.8727,  -2.7792]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.3869409561157227\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8021, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4033,  -7.4949,  -7.3947,  ...,  -6.9838,  -6.4080,  -4.3097],\n",
      "         [ -8.9497,  -8.8621,  -8.8603,  ...,  -9.4659,  -8.1653,  -8.0880],\n",
      "         [ -3.6487,  -3.8094,  -4.4086,  ...,  -4.8256,  -3.3154,  -4.1151],\n",
      "         ...,\n",
      "         [ -7.2248,  -7.3816,  -7.2540,  ...,  -7.6419,  -7.0358,  -5.3709],\n",
      "         [ -7.1423,  -6.9943,  -7.0877,  ...,  -8.4597,  -8.1959,  -4.8789],\n",
      "         [-16.5440, -17.3190, -16.8263,  ..., -16.3230, -13.5989, -11.2037]],\n",
      "\n",
      "        [[ -7.0279,  -7.1500,  -7.0870,  ...,  -6.6759,  -6.0736,  -4.7367],\n",
      "         [-12.6439, -12.9655, -13.0714,  ..., -13.7955,  -9.7738,  -8.3597],\n",
      "         [ -9.9063,  -9.9044,  -9.7682,  ..., -11.4462,  -7.8342,  -8.4673],\n",
      "         ...,\n",
      "         [ -6.9052,  -7.3538,  -7.2114,  ...,  -7.5414,  -5.1804, -10.0713],\n",
      "         [ -9.1266,  -9.4146,  -9.1607,  ...,  -8.2412,  -8.2801,  -8.6116],\n",
      "         [-14.0387, -14.3183, -14.2546,  ..., -14.3709, -13.1947,  -9.0203]],\n",
      "\n",
      "        [[-10.3359, -10.3058, -10.3084,  ...,  -8.8833,  -9.1934,  -5.4813],\n",
      "         [-12.2912, -12.5330, -12.2265,  ..., -10.5732, -11.2190, -11.3676],\n",
      "         [ -4.9171,  -5.2548,  -5.1891,  ...,  -5.7939,  -6.2210,  -2.2401],\n",
      "         ...,\n",
      "         [ -4.9738,  -5.3095,  -5.1775,  ...,  -5.9144,  -6.3535,  -3.4065],\n",
      "         [ -5.4077,  -5.5980,  -5.5749,  ...,  -6.1424,  -6.3038,  -4.1167],\n",
      "         [ -5.0666,  -5.3539,  -5.2775,  ...,  -5.3768,  -6.8695,  -2.8458]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1940,  -7.2161,  -7.1304,  ...,  -6.3395,  -6.2598,  -4.0420],\n",
      "         [ -5.5329,  -5.3370,  -5.9697,  ...,  -6.6160,  -6.4050,  -3.4222],\n",
      "         [-14.6193, -14.6216, -14.4232,  ..., -12.6287, -10.7324, -11.5885],\n",
      "         ...,\n",
      "         [ -7.2363,  -7.3692,  -7.3773,  ...,  -6.3231,  -6.7654,  -2.0601],\n",
      "         [ -8.3509,  -8.5404,  -8.4888,  ...,  -7.8014,  -7.3954,  -3.3791],\n",
      "         [ -8.3150,  -8.4035,  -8.4507,  ...,  -7.7545,  -7.4928,  -3.2591]],\n",
      "\n",
      "        [[ -6.8327,  -6.7896,  -6.7852,  ...,  -6.1236,  -5.9856,  -3.8672],\n",
      "         [-11.5651, -11.1990, -11.4625,  ...,  -8.8239,  -9.8599,  -8.3295],\n",
      "         [ -5.2881,  -5.3978,  -5.4306,  ...,  -5.4877,  -6.5498,  -2.5743],\n",
      "         ...,\n",
      "         [ -4.9669,  -5.1200,  -5.0759,  ...,  -4.8612,  -6.2034,  -2.9029],\n",
      "         [ -5.4685,  -5.5669,  -5.6039,  ...,  -5.6170,  -6.5116,  -2.9388],\n",
      "         [ -5.1170,  -5.2232,  -5.2614,  ...,  -5.3668,  -6.1510,  -2.0816]],\n",
      "\n",
      "        [[ -6.9809,  -7.0150,  -6.9587,  ...,  -6.3302,  -6.1663,  -4.2555],\n",
      "         [ -8.7944,  -8.7643,  -8.7453,  ...,  -9.1681,  -7.2255,  -6.9172],\n",
      "         [-10.2285, -10.2021, -10.2450,  ..., -10.1148,  -8.8741,  -8.6180],\n",
      "         ...,\n",
      "         [ -5.9822,  -6.1823,  -5.9776,  ...,  -7.6373,  -5.2409,  -4.2040],\n",
      "         [ -6.8989,  -7.2873,  -6.8513,  ...,  -8.1253,  -5.5936,  -6.0510],\n",
      "         [ -6.3184,  -6.5956,  -6.3176,  ...,  -6.9314,  -5.3950,  -6.1664]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8020861148834229\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0835, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2572,  -7.2662,  -7.2985,  ...,  -6.6536,  -6.1951,  -4.5191],\n",
      "         [ -6.6294,  -6.9440,  -6.9549,  ...,  -6.3481,  -7.0561,  -3.2672],\n",
      "         [-11.6844, -11.8552, -11.7896,  ..., -11.4632, -11.2999,  -7.8539],\n",
      "         ...,\n",
      "         [ -6.6098,  -6.5909,  -6.7550,  ...,  -6.8377,  -6.2072,  -6.0617],\n",
      "         [ -6.4349,  -6.7041,  -6.5878,  ...,  -7.1337,  -6.3535,  -5.0680],\n",
      "         [ -7.0280,  -7.0194,  -7.1357,  ...,  -7.1457,  -6.5984,  -5.3862]],\n",
      "\n",
      "        [[ -6.3957,  -6.3353,  -6.3603,  ...,  -5.7963,  -5.6263,  -3.8836],\n",
      "         [-10.4209, -10.1300, -10.3745,  ...,  -7.7127,  -8.3807,  -8.8778],\n",
      "         [ -5.3010,  -5.3372,  -5.3795,  ...,  -5.3724,  -6.9761,  -3.6644],\n",
      "         ...,\n",
      "         [ -4.4993,  -4.5706,  -4.6275,  ...,  -4.5715,  -6.1088,  -3.1592],\n",
      "         [ -4.9468,  -4.9202,  -5.0559,  ...,  -5.0960,  -6.4203,  -3.5862],\n",
      "         [ -4.3732,  -4.4437,  -4.5224,  ...,  -4.3820,  -6.1063,  -3.5353]],\n",
      "\n",
      "        [[ -6.1797,  -6.1705,  -6.2143,  ...,  -5.5967,  -5.4379,  -3.4307],\n",
      "         [ -6.4431,  -6.2520,  -6.3759,  ...,  -6.9397,  -6.6387,  -3.1851],\n",
      "         [ -5.3539,  -5.4112,  -5.4276,  ...,  -5.7006,  -5.5084,  -2.0445],\n",
      "         ...,\n",
      "         [ -5.6342,  -5.5229,  -5.6916,  ...,  -5.8622,  -5.5749,  -2.2445],\n",
      "         [ -5.8123,  -5.7753,  -5.8579,  ...,  -6.0316,  -5.8360,  -2.5502],\n",
      "         [ -5.6273,  -5.5486,  -5.8233,  ...,  -5.5721,  -6.0059,  -1.7956]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7381,  -6.7089,  -6.7269,  ...,  -6.0320,  -5.8026,  -4.0567],\n",
      "         [-12.3663, -12.3396, -12.3496,  ...,  -8.2700,  -8.8384, -11.1654],\n",
      "         [ -5.5807,  -5.7743,  -5.6448,  ...,  -5.8712,  -6.4933,  -3.0271],\n",
      "         ...,\n",
      "         [ -6.2653,  -6.3753,  -6.2208,  ...,  -6.5398,  -7.2354,  -2.6387],\n",
      "         [ -5.7601,  -5.8795,  -5.7685,  ...,  -6.0106,  -6.3585,  -2.9456],\n",
      "         [ -5.9813,  -6.2147,  -6.0583,  ...,  -6.2224,  -6.7611,  -3.5061]],\n",
      "\n",
      "        [[ -7.3178,  -7.3122,  -7.2828,  ...,  -6.7598,  -6.4049,  -4.6061],\n",
      "         [-12.3319, -12.2218, -12.4601,  ..., -10.6883, -10.2361,  -8.9661],\n",
      "         [-11.5992, -11.7564, -11.7656,  ...,  -9.9107,  -9.5017, -11.7241],\n",
      "         ...,\n",
      "         [ -4.2402,  -4.6996,  -4.5420,  ...,  -4.9566,  -4.6900,  -3.1092],\n",
      "         [ -5.6585,  -6.0686,  -5.8991,  ...,  -6.4682,  -5.8908,  -3.3860],\n",
      "         [ -5.5439,  -5.9218,  -5.6823,  ...,  -5.3529,  -5.6866,  -4.2470]],\n",
      "\n",
      "        [[ -6.4322,  -6.4006,  -6.4242,  ...,  -5.9601,  -5.6907,  -3.2929],\n",
      "         [ -6.9280,  -6.6761,  -6.8434,  ...,  -6.7615,  -6.7166,  -4.2232],\n",
      "         [ -6.3673,  -6.5263,  -6.4951,  ...,  -6.5095,  -5.2250,  -2.0841],\n",
      "         ...,\n",
      "         [ -5.1805,  -5.3396,  -5.0821,  ...,  -5.7230,  -4.5651,  -1.6225],\n",
      "         [ -6.1629,  -6.1125,  -6.2482,  ...,  -6.3221,  -6.1580,  -1.9991],\n",
      "         [ -6.1515,  -6.0820,  -6.2637,  ...,  -6.3188,  -5.9525,  -1.8945]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0834717750549316\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2017, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0171,  -7.0001,  -6.9507,  ...,  -6.1670,  -5.8769,  -3.9557],\n",
      "         [-13.2420, -13.1685, -13.1398,  ..., -11.7092,  -8.5683, -11.0268],\n",
      "         [-15.6509, -16.5280, -15.8757,  ..., -15.0198, -11.4538, -10.1455],\n",
      "         ...,\n",
      "         [-14.2208, -14.4696, -13.8208,  ..., -11.1916,  -9.3612,  -9.6727],\n",
      "         [ -7.0279,  -7.0912,  -6.8888,  ...,  -5.9093,  -4.6016,  -4.1446],\n",
      "         [-12.1445, -12.4930, -12.4132,  ..., -10.8221,  -9.3828,  -8.6772]],\n",
      "\n",
      "        [[ -7.5514,  -7.7766,  -7.4838,  ...,  -7.5508,  -8.3937,  -6.7908],\n",
      "         [-14.3953, -13.5693, -13.8081,  ..., -12.6155, -11.2209, -10.2896],\n",
      "         [ -5.3698,  -5.3987,  -5.4531,  ...,  -5.8442,  -6.5086,  -4.5828],\n",
      "         ...,\n",
      "         [ -5.7632,  -5.8375,  -5.8247,  ...,  -6.2316,  -6.6167,  -3.9441],\n",
      "         [ -5.6254,  -5.6033,  -5.6148,  ...,  -6.0424,  -6.5514,  -4.9365],\n",
      "         [ -5.2109,  -5.2382,  -5.1723,  ...,  -5.3802,  -5.8505,  -4.9545]],\n",
      "\n",
      "        [[ -6.5433,  -6.5464,  -6.4911,  ...,  -6.1687,  -5.7870,  -3.8273],\n",
      "         [ -6.5286,  -6.6113,  -6.7514,  ...,  -7.6401,  -6.9284,  -3.3837],\n",
      "         [ -8.0659,  -8.1976,  -8.3431,  ...,  -9.1765,  -8.3381,  -4.7621],\n",
      "         ...,\n",
      "         [ -5.9923,  -6.0937,  -6.1174,  ...,  -6.1685,  -6.2748,  -2.5334],\n",
      "         [ -6.1307,  -6.2825,  -6.2534,  ...,  -6.6615,  -6.1988,  -2.0611],\n",
      "         [ -5.7997,  -5.8247,  -5.9079,  ...,  -6.3325,  -5.4629,  -2.1217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2476,  -7.2484,  -7.1558,  ...,  -6.6671,  -6.3811,  -4.4369],\n",
      "         [-14.2354, -14.0919, -14.3752,  ..., -13.1126, -11.7296, -12.8318],\n",
      "         [ -9.8537,  -9.8429,  -9.6100,  ..., -10.3023,  -7.8266, -10.7764],\n",
      "         ...,\n",
      "         [ -8.5384,  -8.6294,  -8.7008,  ...,  -7.8128,  -6.7566,  -6.1473],\n",
      "         [ -5.4516,  -5.7457,  -5.7279,  ...,  -5.7801,  -5.0130,  -3.0973],\n",
      "         [-13.4893, -13.8958, -13.1292,  ..., -12.4908,  -9.5078,  -8.3256]],\n",
      "\n",
      "        [[ -7.6174,  -7.5614,  -7.4805,  ...,  -7.3325,  -6.4606,  -5.1279],\n",
      "         [ -8.4930,  -8.4317,  -8.4336,  ...,  -9.6260,  -8.4653,  -9.1962],\n",
      "         [ -8.2811,  -8.4519,  -8.2240,  ...,  -7.2293,  -6.5323,  -8.4726],\n",
      "         ...,\n",
      "         [-13.6723, -13.3291, -13.6614,  ..., -10.8804, -10.9891, -10.8313],\n",
      "         [-10.9454, -10.7619, -11.4374,  ...,  -9.1369,  -8.6743,  -8.8267],\n",
      "         [ -7.0119,  -7.2655,  -6.8834,  ...,  -7.0304,  -5.3253,  -6.4066]],\n",
      "\n",
      "        [[ -6.3897,  -6.3118,  -6.3210,  ...,  -5.6269,  -5.5534,  -3.6101],\n",
      "         [ -5.9222,  -5.7814,  -5.5285,  ...,  -6.1752,  -6.6711,  -3.7796],\n",
      "         [-10.6962, -10.8778, -10.5972,  ...,  -8.8165,  -9.7223,  -9.8420],\n",
      "         ...,\n",
      "         [ -4.8245,  -4.7492,  -4.6547,  ...,  -4.7443,  -4.8574,  -2.4048],\n",
      "         [ -5.0944,  -5.1127,  -5.0023,  ...,  -5.0586,  -5.6336,  -2.2672],\n",
      "         [ -4.2133,  -4.3211,  -4.2089,  ...,  -5.0372,  -4.7083,  -2.0538]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2016658782958984\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3056, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7113,  -6.7069,  -6.7002,  ...,  -6.0609,  -6.1868,  -3.3303],\n",
      "         [ -7.1140,  -7.0098,  -6.9937,  ...,  -8.1367,  -7.9839,  -4.7523],\n",
      "         [ -8.0144,  -8.6599,  -8.3704,  ...,  -9.3944,  -7.2195,  -3.5650],\n",
      "         ...,\n",
      "         [ -5.4733,  -5.4625,  -5.4706,  ...,  -5.9650,  -5.7475,  -1.6095],\n",
      "         [ -5.4433,  -5.4805,  -5.3964,  ...,  -6.0821,  -5.7920,  -1.5265],\n",
      "         [ -6.1670,  -6.2230,  -6.1005,  ...,  -6.6299,  -6.0663,  -1.0635]],\n",
      "\n",
      "        [[ -6.9198,  -6.9136,  -6.8561,  ...,  -5.8911,  -6.0481,  -4.2292],\n",
      "         [-15.8140, -15.9767, -15.7516,  ..., -11.5916, -11.5905, -15.0243],\n",
      "         [ -6.5272,  -6.8077,  -6.4789,  ...,  -6.1025,  -5.8881,  -8.0468],\n",
      "         ...,\n",
      "         [ -6.5148,  -6.6351,  -6.5521,  ...,  -6.7127,  -5.0149,  -6.1650],\n",
      "         [ -6.0110,  -6.1778,  -6.1719,  ...,  -5.7592,  -4.9161,  -6.7719],\n",
      "         [ -6.6891,  -6.9759,  -6.9428,  ...,  -6.7230,  -5.9881,  -6.6177]],\n",
      "\n",
      "        [[ -6.6790,  -6.6491,  -6.6184,  ...,  -5.9230,  -5.8385,  -3.9959],\n",
      "         [ -1.3755,  -1.7267,  -1.5327,  ...,  -0.8940,  -2.3124,  -3.9895],\n",
      "         [ -4.9517,  -4.9807,  -5.0887,  ...,  -5.5345,  -4.5471,  -2.9810],\n",
      "         ...,\n",
      "         [ -5.8103,  -6.1131,  -6.0063,  ...,  -5.8987,  -5.6573,  -6.9237],\n",
      "         [ -6.9648,  -7.2159,  -7.2824,  ...,  -7.2550,  -7.3477,  -7.2610],\n",
      "         [ -5.7583,  -6.0064,  -6.0263,  ...,  -6.0678,  -6.4874,  -5.7322]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2384,  -6.2386,  -6.1842,  ...,  -5.6239,  -5.2825,  -3.5489],\n",
      "         [-12.9390, -12.6836, -12.7538,  ..., -10.1709,  -9.7922,  -9.5687],\n",
      "         [ -5.7070,  -5.7608,  -5.7969,  ...,  -5.5394,  -6.5215,  -3.3007],\n",
      "         ...,\n",
      "         [ -5.7356,  -5.6991,  -5.6753,  ...,  -5.3316,  -5.8869,  -4.3106],\n",
      "         [ -5.9705,  -5.9538,  -5.9837,  ...,  -5.5553,  -6.9782,  -3.9489],\n",
      "         [ -5.3360,  -5.2822,  -5.2462,  ...,  -4.7116,  -5.8371,  -3.9303]],\n",
      "\n",
      "        [[ -6.5811,  -6.5668,  -6.5725,  ...,  -6.0051,  -5.7951,  -3.9574],\n",
      "         [-10.9347, -10.6033, -11.2072,  ...,  -9.1888,  -8.3509,  -7.1876],\n",
      "         [ -5.5440,  -5.6680,  -5.6775,  ...,  -5.7147,  -6.1980,  -3.0867],\n",
      "         ...,\n",
      "         [ -6.0172,  -6.1103,  -6.0472,  ...,  -5.6804,  -6.1497,  -3.1189],\n",
      "         [ -5.5054,  -5.5816,  -5.5523,  ...,  -5.8507,  -5.9597,  -3.4658],\n",
      "         [ -5.8618,  -5.9233,  -5.8968,  ...,  -5.8585,  -6.1544,  -2.8490]],\n",
      "\n",
      "        [[ -6.1712,  -6.1251,  -6.1385,  ...,  -5.4191,  -5.4638,  -3.6068],\n",
      "         [-14.7141, -14.4329, -14.6051,  ..., -11.4222, -12.3436,  -9.1186],\n",
      "         [ -4.3906,  -4.5411,  -4.4789,  ...,  -4.7945,  -5.7806,  -2.2840],\n",
      "         ...,\n",
      "         [ -4.9060,  -4.8149,  -4.9145,  ...,  -5.5238,  -6.0454,  -2.8130],\n",
      "         [ -4.2632,  -4.2150,  -4.3005,  ...,  -4.4149,  -5.6806,  -2.9094],\n",
      "         [ -5.2690,  -5.2462,  -5.2864,  ...,  -5.2219,  -6.0550,  -4.1734]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.305582880973816\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8744, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7010,  -6.6628,  -6.7021,  ...,  -6.3191,  -6.0706,  -3.6556],\n",
      "         [ -5.8327,  -5.7407,  -5.8477,  ...,  -6.5578,  -5.7003,  -2.8917],\n",
      "         [ -5.5176,  -5.5024,  -5.6537,  ...,  -6.5213,  -5.5122,  -2.9282],\n",
      "         ...,\n",
      "         [ -5.8207,  -5.7147,  -5.9325,  ...,  -5.9488,  -5.8475,  -2.6097],\n",
      "         [ -5.9748,  -5.9481,  -6.1199,  ...,  -6.5827,  -6.0634,  -2.8608],\n",
      "         [ -6.1854,  -6.0767,  -6.2020,  ...,  -6.3578,  -5.9934,  -2.7596]],\n",
      "\n",
      "        [[ -7.2449,  -7.2471,  -7.1428,  ...,  -6.7475,  -6.1071,  -4.4634],\n",
      "         [ -6.9538,  -7.1549,  -6.9571,  ...,  -7.6250,  -5.8958,  -5.7925],\n",
      "         [ -3.8540,  -4.0442,  -3.8336,  ...,  -3.7424,  -3.2163,  -3.5757],\n",
      "         ...,\n",
      "         [ -3.3078,  -3.3222,  -3.2042,  ...,  -1.9106,  -2.3796,  -0.8594],\n",
      "         [ -7.4284,  -7.6122,  -7.5472,  ...,  -6.5119,  -6.0845,  -4.2466],\n",
      "         [ -7.5767,  -7.8503,  -7.7785,  ...,  -7.0729,  -6.5460,  -4.7787]],\n",
      "\n",
      "        [[ -6.5695,  -6.5757,  -6.5455,  ...,  -6.1487,  -5.6127,  -4.3964],\n",
      "         [ -7.1005,  -7.0852,  -6.9658,  ...,  -7.4932,  -5.6965,  -5.7829],\n",
      "         [ -9.3887,  -9.5354,  -9.3373,  ...,  -9.1219,  -7.4150,  -6.6878],\n",
      "         ...,\n",
      "         [ -7.2315,  -7.4284,  -7.3040,  ...,  -7.2766,  -5.7894,  -5.9126],\n",
      "         [ -7.5621,  -7.7321,  -7.6864,  ...,  -7.5930,  -5.7805,  -6.3868],\n",
      "         [ -7.3726,  -7.5547,  -7.4261,  ...,  -7.5595,  -5.6678,  -5.6297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6911,  -7.6420,  -7.6246,  ...,  -6.7176,  -6.7223,  -4.2874],\n",
      "         [ -9.3148,  -9.3305,  -9.7961,  ...,  -7.7447,  -8.0885,  -7.7740],\n",
      "         [ -7.1193,  -7.1278,  -7.8668,  ...,  -6.7675,  -5.7304, -10.9922],\n",
      "         ...,\n",
      "         [ -6.5699,  -6.6014,  -6.7380,  ...,  -5.9530,  -6.6527,  -5.5035],\n",
      "         [ -6.5346,  -6.5605,  -6.7754,  ...,  -5.9069,  -6.7313,  -5.1834],\n",
      "         [ -7.0184,  -7.1425,  -7.2990,  ...,  -5.8245,  -6.9018,  -6.4345]],\n",
      "\n",
      "        [[ -6.1770,  -6.0655,  -6.1097,  ...,  -5.8075,  -5.7193,  -3.1744],\n",
      "         [ -6.4792,  -6.4948,  -6.5302,  ...,  -7.3337,  -6.8091,  -2.8413],\n",
      "         [ -6.3521,  -6.3102,  -6.4404,  ...,  -6.8132,  -6.1606,  -2.8452],\n",
      "         ...,\n",
      "         [ -5.9653,  -5.8376,  -6.0022,  ...,  -6.6077,  -5.6546,  -2.9800],\n",
      "         [ -5.6426,  -5.6544,  -5.7156,  ...,  -6.0005,  -6.1067,  -3.0490],\n",
      "         [ -6.1207,  -6.0426,  -6.1585,  ...,  -6.4103,  -6.1041,  -2.6939]],\n",
      "\n",
      "        [[ -7.4098,  -7.3512,  -7.3657,  ...,  -6.9887,  -6.7880,  -3.5445],\n",
      "         [-11.5387, -11.3652, -11.5859,  ...,  -8.2385,  -9.0562,  -9.8082],\n",
      "         [ -7.1387,  -7.1516,  -7.2215,  ...,  -7.0703,  -7.0309,  -3.5080],\n",
      "         ...,\n",
      "         [ -7.5989,  -7.6074,  -7.5865,  ...,  -7.4093,  -7.2289,  -2.9246],\n",
      "         [ -7.4232,  -7.3374,  -7.4358,  ...,  -7.3558,  -7.1968,  -3.2983],\n",
      "         [ -7.4556,  -7.5675,  -7.5513,  ...,  -7.4068,  -6.7715,  -2.7364]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8744144439697266\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8095, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6670,  -6.6354,  -6.6544,  ...,  -6.0581,  -5.8757,  -3.8869],\n",
      "         [ -5.4391,  -5.2359,  -5.5121,  ...,  -6.0198,  -5.5242,  -1.6574],\n",
      "         [ -6.0518,  -6.0300,  -6.2425,  ...,  -6.4184,  -6.0173,  -3.4360],\n",
      "         ...,\n",
      "         [ -5.6155,  -5.5251,  -5.6384,  ...,  -5.7522,  -5.5090,  -2.5743],\n",
      "         [ -5.6112,  -5.5059,  -5.6776,  ...,  -5.9948,  -5.4107,  -1.9721],\n",
      "         [ -5.9143,  -5.8099,  -5.8832,  ...,  -5.9786,  -5.7271,  -2.4782]],\n",
      "\n",
      "        [[ -7.7835,  -7.5402,  -7.5211,  ...,  -6.7616,  -6.5066,  -4.7649],\n",
      "         [-15.4423, -15.3055, -15.0474,  ..., -12.8079, -13.5541, -14.2082],\n",
      "         [ -4.5684,  -4.6612,  -4.5998,  ...,  -4.5518,  -6.2807,  -2.9734],\n",
      "         ...,\n",
      "         [ -5.0662,  -5.0427,  -5.0175,  ...,  -4.9351,  -6.3826,  -3.8932],\n",
      "         [ -4.1072,  -3.9803,  -4.1222,  ...,  -4.0431,  -5.5369,  -2.7003],\n",
      "         [ -5.2184,  -5.2394,  -5.1478,  ...,  -4.7813,  -5.9020,  -4.2505]],\n",
      "\n",
      "        [[ -6.5882,  -6.5521,  -6.5651,  ...,  -5.8848,  -5.6978,  -3.9928],\n",
      "         [ -9.3053,  -8.9390,  -9.2021,  ...,  -8.2951,  -7.9004,  -4.8983],\n",
      "         [ -4.8559,  -4.9241,  -5.0160,  ...,  -4.9097,  -6.0417,  -3.8372],\n",
      "         ...,\n",
      "         [ -5.1508,  -5.1354,  -5.2052,  ...,  -5.4224,  -5.8254,  -4.6300],\n",
      "         [ -5.4989,  -5.4467,  -5.6490,  ...,  -5.5163,  -6.4038,  -3.6027],\n",
      "         [ -5.5288,  -5.6372,  -5.6570,  ...,  -5.5756,  -6.0876,  -3.5556]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5437,  -6.5096,  -6.5053,  ...,  -5.8657,  -5.6520,  -3.8394],\n",
      "         [-10.8460, -10.5555, -10.7100,  ...,  -7.2601,  -7.2120,  -7.3120],\n",
      "         [ -4.9116,  -5.0327,  -5.0986,  ...,  -5.1642,  -6.4504,  -2.7534],\n",
      "         ...,\n",
      "         [ -5.5455,  -5.6590,  -5.6531,  ...,  -5.3690,  -6.3738,  -2.7068],\n",
      "         [ -5.2007,  -5.2411,  -5.2180,  ...,  -5.0804,  -6.0285,  -3.3071],\n",
      "         [ -4.8655,  -5.0338,  -4.9368,  ...,  -4.7090,  -5.8559,  -3.1403]],\n",
      "\n",
      "        [[ -6.4057,  -6.3556,  -6.3935,  ...,  -5.8515,  -5.6483,  -3.5664],\n",
      "         [ -5.6991,  -5.5772,  -5.6124,  ...,  -6.4577,  -5.6841,  -2.5666],\n",
      "         [ -5.4003,  -5.3423,  -5.4821,  ...,  -6.3935,  -5.2602,  -1.4279],\n",
      "         ...,\n",
      "         [ -5.5199,  -5.4034,  -5.4198,  ...,  -5.8613,  -5.2636,  -1.7545],\n",
      "         [ -5.4293,  -5.2755,  -5.3479,  ...,  -6.2372,  -5.0006,  -2.3310],\n",
      "         [ -5.3849,  -5.2029,  -5.3344,  ...,  -6.0561,  -5.1955,  -1.6047]],\n",
      "\n",
      "        [[ -6.7954,  -6.7881,  -6.7720,  ...,  -5.8713,  -6.0136,  -3.8955],\n",
      "         [-11.6965, -11.1101, -11.5577,  ...,  -9.6829,  -9.1746,  -7.5090],\n",
      "         [ -5.1570,  -5.4007,  -5.3175,  ...,  -5.7178,  -6.9732,  -3.1554],\n",
      "         ...,\n",
      "         [ -5.0579,  -5.1656,  -5.1352,  ...,  -5.3457,  -6.0083,  -3.4903],\n",
      "         [ -4.7989,  -5.0292,  -5.0276,  ...,  -5.1956,  -6.4571,  -2.3758],\n",
      "         [ -5.4433,  -5.6288,  -5.6588,  ...,  -5.2599,  -6.9889,  -2.7650]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.809546947479248\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3680, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6492,  -6.6177,  -6.5854,  ...,  -6.0299,  -5.6978,  -3.8899],\n",
      "         [ -6.7986,  -6.7481,  -6.8029,  ...,  -5.9968,  -6.0924,  -3.4128],\n",
      "         [ -3.6505,  -3.7690,  -3.3793,  ...,  -3.6589,  -2.1366,  -4.6772],\n",
      "         ...,\n",
      "         [ -6.0467,  -6.1218,  -6.2848,  ...,  -5.9537,  -5.6403,  -3.6598],\n",
      "         [ -6.0464,  -6.1254,  -6.2735,  ...,  -6.2441,  -6.2802,  -3.3836],\n",
      "         [ -6.0592,  -6.2225,  -6.2157,  ...,  -6.4442,  -6.3607,  -3.6749]],\n",
      "\n",
      "        [[ -7.4693,  -7.5619,  -7.5239,  ...,  -7.0356,  -6.8352,  -4.5206],\n",
      "         [-10.0769,  -9.6124, -10.0301,  ...,  -9.1604,  -8.5563,  -7.7036],\n",
      "         [ -5.3312,  -5.5011,  -5.5902,  ...,  -5.5440,  -6.6836,  -3.1483],\n",
      "         ...,\n",
      "         [ -5.5060,  -5.6894,  -5.7747,  ...,  -5.3861,  -6.4261,  -4.2051],\n",
      "         [ -5.2084,  -5.3636,  -5.3995,  ...,  -5.4363,  -6.3163,  -3.5025],\n",
      "         [ -5.5140,  -5.6814,  -5.6858,  ...,  -5.5727,  -6.5850,  -3.4990]],\n",
      "\n",
      "        [[ -6.2235,  -6.1830,  -6.2042,  ...,  -5.6223,  -5.8086,  -3.3401],\n",
      "         [ -5.9381,  -5.8693,  -5.9333,  ...,  -6.3930,  -6.0891,  -2.7640],\n",
      "         [ -5.4573,  -5.4146,  -5.5409,  ...,  -6.1857,  -5.4981,  -2.8121],\n",
      "         ...,\n",
      "         [ -5.4376,  -5.3529,  -5.5002,  ...,  -5.9993,  -5.5313,  -2.4971],\n",
      "         [ -5.3113,  -5.2512,  -5.3252,  ...,  -5.7588,  -4.9902,  -2.4626],\n",
      "         [ -5.5269,  -5.4114,  -5.4903,  ...,  -6.1674,  -5.4868,  -2.8366]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7199,  -6.7048,  -6.7106,  ...,  -6.1928,  -5.8519,  -3.8654],\n",
      "         [ -6.5519,  -6.5252,  -6.5657,  ...,  -7.0009,  -6.5113,  -2.7988],\n",
      "         [ -5.7036,  -5.7423,  -5.6830,  ...,  -6.4296,  -5.7043,  -2.0306],\n",
      "         ...,\n",
      "         [ -6.3567,  -6.3545,  -6.3577,  ...,  -6.8097,  -6.3751,  -1.9790],\n",
      "         [ -6.0279,  -6.0437,  -6.0449,  ...,  -6.2671,  -5.9159,  -1.7595],\n",
      "         [ -6.1516,  -6.1367,  -6.1294,  ...,  -6.4159,  -6.3310,  -1.6106]],\n",
      "\n",
      "        [[ -6.7561,  -6.7358,  -6.7755,  ...,  -6.2327,  -6.0265,  -3.8443],\n",
      "         [ -6.0569,  -5.9153,  -6.0963,  ...,  -6.4901,  -6.1750,  -2.1234],\n",
      "         [ -7.0532,  -7.0186,  -7.1020,  ...,  -7.7790,  -6.5509,  -3.6568],\n",
      "         ...,\n",
      "         [ -5.9822,  -5.8847,  -6.0384,  ...,  -6.3579,  -5.8271,  -2.5984],\n",
      "         [ -6.1815,  -6.1575,  -6.3242,  ...,  -6.5157,  -6.2549,  -2.8895],\n",
      "         [ -6.2143,  -6.1720,  -6.2618,  ...,  -6.5294,  -6.3797,  -2.5615]],\n",
      "\n",
      "        [[ -6.8650,  -6.8896,  -6.8116,  ...,  -6.1689,  -5.9121,  -4.0324],\n",
      "         [-11.5450, -11.7122, -11.5506,  ...,  -9.7537,  -9.5958, -12.3277],\n",
      "         [ -3.7046,  -4.0464,  -3.9538,  ...,  -3.5020,  -4.2502,  -2.7037],\n",
      "         ...,\n",
      "         [ -2.2449,  -2.4834,  -1.7875,  ...,  -3.3123,  -4.0529,  -3.7610],\n",
      "         [ -3.3244,  -3.4037,  -3.2823,  ...,  -3.1069,  -2.2969,  -3.1968],\n",
      "         [-10.8609, -10.7691, -11.0678,  ...,  -8.7128,  -7.8161,  -6.9732]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.3680033683776855\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0630, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4240,  -7.4224,  -7.3328,  ...,  -7.1275,  -6.5762,  -5.0682],\n",
      "         [ -6.3242,  -6.8163,  -6.5026,  ...,  -6.4419,  -6.6219,  -2.9789],\n",
      "         [ -7.7716,  -7.6459,  -7.6426,  ...,  -8.2178,  -3.2535,  -8.6214],\n",
      "         ...,\n",
      "         [ -8.5421,  -8.6440,  -8.5404,  ...,  -8.1045,  -4.8841,  -8.4497],\n",
      "         [ -8.3274,  -8.6883,  -8.5288,  ...,  -7.5124,  -8.2061,  -5.5546],\n",
      "         [-13.7211, -14.4164, -14.0673,  ..., -15.2980, -12.6108, -10.2793]],\n",
      "\n",
      "        [[ -6.8674,  -6.8540,  -6.8470,  ...,  -6.2102,  -5.9726,  -3.9357],\n",
      "         [ -6.3060,  -6.2957,  -6.4546,  ...,  -7.3468,  -6.3046,  -2.5765],\n",
      "         [ -6.4446,  -6.4692,  -6.5896,  ...,  -6.9468,  -6.2700,  -3.3225],\n",
      "         ...,\n",
      "         [ -5.7389,  -5.7035,  -5.7898,  ...,  -6.3552,  -5.5890,  -3.1900],\n",
      "         [ -5.8495,  -5.8169,  -5.8796,  ...,  -6.1907,  -5.6929,  -2.9822],\n",
      "         [ -5.7734,  -5.6742,  -5.7487,  ...,  -5.9545,  -5.4225,  -2.2653]],\n",
      "\n",
      "        [[ -7.5548,  -7.5010,  -7.4956,  ...,  -7.0741,  -6.5622,  -5.2067],\n",
      "         [-14.2207, -14.1966, -14.3787,  ..., -13.3771, -11.8475, -10.2673],\n",
      "         [ -8.3956,  -8.6338,  -8.1610,  ...,  -9.1741,  -9.0054, -10.8245],\n",
      "         ...,\n",
      "         [ -8.6292,  -8.4114,  -8.0213,  ...,  -6.8638,  -7.1439,  -7.9095],\n",
      "         [ -9.8808,  -9.4327,  -9.9066,  ...,  -9.8819,  -9.5487,  -4.3206],\n",
      "         [-11.2669, -11.6915, -11.6824,  ..., -10.5300,  -9.1075,  -8.3150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.1726,  -8.2005,  -8.2060,  ...,  -7.5261,  -7.1394,  -4.8068],\n",
      "         [ -7.2307,  -7.2361,  -7.4581,  ...,  -7.1023,  -6.2792,  -7.8984],\n",
      "         [-11.4630, -11.3360, -11.8885,  ..., -11.9326, -10.9780,  -5.8392],\n",
      "         ...,\n",
      "         [ -6.7680,  -6.8406,  -6.7199,  ...,  -6.3570,  -5.6564,  -6.9089],\n",
      "         [-12.3324, -12.7066, -12.4150,  ..., -10.7786,  -8.1826, -11.6720],\n",
      "         [-11.5240, -11.9018, -11.7620,  ..., -10.7739, -10.2524,  -8.1424]],\n",
      "\n",
      "        [[ -7.1893,  -7.2125,  -7.1180,  ...,  -6.4486,  -6.1061,  -4.3168],\n",
      "         [ -6.1123,  -6.4913,  -6.2526,  ...,  -5.7426,  -4.7005,  -9.0293],\n",
      "         [ -5.4067,  -5.4491,  -5.4386,  ...,  -4.9825,  -4.0774,  -7.3391],\n",
      "         ...,\n",
      "         [ -8.9935,  -9.1807,  -9.0924,  ...,  -7.1076,  -8.2055,  -6.7596],\n",
      "         [ -9.6725,  -9.8827,  -9.5738,  ...,  -8.3690,  -7.8941,  -8.2717],\n",
      "         [ -7.9607,  -8.1800,  -7.9503,  ...,  -6.9619,  -6.4618,  -8.3130]],\n",
      "\n",
      "        [[ -7.1994,  -7.1294,  -7.1586,  ...,  -6.9920,  -6.7654,  -5.1111],\n",
      "         [-11.2773, -11.3417, -11.1271,  ...,  -9.3679,  -8.4923,  -8.7298],\n",
      "         [ -5.2051,  -5.3665,  -5.4755,  ...,  -6.0013,  -7.1743,  -3.4097],\n",
      "         ...,\n",
      "         [ -6.2000,  -6.1443,  -6.2402,  ...,  -6.4678,  -6.9223,  -3.9054],\n",
      "         [ -5.7513,  -5.8626,  -5.8870,  ...,  -6.2315,  -7.1180,  -3.6705],\n",
      "         [ -4.8785,  -4.9387,  -5.0628,  ...,  -5.3641,  -6.0095,  -3.4448]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.062969207763672\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7843, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4969,  -7.4205,  -7.3620,  ...,  -6.8212,  -6.0987,  -4.4331],\n",
      "         [ -8.2336,  -7.8132,  -7.8739,  ...,  -8.4069,  -4.9205,  -8.3481],\n",
      "         [ -3.6769,  -3.3530,  -3.2795,  ...,  -3.5572,  -1.3362,  -4.4440],\n",
      "         ...,\n",
      "         [ -5.7211,  -6.0110,  -6.0149,  ...,  -5.6241,  -4.8433,  -4.0369],\n",
      "         [ -7.0041,  -7.0445,  -7.0830,  ...,  -6.8551,  -5.0232,  -5.6224],\n",
      "         [-12.9783, -13.5463, -13.2397,  ..., -12.0756,  -9.3476, -13.0939]],\n",
      "\n",
      "        [[ -6.3755,  -6.3352,  -6.3673,  ...,  -5.8033,  -5.6581,  -3.7164],\n",
      "         [ -5.8093,  -5.8223,  -5.9000,  ...,  -6.6250,  -5.4469,  -2.6180],\n",
      "         [ -5.6710,  -5.6276,  -5.7756,  ...,  -6.3829,  -5.5439,  -2.2124],\n",
      "         ...,\n",
      "         [ -5.5311,  -5.4142,  -5.5275,  ...,  -6.0422,  -5.3102,  -1.7794],\n",
      "         [ -5.6564,  -5.6063,  -5.6536,  ...,  -5.9921,  -5.2797,  -2.0843],\n",
      "         [ -5.8074,  -5.6879,  -5.7653,  ...,  -6.0881,  -5.6160,  -2.4173]],\n",
      "\n",
      "        [[ -6.8814,  -6.8335,  -6.8606,  ...,  -6.0469,  -6.1167,  -3.9180],\n",
      "         [-11.8595, -12.1909, -11.9382,  ...,  -9.7770,  -9.4471,  -8.9947],\n",
      "         [ -4.6834,  -4.7197,  -4.7816,  ...,  -5.1667,  -6.4657,  -2.2860],\n",
      "         ...,\n",
      "         [ -5.2972,  -5.3278,  -5.3710,  ...,  -5.6256,  -6.7297,  -3.0457],\n",
      "         [ -4.8861,  -4.9805,  -4.9670,  ...,  -5.1771,  -6.2214,  -2.9813],\n",
      "         [ -5.4337,  -5.4835,  -5.4647,  ...,  -5.3394,  -6.4881,  -2.6600]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6915,  -6.6649,  -6.6744,  ...,  -5.9782,  -5.8130,  -3.7123],\n",
      "         [ -5.9427,  -5.8652,  -5.9902,  ...,  -6.6577,  -6.1172,  -2.0003],\n",
      "         [ -5.9954,  -5.9568,  -6.0922,  ...,  -6.5800,  -5.7091,  -3.8062],\n",
      "         ...,\n",
      "         [ -5.8914,  -5.8762,  -6.0198,  ...,  -6.3172,  -5.6477,  -2.4591],\n",
      "         [ -6.0677,  -6.0138,  -6.2224,  ...,  -6.2641,  -5.5862,  -2.6905],\n",
      "         [ -5.7312,  -5.7305,  -5.8796,  ...,  -6.1984,  -5.6103,  -2.1852]],\n",
      "\n",
      "        [[ -6.6095,  -6.5668,  -6.5612,  ...,  -5.9268,  -5.7383,  -3.7669],\n",
      "         [ -5.6046,  -5.7597,  -5.3444,  ...,  -5.7767,  -5.8564,  -6.1752],\n",
      "         [ -6.9455,  -7.0109,  -7.0201,  ...,  -7.2526,  -5.3549,  -5.4364],\n",
      "         ...,\n",
      "         [ -7.1379,  -7.4801,  -7.3699,  ...,  -6.8877,  -6.9443,  -3.1496],\n",
      "         [ -8.0114,  -8.2611,  -8.1302,  ...,  -8.1537,  -7.1733,  -4.1203],\n",
      "         [ -7.5809,  -7.8191,  -7.5145,  ...,  -7.5386,  -6.7596,  -4.6881]],\n",
      "\n",
      "        [[ -6.5017,  -6.4652,  -6.4812,  ...,  -5.8239,  -5.7740,  -3.7526],\n",
      "         [ -4.9212,  -4.9486,  -5.1901,  ...,  -6.2330,  -5.5564,  -3.0047],\n",
      "         [ -5.2880,  -5.2664,  -5.6406,  ...,  -6.1030,  -6.2611,  -2.5109],\n",
      "         ...,\n",
      "         [ -5.3841,  -5.3441,  -5.5544,  ...,  -5.9712,  -6.0367,  -2.3917],\n",
      "         [ -5.8120,  -5.7758,  -5.9629,  ...,  -6.4238,  -6.1598,  -2.6357],\n",
      "         [ -5.9027,  -5.7650,  -5.9580,  ...,  -6.5109,  -6.2916,  -2.9582]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.7842514514923096\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3481, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0285,  -6.9982,  -6.9273,  ...,  -6.4672,  -6.1620,  -4.6309],\n",
      "         [ -6.7146,  -6.7327,  -6.7229,  ...,  -7.1207,  -6.8038,  -6.3618],\n",
      "         [ -2.9445,  -3.0125,  -3.0338,  ...,  -4.1545,  -2.1020,  -3.4734],\n",
      "         ...,\n",
      "         [-13.3071, -13.0104, -13.3024,  ..., -12.0480, -11.6680,  -9.1312],\n",
      "         [-14.7762, -14.6782, -14.7153,  ..., -14.4557, -13.6301, -12.9225],\n",
      "         [-15.6044, -15.5849, -15.5311,  ..., -16.2683, -14.2798, -10.4321]],\n",
      "\n",
      "        [[ -6.7408,  -6.6931,  -6.7129,  ...,  -5.9321,  -5.9226,  -3.7341],\n",
      "         [-13.8714, -13.3214, -13.4141,  ..., -12.3098, -11.0857,  -9.9587],\n",
      "         [ -4.9600,  -5.1470,  -5.1996,  ...,  -5.4354,  -6.6764,  -2.7441],\n",
      "         ...,\n",
      "         [ -5.4261,  -5.5568,  -5.5290,  ...,  -5.3798,  -6.5818,  -4.1991],\n",
      "         [ -4.7803,  -4.9772,  -4.9277,  ...,  -4.9060,  -6.0884,  -2.6286],\n",
      "         [ -4.9294,  -5.0731,  -5.0609,  ...,  -5.0122,  -6.1345,  -2.8521]],\n",
      "\n",
      "        [[ -6.5084,  -6.3722,  -6.3751,  ...,  -5.5661,  -5.4946,  -3.7384],\n",
      "         [-11.7601, -11.2248, -11.0535,  ...,  -8.6998,  -8.9486, -10.4825],\n",
      "         [ -5.1701,  -5.1802,  -5.1519,  ...,  -5.0649,  -6.1643,  -2.1739],\n",
      "         ...,\n",
      "         [ -5.9384,  -5.9106,  -5.9380,  ...,  -5.9040,  -6.0361,  -3.2694],\n",
      "         [ -5.0460,  -5.0734,  -5.0457,  ...,  -4.6384,  -5.8324,  -2.7023],\n",
      "         [ -5.0063,  -4.9858,  -5.0200,  ...,  -4.6830,  -5.3802,  -4.0735]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1322,  -7.1248,  -7.1674,  ...,  -6.5898,  -6.1082,  -4.4890],\n",
      "         [-10.4196, -10.0873, -10.5839,  ..., -10.8932,  -7.5049,  -8.8618],\n",
      "         [ -7.3476,  -7.8975,  -7.9339,  ...,  -8.3793,  -5.6806,  -4.9886],\n",
      "         ...,\n",
      "         [ -5.2633,  -5.6481,  -5.5896,  ...,  -6.2600,  -5.4650,  -6.1958],\n",
      "         [ -4.0530,  -4.3827,  -4.3796,  ...,  -5.1896,  -4.9361,  -5.5679],\n",
      "         [ -6.4159,  -6.4638,  -6.5417,  ...,  -6.8399,  -5.6297,  -6.0352]],\n",
      "\n",
      "        [[ -7.3701,  -7.3532,  -7.3090,  ...,  -6.6380,  -6.4678,  -5.0032],\n",
      "         [-10.9056, -11.1367, -11.2635,  ..., -11.9014,  -9.5267,  -9.2727],\n",
      "         [ -6.3719,  -6.0995,  -6.2546,  ...,  -6.7418,  -5.5219,  -2.9620],\n",
      "         ...,\n",
      "         [ -6.5431,  -6.5630,  -6.4240,  ...,  -4.3591,  -5.6364,  -9.1643],\n",
      "         [ -6.7448,  -6.6562,  -6.7882,  ...,  -4.3996,  -6.7624,  -3.8719],\n",
      "         [-11.7806, -11.4355, -11.6623,  ..., -10.9121,  -9.0029,  -7.9007]],\n",
      "\n",
      "        [[ -6.9360,  -6.7964,  -6.8116,  ...,  -6.1611,  -6.2784,  -4.2176],\n",
      "         [-12.1698, -11.8092, -12.1051,  ..., -11.4208, -11.2329,  -9.3248],\n",
      "         [ -4.3021,  -3.9901,  -4.1247,  ...,  -3.1918,  -4.8828,  -2.7192],\n",
      "         ...,\n",
      "         [ -5.5048,  -5.2942,  -5.4383,  ...,  -4.3391,  -6.4330,  -3.3114],\n",
      "         [ -5.3655,  -5.0763,  -5.3175,  ...,  -4.3797,  -6.2870,  -2.9097],\n",
      "         [ -6.5035,  -6.3385,  -6.5073,  ...,  -5.4743,  -6.8858,  -4.0427]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.348095178604126\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1612, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1090,  -7.1549,  -7.0266,  ...,  -6.6397,  -6.2261,  -4.3080],\n",
      "         [-11.5133, -11.3128, -11.1097,  ...,  -8.6712,  -9.4677,  -7.1013],\n",
      "         [ -9.3469,  -9.6950,  -9.2654,  ...,  -8.0795,  -6.7923,  -5.4974],\n",
      "         ...,\n",
      "         [ -4.1575,  -4.7219,  -4.0823,  ...,  -5.6469,  -4.7816,  -0.7643],\n",
      "         [ -9.9486, -10.1956, -10.0579,  ...,  -9.1509,  -8.0783,  -6.7541],\n",
      "         [-11.3882, -11.7235, -11.2476,  ...,  -9.8094,  -9.7527,  -9.9317]],\n",
      "\n",
      "        [[ -6.2052,  -6.1452,  -6.1696,  ...,  -5.5044,  -5.2895,  -3.7234],\n",
      "         [-10.5952, -10.3331, -10.3047,  ...,  -8.0679,  -8.9283,  -7.8349],\n",
      "         [ -5.6917,  -5.7709,  -5.7767,  ...,  -5.8085,  -6.3083,  -3.5628],\n",
      "         ...,\n",
      "         [ -5.9276,  -6.0599,  -5.9700,  ...,  -6.1372,  -5.8537,  -3.6782],\n",
      "         [ -6.0606,  -6.0687,  -6.0326,  ...,  -6.0839,  -6.2531,  -3.7407],\n",
      "         [ -6.0575,  -6.1521,  -6.1217,  ...,  -5.7575,  -6.1642,  -3.9325]],\n",
      "\n",
      "        [[ -6.8778,  -6.8280,  -6.8230,  ...,  -5.8994,  -5.9857,  -3.9179],\n",
      "         [-11.8199, -11.9291, -11.7294,  ...,  -9.4072,  -8.5917,  -9.8897],\n",
      "         [ -5.6215,  -5.5839,  -5.6381,  ...,  -5.4074,  -6.6982,  -3.3729],\n",
      "         ...,\n",
      "         [ -5.7708,  -5.6905,  -5.6524,  ...,  -5.6700,  -6.5096,  -4.2144],\n",
      "         [ -6.0625,  -6.0295,  -6.0291,  ...,  -6.0777,  -6.8645,  -4.0723],\n",
      "         [ -6.0780,  -5.9715,  -5.9470,  ...,  -5.7477,  -6.8512,  -4.4982]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7104,  -6.7198,  -6.7214,  ...,  -6.3953,  -6.0538,  -4.5594],\n",
      "         [-11.4795, -11.6900, -11.5927,  ..., -12.3575,  -8.8442, -11.6219],\n",
      "         [ -4.4311,  -4.2059,  -4.4208,  ...,  -5.4601,  -4.1932,  -7.1783],\n",
      "         ...,\n",
      "         [ -5.5840,  -6.3627,  -5.6902,  ...,  -5.5005,  -5.9340,  -5.4962],\n",
      "         [ -5.8078,  -6.6839,  -6.4546,  ...,  -5.4764,  -5.9324,  -0.7046],\n",
      "         [ -8.5228,  -8.8493,  -8.3271,  ...,  -8.2013,  -8.9328,  -7.5148]],\n",
      "\n",
      "        [[ -6.5034,  -6.6259,  -6.6497,  ...,  -6.1556,  -5.8591,  -4.1289],\n",
      "         [-12.2720, -12.1551, -12.1072,  ...,  -8.7534,  -8.5861,  -9.4537],\n",
      "         [ -5.2079,  -5.4437,  -5.4454,  ...,  -5.8763,  -6.9497,  -3.4090],\n",
      "         ...,\n",
      "         [ -5.8443,  -5.8124,  -5.9225,  ...,  -6.0218,  -6.9345,  -4.4715],\n",
      "         [ -5.6203,  -5.5656,  -5.5857,  ...,  -5.7335,  -6.4254,  -4.5326],\n",
      "         [ -6.0385,  -5.9453,  -5.9579,  ...,  -6.1404,  -6.7742,  -4.0222]],\n",
      "\n",
      "        [[ -6.6860,  -6.7010,  -6.7681,  ...,  -5.9857,  -5.9964,  -3.7853],\n",
      "         [-11.3110, -11.2105, -11.1338,  ...,  -7.9634,  -8.7420, -10.0163],\n",
      "         [ -4.6016,  -4.7377,  -4.6723,  ...,  -4.6779,  -5.6984,  -3.2267],\n",
      "         ...,\n",
      "         [ -5.6221,  -5.6229,  -5.6441,  ...,  -5.6231,  -6.1653,  -4.2401],\n",
      "         [ -4.9279,  -4.9501,  -5.0399,  ...,  -5.2026,  -5.7135,  -2.9925],\n",
      "         [ -5.4792,  -5.5144,  -5.5114,  ...,  -5.3506,  -6.0952,  -3.0918]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.1611974239349365\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3068, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9422,  -6.9445,  -6.8947,  ...,  -6.1465,  -5.9984,  -3.8434],\n",
      "         [ -7.0855,  -7.3987,  -7.0861,  ...,  -7.4273,  -6.4417,  -2.6680],\n",
      "         [-13.1621, -13.8560, -13.1228,  ..., -13.6794, -11.0430,  -6.5824],\n",
      "         ...,\n",
      "         [ -6.4066,  -6.4715,  -6.2869,  ...,  -5.8431,  -5.9911,  -2.0711],\n",
      "         [ -7.5239,  -7.6972,  -7.4836,  ...,  -6.9978,  -6.3643,  -2.6798],\n",
      "         [ -7.6642,  -7.7662,  -7.6243,  ...,  -7.2861,  -6.9397,  -2.4476]],\n",
      "\n",
      "        [[ -6.6929,  -6.6306,  -6.6826,  ...,  -6.0167,  -6.0103,  -3.8986],\n",
      "         [ -6.3151,  -6.2711,  -6.4017,  ...,  -6.3997,  -6.0855,  -2.2800],\n",
      "         [ -5.8856,  -5.7662,  -5.9446,  ...,  -6.2255,  -5.8616,  -3.4282],\n",
      "         ...,\n",
      "         [ -5.3245,  -5.2386,  -5.4235,  ...,  -5.6528,  -5.3340,  -2.5083],\n",
      "         [ -6.0090,  -5.9631,  -6.0756,  ...,  -6.2630,  -5.9436,  -2.4450],\n",
      "         [ -5.7997,  -5.6767,  -5.9094,  ...,  -6.3093,  -5.8824,  -2.6195]],\n",
      "\n",
      "        [[ -6.3274,  -6.2688,  -6.2980,  ...,  -5.6760,  -5.3795,  -3.7622],\n",
      "         [-12.6273, -12.1899, -12.3691,  ...,  -8.8816,  -8.5494, -10.9247],\n",
      "         [ -5.5472,  -5.6974,  -5.6846,  ...,  -5.6234,  -6.2717,  -2.9141],\n",
      "         ...,\n",
      "         [ -6.1460,  -6.2652,  -6.2727,  ...,  -6.2304,  -6.8722,  -4.0717],\n",
      "         [ -5.3747,  -5.5423,  -5.5386,  ...,  -5.3409,  -6.6059,  -3.7520],\n",
      "         [ -5.4546,  -5.5990,  -5.5068,  ...,  -5.4548,  -6.2085,  -3.9893]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4058,  -6.3111,  -6.2634,  ...,  -5.2764,  -5.6289,  -4.7732],\n",
      "         [-10.7148, -10.4332, -10.4676,  ...,  -8.3623,  -7.7728,  -9.0336],\n",
      "         [ -5.0475,  -5.1521,  -5.1368,  ...,  -4.8980,  -5.7265,  -3.0044],\n",
      "         ...,\n",
      "         [ -5.4280,  -5.3845,  -5.4321,  ...,  -5.1269,  -5.7208,  -4.2497],\n",
      "         [ -5.4839,  -5.3639,  -5.5044,  ...,  -4.9685,  -5.5463,  -3.7396],\n",
      "         [ -5.5017,  -5.3935,  -5.5027,  ...,  -5.1036,  -6.0232,  -3.6146]],\n",
      "\n",
      "        [[ -8.7260,  -8.7081,  -8.5810,  ...,  -7.8297,  -7.2813,  -5.6456],\n",
      "         [ -5.3402,  -5.3445,  -4.9486,  ...,  -4.5298,  -4.0136,  -6.7703],\n",
      "         [-15.4186, -15.3092, -15.1713,  ..., -14.0156, -12.5861, -13.4844],\n",
      "         ...,\n",
      "         [ -7.2373,  -7.7597,  -7.3281,  ...,  -5.9482,  -5.2886,  -3.8638],\n",
      "         [ -8.4187,  -9.0506,  -8.5193,  ...,  -6.0359,  -6.7497,  -4.8269],\n",
      "         [ -7.4005,  -7.7227,  -7.3918,  ...,  -6.8803,  -5.9003,  -5.3733]],\n",
      "\n",
      "        [[ -8.0111,  -8.0308,  -7.9708,  ...,  -7.4176,  -6.8538,  -5.0825],\n",
      "         [ -7.6287,  -7.5207,  -7.8393,  ...,  -6.9508,  -5.9408,  -7.1046],\n",
      "         [-12.5288, -12.5294, -12.6845,  ..., -12.2016,  -9.3221, -12.0118],\n",
      "         ...,\n",
      "         [ -3.4206,  -2.9998,  -3.1163,  ...,  -3.4364,  -1.2874,  -2.9066],\n",
      "         [-13.4470, -13.5635, -13.0547,  ..., -10.7616,  -9.1549, -10.4417],\n",
      "         [-14.7147, -15.0054, -14.6332,  ..., -15.5290, -13.2278, -14.7114]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.3068339824676514\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2696, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2931,  -6.2488,  -6.2596,  ...,  -5.5748,  -5.7673,  -3.2436],\n",
      "         [ -5.8569,  -5.6500,  -5.6466,  ...,  -6.9016,  -6.7817,  -2.5715],\n",
      "         [ -5.8466,  -5.9899,  -5.8766,  ...,  -6.1875,  -7.2011,  -2.2447],\n",
      "         ...,\n",
      "         [ -5.7643,  -5.7198,  -5.8385,  ...,  -6.2505,  -5.5728,  -2.1242],\n",
      "         [ -5.5202,  -5.5073,  -5.5326,  ...,  -5.9451,  -5.6582,  -1.9795],\n",
      "         [ -5.4269,  -5.3960,  -5.4441,  ...,  -5.8991,  -5.4445,  -2.0098]],\n",
      "\n",
      "        [[ -6.3609,  -6.3489,  -6.3028,  ...,  -5.5964,  -5.8009,  -3.4820],\n",
      "         [ -8.3136,  -8.5469,  -8.3092,  ...,  -8.6689,  -7.4452,  -2.5819],\n",
      "         [ -5.9974,  -6.1519,  -6.1549,  ...,  -5.3182,  -5.2810,  -8.1788],\n",
      "         ...,\n",
      "         [ -6.3760,  -6.4695,  -6.2793,  ...,  -6.0979,  -6.1727,  -2.4824],\n",
      "         [ -5.5123,  -5.7288,  -5.3680,  ...,  -5.6096,  -5.0437,  -2.6323],\n",
      "         [ -6.1202,  -6.1844,  -6.0707,  ...,  -6.2287,  -5.8222,  -2.8052]],\n",
      "\n",
      "        [[ -5.8716,  -5.8548,  -5.8949,  ...,  -5.5055,  -5.5819,  -2.7951],\n",
      "         [-12.3089, -12.2919, -12.5701,  ..., -10.7298, -11.1929,  -8.8458],\n",
      "         [ -5.4526,  -5.7729,  -5.7418,  ...,  -6.0574,  -6.7310,  -2.7836],\n",
      "         ...,\n",
      "         [ -5.3980,  -5.5583,  -5.5756,  ...,  -5.4586,  -6.2982,  -3.0431],\n",
      "         [ -4.9701,  -5.1556,  -5.1270,  ...,  -5.0399,  -5.3058,  -2.8433],\n",
      "         [ -5.7506,  -5.8559,  -5.8639,  ...,  -5.9666,  -6.5018,  -3.4706]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6898,  -6.6329,  -6.6466,  ...,  -6.0274,  -5.9013,  -3.8602],\n",
      "         [ -5.8433,  -5.8127,  -5.9285,  ...,  -6.2542,  -5.5613,  -2.5030],\n",
      "         [ -5.0751,  -5.1318,  -5.2993,  ...,  -6.0416,  -4.9040,  -2.7983],\n",
      "         ...,\n",
      "         [ -5.7643,  -5.7261,  -5.8160,  ...,  -6.2725,  -5.6871,  -2.2529],\n",
      "         [ -5.9379,  -5.9612,  -6.0082,  ...,  -6.7320,  -5.6668,  -3.1250],\n",
      "         [ -6.0045,  -6.0829,  -6.1031,  ...,  -6.5567,  -5.7172,  -2.3488]],\n",
      "\n",
      "        [[ -7.7045,  -7.6999,  -7.5998,  ...,  -7.0980,  -6.7868,  -4.2556],\n",
      "         [-11.6455, -11.5370, -11.5687,  ...,  -9.8597,  -9.7964,  -8.9202],\n",
      "         [ -9.4265,  -9.5401,  -8.9596,  ...,  -8.6398,  -7.2417,  -8.0793],\n",
      "         ...,\n",
      "         [-12.5287, -12.2167, -12.1903,  ..., -12.3152, -11.0075,  -8.5556],\n",
      "         [-10.2361, -10.6752, -10.5480,  ...,  -7.4141,  -8.2226,  -6.1891],\n",
      "         [-13.3756, -12.7967, -13.1949,  ..., -10.6120, -10.9034,  -7.8628]],\n",
      "\n",
      "        [[ -6.2342,  -6.1310,  -6.1264,  ...,  -5.5835,  -5.4372,  -2.9974],\n",
      "         [ -5.7523,  -5.6753,  -5.5964,  ...,  -6.7373,  -5.7706,  -1.1649],\n",
      "         [-11.4300, -11.5840, -11.6267,  ..., -11.9856,  -9.9428,  -6.5573],\n",
      "         ...,\n",
      "         [ -7.9423,  -8.0184,  -7.9916,  ...,  -8.0849,  -7.0082,  -4.4017],\n",
      "         [ -7.7672,  -7.8178,  -7.7884,  ...,  -7.5817,  -6.7782,  -4.0444],\n",
      "         [ -6.9732,  -7.0539,  -6.9774,  ...,  -7.1130,  -6.1702,  -3.9486]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.2696301937103271\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6788, grad_fn=<NllLossBackward0>), logits=tensor([[[ -4.6193,  -4.5475,  -4.4575,  ...,  -4.9507,  -4.1013,  -3.4078],\n",
      "         [-11.0682, -10.2703, -10.6150,  ...,  -8.0177,  -9.1454,  -9.7757],\n",
      "         [ -5.6603,  -5.7303,  -5.7516,  ...,  -6.0316,  -5.9785,  -3.6019],\n",
      "         ...,\n",
      "         [ -6.8504,  -6.8912,  -6.8218,  ...,  -7.0719,  -6.3497,  -3.3673],\n",
      "         [ -6.1307,  -6.1400,  -6.1356,  ...,  -6.8169,  -5.9236,  -2.6359],\n",
      "         [ -6.2537,  -6.2405,  -6.2316,  ...,  -6.3909,  -6.0437,  -2.1572]],\n",
      "\n",
      "        [[ -6.7243,  -6.6905,  -6.7024,  ...,  -6.0101,  -5.8358,  -3.7941],\n",
      "         [ -5.8971,  -5.8224,  -6.0005,  ...,  -6.4931,  -6.1442,  -3.1452],\n",
      "         [ -6.0251,  -6.0614,  -6.1182,  ...,  -6.9008,  -5.9465,  -3.3810],\n",
      "         ...,\n",
      "         [ -5.8511,  -5.7541,  -6.0080,  ...,  -6.4179,  -5.8727,  -2.3512],\n",
      "         [ -6.2242,  -6.1579,  -6.2655,  ...,  -6.7640,  -5.9792,  -2.3637],\n",
      "         [ -5.7076,  -5.6364,  -5.8195,  ...,  -6.0714,  -5.4268,  -2.2468]],\n",
      "\n",
      "        [[ -6.6145,  -6.5868,  -6.5999,  ...,  -5.9344,  -5.9042,  -4.0844],\n",
      "         [ -9.5717,  -9.6172,  -9.4703,  ...,  -8.3169,  -7.8088,  -5.2894],\n",
      "         [ -5.1972,  -5.3307,  -5.0339,  ...,  -4.6550,  -5.4869,  -2.0421],\n",
      "         ...,\n",
      "         [ -8.3884,  -8.4478,  -8.5064,  ...,  -8.3846,  -7.3337,  -5.7876],\n",
      "         [ -8.6166,  -8.6227,  -8.7068,  ...,  -8.4344,  -7.4447,  -5.8640],\n",
      "         [ -8.6234,  -8.6593,  -8.6681,  ...,  -8.2632,  -7.4717,  -5.3189]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9513,  -7.0211,  -6.9505,  ...,  -5.4808,  -4.8373,  -7.0051],\n",
      "         [-12.3865, -12.4239, -12.3995,  ..., -11.1590, -11.5271, -10.2702],\n",
      "         [ -4.9733,  -4.8584,  -4.9882,  ...,  -3.9892,  -5.9172,  -3.4065],\n",
      "         ...,\n",
      "         [ -4.8932,  -4.8724,  -4.8928,  ...,  -4.0370,  -5.3313,  -4.3122],\n",
      "         [ -4.7468,  -4.7644,  -4.8249,  ...,  -3.6045,  -5.4166,  -4.3501],\n",
      "         [ -4.7327,  -4.7872,  -4.8507,  ...,  -3.8630,  -5.3651,  -3.8788]],\n",
      "\n",
      "        [[ -6.3933,  -6.3462,  -6.3731,  ...,  -5.7116,  -5.5182,  -3.7970],\n",
      "         [-11.3316, -11.1857, -10.7684,  ...,  -9.3145,  -9.6478,  -7.9089],\n",
      "         [ -5.9230,  -5.9376,  -5.9800,  ...,  -5.9718,  -6.4536,  -4.0419],\n",
      "         ...,\n",
      "         [ -6.4658,  -6.3650,  -6.5093,  ...,  -6.7115,  -6.8221,  -4.6252],\n",
      "         [ -6.1385,  -6.1849,  -6.2342,  ...,  -6.3995,  -6.6823,  -4.8896],\n",
      "         [ -6.0423,  -6.0407,  -6.1083,  ...,  -5.8147,  -6.7563,  -3.6736]],\n",
      "\n",
      "        [[ -6.9419,  -6.9063,  -6.8900,  ...,  -6.5826,  -6.2124,  -4.2439],\n",
      "         [ -6.9180,  -7.0513,  -7.0573,  ...,  -6.7930,  -6.0863,  -5.8924],\n",
      "         [ -7.6133,  -7.2637,  -7.5757,  ...,  -7.0931,  -6.2769,  -6.2272],\n",
      "         ...,\n",
      "         [ -0.5047,  -0.6551,  -0.7720,  ...,  -1.4671,  -2.1771,  -3.8266],\n",
      "         [ -4.4054,  -4.2859,  -4.3261,  ...,  -5.0871,  -4.1753,  -5.8426],\n",
      "         [-16.0626, -16.6806, -16.6723,  ..., -15.4014, -14.4218,  -9.2685]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.6788252592086792\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4035, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3685,  -7.3009,  -7.3074,  ...,  -6.7617,  -6.3529,  -4.8125],\n",
      "         [ -8.5305,  -8.4362,  -8.6692,  ...,  -8.5321,  -7.1129,  -6.4603],\n",
      "         [ -4.8167,  -4.5987,  -5.0989,  ...,  -3.9274,  -3.7086,  -6.1917],\n",
      "         ...,\n",
      "         [ -7.2523,  -7.3336,  -7.2281,  ...,  -7.5476,  -7.0902,  -4.6992],\n",
      "         [ -6.0386,  -6.0129,  -6.0919,  ...,  -6.2152,  -6.4697,  -4.2107],\n",
      "         [ -5.6503,  -5.6989,  -5.8536,  ...,  -5.6982,  -6.2049,  -4.1823]],\n",
      "\n",
      "        [[ -7.6312,  -7.7101,  -7.5402,  ...,  -7.3170,  -6.8358,  -4.6778],\n",
      "         [-11.8113, -12.0479, -11.8711,  ..., -10.3148,  -7.9476, -10.5346],\n",
      "         [ -3.9614,  -4.4438,  -4.2442,  ...,  -5.0011,  -4.1142,  -6.4669],\n",
      "         ...,\n",
      "         [ -4.4588,  -4.6727,  -4.5567,  ...,  -5.9379,  -4.1440,  -3.5910],\n",
      "         [ -4.3001,  -4.2815,  -4.2815,  ...,  -5.7811,  -4.4399,  -3.7175],\n",
      "         [ -3.8090,  -3.8570,  -3.8440,  ...,  -5.2946,  -3.8950,  -3.3567]],\n",
      "\n",
      "        [[ -6.5056,  -6.4521,  -6.4654,  ...,  -5.8369,  -5.6624,  -3.6500],\n",
      "         [ -5.9709,  -5.9164,  -6.1007,  ...,  -6.9302,  -5.9195,  -2.1599],\n",
      "         [ -5.6704,  -5.6744,  -5.7872,  ...,  -6.3151,  -5.6213,  -2.1959],\n",
      "         ...,\n",
      "         [ -5.7182,  -5.6691,  -5.7647,  ...,  -6.4070,  -5.5668,  -2.4474],\n",
      "         [ -6.0378,  -5.9653,  -6.1655,  ...,  -6.4789,  -5.9324,  -2.4928],\n",
      "         [ -6.0534,  -5.9973,  -6.1045,  ...,  -6.4101,  -5.8526,  -2.3566]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1483,  -7.0987,  -7.1099,  ...,  -6.3033,  -6.1482,  -4.1915],\n",
      "         [-15.4865, -15.1013, -15.4115,  ..., -13.8505, -12.9351, -13.5962],\n",
      "         [ -5.8995,  -6.0597,  -5.9983,  ...,  -5.8593,  -6.5519,  -2.5806],\n",
      "         ...,\n",
      "         [ -6.3371,  -6.4670,  -6.3756,  ...,  -6.0379,  -6.9101,  -3.5764],\n",
      "         [ -6.3604,  -6.5182,  -6.5223,  ...,  -6.1455,  -6.8942,  -3.3058],\n",
      "         [ -5.6341,  -5.7823,  -5.7178,  ...,  -5.4151,  -5.9695,  -2.9206]],\n",
      "\n",
      "        [[ -7.7845,  -7.8275,  -7.8322,  ...,  -7.0770,  -6.8296,  -5.3948],\n",
      "         [ -6.5063,  -6.7664,  -6.6069,  ...,  -7.7262,  -5.5204,  -7.8581],\n",
      "         [ -4.6055,  -4.5244,  -4.6037,  ...,  -4.8441,  -5.9222,  -3.8411],\n",
      "         ...,\n",
      "         [ -5.8028,  -5.8737,  -6.0170,  ...,  -5.9102,  -5.1094,  -5.6323],\n",
      "         [ -3.8598,  -4.1110,  -4.2116,  ...,  -3.6838,  -3.3736,  -5.6855],\n",
      "         [ -4.2437,  -4.3487,  -4.3708,  ...,  -4.8380,  -4.2196,  -2.6618]],\n",
      "\n",
      "        [[ -8.0874,  -8.0909,  -8.1198,  ...,  -7.3990,  -7.2051,  -5.2736],\n",
      "         [ -5.1081,  -5.2955,  -5.3244,  ...,  -4.2296,  -5.7616,  -4.9676],\n",
      "         [ -2.8638,  -3.0448,  -2.9383,  ...,  -2.6114,  -2.3498,  -3.5421],\n",
      "         ...,\n",
      "         [ -6.2205,  -6.8227,  -6.5696,  ...,  -8.1092,  -6.3941,  -3.1019],\n",
      "         [ -3.3365,  -3.4049,  -3.6934,  ...,  -2.3379,  -2.6617,   0.1792],\n",
      "         [ -9.7474,  -9.1083,  -9.5169,  ...,  -7.8359,  -8.0209,  -8.8209]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.4034819602966309\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1072, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.3977,  -8.2896,  -8.3706,  ...,  -7.3355,  -7.1853,  -5.0106],\n",
      "         [ -9.9585,  -9.7476, -10.0688,  ...,  -8.3821,  -9.2646,  -7.7662],\n",
      "         [ -9.3427,  -9.6077,  -9.4926,  ...,  -7.7815,  -6.8673,  -2.6338],\n",
      "         ...,\n",
      "         [ -7.9160,  -8.0922,  -7.7956,  ...,  -7.1616,  -7.6210,  -4.7197],\n",
      "         [ -8.1122,  -8.1290,  -8.0430,  ...,  -7.4690,  -7.5488,  -4.6443],\n",
      "         [ -6.9798,  -6.9495,  -7.0286,  ...,  -6.6708,  -6.7051,  -5.0913]],\n",
      "\n",
      "        [[ -7.5184,  -7.4680,  -7.2966,  ...,  -6.6712,  -6.1895,  -3.3722],\n",
      "         [ -5.7401,  -6.3521,  -5.9217,  ...,  -6.3601,  -4.6759,  -6.4707],\n",
      "         [ -3.9976,  -4.3841,  -3.8621,  ...,  -5.0034,  -3.0783,  -7.8011],\n",
      "         ...,\n",
      "         [ -8.0700,  -8.3090,  -8.0913,  ...,  -7.3826,  -6.6104,  -5.7394],\n",
      "         [ -7.9234,  -8.2742,  -7.9937,  ...,  -7.2636,  -6.6055,  -5.0553],\n",
      "         [ -6.8038,  -7.0550,  -6.7315,  ...,  -5.8131,  -5.0883,  -4.0996]],\n",
      "\n",
      "        [[ -7.1237,  -7.0988,  -7.0685,  ...,  -6.2977,  -6.0789,  -4.5906],\n",
      "         [ -9.1106,  -9.1883,  -9.3133,  ..., -10.3300,  -8.7763, -12.0717],\n",
      "         [ -7.7071,  -7.5350,  -8.0845,  ...,  -8.2589,  -6.7969,  -9.5581],\n",
      "         ...,\n",
      "         [ -7.0561,  -7.3627,  -6.9115,  ...,  -5.1822,  -6.0327,  -6.3027],\n",
      "         [ -6.6786,  -7.0053,  -6.8631,  ...,  -5.6437,  -6.2867,  -4.3449],\n",
      "         [ -8.1412,  -8.3072,  -8.1603,  ...,  -6.6269,  -6.1525,  -7.0439]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3258,  -7.2354,  -7.2277,  ...,  -6.8748,  -6.5731,  -3.5945],\n",
      "         [ -7.2187,  -6.9118,  -7.0214,  ...,  -7.5822,  -6.2375,  -5.6415],\n",
      "         [ -4.5305,  -4.1585,  -3.8474,  ...,  -4.0179,  -3.6330,  -4.7626],\n",
      "         ...,\n",
      "         [ -3.4719,  -3.4683,  -3.5488,  ...,  -3.1203,  -4.2625,  -3.9052],\n",
      "         [-10.0780, -10.5362, -10.2993,  ..., -10.4952,  -9.1024,  -9.1687],\n",
      "         [ -7.2716,  -7.7515,  -7.1170,  ...,  -8.1968,  -5.5540,  -5.3670]],\n",
      "\n",
      "        [[ -6.1388,  -6.1836,  -6.2074,  ...,  -5.6257,  -5.2147,  -3.7316],\n",
      "         [-17.6334, -17.3209, -17.3088,  ..., -15.3059, -13.8301, -13.4554],\n",
      "         [ -5.1826,  -5.2764,  -5.3648,  ...,  -5.2487,  -6.2970,  -3.4564],\n",
      "         ...,\n",
      "         [ -5.6354,  -5.6945,  -5.6995,  ...,  -5.5552,  -6.4071,  -3.8707],\n",
      "         [ -5.8557,  -5.9451,  -6.0237,  ...,  -5.9003,  -6.1445,  -4.1001],\n",
      "         [ -5.3281,  -5.3311,  -5.5192,  ...,  -5.2165,  -6.1612,  -3.7035]],\n",
      "\n",
      "        [[ -7.2801,  -7.2961,  -7.2378,  ...,  -6.4441,  -6.4315,  -3.9624],\n",
      "         [-10.1277, -10.3748, -10.1232,  ...,  -8.8229,  -8.1887, -11.6519],\n",
      "         [ -3.4009,  -3.6456,  -3.5948,  ...,  -2.8196,  -4.5046,  -5.6471],\n",
      "         ...,\n",
      "         [ -2.7340,  -3.1219,  -2.7685,  ...,  -1.7883,  -4.1781,  -1.7444],\n",
      "         [ -1.4974,  -1.4270,  -1.4271,  ...,  -0.1471,  -1.2161,  -0.9278],\n",
      "         [-12.9305, -13.5153, -13.4802,  ..., -11.9735, -12.4332,  -9.9265]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.1072421073913574\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9710, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3938,  -7.4123,  -7.4151,  ...,  -7.1498,  -6.9874,  -4.8607],\n",
      "         [-12.1292, -12.3763, -12.3485,  ..., -12.1643, -10.1457, -11.1249],\n",
      "         [ -9.0514,  -8.9105,  -8.9441,  ...,  -9.6582,  -5.4867, -10.9396],\n",
      "         ...,\n",
      "         [-10.4178, -10.5667, -10.7867,  ..., -11.9768,  -7.7091, -13.9788],\n",
      "         [-11.2192, -11.7771, -11.6640,  ..., -10.8943, -10.7965,  -9.4283],\n",
      "         [-15.3425, -15.7597, -15.9153,  ..., -15.9041, -12.9363, -11.4353]],\n",
      "\n",
      "        [[ -6.7097,  -6.6984,  -6.6958,  ...,  -6.1887,  -5.8531,  -3.9944],\n",
      "         [ -6.8833,  -6.6556,  -6.9509,  ...,  -6.5518,  -6.3492,  -4.6662],\n",
      "         [ -3.0311,  -2.9021,  -3.1144,  ...,  -2.9126,  -2.8639,  -4.4804],\n",
      "         ...,\n",
      "         [ -7.2331,  -7.2161,  -7.2151,  ...,  -7.8684,  -7.3405,  -6.0809],\n",
      "         [ -6.4444,  -6.5205,  -6.4495,  ...,  -7.7636,  -6.4973,  -5.9734],\n",
      "         [ -7.2496,  -7.3321,  -7.2649,  ...,  -8.0533,  -7.3483,  -6.5054]],\n",
      "\n",
      "        [[ -6.6890,  -6.6713,  -6.6840,  ...,  -6.0352,  -5.7812,  -3.7716],\n",
      "         [ -5.5891,  -5.5455,  -5.6522,  ...,  -6.1329,  -5.6403,  -2.5367],\n",
      "         [ -6.3987,  -6.4661,  -6.5327,  ...,  -7.3147,  -6.1322,  -3.0613],\n",
      "         ...,\n",
      "         [ -5.9972,  -6.0684,  -6.0894,  ...,  -6.5869,  -6.0920,  -2.5470],\n",
      "         [ -5.5546,  -5.5351,  -5.5984,  ...,  -6.0722,  -5.5614,  -1.7784],\n",
      "         [ -5.8057,  -5.8613,  -5.8864,  ...,  -6.2405,  -5.6199,  -2.1804]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2558,  -6.2218,  -6.2039,  ...,  -5.5802,  -5.3654,  -3.7559],\n",
      "         [ -9.4956,  -9.1485,  -9.5082,  ...,  -6.3413,  -8.9267,  -7.3603],\n",
      "         [ -5.3976,  -5.5122,  -5.4766,  ...,  -5.3526,  -6.1584,  -3.1734],\n",
      "         ...,\n",
      "         [ -5.2883,  -5.3901,  -5.2647,  ...,  -5.0006,  -5.6563,  -3.8784],\n",
      "         [ -5.7507,  -5.7478,  -5.7390,  ...,  -5.6913,  -6.0411,  -3.2624],\n",
      "         [ -5.6341,  -5.7261,  -5.7555,  ...,  -5.4184,  -5.9039,  -3.1177]],\n",
      "\n",
      "        [[ -7.2731,  -7.2333,  -7.1851,  ...,  -6.4399,  -6.4388,  -4.2827],\n",
      "         [ -8.6184,  -8.6120,  -8.6313,  ...,  -8.4740,  -7.6766,  -5.2212],\n",
      "         [ -6.8373,  -6.5021,  -7.0970,  ...,  -6.8650,  -5.5691,  -4.3843],\n",
      "         ...,\n",
      "         [-11.4222, -11.5987, -11.6652,  ..., -11.0267, -10.2845, -13.6093],\n",
      "         [-11.5995, -11.7957, -11.6989,  ..., -11.5297, -10.5756, -10.5011],\n",
      "         [-16.3773, -16.6768, -16.8277,  ..., -17.4059, -14.3486, -13.5281]],\n",
      "\n",
      "        [[ -2.6086,  -2.9330,  -2.7514,  ...,  -2.9230,  -1.8819,  -0.4031],\n",
      "         [-12.5553, -12.5491, -12.6668,  ...,  -9.9508,  -9.2641,  -8.5167],\n",
      "         [ -5.6147,  -5.5731,  -5.6424,  ...,  -6.2285,  -6.5991,  -3.2911],\n",
      "         ...,\n",
      "         [ -4.9058,  -4.9843,  -5.0087,  ...,  -5.1168,  -5.0029,  -3.1922],\n",
      "         [ -5.1120,  -5.0459,  -5.1244,  ...,  -5.4216,  -5.3013,  -2.5217],\n",
      "         [ -5.4663,  -5.4434,  -5.4834,  ...,  -5.5867,  -5.2104,  -2.9823]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.9710021018981934\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0818, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5012,  -7.5641,  -7.4945,  ...,  -7.2217,  -6.4798,  -5.1071],\n",
      "         [ -6.3073,  -6.2561,  -6.3303,  ...,  -6.3724,  -5.0553,  -6.7610],\n",
      "         [ -8.4232,  -8.4096,  -8.5394,  ...,  -7.3815,  -7.8503,  -6.3437],\n",
      "         ...,\n",
      "         [ -9.0796,  -9.3722,  -9.0367,  ...,  -9.0989,  -6.2287,  -9.8232],\n",
      "         [ -5.8249,  -6.0575,  -5.9010,  ...,  -5.3613,  -5.3775,  -4.7661],\n",
      "         [-11.0851, -11.2761, -11.3938,  ...,  -9.9720,  -8.5061,  -7.2093]],\n",
      "\n",
      "        [[ -6.9615,  -7.1193,  -6.9905,  ...,  -6.2712,  -6.3380,  -4.8807],\n",
      "         [-12.8962, -13.2443, -13.3151,  ..., -13.0054, -10.9626, -10.8818],\n",
      "         [ -5.9833,  -6.3665,  -6.3081,  ...,  -5.9070,  -4.6024,  -6.9964],\n",
      "         ...,\n",
      "         [ -4.7618,  -5.0844,  -5.3802,  ...,  -6.9971,  -5.3398,  -6.2669],\n",
      "         [ -4.8691,  -5.1951,  -4.9821,  ...,  -6.8046,  -5.9504,  -5.3578],\n",
      "         [-10.3970, -10.8562, -10.7889,  ..., -12.2727, -11.5125,  -8.5794]],\n",
      "\n",
      "        [[ -6.5029,  -6.4657,  -6.4927,  ...,  -5.7843,  -5.6580,  -3.7276],\n",
      "         [-15.4165, -15.0973, -15.2186,  ..., -12.9370, -13.5051, -12.3829],\n",
      "         [ -4.6435,  -4.8388,  -4.9079,  ...,  -4.5612,  -6.1540,  -3.5156],\n",
      "         ...,\n",
      "         [ -5.2939,  -5.4642,  -5.5104,  ...,  -4.9119,  -6.1646,  -4.1693],\n",
      "         [ -5.4574,  -5.6148,  -5.6614,  ...,  -5.3249,  -6.6923,  -4.2099],\n",
      "         [ -5.4024,  -5.6153,  -5.7100,  ...,  -5.0298,  -6.7095,  -4.3666]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4351,  -7.4464,  -7.3943,  ...,  -6.8118,  -6.5235,  -4.4845],\n",
      "         [-10.6331, -10.8971, -10.4837,  ...,  -8.1194,  -8.6625, -10.1214],\n",
      "         [ -5.6619,  -5.7732,  -5.7124,  ...,  -6.2399,  -7.2780,  -3.0602],\n",
      "         ...,\n",
      "         [ -6.0793,  -6.2651,  -6.1179,  ...,  -6.2873,  -7.0114,  -3.5293],\n",
      "         [ -5.2789,  -5.3627,  -5.3309,  ...,  -5.4488,  -6.4473,  -3.6913],\n",
      "         [ -5.7042,  -5.7575,  -5.7372,  ...,  -6.0284,  -6.7096,  -2.9404]],\n",
      "\n",
      "        [[ -7.1147,  -7.0877,  -7.1004,  ...,  -6.3296,  -6.1253,  -3.8021],\n",
      "         [ -6.2021,  -6.1292,  -6.1935,  ...,  -6.6499,  -5.6153,  -2.5673],\n",
      "         [ -7.6412,  -7.8442,  -7.7179,  ...,  -6.8485,  -6.3589,  -2.5284],\n",
      "         ...,\n",
      "         [ -6.1690,  -6.1169,  -6.0742,  ...,  -6.1659,  -5.2207,  -1.6179],\n",
      "         [ -6.1652,  -6.1498,  -6.2515,  ...,  -6.3337,  -5.4576,  -1.8175],\n",
      "         [ -5.9236,  -5.9738,  -5.9623,  ...,  -6.1892,  -5.1915,  -1.9252]],\n",
      "\n",
      "        [[ -7.5847,  -7.5831,  -7.5457,  ...,  -6.3383,  -6.9036,  -4.7991],\n",
      "         [-11.5693, -11.4846, -11.4275,  ..., -10.1485, -10.5401,  -9.6654],\n",
      "         [ -5.0581,  -5.1282,  -5.0832,  ...,  -5.0902,  -6.6078,  -2.1610],\n",
      "         ...,\n",
      "         [ -4.8895,  -4.9858,  -4.9278,  ...,  -5.2754,  -6.2714,  -2.8937],\n",
      "         [ -5.1189,  -5.2497,  -5.1912,  ...,  -5.2100,  -6.3161,  -3.2174],\n",
      "         [ -4.9775,  -4.9149,  -4.9676,  ...,  -5.1058,  -5.7219,  -2.6471]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0817830562591553\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8056, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.9044,  -8.9628,  -8.9927,  ...,  -7.9570,  -8.2895,  -5.5183],\n",
      "         [-11.0932, -10.9108, -10.9626,  ...,  -9.2575,  -9.1044, -10.3692],\n",
      "         [ -4.3347,  -4.5616,  -4.5998,  ...,  -5.1676,  -6.0789,  -3.8214],\n",
      "         ...,\n",
      "         [ -4.0433,  -4.1931,  -4.1649,  ...,  -4.3584,  -5.4371,  -4.7800],\n",
      "         [ -4.7027,  -4.8452,  -4.9424,  ...,  -5.4472,  -6.2088,  -4.4938],\n",
      "         [ -4.5077,  -4.7119,  -4.8061,  ...,  -4.5678,  -6.0770,  -3.4513]],\n",
      "\n",
      "        [[ -8.6927,  -8.5827,  -8.5937,  ...,  -8.5295,  -8.5035,  -5.3947],\n",
      "         [ -9.5692,  -9.1584,  -9.4338,  ...,  -7.6807,  -7.9753, -10.3394],\n",
      "         [ -5.2074,  -5.2380,  -5.2675,  ...,  -5.6470,  -6.8280,  -3.7213],\n",
      "         ...,\n",
      "         [ -5.0737,  -5.1866,  -5.1968,  ...,  -5.6067,  -6.4125,  -2.4723],\n",
      "         [ -4.4035,  -4.4832,  -4.5025,  ...,  -5.0614,  -5.5589,  -3.0180],\n",
      "         [ -5.1266,  -5.1441,  -5.1444,  ...,  -5.6289,  -5.8540,  -3.8045]],\n",
      "\n",
      "        [[ -7.6088,  -7.5571,  -7.5263,  ...,  -6.6476,  -6.6925,  -4.2335],\n",
      "         [ -8.8246,  -8.6007,  -8.7376,  ...,  -7.0171,  -6.5587,  -8.8046],\n",
      "         [-13.0932, -12.6262, -12.8206,  ..., -10.4378,  -9.7161,  -5.5745],\n",
      "         ...,\n",
      "         [ -6.9519,  -6.8599,  -6.8966,  ...,  -5.9639,  -6.1453,  -4.6843],\n",
      "         [ -6.6344,  -6.6040,  -6.6369,  ...,  -5.7227,  -5.6564,  -4.5926],\n",
      "         [ -7.3194,  -7.2703,  -7.4562,  ...,  -6.1633,  -6.6454,  -4.3279]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.0458,  -8.0150,  -7.9004,  ...,  -7.0215,  -7.1144,  -5.1085],\n",
      "         [ -8.1042,  -8.2960,  -8.1940,  ...,  -8.6397,  -7.9085,  -5.2518],\n",
      "         [ -5.7497,  -6.0677,  -6.0812,  ...,  -6.5506,  -5.6747,  -3.1165],\n",
      "         ...,\n",
      "         [-14.5796, -14.0385, -14.4323,  ..., -11.8538, -12.5016,  -8.9358],\n",
      "         [-12.3172, -12.5158, -12.3639,  ..., -10.7402, -11.5324,  -7.8912],\n",
      "         [ -7.9466,  -7.9620,  -7.9799,  ...,  -8.0181,  -7.9789,  -5.6583]],\n",
      "\n",
      "        [[-13.4832, -13.0384, -13.3326,  ..., -12.5075, -12.4345, -12.3534],\n",
      "         [-11.3729, -11.0130, -10.9742,  ...,  -9.1535,  -9.2645, -11.0434],\n",
      "         [ -4.9652,  -5.0633,  -5.0889,  ...,  -5.1291,  -6.9274,  -2.4356],\n",
      "         ...,\n",
      "         [ -4.6504,  -4.6136,  -4.6534,  ...,  -4.4240,  -6.5980,  -4.0710],\n",
      "         [ -4.4976,  -4.4565,  -4.5108,  ...,  -4.8810,  -6.2839,  -4.9481],\n",
      "         [ -5.0499,  -4.9885,  -5.1052,  ...,  -5.3885,  -6.5918,  -4.6699]],\n",
      "\n",
      "        [[ -7.0206,  -7.0759,  -7.0238,  ...,  -6.3394,  -6.4932,  -4.0449],\n",
      "         [-11.0068, -11.0075, -10.9537,  ...,  -9.2650, -10.6494,  -8.2600],\n",
      "         [ -4.1302,  -4.2948,  -4.2210,  ...,  -5.0966,  -5.8965,  -2.4793],\n",
      "         ...,\n",
      "         [ -5.2945,  -5.3935,  -5.3669,  ...,  -5.6848,  -6.0954,  -4.4921],\n",
      "         [ -5.1347,  -5.1571,  -5.2286,  ...,  -5.3775,  -6.0888,  -3.3275],\n",
      "         [ -5.1986,  -5.3168,  -5.2975,  ...,  -5.9061,  -6.4114,  -3.4165]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8056062459945679\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0039, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6921,  -6.7538,  -6.8032,  ...,  -6.2500,  -6.0859,  -4.1351],\n",
      "         [-11.4534, -11.2080, -11.5459,  ..., -10.1105, -11.3199,  -8.9067],\n",
      "         [ -5.0170,  -5.1086,  -5.1980,  ...,  -5.2878,  -5.9596,  -3.7529],\n",
      "         ...,\n",
      "         [ -5.3880,  -5.4595,  -5.4855,  ...,  -5.6150,  -6.2401,  -4.3053],\n",
      "         [ -5.6778,  -5.6543,  -5.7845,  ...,  -5.5681,  -5.9585,  -4.4972],\n",
      "         [ -5.4657,  -5.4740,  -5.5868,  ...,  -5.4090,  -6.2025,  -3.6654]],\n",
      "\n",
      "        [[ -6.0655,  -6.0014,  -6.0455,  ...,  -5.3840,  -5.2695,  -3.4513],\n",
      "         [-11.4377, -11.0888, -11.2155,  ...,  -7.7889,  -9.3124,  -8.1104],\n",
      "         [ -4.3040,  -4.2429,  -4.4027,  ...,  -4.8481,  -5.4021,  -3.2396],\n",
      "         ...,\n",
      "         [ -4.1580,  -4.1857,  -4.3810,  ...,  -4.2486,  -5.9760,  -3.7880],\n",
      "         [ -3.8697,  -3.9764,  -3.9957,  ...,  -4.0812,  -5.1896,  -2.3660],\n",
      "         [ -4.3273,  -4.2836,  -4.3587,  ...,  -4.0545,  -5.3611,  -4.1844]],\n",
      "\n",
      "        [[ -7.2325,  -7.2240,  -7.1464,  ...,  -6.3482,  -6.0341,  -5.0665],\n",
      "         [-13.4241, -13.7680, -13.2229,  ..., -12.4871, -10.7161, -12.4154],\n",
      "         [ -3.9455,  -4.1517,  -4.0136,  ...,  -4.4903,  -3.7843,  -6.6657],\n",
      "         ...,\n",
      "         [ -8.0024,  -8.1890,  -8.2642,  ...,  -7.7163,  -7.8479,  -5.8908],\n",
      "         [ -6.6269,  -6.7718,  -6.7421,  ...,  -6.8318,  -6.2580,  -4.6023],\n",
      "         [ -5.7971,  -5.9813,  -5.8199,  ...,  -6.3207,  -5.3649,  -4.0630]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5514,  -6.4910,  -6.4678,  ...,  -5.9744,  -5.7820,  -4.0066],\n",
      "         [-11.8046, -11.6220, -11.8953,  ...,  -8.2007, -10.1091, -10.0219],\n",
      "         [ -5.5168,  -5.5721,  -5.5202,  ...,  -6.0836,  -6.7794,  -3.6134],\n",
      "         ...,\n",
      "         [ -6.2911,  -6.4194,  -6.3752,  ...,  -6.3514,  -6.6046,  -4.7623],\n",
      "         [ -5.9794,  -6.0529,  -6.0741,  ...,  -6.2020,  -6.5287,  -4.1367],\n",
      "         [ -6.5178,  -6.5089,  -6.5729,  ...,  -6.7909,  -6.9571,  -4.7056]],\n",
      "\n",
      "        [[ -6.9598,  -6.9270,  -6.8946,  ...,  -6.3070,  -6.0703,  -4.2021],\n",
      "         [ -8.9933,  -9.0071,  -8.9831,  ...,  -8.7127,  -6.9217,  -5.8816],\n",
      "         [ -4.4711,  -4.5134,  -4.5146,  ...,  -4.2762,  -4.3534,  -2.5613],\n",
      "         ...,\n",
      "         [ -7.8207,  -7.9328,  -7.8551,  ...,  -8.6171,  -6.6909,  -5.7945],\n",
      "         [ -4.6963,  -4.7895,  -4.4784,  ...,  -4.6022,  -3.4571,  -3.4004],\n",
      "         [ -5.5838,  -5.7343,  -5.5780,  ...,  -5.4322,  -4.0500,  -3.2502]],\n",
      "\n",
      "        [[ -7.1436,  -7.0668,  -7.0075,  ...,  -6.4921,  -5.9889,  -4.2326],\n",
      "         [ -5.1495,  -5.5616,  -5.5334,  ...,  -4.5243,  -3.6669,  -4.8428],\n",
      "         [-12.1333, -12.0889, -11.8320,  ..., -10.0155, -10.8554,  -8.3193],\n",
      "         ...,\n",
      "         [-10.7245, -10.7528, -10.8555,  ...,  -8.9285,  -7.6351,  -6.3915],\n",
      "         [ -6.2125,  -6.3910,  -6.1127,  ...,  -6.1147,  -4.9919,  -5.3205],\n",
      "         [ -6.7684,  -6.9166,  -6.6614,  ...,  -6.0505,  -4.7362,  -5.4692]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0038836002349854\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6135, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9001,  -6.9175,  -6.8934,  ...,  -6.0331,  -6.0893,  -3.9161],\n",
      "         [ -8.0413,  -8.2847,  -8.1820,  ...,  -9.0751,  -8.9901,  -5.5314],\n",
      "         [ -0.5295,  -0.6115,  -0.4310,  ...,  -1.1598,  -0.8728,   2.8614],\n",
      "         ...,\n",
      "         [ -8.1059,  -8.5334,  -8.3975,  ...,  -8.9021,  -9.0052,  -5.0205],\n",
      "         [ -6.5833,  -6.5970,  -6.5077,  ...,  -6.7653,  -7.4559,  -5.0433],\n",
      "         [ -6.4498,  -6.4830,  -6.3482,  ...,  -6.6046,  -6.7900,  -5.4261]],\n",
      "\n",
      "        [[ -7.3546,  -7.4320,  -7.3561,  ...,  -6.5347,  -6.8460,  -4.7576],\n",
      "         [ -8.9176,  -8.8781,  -8.9748,  ...,  -8.6799,  -8.9076,  -8.0398],\n",
      "         [ -7.0343,  -7.4333,  -7.5682,  ...,  -6.3112,  -7.1056,  -6.7832],\n",
      "         ...,\n",
      "         [ -5.9894,  -6.1748,  -6.2571,  ...,  -6.0178,  -6.8582,  -2.9776],\n",
      "         [ -5.0323,  -5.1746,  -5.2456,  ...,  -4.9380,  -5.1199,  -3.2412],\n",
      "         [ -5.4884,  -5.6948,  -5.6325,  ...,  -5.3635,  -5.4686,  -3.9525]],\n",
      "\n",
      "        [[ -8.8585,  -8.8002,  -8.7097,  ...,  -7.9479,  -8.2744,  -5.8073],\n",
      "         [-14.5041, -14.1262, -14.2751,  ..., -11.5971, -10.4255, -10.5520],\n",
      "         [ -4.5724,  -4.8169,  -4.7312,  ...,  -5.4181,  -6.1834,  -3.5685],\n",
      "         ...,\n",
      "         [ -4.6000,  -4.6785,  -4.7238,  ...,  -5.1961,  -5.4147,  -3.3582],\n",
      "         [ -4.8742,  -4.9122,  -4.9460,  ...,  -5.9646,  -6.0621,  -4.0401],\n",
      "         [ -5.3252,  -5.3599,  -5.3465,  ...,  -5.7548,  -5.7869,  -3.1085]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1352,  -7.2992,  -7.1294,  ...,  -7.2164,  -6.2308,  -4.8850],\n",
      "         [ -4.6801,  -5.1635,  -5.1701,  ...,  -5.8276,  -3.0788,  -2.4403],\n",
      "         [ -9.4919,  -9.8249,  -9.9206,  ...,  -9.5097,  -9.0954,  -6.9676],\n",
      "         ...,\n",
      "         [ -6.1376,  -5.9774,  -6.3565,  ...,  -4.5424,  -4.6708,  -9.6438],\n",
      "         [ -3.4041,  -3.4527,  -3.3872,  ...,  -3.3171,  -2.0707,  -2.8491],\n",
      "         [-10.5595, -11.0589, -11.0076,  ..., -12.3226, -11.2759,  -7.4326]],\n",
      "\n",
      "        [[ -6.5879,  -6.6235,  -6.6121,  ...,  -6.2365,  -5.7622,  -4.2744],\n",
      "         [ -9.4138,  -9.0866,  -9.2024,  ..., -10.8758,  -8.1594,  -9.2680],\n",
      "         [-13.5117, -13.8506, -13.8204,  ..., -11.6972, -11.2389, -12.2144],\n",
      "         ...,\n",
      "         [ -8.1718,  -8.3132,  -7.7177,  ...,  -7.6907,  -5.4278,  -6.7433],\n",
      "         [ -5.1495,  -5.4658,  -4.5793,  ...,  -5.9672,  -4.3439,  -3.3035],\n",
      "         [-10.7238, -10.5789, -11.0341,  ...,  -9.4808,  -8.2562,  -6.7924]],\n",
      "\n",
      "        [[ -6.8130,  -7.0236,  -6.8539,  ...,  -5.2933,  -7.1285,  -3.8274],\n",
      "         [-10.6359, -10.2802, -10.8270,  ...,  -7.5983,  -8.3899,  -7.7104],\n",
      "         [ -5.6982,  -5.8022,  -5.8814,  ...,  -6.3106,  -6.6175,  -3.2794],\n",
      "         ...,\n",
      "         [ -5.9778,  -6.0243,  -5.9711,  ...,  -6.1807,  -6.4166,  -4.1373],\n",
      "         [ -5.7209,  -5.7785,  -5.7589,  ...,  -6.2890,  -6.0788,  -3.1126],\n",
      "         [ -6.2253,  -6.2615,  -6.2806,  ...,  -6.5863,  -6.7094,  -4.0413]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.6135079860687256\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8762, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6318,  -6.6413,  -6.6586,  ...,  -5.8723,  -6.1929,  -3.4233],\n",
      "         [ -6.0257,  -6.0051,  -6.1249,  ...,  -6.8645,  -6.2790,  -2.6304],\n",
      "         [ -7.8041,  -7.6564,  -7.9630,  ...,  -7.1299,  -6.8124,  -5.4090],\n",
      "         ...,\n",
      "         [ -5.7805,  -5.8125,  -5.8532,  ...,  -6.2682,  -5.6772,  -2.0377],\n",
      "         [ -6.1772,  -6.1957,  -6.3083,  ...,  -6.7008,  -6.2257,  -2.9546],\n",
      "         [ -6.1361,  -6.1432,  -6.2276,  ...,  -6.3014,  -5.9591,  -2.0460]],\n",
      "\n",
      "        [[ -6.6442,  -6.6338,  -6.6322,  ...,  -6.1147,  -5.7982,  -4.1357],\n",
      "         [-10.9654, -11.0761, -10.8547,  ...,  -7.9797,  -8.2462,  -8.0999],\n",
      "         [ -6.3536,  -6.4529,  -6.4857,  ...,  -6.4524,  -6.2765,  -3.6955],\n",
      "         ...,\n",
      "         [ -6.4624,  -6.5735,  -6.4724,  ...,  -6.5159,  -5.8758,  -4.2812],\n",
      "         [ -6.8184,  -6.8381,  -6.8054,  ...,  -6.8875,  -6.2366,  -3.6870],\n",
      "         [ -6.7905,  -6.8296,  -6.8287,  ...,  -6.8731,  -6.5928,  -4.3727]],\n",
      "\n",
      "        [[ -7.1739,  -7.1431,  -7.1232,  ...,  -6.4746,  -6.2251,  -4.0562],\n",
      "         [-11.2375, -10.7775, -11.2286,  ...,  -9.7903,  -8.4999,  -7.6724],\n",
      "         [ -5.4594,  -5.5124,  -5.5372,  ...,  -5.7598,  -6.7637,  -2.9024],\n",
      "         ...,\n",
      "         [ -6.1228,  -6.2074,  -6.1458,  ...,  -6.2524,  -6.7011,  -4.0308],\n",
      "         [ -6.2498,  -6.2955,  -6.3152,  ...,  -6.3106,  -6.4433,  -4.0226],\n",
      "         [ -5.9310,  -6.0980,  -6.1018,  ...,  -6.1872,  -6.8843,  -3.0670]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4849,  -7.4883,  -7.5278,  ...,  -6.9965,  -6.4732,  -4.9420],\n",
      "         [ -5.7595,  -5.9106,  -5.9483,  ...,  -6.0133,  -5.4557,  -5.3226],\n",
      "         [ -8.3875,  -8.4813,  -8.2953,  ...,  -8.3555,  -4.8850,  -8.4715],\n",
      "         ...,\n",
      "         [ -7.0902,  -7.2835,  -7.2966,  ...,  -7.6081,  -6.5066,  -5.4353],\n",
      "         [ -6.4291,  -6.6579,  -6.6167,  ...,  -6.8161,  -5.7749,  -5.1424],\n",
      "         [ -5.2441,  -5.3036,  -5.1986,  ...,  -5.1912,  -4.6387,  -4.5528]],\n",
      "\n",
      "        [[ -6.8739,  -6.8356,  -6.8638,  ...,  -6.3833,  -5.8376,  -4.5053],\n",
      "         [-10.7467, -10.5633, -11.0357,  ..., -11.3204,  -8.7034, -11.4703],\n",
      "         [ -7.4147,  -7.6913,  -7.9119,  ...,  -9.7290,  -6.2844,  -8.5164],\n",
      "         ...,\n",
      "         [ -5.2297,  -5.8755,  -5.4299,  ...,  -4.1721,  -5.6514,  -1.3490],\n",
      "         [ -5.5278,  -6.4166,  -5.8891,  ...,  -5.5953,  -4.8741,  -5.2333],\n",
      "         [ -6.4691,  -6.9400,  -6.7875,  ...,  -6.5416,  -5.8511,  -5.9242]],\n",
      "\n",
      "        [[ -7.2337,  -7.2872,  -7.2413,  ...,  -6.6957,  -6.3841,  -4.4192],\n",
      "         [ -8.0506,  -7.5993,  -7.5161,  ...,  -8.2230,  -8.2805,  -8.5396],\n",
      "         [ -4.2584,  -4.1390,  -4.5080,  ...,  -3.8954,  -4.3801,  -4.4098],\n",
      "         ...,\n",
      "         [ -1.7724,  -1.8475,  -2.4652,  ...,  -2.3823,  -3.6714,  -0.3488],\n",
      "         [-12.8096, -13.0171, -12.9253,  ..., -11.9062,  -8.7236, -10.6755],\n",
      "         [-11.1491, -11.2740, -11.3721,  ...,  -9.1654,  -8.9863, -10.2350]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8762056827545166\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0385, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6343,  -6.5575,  -6.5768,  ...,  -6.0455,  -5.8300,  -3.4795],\n",
      "         [ -5.4464,  -5.4630,  -5.4524,  ...,  -6.4628,  -5.8007,  -2.2081],\n",
      "         [ -6.7781,  -6.7878,  -6.8648,  ...,  -7.6578,  -6.2212,  -3.8622],\n",
      "         ...,\n",
      "         [ -5.5934,  -5.5870,  -5.7231,  ...,  -6.1756,  -5.6686,  -2.2702],\n",
      "         [ -5.9084,  -6.0032,  -6.0260,  ...,  -6.6689,  -5.8512,  -2.2413],\n",
      "         [ -5.7902,  -5.8284,  -5.9048,  ...,  -6.3359,  -5.5750,  -2.2134]],\n",
      "\n",
      "        [[ -7.2826,  -7.3724,  -7.3522,  ...,  -7.2521,  -7.1181,  -4.8656],\n",
      "         [-11.6930, -11.5015, -11.5408,  ...,  -9.1276,  -9.4518, -10.0422],\n",
      "         [ -5.3201,  -5.4688,  -5.5062,  ...,  -5.9386,  -6.7972,  -3.1477],\n",
      "         ...,\n",
      "         [ -5.2892,  -5.4517,  -5.5249,  ...,  -5.4659,  -6.4811,  -3.9259],\n",
      "         [ -4.2596,  -4.3964,  -4.4333,  ...,  -4.6927,  -5.7750,  -5.1376],\n",
      "         [ -5.0088,  -5.1362,  -5.1403,  ...,  -5.1110,  -6.0552,  -3.9509]],\n",
      "\n",
      "        [[ -6.7125,  -6.6377,  -6.6091,  ...,  -5.6997,  -6.0075,  -3.9986],\n",
      "         [-12.6425, -12.6144, -13.0198,  ...,  -9.5745,  -9.8598,  -7.8398],\n",
      "         [ -4.4887,  -4.4803,  -4.4807,  ...,  -4.4670,  -5.7376,  -2.8770],\n",
      "         ...,\n",
      "         [ -3.5001,  -3.4952,  -3.5749,  ...,  -4.0575,  -4.8728,  -3.1514],\n",
      "         [ -4.3375,  -4.3925,  -4.3515,  ...,  -4.6363,  -5.5321,  -4.0134],\n",
      "         [ -3.7576,  -3.6741,  -3.7990,  ...,  -3.8453,  -4.9111,  -2.7598]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.5229,  -7.4507,  -7.4291,  ...,  -6.6367,  -6.1783,  -4.4538],\n",
      "         [ -7.6355,  -7.9491,  -7.8342,  ...,  -6.4493,  -5.2087,  -4.7521],\n",
      "         [ -3.0968,  -3.1918,  -3.3583,  ...,  -2.6903,  -2.5638,  -4.4127],\n",
      "         ...,\n",
      "         [-10.0693,  -9.8438,  -9.7263,  ...,  -7.8677,  -7.3315, -10.4207],\n",
      "         [ -4.8583,  -4.8270,  -5.1240,  ...,  -3.8623,  -4.1111,  -4.0059],\n",
      "         [-11.6445, -11.7468, -11.7052,  ...,  -8.1878,  -8.9849,  -8.6196]],\n",
      "\n",
      "        [[ -7.3779,  -7.3746,  -7.3059,  ...,  -6.8876,  -6.4835,  -4.5502],\n",
      "         [-15.4729, -15.7141, -15.5591,  ..., -15.2535, -13.4118, -12.5435],\n",
      "         [-12.5788, -12.6988, -12.6430,  ..., -13.0908, -11.0088, -11.3606],\n",
      "         ...,\n",
      "         [ -8.9065,  -9.3687,  -9.3278,  ...,  -9.9733,  -8.3466,  -7.2605],\n",
      "         [ -9.7912, -10.2520,  -9.7285,  ..., -10.3285,  -8.3267,  -6.2792],\n",
      "         [-10.9660, -11.6244, -10.8516,  ..., -12.9930,  -8.0416,  -8.5187]],\n",
      "\n",
      "        [[ -7.2617,  -7.2266,  -7.2867,  ...,  -7.2615,  -6.7155,  -5.6466],\n",
      "         [ -9.3852,  -9.5205,  -9.6447,  ...,  -9.3256,  -8.2142, -11.2145],\n",
      "         [ -5.6102,  -5.9132,  -5.7163,  ...,  -6.6765,  -4.8921,  -1.7001],\n",
      "         ...,\n",
      "         [ -3.0438,  -3.2784,  -3.0695,  ...,  -2.9421,  -3.7170,  -4.5790],\n",
      "         [ -6.3566,  -6.2183,  -6.5220,  ...,  -6.8504,  -6.8298,  -7.1250],\n",
      "         [-14.1472, -14.4568, -14.5053,  ..., -15.0234, -12.4477, -11.1204]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.038512945175171\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2438, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.1521,  -6.1026,  -6.1407,  ...,  -5.3042,  -5.5111,  -3.6822],\n",
      "         [-11.3388, -10.8234, -11.5000,  ...,  -8.7254,  -8.8235,  -7.5573],\n",
      "         [ -4.8116,  -4.9911,  -5.0899,  ...,  -5.1508,  -6.4053,  -3.3748],\n",
      "         ...,\n",
      "         [ -5.8149,  -5.9292,  -6.0080,  ...,  -5.6463,  -6.5677,  -3.6906],\n",
      "         [ -5.3098,  -5.2678,  -5.3660,  ...,  -5.7054,  -6.4529,  -4.1305],\n",
      "         [ -5.5427,  -5.6775,  -5.6592,  ...,  -5.6742,  -6.1740,  -4.4116]],\n",
      "\n",
      "        [[ -6.9646,  -7.1025,  -6.8188,  ...,  -6.7689,  -6.7160,  -7.2079],\n",
      "         [-11.7210, -12.0611, -11.9693,  ...,  -9.3565,  -9.4033,  -9.9074],\n",
      "         [ -4.4125,  -4.4988,  -4.7073,  ...,  -5.8424,  -6.2612,  -3.0207],\n",
      "         ...,\n",
      "         [ -4.4296,  -4.5943,  -4.5725,  ...,  -5.2199,  -6.2396,  -3.3166],\n",
      "         [ -5.0905,  -5.1194,  -5.2763,  ...,  -5.9185,  -6.7756,  -4.0953],\n",
      "         [ -4.3302,  -4.4152,  -4.5987,  ...,  -5.2261,  -6.1036,  -3.6143]],\n",
      "\n",
      "        [[ -8.1679,  -8.0927,  -8.0838,  ...,  -7.1565,  -6.9981,  -5.2886],\n",
      "         [-12.4722, -13.1334, -12.9440,  ..., -11.1351, -10.4730, -11.7597],\n",
      "         [ -8.8605,  -9.1640,  -9.0430,  ...,  -8.5683,  -8.0747,  -8.7795],\n",
      "         ...,\n",
      "         [ -6.0958,  -6.6660,  -6.4124,  ...,  -4.7692,  -5.2795,  -6.3129],\n",
      "         [ -8.5881,  -9.0853,  -8.7796,  ...,  -8.4030,  -6.3031, -10.2691],\n",
      "         [-12.3228, -12.9892, -12.2241,  ..., -12.5698, -11.8603, -13.0772]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4759,  -6.4915,  -6.4136,  ...,  -5.7188,  -5.6126,  -4.4915],\n",
      "         [-15.9094, -16.4941, -16.1304,  ..., -14.4706, -13.8510, -14.5889],\n",
      "         [ -6.6436,  -7.1090,  -6.8889,  ...,  -7.6120,  -5.5013,  -9.3305],\n",
      "         ...,\n",
      "         [ -6.0732,  -6.1037,  -6.0804,  ...,  -5.8220,  -4.8077,  -7.0177],\n",
      "         [ -4.6969,  -4.8653,  -4.7714,  ...,  -3.8713,  -3.8651,  -5.1644],\n",
      "         [ -4.3387,  -4.6499,  -4.4722,  ...,  -3.8427,  -3.6584,  -4.4929]],\n",
      "\n",
      "        [[ -6.7581,  -6.6730,  -6.6820,  ...,  -6.3296,  -6.1433,  -3.7683],\n",
      "         [-13.4141, -13.4973, -13.5149,  ..., -15.1336, -12.4997,  -9.4373],\n",
      "         [-11.2696, -11.5186, -11.3171,  ..., -12.5474, -10.3140,  -9.0142],\n",
      "         ...,\n",
      "         [ -6.6703,  -7.0842,  -6.8578,  ...,  -7.9128,  -5.4914,  -6.3111],\n",
      "         [ -9.0753,  -9.1259,  -8.5527,  ...,  -8.5863,  -7.5700,  -6.1833],\n",
      "         [-12.6633, -13.4193, -13.1241,  ..., -14.0672, -10.4606,  -5.5600]],\n",
      "\n",
      "        [[ -7.1360,  -7.1361,  -7.0851,  ...,  -6.6698,  -5.9679,  -4.9873],\n",
      "         [ -9.2468,  -9.1987,  -9.1617,  ...,  -9.0217,  -8.9982,  -8.5429],\n",
      "         [ -8.3442,  -8.5841,  -8.1775,  ...,  -9.8160,  -8.6763, -10.1000],\n",
      "         ...,\n",
      "         [-13.5663, -13.4301, -13.3963,  ..., -12.6177, -10.1936,  -9.4559],\n",
      "         [ -7.7591,  -7.5602,  -7.8215,  ...,  -7.2491,  -6.2027,  -7.9842],\n",
      "         [-11.2897, -11.6061, -11.3935,  ..., -11.9763,  -8.6880, -11.0821]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.243774652481079\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.1438, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4034,  -6.4004,  -6.3822,  ...,  -5.7323,  -5.7778,  -3.6970],\n",
      "         [ -6.0098,  -6.0486,  -6.1142,  ...,  -6.7989,  -5.8681,  -2.9040],\n",
      "         [ -5.4345,  -5.4361,  -5.4722,  ...,  -6.4427,  -5.3493,  -2.3150],\n",
      "         ...,\n",
      "         [ -6.0003,  -6.0098,  -6.0136,  ...,  -6.9186,  -5.9670,  -3.0300],\n",
      "         [ -5.5859,  -5.5017,  -5.6347,  ...,  -6.2682,  -5.5603,  -2.8875],\n",
      "         [ -5.4888,  -5.4776,  -5.6169,  ...,  -6.1185,  -5.5467,  -1.7677]],\n",
      "\n",
      "        [[ -6.8678,  -6.7317,  -6.5670,  ...,  -6.1380,  -6.7072,  -5.7137],\n",
      "         [-12.1538, -12.1005, -11.8021,  ...,  -9.1241, -10.6104, -11.0194],\n",
      "         [ -5.0035,  -5.0867,  -5.1881,  ...,  -5.4892,  -6.2081,  -4.1288],\n",
      "         ...,\n",
      "         [ -5.2355,  -5.2771,  -5.1729,  ...,  -5.2516,  -5.3644,  -3.2723],\n",
      "         [ -4.5930,  -4.6053,  -4.6643,  ...,  -5.0380,  -5.5132,  -3.5606],\n",
      "         [ -5.8597,  -5.8648,  -5.8567,  ...,  -5.9306,  -5.6445,  -4.1027]],\n",
      "\n",
      "        [[ -6.7868,  -6.7752,  -6.7765,  ...,  -6.1590,  -6.0527,  -3.7598],\n",
      "         [ -6.5056,  -6.4085,  -6.4974,  ...,  -6.9808,  -6.1759,  -3.0953],\n",
      "         [ -5.9403,  -5.8613,  -5.9941,  ...,  -6.9768,  -5.9072,  -3.6367],\n",
      "         ...,\n",
      "         [ -5.4075,  -5.3997,  -5.5062,  ...,  -6.0065,  -5.3374,  -2.6643],\n",
      "         [ -5.9450,  -5.9225,  -5.9726,  ...,  -6.1005,  -5.5185,  -2.3327],\n",
      "         [ -5.5473,  -5.5393,  -5.6138,  ...,  -5.9729,  -5.7020,  -1.6189]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4348,  -7.5114,  -7.4701,  ...,  -6.8999,  -7.0574,  -4.4214],\n",
      "         [ -7.0324,  -7.0876,  -7.1334,  ...,  -8.0056,  -6.3282,  -5.1590],\n",
      "         [ -5.8629,  -5.6927,  -5.8828,  ...,  -6.6420,  -6.0269,  -3.5107],\n",
      "         ...,\n",
      "         [ -6.3742,  -6.4206,  -6.1905,  ...,  -6.5559,  -5.6948,  -4.2841],\n",
      "         [ -7.0379,  -7.0265,  -6.9286,  ...,  -7.5164,  -6.5504,  -4.0554],\n",
      "         [ -7.6441,  -7.8089,  -7.6376,  ...,  -8.5955,  -7.4885,  -4.8615]],\n",
      "\n",
      "        [[ -6.6118,  -6.6098,  -6.6557,  ...,  -6.0633,  -5.5873,  -3.2558],\n",
      "         [ -5.8056,  -5.6794,  -5.8563,  ...,  -6.0247,  -5.6698,  -1.4710],\n",
      "         [ -5.8855,  -5.7484,  -5.8458,  ...,  -6.2354,  -5.5492,  -1.0998],\n",
      "         ...,\n",
      "         [ -5.4244,  -5.4005,  -5.4670,  ...,  -5.7902,  -5.6740,  -0.8417],\n",
      "         [ -5.6744,  -5.6119,  -5.7097,  ...,  -6.0783,  -5.5640,  -1.2089],\n",
      "         [ -5.6781,  -5.5199,  -5.6009,  ...,  -6.0482,  -5.5752,  -1.4351]],\n",
      "\n",
      "        [[ -6.5663,  -6.5528,  -6.5655,  ...,  -5.9376,  -5.8875,  -3.5206],\n",
      "         [ -6.4348,  -6.4282,  -6.5111,  ...,  -7.3187,  -6.3906,  -2.7638],\n",
      "         [ -6.3445,  -6.3487,  -6.4921,  ...,  -7.0785,  -6.2587,  -2.9792],\n",
      "         ...,\n",
      "         [ -5.4987,  -5.4900,  -5.6159,  ...,  -5.9866,  -5.5803,  -1.6832],\n",
      "         [ -5.7605,  -5.7347,  -5.8790,  ...,  -6.1581,  -5.9695,  -2.2295],\n",
      "         [ -5.8826,  -5.8787,  -6.0511,  ...,  -6.4403,  -5.7844,  -2.1025]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.1437771320343018\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0821, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4799,  -7.6229,  -7.5448,  ...,  -7.0824,  -6.4679,  -5.0893],\n",
      "         [ -2.4311,  -2.7402,  -2.3725,  ...,  -3.2170,  -2.3111,  -4.9871],\n",
      "         [ -8.9773,  -9.6099,  -9.2700,  ..., -10.1468,  -7.7789, -10.0315],\n",
      "         ...,\n",
      "         [ -6.9970,  -7.2391,  -6.7899,  ...,  -6.8557,  -4.8832,  -7.2397],\n",
      "         [ -4.2816,  -4.3596,  -4.4224,  ...,  -5.8103,  -3.0149,  -4.6300],\n",
      "         [-14.5113, -15.4036, -14.8445,  ..., -14.8494, -12.1204, -14.8980]],\n",
      "\n",
      "        [[ -7.2799,  -7.4276,  -7.2609,  ...,  -7.1397,  -6.7339,  -4.9169],\n",
      "         [-13.6668, -13.6038, -13.6800,  ..., -12.9823,  -9.3865, -11.1394],\n",
      "         [ -7.8919,  -7.3577,  -7.5709,  ...,  -6.8280,  -5.5250,  -9.6540],\n",
      "         ...,\n",
      "         [-11.7769, -11.5590, -11.2530,  ...,  -9.4922,  -8.7696, -13.3138],\n",
      "         [ -6.3149,  -6.4774,  -6.5227,  ...,  -6.5221,  -5.9229,  -5.7672],\n",
      "         [ -9.5792,  -9.8753,  -9.7295,  ...,  -8.2669,  -7.5482,  -3.2856]],\n",
      "\n",
      "        [[ -7.0533,  -7.0265,  -7.0430,  ...,  -6.2864,  -6.1700,  -4.2775],\n",
      "         [-12.8452, -12.6894, -12.8413,  ...,  -9.4784,  -9.4697,  -9.1989],\n",
      "         [ -5.9160,  -5.9957,  -6.1076,  ...,  -6.2268,  -7.0895,  -3.0701],\n",
      "         ...,\n",
      "         [ -6.0369,  -6.1310,  -6.3005,  ...,  -6.1963,  -6.5567,  -3.4137],\n",
      "         [ -6.0376,  -6.0938,  -6.1315,  ...,  -6.3734,  -6.8337,  -3.7568],\n",
      "         [ -5.7293,  -5.7691,  -5.8458,  ...,  -5.7628,  -6.1528,  -3.5180]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6771,  -6.6332,  -6.6453,  ...,  -5.9548,  -5.7815,  -3.9568],\n",
      "         [ -4.7369,  -4.7807,  -4.5723,  ...,  -6.0078,  -5.7385,  -2.4511],\n",
      "         [-13.8977, -14.0794, -14.0059,  ..., -10.5281, -11.3355, -11.2704],\n",
      "         ...,\n",
      "         [ -5.3593,  -5.4123,  -5.3028,  ...,  -6.3222,  -6.2340,  -2.8584],\n",
      "         [ -6.4926,  -6.3523,  -6.3106,  ...,  -6.6475,  -6.7238,  -3.8969],\n",
      "         [ -5.6686,  -5.6667,  -5.6060,  ...,  -6.2418,  -6.5068,  -3.3970]],\n",
      "\n",
      "        [[ -6.9021,  -6.9050,  -6.8795,  ...,  -6.3412,  -6.2159,  -4.3781],\n",
      "         [-15.2459, -15.0572, -14.9087,  ..., -12.2665, -12.7981, -11.7042],\n",
      "         [ -5.7761,  -5.9089,  -5.8544,  ...,  -6.4140,  -7.0540,  -4.0657],\n",
      "         ...,\n",
      "         [ -5.5324,  -5.6136,  -5.5553,  ...,  -5.3104,  -6.3802,  -4.6633],\n",
      "         [ -5.4781,  -5.6461,  -5.6107,  ...,  -5.7430,  -6.6958,  -4.3853],\n",
      "         [ -5.7277,  -5.7876,  -5.8332,  ...,  -5.7164,  -6.3531,  -4.6805]],\n",
      "\n",
      "        [[ -7.1454,  -7.2317,  -7.1403,  ...,  -6.6296,  -6.2610,  -5.1467],\n",
      "         [-14.0261, -14.2669, -14.3626,  ..., -12.0293, -10.4458, -15.0886],\n",
      "         [ -9.6310, -10.6095, -10.5184,  ...,  -8.5785,  -7.9356,  -9.3733],\n",
      "         ...,\n",
      "         [ -4.3584,  -4.9636,  -4.4496,  ...,  -4.7643,  -3.3592,  -5.1971],\n",
      "         [ -4.8274,  -5.3654,  -5.1916,  ...,  -5.4141,  -4.2085,  -5.2762],\n",
      "         [ -6.8643,  -7.2462,  -7.0074,  ...,  -6.5527,  -6.1189,  -5.2040]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.08209490776062\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0612, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2525,  -7.2473,  -7.2000,  ...,  -6.5265,  -6.2069,  -4.5541],\n",
      "         [-14.8754, -15.0355, -14.8670,  ..., -14.8852, -12.1589, -11.6860],\n",
      "         [ -4.2129,  -4.2117,  -4.2249,  ...,  -4.5936,  -4.0492,  -4.8915],\n",
      "         ...,\n",
      "         [-11.4965, -11.2175, -11.5901,  ...,  -8.7790,  -9.1210,  -6.8745],\n",
      "         [-10.9977, -11.5913, -11.5563,  ..., -12.6379,  -9.7866,  -5.7564],\n",
      "         [-11.6326, -11.5392, -11.2780,  ...,  -9.2834,  -8.3848,  -8.4106]],\n",
      "\n",
      "        [[ -6.4843,  -6.4292,  -6.4386,  ...,  -5.9460,  -5.8991,  -3.7547],\n",
      "         [ -6.4573,  -6.3807,  -6.4902,  ...,  -6.8903,  -6.3067,  -2.8027],\n",
      "         [ -6.1413,  -6.2011,  -6.2500,  ...,  -7.4661,  -6.6267,  -3.7402],\n",
      "         ...,\n",
      "         [ -5.6355,  -5.5610,  -5.6567,  ...,  -5.8663,  -5.4528,  -2.6395],\n",
      "         [ -5.5224,  -5.5067,  -5.5712,  ...,  -5.9231,  -5.4472,  -2.3908],\n",
      "         [ -5.5262,  -5.5064,  -5.5744,  ...,  -5.8135,  -5.4862,  -2.2439]],\n",
      "\n",
      "        [[ -7.3477,  -7.3515,  -7.3704,  ...,  -7.2589,  -6.8375,  -5.1180],\n",
      "         [ -5.2869,  -5.4785,  -5.7950,  ...,  -5.9013,  -5.7262,  -6.5874],\n",
      "         [ -8.2510,  -7.7591,  -8.3538,  ...,  -8.2182,  -7.6676,  -8.9664],\n",
      "         ...,\n",
      "         [ -4.9691,  -4.8631,  -5.0084,  ...,  -5.8155,  -5.2967,  -6.3300],\n",
      "         [ -5.3354,  -5.3528,  -5.4063,  ...,  -6.2356,  -5.7322,  -5.1108],\n",
      "         [ -5.9173,  -5.8609,  -5.9675,  ...,  -6.9731,  -5.8448,  -6.1376]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6845,  -6.6767,  -6.5983,  ...,  -6.1382,  -6.0273,  -4.2189],\n",
      "         [ -7.1153,  -6.9641,  -7.3099,  ...,  -8.2064,  -6.9069,  -7.0270],\n",
      "         [ -1.0794,  -0.6478,  -0.9231,  ...,  -0.7265,  -2.5465,  -3.2102],\n",
      "         ...,\n",
      "         [ -4.2784,  -4.3859,  -4.1428,  ...,  -4.0864,  -4.3240,  -4.4969],\n",
      "         [ -5.1270,  -5.1308,  -4.8987,  ...,  -4.9302,  -4.8086,  -4.4986],\n",
      "         [ -4.1964,  -4.3274,  -3.9056,  ...,  -4.8271,  -3.6358,  -5.0473]],\n",
      "\n",
      "        [[ -6.3907,  -6.3160,  -6.3403,  ...,  -5.6241,  -5.6535,  -3.4259],\n",
      "         [ -5.6762,  -5.6461,  -5.6433,  ...,  -6.3752,  -5.5210,  -1.9443],\n",
      "         [ -5.5937,  -5.5932,  -5.5359,  ...,  -6.1860,  -4.7368,  -1.9443],\n",
      "         ...,\n",
      "         [ -5.9180,  -5.9704,  -6.0469,  ...,  -6.6391,  -5.7321,  -2.7019],\n",
      "         [ -5.7545,  -5.7428,  -5.8165,  ...,  -6.1618,  -5.6087,  -1.9213],\n",
      "         [ -5.5797,  -5.6009,  -5.6470,  ...,  -6.0467,  -5.1044,  -2.1366]],\n",
      "\n",
      "        [[ -7.8605,  -8.0411,  -7.8463,  ...,  -7.3733,  -7.1891,  -4.9523],\n",
      "         [-13.4331, -13.4205, -13.8333,  ..., -12.6692, -11.7434, -13.5538],\n",
      "         [ -7.1586,  -7.5534,  -8.0074,  ...,  -8.1182,  -7.5331,  -8.7808],\n",
      "         ...,\n",
      "         [ -6.5280,  -6.8655,  -6.8470,  ...,  -7.3328,  -6.1975,  -3.6468],\n",
      "         [ -9.0483,  -9.1011,  -9.2645,  ...,  -9.4093,  -7.9709,  -8.2715],\n",
      "         [-10.7163, -10.9614, -11.0066,  ...,  -8.8341,  -9.0643,  -6.6844]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.0612412691116333\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6496, grad_fn=<NllLossBackward0>), logits=tensor([[[ -3.4792,  -3.4703,  -3.3901,  ...,  -3.1607,  -3.8382,  -3.8959],\n",
      "         [-12.4212, -12.3326, -12.2351,  ...,  -9.8272,  -9.1637,  -7.0425],\n",
      "         [ -5.3272,  -5.3196,  -5.4148,  ...,  -5.5266,  -6.6375,  -3.2807],\n",
      "         ...,\n",
      "         [ -5.0163,  -5.1329,  -5.0678,  ...,  -5.1001,  -6.0802,  -3.3657],\n",
      "         [ -5.0492,  -5.1249,  -5.1375,  ...,  -5.0912,  -6.3013,  -2.9660],\n",
      "         [ -5.3599,  -5.4947,  -5.4406,  ...,  -5.2744,  -6.3669,  -3.2236]],\n",
      "\n",
      "        [[ -7.8120,  -7.8138,  -7.7516,  ...,  -7.1871,  -6.9385,  -4.3867],\n",
      "         [ -6.8972,  -7.3559,  -7.2076,  ...,  -8.9268,  -5.4957,  -8.0859],\n",
      "         [ -8.7990,  -9.1916,  -9.1789,  ...,  -8.2567,  -8.8416,  -6.2487],\n",
      "         ...,\n",
      "         [ -6.2069,  -6.4672,  -6.5759,  ...,  -6.3069,  -6.1178,  -3.9723],\n",
      "         [ -7.4974,  -7.4262,  -7.5722,  ...,  -6.7093,  -5.8952,  -5.3277],\n",
      "         [-14.9154, -15.2342, -15.2415,  ..., -13.3374, -11.7048, -10.0369]],\n",
      "\n",
      "        [[ -6.6879,  -6.6301,  -6.6028,  ...,  -5.9588,  -5.6956,  -4.1774],\n",
      "         [-11.0025, -10.8939, -11.3391,  ...,  -9.5824,  -9.2164,  -9.6529],\n",
      "         [ -6.7550,  -7.1059,  -6.6942,  ...,  -6.0241,  -5.4799,  -3.7510],\n",
      "         ...,\n",
      "         [ -6.8757,  -7.0027,  -6.9794,  ...,  -7.1000,  -6.4904,  -4.2186],\n",
      "         [ -6.8193,  -6.9833,  -6.7942,  ...,  -6.8530,  -6.5645,  -3.4443],\n",
      "         [ -7.1554,  -7.3660,  -7.2523,  ...,  -6.9470,  -6.3060,  -4.2313]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7270,  -6.7353,  -6.7234,  ...,  -6.0264,  -6.0701,  -3.7060],\n",
      "         [ -7.1227,  -7.1059,  -7.2427,  ...,  -7.8305,  -6.9115,  -3.4841],\n",
      "         [ -6.5343,  -6.5489,  -6.6074,  ...,  -7.4831,  -6.6736,  -2.3396],\n",
      "         ...,\n",
      "         [ -6.2010,  -6.2275,  -6.3358,  ...,  -6.6907,  -5.9611,  -2.0560],\n",
      "         [ -6.2734,  -6.2717,  -6.3613,  ...,  -6.5822,  -6.0427,  -2.4558],\n",
      "         [ -6.1212,  -6.0819,  -6.1637,  ...,  -6.3274,  -6.0364,  -2.0116]],\n",
      "\n",
      "        [[ -6.9416,  -7.1103,  -6.9195,  ...,  -5.8645,  -6.7271,  -3.6973],\n",
      "         [-10.6947, -10.5534, -10.4959,  ...,  -9.0721,  -8.7146,  -9.5185],\n",
      "         [ -4.6863,  -4.8112,  -4.9295,  ...,  -5.4349,  -6.6280,  -3.2781],\n",
      "         ...,\n",
      "         [ -5.1551,  -5.2239,  -5.1414,  ...,  -4.5989,  -6.0333,  -4.2281],\n",
      "         [ -5.2166,  -5.4405,  -5.3690,  ...,  -5.5140,  -6.1071,  -4.3391],\n",
      "         [ -4.6530,  -4.6652,  -4.7394,  ...,  -4.7410,  -5.5427,  -4.4124]],\n",
      "\n",
      "        [[ -7.7816,  -7.8413,  -7.6853,  ...,  -6.9925,  -6.9960,  -3.6762],\n",
      "         [-11.0920, -11.2085, -11.2526,  ..., -10.1890, -10.3395,  -4.8262],\n",
      "         [ -3.3211,  -3.3727,  -3.3207,  ...,  -3.4003,  -4.6121,  -0.7760],\n",
      "         ...,\n",
      "         [ -6.8138,  -6.9361,  -7.0079,  ...,  -5.3890,  -5.9121,  -3.2698],\n",
      "         [ -6.5457,  -6.5970,  -6.5578,  ...,  -5.1086,  -6.0134,  -3.5075],\n",
      "         [ -7.6282,  -7.7189,  -7.6739,  ...,  -7.2242,  -7.1440,  -4.8847]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.6496433019638062\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0881, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8071,  -6.8462,  -6.7992,  ...,  -5.9451,  -5.8785,  -4.2559],\n",
      "         [-11.9726, -11.4630, -11.7434,  ...,  -9.8551,  -8.7051,  -9.2744],\n",
      "         [ -4.5480,  -4.5944,  -4.6529,  ...,  -4.9053,  -6.2015,  -2.9056],\n",
      "         ...,\n",
      "         [ -5.2019,  -5.2290,  -5.2246,  ...,  -5.2266,  -6.2489,  -3.2078],\n",
      "         [ -5.3364,  -5.3718,  -5.3654,  ...,  -5.5376,  -6.3780,  -4.0690],\n",
      "         [ -5.2561,  -5.3885,  -5.3449,  ...,  -5.4011,  -6.4263,  -3.6389]],\n",
      "\n",
      "        [[ -6.3776,  -6.3212,  -6.3352,  ...,  -5.6748,  -5.4954,  -3.6607],\n",
      "         [ -5.6463,  -5.6555,  -5.8172,  ...,  -5.7846,  -5.5999,  -2.3442],\n",
      "         [ -5.5582,  -5.5483,  -5.5593,  ...,  -6.0384,  -5.7300,  -2.7209],\n",
      "         ...,\n",
      "         [ -5.6221,  -5.6193,  -5.7658,  ...,  -6.1797,  -5.5303,  -2.2944],\n",
      "         [ -6.1068,  -6.0490,  -6.2363,  ...,  -6.4596,  -5.7969,  -2.7118],\n",
      "         [ -5.9198,  -5.8322,  -5.9296,  ...,  -6.1102,  -5.6333,  -2.6194]],\n",
      "\n",
      "        [[ -7.0701,  -7.0265,  -7.0033,  ...,  -6.3524,  -6.1144,  -4.0317],\n",
      "         [-14.8892, -14.5952, -14.8975,  ..., -13.0945, -12.2109, -15.6544],\n",
      "         [-16.1554, -15.9389, -16.0708,  ..., -12.9300, -11.9923, -13.3404],\n",
      "         ...,\n",
      "         [ -5.7281,  -5.9586,  -5.9465,  ...,  -5.8707,  -5.2925,  -5.1077],\n",
      "         [ -6.3407,  -6.5069,  -6.3260,  ...,  -5.7009,  -6.3347,  -3.5239],\n",
      "         [ -7.5813,  -7.6186,  -7.7124,  ...,  -7.3338,  -6.3931,  -5.4132]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4618,  -6.4255,  -6.4200,  ...,  -5.6700,  -5.5369,  -3.8592],\n",
      "         [ -9.0145,  -9.1773,  -9.1789,  ...,  -8.8514,  -8.6420,  -8.2537],\n",
      "         [ -8.8394,  -8.3949,  -7.9271,  ...,  -8.4808,  -6.7254, -10.8128],\n",
      "         ...,\n",
      "         [ -2.4668,  -2.4233,  -2.1200,  ...,  -0.8654,  -3.0108,  -6.2656],\n",
      "         [ -2.7815,  -2.7545,  -2.4344,  ...,  -1.6426,  -2.8523,  -8.5860],\n",
      "         [ -4.2952,  -4.2053,  -4.0501,  ...,  -3.5070,  -4.3033,  -5.0867]],\n",
      "\n",
      "        [[ -6.7451,  -6.7382,  -6.7047,  ...,  -6.4469,  -6.3025,  -3.4295],\n",
      "         [-10.3187, -10.7276, -10.4026,  ..., -11.2804,  -7.8243, -10.4904],\n",
      "         [ -9.8254,  -9.9397,  -9.9001,  ...,  -9.9207,  -8.3298,  -6.3571],\n",
      "         ...,\n",
      "         [ -7.1195,  -7.6541,  -7.4246,  ...,  -6.7291,  -5.4793,  -8.0962],\n",
      "         [ -5.3665,  -5.6635,  -5.4296,  ...,  -5.9356,  -5.2973,  -3.4776],\n",
      "         [-10.2774, -10.4530, -10.6878,  ..., -10.3458,  -8.6233,  -8.5976]],\n",
      "\n",
      "        [[ -6.7812,  -6.7481,  -6.6808,  ...,  -6.1239,  -5.7690,  -4.4502],\n",
      "         [-11.6143, -11.3874, -11.3399,  ..., -12.0316,  -9.5188, -11.8286],\n",
      "         [ -9.6241,  -9.6918,  -9.4927,  ...,  -9.2026,  -8.1733, -11.7158],\n",
      "         ...,\n",
      "         [ -5.7070,  -5.7999,  -5.7512,  ...,  -6.1942,  -5.5399,  -4.0915],\n",
      "         [ -6.4095,  -6.4433,  -6.3958,  ...,  -6.8664,  -5.9699,  -5.2615],\n",
      "         [ -5.9658,  -5.9027,  -5.9855,  ...,  -5.9584,  -5.8558,  -4.8337]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.088128089904785\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.1094, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3527,  -6.3045,  -6.2847,  ...,  -5.8131,  -5.8140,  -3.4316],\n",
      "         [ -6.9659,  -6.8929,  -7.0773,  ...,  -8.0992,  -7.0775,  -3.5216],\n",
      "         [ -6.3898,  -6.3532,  -6.4871,  ...,  -7.2909,  -6.2437,  -3.1184],\n",
      "         ...,\n",
      "         [ -6.3955,  -6.3603,  -6.4373,  ...,  -6.9447,  -6.1607,  -2.5824],\n",
      "         [ -6.3252,  -6.2763,  -6.4009,  ...,  -6.7296,  -6.0913,  -2.3601],\n",
      "         [ -6.0407,  -5.9618,  -6.0954,  ...,  -6.6766,  -5.8839,  -2.3485]],\n",
      "\n",
      "        [[ -7.1782,  -7.1699,  -7.1340,  ...,  -6.6509,  -6.7117,  -4.9604],\n",
      "         [ -4.9361,  -4.8903,  -5.1576,  ...,  -5.6088,  -5.4256,  -2.8771],\n",
      "         [ -7.3705,  -7.7983,  -7.3626,  ...,  -8.0008,  -7.5227,  -5.6985],\n",
      "         ...,\n",
      "         [ -5.2615,  -5.2969,  -5.4708,  ...,  -5.0397,  -5.4962,  -2.4382],\n",
      "         [ -5.3200,  -5.4176,  -5.4533,  ...,  -5.1837,  -5.8160,  -2.5524],\n",
      "         [ -5.0788,  -5.0706,  -5.2547,  ...,  -5.3490,  -5.2879,  -1.6331]],\n",
      "\n",
      "        [[ -6.4882,  -6.4506,  -6.4465,  ...,  -5.6988,  -5.5775,  -3.7527],\n",
      "         [-11.3120, -11.5440, -11.6174,  ...,  -8.1400,  -8.2191,  -9.0527],\n",
      "         [ -5.5664,  -5.6833,  -5.6613,  ...,  -6.1443,  -6.9033,  -3.5067],\n",
      "         ...,\n",
      "         [ -5.7257,  -5.7527,  -5.6610,  ...,  -6.3646,  -6.7192,  -3.1560],\n",
      "         [ -5.8948,  -5.9950,  -5.9265,  ...,  -6.7095,  -6.5878,  -3.7217],\n",
      "         [ -5.5592,  -5.5859,  -5.6151,  ...,  -5.9049,  -6.6343,  -3.6126]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8932,  -6.5517,  -6.6960,  ...,  -8.1515,  -8.0079,  -6.1246],\n",
      "         [-12.9114, -13.1625, -13.2033,  ..., -10.5635,  -9.7921, -12.1647],\n",
      "         [ -4.8016,  -4.7392,  -4.9537,  ...,  -5.6069,  -6.4742,  -4.2924],\n",
      "         ...,\n",
      "         [ -4.8621,  -4.8921,  -4.9529,  ...,  -5.4203,  -6.1950,  -5.8563],\n",
      "         [ -5.4428,  -5.4637,  -5.5889,  ...,  -6.1737,  -6.7401,  -6.8331],\n",
      "         [ -5.4875,  -5.4371,  -5.5842,  ...,  -5.6812,  -6.6205,  -6.7552]],\n",
      "\n",
      "        [[ -6.7591,  -6.7172,  -6.7309,  ...,  -6.1181,  -5.9468,  -3.9780],\n",
      "         [-12.1745, -12.0203, -11.9668,  ..., -10.2551, -10.7071,  -8.6406],\n",
      "         [ -7.0485,  -7.1241,  -7.1435,  ...,  -7.5093,  -7.6994,  -3.3392],\n",
      "         ...,\n",
      "         [ -7.3331,  -7.4230,  -7.3400,  ...,  -7.9328,  -7.2207,  -4.6121],\n",
      "         [ -6.9953,  -6.8998,  -6.9722,  ...,  -7.0809,  -6.9507,  -4.0053],\n",
      "         [ -7.1491,  -7.2989,  -7.2790,  ...,  -7.5407,  -7.4948,  -3.8614]],\n",
      "\n",
      "        [[ -5.0964,  -5.2835,  -5.1180,  ...,  -4.7600,  -4.4010,  -5.1697],\n",
      "         [-12.0558, -11.8213, -12.3797,  ...,  -8.5725,  -9.3496,  -7.7098],\n",
      "         [ -4.8272,  -4.9973,  -4.9341,  ...,  -5.3427,  -5.3167,  -2.5904],\n",
      "         ...,\n",
      "         [ -4.8792,  -4.9765,  -4.9314,  ...,  -4.5775,  -4.9783,  -4.3104],\n",
      "         [ -5.9115,  -6.0036,  -5.9133,  ...,  -6.0810,  -5.8109,  -4.5845],\n",
      "         [ -4.7473,  -4.7576,  -4.8239,  ...,  -4.8770,  -4.5898,  -2.8099]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.1093735694885254\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6321, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7916,  -6.8633,  -6.7338,  ...,  -5.9555,  -5.5117,  -3.9575],\n",
      "         [ -6.3742,  -6.4378,  -6.2555,  ...,  -5.9681,  -4.8454,  -5.8569],\n",
      "         [ -0.3153,  -0.5915,   0.0957,  ...,  -2.1841,  -0.4420,  -2.2797],\n",
      "         ...,\n",
      "         [ -5.8447,  -6.3104,  -5.4906,  ...,  -5.6417,  -3.7592,  -3.6300],\n",
      "         [ -0.2738,  -0.3148,   0.2851,  ...,  -1.5292,   0.1921,  -0.3050],\n",
      "         [-11.5635, -11.7021, -12.1169,  ...,  -9.7226,  -9.7300,  -8.5784]],\n",
      "\n",
      "        [[ -6.8107,  -6.8039,  -6.7652,  ...,  -6.1111,  -5.7007,  -4.4365],\n",
      "         [ -4.4540,  -4.6918,  -4.8428,  ...,  -4.2709,  -4.1804,  -1.6169],\n",
      "         [ -6.1097,  -6.3345,  -6.4393,  ...,  -4.8695,  -4.3872,  -5.0671],\n",
      "         ...,\n",
      "         [ -4.0783,  -4.2136,  -4.1063,  ...,  -4.8159,  -4.9170,  -3.4753],\n",
      "         [ -6.8536,  -6.9804,  -6.8822,  ...,  -6.8898,  -6.5914,  -5.4028],\n",
      "         [ -6.5083,  -6.6074,  -6.5190,  ...,  -6.5768,  -6.1477,  -5.6284]],\n",
      "\n",
      "        [[ -7.3161,  -7.3256,  -7.2769,  ...,  -6.7692,  -6.3732,  -4.5462],\n",
      "         [ -3.4613,  -3.9489,  -3.6703,  ...,  -3.8707,  -4.4343,  -4.3954],\n",
      "         [ -8.3096,  -8.1058,  -7.7483,  ...,  -8.4895,  -3.4385,  -8.2245],\n",
      "         ...,\n",
      "         [ -7.6046,  -7.6965,  -7.5214,  ...,  -7.4166,  -7.0765,  -5.3412],\n",
      "         [ -6.3566,  -6.4509,  -6.3325,  ...,  -6.1170,  -6.0496,  -4.8585],\n",
      "         [ -7.6582,  -7.7831,  -7.6961,  ...,  -7.4634,  -6.8566,  -5.7778]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8804,  -6.8565,  -6.8770,  ...,  -6.5538,  -6.2673,  -3.6510],\n",
      "         [ -2.9705,  -3.3167,  -3.3314,  ...,  -3.0953,  -3.7768,  -2.1915],\n",
      "         [ -7.4554,  -7.5644,  -7.4638,  ...,  -6.7174,  -7.3929,  -5.5563],\n",
      "         ...,\n",
      "         [ -7.5734,  -7.8367,  -7.4689,  ...,  -7.0535,  -6.5121,  -4.3464],\n",
      "         [ -3.2964,  -2.7068,  -2.6395,  ...,  -3.4302,  -1.2015,  -1.3898],\n",
      "         [ -8.4086,  -8.8828,  -8.2206,  ...,  -9.3512,  -6.4060,  -9.1056]],\n",
      "\n",
      "        [[ -7.1550,  -7.1587,  -7.1516,  ...,  -6.6850,  -6.5221,  -3.6721],\n",
      "         [-10.5639, -10.5989, -10.5089,  ...,  -8.3580,  -9.7484,  -7.3099],\n",
      "         [ -5.9123,  -5.9906,  -6.0165,  ...,  -6.7089,  -7.1654,  -2.8125],\n",
      "         ...,\n",
      "         [ -6.2252,  -6.2832,  -6.2412,  ...,  -6.9436,  -7.0409,  -3.1402],\n",
      "         [ -5.6189,  -5.6280,  -5.6727,  ...,  -6.5036,  -6.9270,  -3.6766],\n",
      "         [ -5.6038,  -5.7127,  -5.6960,  ...,  -6.2521,  -6.8372,  -3.0589]],\n",
      "\n",
      "        [[ -7.2213,  -7.3094,  -7.2375,  ...,  -6.7824,  -6.4888,  -4.5083],\n",
      "         [-13.0482, -13.3688, -13.5879,  ..., -14.1916, -10.2661, -10.0469],\n",
      "         [-11.6201, -12.1917, -12.0029,  ..., -13.8240,  -9.7689,  -5.9434],\n",
      "         ...,\n",
      "         [-12.0488, -12.2061, -11.9957,  ..., -12.2603, -11.2321, -10.1987],\n",
      "         [ -6.6008,  -7.1251,  -7.1038,  ...,  -8.3412,  -7.1580,  -4.3933],\n",
      "         [-12.5038, -12.2912, -12.5307,  ..., -10.7362, -10.1572,  -8.2351]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.632124185562134\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.6082, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2708,  -7.2909,  -7.2158,  ...,  -6.9235,  -6.4637,  -4.3793],\n",
      "         [ -8.1306,  -8.0828,  -8.3990,  ...,  -8.5031,  -7.7160,  -6.9566],\n",
      "         [ -9.6976, -10.0120,  -9.6584,  ...,  -7.7877,  -6.4424,  -9.1144],\n",
      "         ...,\n",
      "         [ -5.3280,  -5.6641,  -5.6540,  ...,  -4.9928,  -4.5622,  -5.1614],\n",
      "         [ -3.8366,  -4.1917,  -4.0949,  ...,  -2.9795,  -3.5970,  -3.9609],\n",
      "         [ -6.3370,  -6.6387,  -6.5475,  ...,  -5.9742,  -5.5296,  -5.5780]],\n",
      "\n",
      "        [[ -6.5518,  -6.4839,  -6.4999,  ...,  -6.0276,  -5.7514,  -3.9501],\n",
      "         [ -5.0550,  -5.0435,  -5.1505,  ...,  -6.1270,  -5.3524,  -2.3191],\n",
      "         [ -6.1501,  -6.0220,  -6.0757,  ...,  -7.2096,  -5.9533,  -4.5017],\n",
      "         ...,\n",
      "         [ -5.4891,  -5.3745,  -5.4482,  ...,  -6.3814,  -5.8419,  -2.6580],\n",
      "         [ -5.5654,  -5.5075,  -5.5830,  ...,  -6.0488,  -5.7902,  -2.9520],\n",
      "         [ -5.5759,  -5.5168,  -5.5901,  ...,  -6.1963,  -5.6988,  -3.0621]],\n",
      "\n",
      "        [[ -6.5255,  -6.5140,  -6.5301,  ...,  -5.9276,  -5.9133,  -3.6235],\n",
      "         [ -6.9619,  -6.8682,  -7.0034,  ...,  -7.8484,  -6.9689,  -4.3884],\n",
      "         [ -5.8119,  -5.7770,  -5.8942,  ...,  -6.3296,  -5.7628,  -3.4017],\n",
      "         ...,\n",
      "         [ -5.8550,  -5.7284,  -5.9161,  ...,  -6.4780,  -5.8924,  -2.6186],\n",
      "         [ -5.9701,  -5.9766,  -5.9853,  ...,  -6.7868,  -5.8120,  -2.9555],\n",
      "         [ -5.8181,  -5.7401,  -5.8369,  ...,  -6.2607,  -5.4634,  -2.5134]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9694,  -7.0552,  -6.9711,  ...,  -6.3481,  -6.2781,  -4.4237],\n",
      "         [-11.8555, -11.8031, -11.9734,  ..., -11.2952, -10.5684, -10.9284],\n",
      "         [-11.8439, -12.0190, -12.1273,  ..., -11.2022,  -9.8782, -12.1589],\n",
      "         ...,\n",
      "         [ -2.4256,  -2.4735,  -2.2973,  ...,  -1.2946,  -2.0195,  -1.2082],\n",
      "         [ -4.1589,  -4.4592,  -4.2477,  ...,  -4.5726,  -3.8922,  -3.7174],\n",
      "         [ -3.9904,  -4.2897,  -4.1412,  ...,  -4.0665,  -3.9478,  -3.7587]],\n",
      "\n",
      "        [[ -6.8735,  -6.7719,  -6.7274,  ...,  -6.7302,  -5.2737,  -3.6026],\n",
      "         [ -9.4481,  -9.1275,  -9.3727,  ...,  -7.4991,  -6.2133,  -8.3278],\n",
      "         [ -5.2431,  -5.3081,  -5.3859,  ...,  -5.3914,  -5.8693,  -3.1610],\n",
      "         ...,\n",
      "         [ -5.9789,  -5.9928,  -5.9992,  ...,  -5.9819,  -5.7546,  -4.6745],\n",
      "         [ -5.4867,  -5.5904,  -5.7005,  ...,  -5.8735,  -6.3348,  -3.3114],\n",
      "         [ -6.0875,  -6.2680,  -6.2510,  ...,  -6.0836,  -6.2618,  -2.9859]],\n",
      "\n",
      "        [[ -6.7663,  -6.7466,  -6.7433,  ...,  -6.0857,  -5.9093,  -3.8541],\n",
      "         [ -7.6239,  -7.5835,  -7.7291,  ...,  -6.7749,  -6.1245,  -6.7107],\n",
      "         [-13.8199, -13.8642, -13.9482,  ..., -12.7397, -11.9117, -12.9314],\n",
      "         ...,\n",
      "         [-13.8488, -13.5926, -14.0129,  ..., -11.5282, -12.3687, -12.5747],\n",
      "         [ -7.7655,  -7.9676,  -8.1440,  ...,  -6.4033,  -7.0683,  -3.9286],\n",
      "         [-11.5823, -11.9730, -11.9305,  ...,  -9.8947, -10.4677,  -7.5946]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.608198642730713\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.7215, grad_fn=<NllLossBackward0>), logits=tensor([[[-10.3318,  -9.9977, -10.0960,  ...,  -9.6909, -10.5910, -12.3323],\n",
      "         [-10.4674, -10.2336, -10.0601,  ...,  -9.5539, -10.4521,  -9.8213],\n",
      "         [ -4.9532,  -4.7871,  -5.1048,  ...,  -6.1873,  -6.6156,  -4.3366],\n",
      "         ...,\n",
      "         [ -5.7178,  -5.8115,  -5.9869,  ...,  -5.9851,  -6.5738,  -4.5506],\n",
      "         [ -4.8110,  -5.0285,  -5.0795,  ...,  -5.7589,  -6.0010,  -2.9663],\n",
      "         [ -5.1109,  -5.1469,  -5.2361,  ...,  -5.8621,  -6.6511,  -5.0001]],\n",
      "\n",
      "        [[ -7.2441,  -7.2203,  -7.1628,  ...,  -6.3983,  -6.6335,  -4.0879],\n",
      "         [ -9.0476,  -9.2000,  -9.1294,  ...,  -6.8754,  -9.0211,  -3.2655],\n",
      "         [ -4.8037,  -4.9822,  -4.9965,  ...,  -5.5480,  -6.7617,  -3.1864],\n",
      "         ...,\n",
      "         [ -5.2849,  -5.4085,  -5.3372,  ...,  -5.9727,  -6.8215,  -2.8929],\n",
      "         [ -5.2926,  -5.4196,  -5.4013,  ...,  -5.6455,  -6.3351,  -2.0529],\n",
      "         [ -4.5721,  -4.6698,  -4.6346,  ...,  -5.1402,  -6.2878,  -1.8691]],\n",
      "\n",
      "        [[ -6.4630,  -6.4173,  -6.4038,  ...,  -5.7484,  -5.7410,  -3.8406],\n",
      "         [-18.0369, -17.7629, -17.8564,  ..., -15.7675, -15.3569, -15.9472],\n",
      "         [ -4.6074,  -4.7262,  -4.6845,  ...,  -4.7674,  -6.0829,  -2.8470],\n",
      "         ...,\n",
      "         [ -5.7147,  -5.8526,  -5.8263,  ...,  -5.5986,  -6.5180,  -4.6945],\n",
      "         [ -5.1823,  -5.3212,  -5.2583,  ...,  -5.3929,  -6.0014,  -3.7667],\n",
      "         [ -5.0007,  -5.0933,  -5.1403,  ...,  -5.3582,  -6.3046,  -3.5723]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5085,  -6.4435,  -6.4932,  ...,  -5.7740,  -5.7122,  -3.7604],\n",
      "         [ -9.7252,  -9.4459,  -9.8184,  ...,  -7.3775,  -8.6445,  -8.6577],\n",
      "         [ -4.9768,  -5.0177,  -5.0575,  ...,  -6.0449,  -5.9819,  -3.6096],\n",
      "         ...,\n",
      "         [ -5.0838,  -5.1529,  -5.1801,  ...,  -5.7026,  -5.9140,  -3.2349],\n",
      "         [ -5.2218,  -5.2654,  -5.3619,  ...,  -6.0607,  -6.3154,  -3.8567],\n",
      "         [ -5.4633,  -5.5444,  -5.5202,  ...,  -5.6760,  -6.2813,  -3.5364]],\n",
      "\n",
      "        [[ -7.6906,  -7.7391,  -7.6114,  ...,  -6.9757,  -6.5929,  -4.7787],\n",
      "         [-14.3709, -14.3375, -14.1657,  ..., -13.9160, -10.7339, -11.2659],\n",
      "         [ -6.8077,  -6.7448,  -6.8703,  ...,  -6.7741,  -5.3229,  -6.2681],\n",
      "         ...,\n",
      "         [ -8.4552,  -8.6483,  -8.4277,  ...,  -7.3326,  -7.0111,  -6.6253],\n",
      "         [ -8.7028,  -9.3467,  -9.3113,  ...,  -8.4191,  -5.9240,  -8.1499],\n",
      "         [-13.3574, -13.3175, -13.6688,  ..., -10.5591, -10.2382, -11.8852]],\n",
      "\n",
      "        [[ -6.3736,  -6.3330,  -6.3398,  ...,  -5.7465,  -5.5526,  -3.8169],\n",
      "         [ -9.7256,  -9.5975,  -9.6504,  ...,  -5.6887,  -6.6910,  -8.7702],\n",
      "         [ -6.2067,  -6.2688,  -6.2709,  ...,  -6.6204,  -6.2675,  -4.0841],\n",
      "         ...,\n",
      "         [ -5.5263,  -5.6332,  -5.6386,  ...,  -5.7185,  -5.9739,  -3.2791],\n",
      "         [ -6.3944,  -6.4053,  -6.4506,  ...,  -6.8015,  -6.5488,  -4.5735],\n",
      "         [ -6.0980,  -6.0763,  -6.2132,  ...,  -6.4937,  -6.1549,  -3.7730]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 0.7215173244476318\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9337, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7493,  -6.7191,  -6.7221,  ...,  -6.2345,  -6.2706,  -3.4841],\n",
      "         [ -7.1098,  -7.1138,  -7.2122,  ...,  -8.5875,  -7.4242,  -2.3176],\n",
      "         [ -6.6287,  -6.7564,  -6.8176,  ...,  -8.5461,  -7.0713,  -2.9834],\n",
      "         ...,\n",
      "         [ -6.1514,  -6.1018,  -6.1314,  ...,  -6.7177,  -6.3742,  -1.5423],\n",
      "         [ -6.2613,  -6.1522,  -6.2551,  ...,  -6.8608,  -6.1174,  -2.1022],\n",
      "         [ -6.5009,  -6.4777,  -6.5526,  ...,  -7.2616,  -6.1698,  -2.8892]],\n",
      "\n",
      "        [[ -6.3045,  -6.2595,  -6.2448,  ...,  -5.4737,  -5.4655,  -3.6042],\n",
      "         [ -9.6313,  -9.5664,  -9.3653,  ...,  -7.3864,  -7.1285,  -5.9324],\n",
      "         [ -5.1715,  -5.2440,  -5.2692,  ...,  -5.4118,  -6.4066,  -3.0523],\n",
      "         ...,\n",
      "         [ -4.9396,  -4.9941,  -4.9793,  ...,  -5.2049,  -6.2023,  -3.2154],\n",
      "         [ -5.4181,  -5.4961,  -5.4652,  ...,  -5.6357,  -6.4641,  -4.1920],\n",
      "         [ -5.4357,  -5.5289,  -5.4917,  ...,  -5.8646,  -6.7572,  -3.8448]],\n",
      "\n",
      "        [[ -7.0161,  -7.1905,  -7.1442,  ...,  -6.5124,  -6.2573,  -4.7209],\n",
      "         [-13.9240, -13.5638, -13.7651,  ..., -14.3539, -12.4355, -13.1461],\n",
      "         [ -5.4737,  -6.0908,  -5.8354,  ...,  -6.7645,  -5.2993,  -7.0510],\n",
      "         ...,\n",
      "         [ -7.0134,  -7.0417,  -6.9216,  ...,  -7.0749,  -6.2772,  -3.4187],\n",
      "         [ -3.2792,  -3.5745,  -3.4668,  ...,  -4.3541,  -3.7776,  -2.4108],\n",
      "         [-12.0352, -12.3633, -12.0758,  ..., -12.8355, -10.9779,  -9.1890]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9632,  -6.9474,  -6.9574,  ...,  -6.3954,  -6.3112,  -4.1429],\n",
      "         [-11.5475, -10.8219, -11.2435,  ...,  -8.9365,  -8.8861,  -8.3239],\n",
      "         [ -5.5159,  -5.5356,  -5.6673,  ...,  -5.9720,  -7.0724,  -3.9014],\n",
      "         ...,\n",
      "         [ -6.1038,  -6.0404,  -6.1120,  ...,  -6.3614,  -6.8602,  -3.6238],\n",
      "         [ -6.0990,  -6.0161,  -6.0587,  ...,  -6.0812,  -6.8373,  -3.4237],\n",
      "         [ -6.1725,  -6.1793,  -6.3002,  ...,  -6.4830,  -6.7968,  -4.0530]],\n",
      "\n",
      "        [[ -8.5097,  -8.5748,  -8.4140,  ...,  -7.9774,  -7.2168,  -5.6246],\n",
      "         [-13.3346, -13.3955, -13.4291,  ..., -12.9493, -10.3288, -11.3406],\n",
      "         [ -9.0267,  -8.9456,  -9.4772,  ...,  -9.5521,  -5.8331, -10.9910],\n",
      "         ...,\n",
      "         [ -6.4415,  -6.6015,  -6.7165,  ...,  -7.1735,  -5.3441,  -7.0090],\n",
      "         [ -7.6139,  -7.8339,  -7.7379,  ...,  -8.2229,  -5.8381,  -7.3891],\n",
      "         [ -7.9380,  -8.0379,  -8.0554,  ...,  -7.3496,  -5.6714,  -7.2344]],\n",
      "\n",
      "        [[ -7.3255,  -7.4009,  -7.2139,  ...,  -6.6670,  -6.5260,  -5.0655],\n",
      "         [-10.6641, -10.4851, -10.6284,  ..., -10.0135,  -7.7746,  -9.3480],\n",
      "         [ -6.9512,  -7.1389,  -6.9537,  ...,  -6.7845,  -5.6621,  -6.5330],\n",
      "         ...,\n",
      "         [ -7.0538,  -7.3543,  -7.1792,  ...,  -6.4681,  -6.3007,  -6.4385],\n",
      "         [ -6.8978,  -7.1455,  -6.9285,  ...,  -6.4588,  -6.2971,  -6.0152],\n",
      "         [ -6.4506,  -6.6712,  -6.4023,  ...,  -6.4459,  -5.7291,  -4.8617]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.933671236038208\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2737, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7100,  -6.6893,  -6.7021,  ...,  -6.0508,  -5.8970,  -3.7244],\n",
      "         [ -6.6349,  -6.5873,  -6.7186,  ...,  -7.0940,  -6.7306,  -4.1556],\n",
      "         [ -5.4513,  -5.6064,  -5.6572,  ...,  -6.2139,  -5.8842,  -2.0168],\n",
      "         ...,\n",
      "         [ -5.5464,  -5.6160,  -5.6873,  ...,  -6.1279,  -5.4664,  -2.2232],\n",
      "         [ -5.8977,  -5.9430,  -6.0617,  ...,  -6.7055,  -6.0335,  -2.7497],\n",
      "         [ -6.0052,  -6.0977,  -6.1834,  ...,  -6.8406,  -5.9771,  -2.8000]],\n",
      "\n",
      "        [[ -6.9969,  -6.9613,  -6.9773,  ...,  -6.3177,  -6.1322,  -4.3093],\n",
      "         [-11.5928, -11.0877, -11.4660,  ...,  -8.8196,  -9.8185,  -9.0530],\n",
      "         [ -5.3356,  -5.4672,  -5.4940,  ...,  -6.3038,  -6.3268,  -2.9977],\n",
      "         ...,\n",
      "         [ -6.8354,  -6.9461,  -6.8900,  ...,  -7.3673,  -7.2167,  -3.1755],\n",
      "         [ -6.3703,  -6.4858,  -6.4451,  ...,  -7.1590,  -6.5735,  -3.5449],\n",
      "         [ -5.3471,  -5.4737,  -5.4937,  ...,  -6.4102,  -6.0180,  -3.3137]],\n",
      "\n",
      "        [[ -6.5801,  -6.5318,  -6.5396,  ...,  -5.9444,  -5.8781,  -4.0874],\n",
      "         [ -6.3261,  -6.2662,  -6.3503,  ...,  -7.1521,  -6.9732,  -2.9326],\n",
      "         [ -6.8686,  -6.8484,  -7.0160,  ...,  -7.7412,  -7.2271,  -3.8357],\n",
      "         ...,\n",
      "         [ -5.6962,  -5.6465,  -5.7476,  ...,  -6.0361,  -5.6379,  -3.1577],\n",
      "         [ -5.3888,  -5.3732,  -5.4268,  ...,  -5.7071,  -5.5826,  -1.8809],\n",
      "         [ -6.0638,  -6.0489,  -6.0842,  ...,  -6.5279,  -6.2176,  -2.3834]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.2300,  -8.2434,  -8.1763,  ...,  -7.8320,  -7.2034,  -5.2091],\n",
      "         [-10.5162, -10.2290, -10.4077,  ...,  -8.7676,  -8.3946,  -9.5085],\n",
      "         [ -4.4876,  -4.9414,  -4.5950,  ...,  -5.5487,  -2.4857,  -2.3734],\n",
      "         ...,\n",
      "         [ -1.7237,  -1.8974,  -1.5357,  ...,  -1.4751,  -1.7749,  -2.5346],\n",
      "         [ -9.4339,  -9.3044,  -9.2298,  ...,  -8.8851,  -7.2064,  -7.4062],\n",
      "         [-10.5674, -10.8280, -10.9890,  ..., -11.5879,  -7.5840,  -7.8942]],\n",
      "\n",
      "        [[ -7.1537,  -7.1575,  -7.0977,  ...,  -6.2510,  -6.0546,  -3.7758],\n",
      "         [-12.3822, -12.5406, -12.2428,  ..., -12.7002,  -9.9820,  -7.9544],\n",
      "         [ -7.1518,  -7.4724,  -7.5024,  ...,  -6.4078,  -6.5133,  -1.6405],\n",
      "         ...,\n",
      "         [ -7.8774,  -7.7468,  -7.6358,  ...,  -6.8300,  -6.3480,  -4.1171],\n",
      "         [-12.7757, -12.7991, -13.1180,  ..., -10.9972, -11.0892,  -9.4199],\n",
      "         [ -8.8654,  -8.9098,  -8.6607,  ...,  -7.6444,  -6.9324,  -5.2195]],\n",
      "\n",
      "        [[ -8.9661,  -8.9660,  -8.9682,  ...,  -8.3604,  -7.8722,  -4.8723],\n",
      "         [ -5.6918,  -5.7256,  -5.5212,  ...,  -6.6223,  -5.1774,  -5.5963],\n",
      "         [-12.1329, -12.4211, -12.1151,  ..., -13.0309, -10.0653,  -8.3591],\n",
      "         ...,\n",
      "         [ -5.5852,  -5.5853,  -5.4367,  ...,  -6.5434,  -5.1329,  -4.4283],\n",
      "         [ -7.4406,  -7.3194,  -7.5241,  ...,  -7.5949,  -5.0285,  -6.5283],\n",
      "         [-11.3692, -11.4329, -11.2230,  ..., -11.0025,  -8.8468,  -4.6597]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.2737250328063965\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7377, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8045,  -6.7765,  -6.7652,  ...,  -6.0059,  -6.1280,  -3.4048],\n",
      "         [ -5.3556,  -5.1917,  -5.3689,  ...,  -6.7414,  -5.9960,  -2.1083],\n",
      "         [-12.5940, -13.1472, -13.0134,  ..., -12.2217, -11.2019,  -4.6984],\n",
      "         ...,\n",
      "         [ -5.6261,  -5.5064,  -5.6108,  ...,  -6.1355,  -5.9702,  -1.1479],\n",
      "         [ -6.4642,  -6.4651,  -6.5325,  ...,  -6.9246,  -6.6378,  -1.7592],\n",
      "         [ -5.9844,  -5.9450,  -6.0760,  ...,  -6.5136,  -5.9971,  -1.0920]],\n",
      "\n",
      "        [[ -7.0288,  -6.9945,  -6.9718,  ...,  -6.3079,  -6.1642,  -4.2396],\n",
      "         [ -7.6270,  -7.9539,  -7.6483,  ...,  -8.2864,  -7.5422,  -5.4159],\n",
      "         [ -4.0988,  -4.1434,  -4.2913,  ...,  -4.6357,  -2.6514,  -2.8772],\n",
      "         ...,\n",
      "         [ -8.5960,  -8.7779,  -8.6075,  ...,  -9.2020,  -7.9152,  -3.9800],\n",
      "         [ -8.4262,  -8.5880,  -8.4134,  ...,  -8.9327,  -7.4674,  -3.6373],\n",
      "         [ -8.8158,  -9.0398,  -8.9916,  ...,  -9.4885,  -8.0946,  -3.7843]],\n",
      "\n",
      "        [[ -7.3004,  -7.3105,  -7.2550,  ...,  -6.7139,  -6.4883,  -4.3681],\n",
      "         [ -9.8295, -10.0051,  -9.4738,  ...,  -9.0825,  -8.3434,  -8.7143],\n",
      "         [ -8.5836,  -8.3143,  -8.2822,  ...,  -7.6111,  -7.5976,  -5.5199],\n",
      "         ...,\n",
      "         [ -7.9514,  -8.0785,  -7.9772,  ...,  -8.9924,  -7.1521,  -7.1056],\n",
      "         [ -6.9124,  -7.0206,  -6.8968,  ...,  -7.9958,  -6.4432,  -7.1771],\n",
      "         [ -7.5930,  -7.9093,  -7.7155,  ...,  -8.8241,  -6.6182,  -8.0411]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2930,  -7.2522,  -7.1983,  ...,  -6.4721,  -6.3566,  -4.2001],\n",
      "         [ -5.1916,  -5.2879,  -5.3807,  ...,  -6.0021,  -5.0509,  -3.0982],\n",
      "         [ -8.1596,  -8.1224,  -7.9359,  ...,  -7.6787,  -5.3760,  -7.5328],\n",
      "         ...,\n",
      "         [ -7.1877,  -7.2364,  -7.1642,  ...,  -8.0304,  -6.6039,  -5.1637],\n",
      "         [ -7.4899,  -7.5702,  -7.4080,  ...,  -7.8553,  -6.2670,  -5.8848],\n",
      "         [ -7.3789,  -7.4515,  -7.3653,  ...,  -7.8895,  -6.5779,  -5.1902]],\n",
      "\n",
      "        [[ -7.1805,  -7.1105,  -7.1146,  ...,  -6.2819,  -6.2740,  -4.3206],\n",
      "         [-11.0541, -11.2466, -11.0602,  ...,  -9.3508,  -9.2807,  -7.8685],\n",
      "         [ -5.1916,  -5.2421,  -5.2250,  ...,  -5.1825,  -6.3385,  -3.0996],\n",
      "         ...,\n",
      "         [ -5.4214,  -5.5140,  -5.4124,  ...,  -5.3787,  -5.8475,  -3.8556],\n",
      "         [ -5.0342,  -5.1714,  -5.1100,  ...,  -5.3376,  -5.8727,  -2.8640],\n",
      "         [ -5.5917,  -5.6937,  -5.6176,  ...,  -5.6698,  -5.9742,  -3.6687]],\n",
      "\n",
      "        [[ -7.9465,  -7.7646,  -7.5953,  ...,  -7.6560,  -8.1319,  -3.7909],\n",
      "         [-12.6126, -12.3350, -12.3798,  ..., -10.2601, -10.9576, -13.3689],\n",
      "         [ -5.7632,  -5.8848,  -6.0548,  ...,  -6.1396,  -7.2050,  -4.4809],\n",
      "         ...,\n",
      "         [ -5.7559,  -5.7846,  -5.7328,  ...,  -5.5468,  -7.0313,  -4.2773],\n",
      "         [ -5.7859,  -5.7374,  -5.7826,  ...,  -6.0229,  -6.8942,  -4.3859],\n",
      "         [ -6.2257,  -6.4085,  -6.2911,  ...,  -6.1484,  -6.8890,  -4.5048]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.737673044204712\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9468, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8918,  -6.8635,  -6.8632,  ...,  -6.1910,  -5.8878,  -4.1118],\n",
      "         [-10.2584, -10.6585, -10.7979,  ..., -11.1072,  -9.0410,  -7.1348],\n",
      "         [ -7.7221,  -7.9190,  -7.8045,  ...,  -8.6096,  -6.5139,  -6.3712],\n",
      "         ...,\n",
      "         [ -7.4796,  -7.6975,  -7.4538,  ...,  -7.6650,  -6.2305,  -3.8465],\n",
      "         [ -7.1460,  -7.2148,  -6.9132,  ...,  -6.6776,  -5.1064,  -3.6422],\n",
      "         [ -6.6658,  -6.7299,  -6.4167,  ...,  -5.8642,  -4.1469,  -4.3981]],\n",
      "\n",
      "        [[ -3.3254,  -3.4404,  -3.3358,  ...,  -3.2226,  -2.3213,  -3.6005],\n",
      "         [-14.4955, -14.3632, -14.5695,  ..., -12.3566, -11.7044, -10.4606],\n",
      "         [ -5.1252,  -5.1771,  -5.0747,  ...,  -5.3729,  -5.5397,  -4.6989],\n",
      "         ...,\n",
      "         [ -5.6930,  -5.8319,  -5.9215,  ...,  -5.9407,  -6.7693,  -4.0689],\n",
      "         [ -5.1268,  -5.0949,  -5.0704,  ...,  -5.5428,  -5.9716,  -2.6904],\n",
      "         [ -4.9126,  -4.9421,  -4.9091,  ...,  -4.7282,  -5.7406,  -3.2144]],\n",
      "\n",
      "        [[ -6.4966,  -6.4459,  -6.4792,  ...,  -5.8677,  -5.6394,  -3.8505],\n",
      "         [-10.6932, -10.5885, -10.7211,  ...,  -7.7049,  -9.1522,  -6.9582],\n",
      "         [ -4.6307,  -4.7172,  -4.7284,  ...,  -5.4317,  -6.2579,  -2.6362],\n",
      "         ...,\n",
      "         [ -5.8335,  -5.8569,  -5.8135,  ...,  -5.4580,  -6.0720,  -4.6739],\n",
      "         [ -5.3132,  -5.3456,  -5.3402,  ...,  -5.5018,  -6.3560,  -4.4932],\n",
      "         [ -5.2900,  -5.4522,  -5.4028,  ...,  -5.5898,  -6.2066,  -4.5377]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4068,  -7.4080,  -7.3272,  ...,  -6.5964,  -6.5785,  -4.1817],\n",
      "         [ -6.4386,  -6.5335,  -6.0869,  ...,  -6.5863,  -6.1041,  -8.1578],\n",
      "         [ -7.2303,  -6.9707,  -7.2637,  ...,  -7.1311,  -5.7618,  -7.4621],\n",
      "         ...,\n",
      "         [ -6.0959,  -6.2313,  -5.9857,  ...,  -5.4103,  -5.3275,  -6.5356],\n",
      "         [ -8.3959,  -8.4420,  -8.3564,  ...,  -7.2249,  -6.5592,  -6.9820],\n",
      "         [ -6.6918,  -6.6977,  -6.8698,  ...,  -5.2911,  -5.3996,  -6.5379]],\n",
      "\n",
      "        [[ -6.9795,  -7.0278,  -6.9636,  ...,  -6.3762,  -6.3042,  -4.6825],\n",
      "         [ -8.2100,  -8.4788,  -8.1659,  ...,  -8.5943,  -7.4029,  -8.4573],\n",
      "         [ -4.0019,  -3.8754,  -4.6063,  ...,  -4.7925,  -3.7801,  -6.6262],\n",
      "         ...,\n",
      "         [ -6.0629,  -6.0971,  -6.2006,  ...,  -6.8807,  -6.0346,  -5.3321],\n",
      "         [ -3.9540,  -4.0578,  -3.9392,  ...,  -4.7278,  -4.2146,  -2.3187],\n",
      "         [ -2.2587,  -2.6386,  -2.3457,  ...,  -2.8160,  -2.7270,  -2.5190]],\n",
      "\n",
      "        [[ -6.9924,  -6.9954,  -6.9446,  ...,  -6.3393,  -6.0083,  -4.3228],\n",
      "         [ -8.1591,  -8.5068,  -8.5952,  ...,  -8.9709,  -7.2848,  -6.7634],\n",
      "         [ -7.0533,  -6.6367,  -6.9963,  ...,  -6.7793,  -5.2314,  -8.4093],\n",
      "         ...,\n",
      "         [ -6.9230,  -7.2434,  -7.2221,  ...,  -8.1446,  -6.4335,  -7.1366],\n",
      "         [ -8.6304,  -8.7855,  -8.8621,  ...,  -9.4155,  -7.8988,  -8.2485],\n",
      "         [ -8.0979,  -8.2593,  -8.1788,  ...,  -9.2335,  -7.4111,  -6.7419]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.9468048810958862\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8863, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4129,  -7.3753,  -7.3095,  ...,  -6.6966,  -6.3865,  -4.4742],\n",
      "         [-11.5878, -11.7137, -11.9391,  ...,  -9.9106,  -9.2511,  -9.1904],\n",
      "         [ -8.6372,  -8.8237,  -8.9018,  ..., -10.0221,  -5.9193,  -6.3160],\n",
      "         ...,\n",
      "         [-11.7235, -11.7168, -11.9072,  ..., -14.0309,  -9.7485,  -9.6515],\n",
      "         [-12.0509, -11.7250, -11.9919,  ..., -10.6129, -10.1318,  -7.1104],\n",
      "         [-13.9735, -14.1547, -13.8719,  ..., -16.3321, -11.4146, -12.1718]],\n",
      "\n",
      "        [[ -6.4384,  -6.3938,  -6.4194,  ...,  -5.7222,  -5.5801,  -3.8072],\n",
      "         [-12.7657, -12.5650, -12.4465,  ..., -10.7211, -11.5294,  -7.6655],\n",
      "         [ -4.8439,  -4.8583,  -4.9861,  ...,  -5.1854,  -5.7671,  -3.2798],\n",
      "         ...,\n",
      "         [ -5.5306,  -5.5612,  -5.6352,  ...,  -5.6426,  -5.6449,  -3.7672],\n",
      "         [ -4.7425,  -4.7896,  -4.6627,  ...,  -5.0881,  -5.4085,  -3.4716],\n",
      "         [ -5.2265,  -5.3031,  -5.2620,  ...,  -5.2146,  -5.9117,  -3.9222]],\n",
      "\n",
      "        [[ -7.5618,  -7.5512,  -7.5012,  ...,  -7.2493,  -6.5632,  -4.9494],\n",
      "         [-12.2185, -12.7219, -12.5544,  ..., -10.7224,  -8.5290, -11.4285],\n",
      "         [ -8.6586,  -8.7420,  -9.0147,  ...,  -9.5351,  -4.6386,  -7.5038],\n",
      "         ...,\n",
      "         [ -8.5622,  -8.8111,  -8.7995,  ...,  -7.6641,  -6.8448,  -6.8649],\n",
      "         [ -7.5097,  -7.6411,  -7.7162,  ...,  -6.7284,  -7.0230,  -4.8892],\n",
      "         [ -6.6822,  -6.7222,  -6.8273,  ...,  -5.6033,  -5.3885,  -4.9675]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8425,  -6.7642,  -6.7780,  ...,  -6.1683,  -6.0292,  -3.9165],\n",
      "         [-10.2811, -10.3232, -10.0824,  ...,  -8.1412,  -8.4612,  -9.4596],\n",
      "         [ -5.1609,  -5.1495,  -5.3015,  ...,  -5.7873,  -6.3278,  -4.4998],\n",
      "         ...,\n",
      "         [ -5.0608,  -4.9669,  -5.0593,  ...,  -5.5037,  -5.9763,  -4.1664],\n",
      "         [ -4.6745,  -4.6310,  -4.6945,  ...,  -5.2488,  -5.8042,  -3.4882],\n",
      "         [ -5.1159,  -5.0322,  -5.0979,  ...,  -5.2985,  -6.0542,  -4.2298]],\n",
      "\n",
      "        [[ -6.7563,  -6.7598,  -6.7559,  ...,  -6.1883,  -5.9982,  -3.9483],\n",
      "         [ -6.6288,  -6.6407,  -6.6600,  ...,  -7.2984,  -6.6379,  -2.1324],\n",
      "         [ -6.7959,  -6.7687,  -6.7769,  ...,  -7.3080,  -6.9885,  -3.9275],\n",
      "         ...,\n",
      "         [ -5.9271,  -5.9342,  -5.9938,  ...,  -6.2508,  -5.5874,  -2.2375],\n",
      "         [ -6.0247,  -5.9736,  -6.0731,  ...,  -6.4280,  -5.9334,  -2.6126],\n",
      "         [ -5.8280,  -5.7204,  -5.7919,  ...,  -6.2621,  -6.0227,  -2.1293]],\n",
      "\n",
      "        [[ -7.5251,  -7.5429,  -7.3921,  ...,  -6.8163,  -6.5401,  -4.5626],\n",
      "         [ -8.3555,  -8.3802,  -8.3860,  ...,  -7.9218,  -7.2564,  -8.3973],\n",
      "         [-12.5036, -12.6049, -12.3834,  ..., -11.6304,  -8.9472,  -9.8467],\n",
      "         ...,\n",
      "         [ -9.5448, -10.1789, -10.1162,  ...,  -9.1594,  -9.4506,  -8.4116],\n",
      "         [-10.5540, -11.0474, -10.9208,  ..., -11.8832, -10.2824,  -7.2793],\n",
      "         [-11.7784, -11.6720, -11.6952,  ...,  -9.0121,  -9.4294, -11.3767]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8862941265106201\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2159, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6313,  -6.6356,  -6.6235,  ...,  -5.9324,  -5.7437,  -3.7653],\n",
      "         [-11.9760, -12.0675, -12.0371,  ...,  -8.6705,  -9.4361,  -9.2611],\n",
      "         [ -5.1195,  -5.2558,  -5.2636,  ...,  -5.7913,  -6.8923,  -2.7307],\n",
      "         ...,\n",
      "         [ -5.3476,  -5.5148,  -5.5314,  ...,  -5.5711,  -6.5751,  -2.8138],\n",
      "         [ -5.2856,  -5.4099,  -5.3968,  ...,  -5.8938,  -6.5395,  -3.0827],\n",
      "         [ -6.2778,  -6.2670,  -6.2224,  ...,  -6.5466,  -6.8490,  -4.1735]],\n",
      "\n",
      "        [[ -7.9587,  -8.0161,  -7.7764,  ...,  -7.0406,  -6.4964,  -4.5048],\n",
      "         [ -6.6405,  -6.6000,  -6.8357,  ...,  -6.5306,  -5.7877,  -5.7767],\n",
      "         [-12.8212, -13.0420, -12.5770,  ..., -11.2006, -11.1551, -10.9837],\n",
      "         ...,\n",
      "         [-14.2333, -14.6187, -14.2743,  ..., -11.4660, -10.9572, -11.2266],\n",
      "         [-12.9886, -13.4193, -13.0299,  ..., -10.8756,  -8.8370, -10.8901],\n",
      "         [-13.7521, -14.1746, -13.4757,  ..., -12.9620,  -9.7002,  -9.2630]],\n",
      "\n",
      "        [[ -7.0078,  -6.9892,  -7.0003,  ...,  -6.3184,  -6.1908,  -4.0908],\n",
      "         [-12.8135, -12.8445, -12.7839,  ...,  -9.2916, -10.2301,  -9.6936],\n",
      "         [ -5.9267,  -6.1530,  -6.0976,  ...,  -6.3968,  -7.2152,  -2.4909],\n",
      "         ...,\n",
      "         [ -6.3565,  -6.4056,  -6.3648,  ...,  -6.6532,  -6.9619,  -3.2092],\n",
      "         [ -6.1690,  -6.3407,  -6.3564,  ...,  -6.4510,  -7.5594,  -2.5842],\n",
      "         [ -6.5335,  -6.7543,  -6.7445,  ...,  -6.9754,  -6.8355,  -3.3933]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.4882,  -5.4591,  -5.3722,  ...,  -5.2856,  -6.2286,  -5.4207],\n",
      "         [-11.0402, -11.1549, -11.2169,  ...,  -8.7560,  -9.3911, -10.5420],\n",
      "         [ -5.3498,  -5.4266,  -5.4662,  ...,  -6.3537,  -6.5734,  -3.6841],\n",
      "         ...,\n",
      "         [ -6.2142,  -6.2410,  -6.2985,  ...,  -6.5998,  -6.8028,  -5.5421],\n",
      "         [ -5.6836,  -5.7486,  -5.7682,  ...,  -6.3071,  -6.3142,  -4.7176],\n",
      "         [ -5.6628,  -5.8209,  -5.8462,  ...,  -6.0084,  -6.6880,  -3.8588]],\n",
      "\n",
      "        [[ -6.7781,  -7.5093,  -6.7873,  ...,  -6.3143,  -5.9506,  -4.5760],\n",
      "         [-11.5579, -11.1661, -11.0937,  ...,  -9.3843,  -8.4446, -10.6591],\n",
      "         [ -5.6613,  -5.8810,  -5.9348,  ...,  -6.6016,  -7.2550,  -3.3730],\n",
      "         ...,\n",
      "         [ -4.4023,  -4.6119,  -4.4186,  ...,  -5.0607,  -5.3689,  -2.8116],\n",
      "         [ -4.7864,  -5.0976,  -4.8560,  ...,  -5.3498,  -5.7704,  -3.8304],\n",
      "         [ -4.1112,  -4.3204,  -4.0354,  ...,  -4.3204,  -5.4414,  -2.5627]],\n",
      "\n",
      "        [[ -6.6267,  -6.6084,  -6.6105,  ...,  -5.9963,  -5.8170,  -3.8554],\n",
      "         [ -7.0315,  -7.0914,  -7.1714,  ...,  -8.0114,  -7.1523,  -4.4763],\n",
      "         [ -6.8115,  -6.9840,  -6.9857,  ...,  -7.7195,  -6.8255,  -4.7317],\n",
      "         ...,\n",
      "         [ -6.2207,  -6.2239,  -6.3171,  ...,  -6.6718,  -6.0784,  -3.2632],\n",
      "         [ -6.1678,  -6.1771,  -6.2488,  ...,  -6.6999,  -6.0111,  -2.9762],\n",
      "         [ -6.1950,  -6.2109,  -6.2959,  ...,  -6.7367,  -5.9951,  -2.7801]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.215944528579712\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0285, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.6691,  -7.6873,  -7.6263,  ...,  -7.3592,  -6.7133,  -4.9059],\n",
      "         [-10.1761, -10.4789, -10.4043,  ...,  -8.3436,  -9.4319,  -5.0589],\n",
      "         [ -9.9832,  -9.7969, -10.1328,  ...,  -8.1439,  -9.2338,  -9.1023],\n",
      "         ...,\n",
      "         [-15.4842, -15.6379, -15.4741,  ..., -14.1262, -13.4830, -14.8778],\n",
      "         [ -6.8444,  -6.9352,  -7.0035,  ...,  -7.0047,  -6.4024,  -4.4852],\n",
      "         [-15.9363, -16.3762, -16.1958,  ..., -16.5657, -11.9561, -12.0795]],\n",
      "\n",
      "        [[ -6.5299,  -6.5235,  -6.5827,  ...,  -6.3423,  -6.2420,  -3.5280],\n",
      "         [ -6.4142,  -6.3805,  -6.5184,  ...,  -7.4306,  -6.2719,  -3.0971],\n",
      "         [ -6.7703,  -6.8652,  -6.9942,  ...,  -7.8344,  -6.7104,  -4.2954],\n",
      "         ...,\n",
      "         [ -5.9280,  -5.9337,  -5.9992,  ...,  -6.9266,  -5.7244,  -2.7233],\n",
      "         [ -5.6477,  -5.6819,  -5.7258,  ...,  -6.4185,  -5.4204,  -3.2230],\n",
      "         [ -6.2747,  -6.1867,  -6.2788,  ...,  -6.8093,  -5.9366,  -2.9831]],\n",
      "\n",
      "        [[ -8.8252,  -8.8015,  -8.6650,  ...,  -8.0437,  -7.8806,  -4.8364],\n",
      "         [-18.5618, -18.3558, -18.4140,  ..., -17.0248, -14.5868, -10.5161],\n",
      "         [-14.0784, -14.2885, -14.3948,  ..., -13.0558, -11.7281,  -7.7160],\n",
      "         ...,\n",
      "         [ -9.8830, -10.8792, -10.0649,  ..., -10.7858,  -9.3320, -10.1194],\n",
      "         [ -8.2249,  -8.6414,  -8.3136,  ...,  -7.1869,  -7.7880,  -5.9477],\n",
      "         [-14.7654, -14.9858, -14.8307,  ..., -15.5985, -11.5681,  -7.8095]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9342,  -6.9565,  -6.9325,  ...,  -6.3410,  -6.1407,  -4.7022],\n",
      "         [-16.3802, -16.5575, -16.7343,  ..., -14.6203, -13.9719, -11.2932],\n",
      "         [-10.7317, -10.5998, -10.7900,  ...,  -9.6937,  -9.5862, -11.0066],\n",
      "         ...,\n",
      "         [ -7.1628,  -7.2634,  -7.5087,  ...,  -8.0073,  -7.9735, -11.5328],\n",
      "         [-12.0380, -11.9549, -11.7796,  ..., -11.1022,  -9.8981, -11.0758],\n",
      "         [-11.6921, -12.0569, -11.7074,  ...,  -8.8107,  -8.6174,  -9.6741]],\n",
      "\n",
      "        [[ -6.3901,  -6.3757,  -6.3614,  ...,  -5.8192,  -5.6638,  -3.5808],\n",
      "         [ -6.3941,  -6.2564,  -6.3424,  ...,  -7.5002,  -6.8817,  -2.5667],\n",
      "         [ -5.3200,  -5.0437,  -5.2212,  ...,  -6.3183,  -6.1034,  -2.3467],\n",
      "         ...,\n",
      "         [ -5.6207,  -5.6114,  -5.6772,  ...,  -6.4078,  -6.0283,  -1.5296],\n",
      "         [ -5.6977,  -5.6913,  -5.7935,  ...,  -6.6996,  -6.0253,  -2.6547],\n",
      "         [ -4.9922,  -4.9695,  -5.0555,  ...,  -5.5117,  -5.4096,  -1.3724]],\n",
      "\n",
      "        [[ -8.2951,  -8.2760,  -8.1774,  ...,  -7.9715,  -7.1497,  -4.6397],\n",
      "         [-11.6484, -11.6837, -12.0725,  ...,  -9.7972, -10.2606,  -9.5910],\n",
      "         [ -5.3803,  -5.4614,  -5.3966,  ...,  -5.8235,  -6.4019,  -3.6631],\n",
      "         ...,\n",
      "         [ -5.7403,  -5.7769,  -5.7068,  ...,  -6.4974,  -6.2149,  -3.7678],\n",
      "         [ -5.3489,  -5.4886,  -5.4140,  ...,  -5.6050,  -6.1798,  -3.3816],\n",
      "         [ -5.9701,  -6.1015,  -6.0297,  ...,  -6.2758,  -6.3567,  -3.4555]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.028513193130493\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.0691, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5382,  -7.5500,  -7.4476,  ...,  -6.9993,  -6.6215,  -4.6505],\n",
      "         [ -9.6898,  -9.2370,  -9.9473,  ..., -10.7371,  -6.9555,  -6.8848],\n",
      "         [ -2.8710,  -2.9883,  -2.7564,  ...,  -3.1460,  -1.7505,  -3.6006],\n",
      "         ...,\n",
      "         [ -8.1370,  -8.0340,  -8.1322,  ...,  -8.2715,  -7.8750,  -4.7263],\n",
      "         [ -4.1454,  -4.3603,  -4.2204,  ...,  -5.3091,  -3.3630,  -2.0457],\n",
      "         [-14.0344, -14.3034, -14.3728,  ..., -15.5085, -12.5094, -11.1026]],\n",
      "\n",
      "        [[ -7.3992,  -7.4388,  -7.3284,  ...,  -6.8434,  -6.5034,  -5.1270],\n",
      "         [ -9.1410,  -9.2196,  -9.2862,  ...,  -8.5098,  -6.9020,  -7.4378],\n",
      "         [ -5.5505,  -5.3787,  -5.7361,  ...,  -5.1601,  -5.5877,  -5.1461],\n",
      "         ...,\n",
      "         [ -8.1159,  -8.2210,  -8.3316,  ...,  -7.6245,  -7.6495,  -5.5812],\n",
      "         [ -7.2713,  -7.5339,  -7.3147,  ...,  -6.5850,  -7.1210,  -5.1611],\n",
      "         [ -7.4632,  -7.5778,  -7.4458,  ...,  -7.4001,  -7.1886,  -5.4190]],\n",
      "\n",
      "        [[ -6.7146,  -6.7500,  -6.7076,  ...,  -6.3687,  -5.8981,  -4.2961],\n",
      "         [ -5.3766,  -5.5215,  -5.5783,  ...,  -5.8428,  -4.2384,  -4.5103],\n",
      "         [-10.2989, -10.0373, -10.4273,  ...,  -8.9255,  -7.8084,  -8.5227],\n",
      "         ...,\n",
      "         [ -6.8204,  -6.8110,  -6.9557,  ...,  -7.0396,  -6.0976,  -5.4179],\n",
      "         [ -4.8649,  -4.9119,  -4.8280,  ...,  -4.6941,  -4.6726,  -2.3175],\n",
      "         [ -7.1622,  -7.2956,  -7.2700,  ...,  -7.2395,  -6.3554,  -4.3769]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9438,  -6.9808,  -6.9098,  ...,  -6.4587,  -6.1590,  -4.3732],\n",
      "         [ -6.4305,  -6.7689,  -6.3535,  ...,  -5.6442,  -5.4569,  -2.9323],\n",
      "         [ -9.6696,  -9.7129,  -9.7185,  ...,  -9.3589,  -9.2201,  -8.3565],\n",
      "         ...,\n",
      "         [ -4.2992,  -4.3843,  -4.2087,  ...,  -4.8656,  -3.9797,  -4.2266],\n",
      "         [ -5.6377,  -5.8486,  -5.7016,  ...,  -6.3333,  -5.3284,  -5.2940],\n",
      "         [-11.5915, -11.7168, -11.4650,  ..., -12.4272,  -8.5968,  -8.3930]],\n",
      "\n",
      "        [[ -6.8241,  -6.7968,  -6.8189,  ...,  -6.0670,  -5.9761,  -4.1446],\n",
      "         [-12.8463, -11.9962, -12.4065,  ...,  -9.0047, -10.5464,  -7.9767],\n",
      "         [ -5.9654,  -5.9273,  -6.0300,  ...,  -6.5414,  -7.2865,  -3.3353],\n",
      "         ...,\n",
      "         [ -6.0478,  -6.1501,  -6.1818,  ...,  -6.6568,  -7.2006,  -3.4009],\n",
      "         [ -6.6211,  -6.6869,  -6.6720,  ...,  -6.8299,  -6.7366,  -3.7533],\n",
      "         [ -5.9956,  -6.0806,  -6.0482,  ...,  -5.9811,  -6.3340,  -3.4714]],\n",
      "\n",
      "        [[ -6.1077,  -6.1366,  -6.1718,  ...,  -5.8693,  -6.0616,  -3.1124],\n",
      "         [ -7.0370,  -7.0290,  -7.0757,  ...,  -8.2356,  -7.4651,  -2.8403],\n",
      "         [ -6.5196,  -6.4694,  -6.3922,  ...,  -8.1448,  -7.1104,  -3.4987],\n",
      "         ...,\n",
      "         [ -6.2642,  -6.2538,  -6.2278,  ...,  -6.9106,  -6.3488,  -2.5136],\n",
      "         [ -5.8404,  -5.9067,  -5.8533,  ...,  -6.5688,  -5.8225,  -2.1249],\n",
      "         [ -6.0000,  -5.9456,  -6.0554,  ...,  -6.6827,  -6.0293,  -2.1207]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 3.069129228591919\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8347, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1469,  -7.0340,  -6.9922,  ...,  -6.5013,  -6.0237,  -4.5291],\n",
      "         [ -9.0839,  -8.7486,  -8.8225,  ...,  -8.3029,  -7.8465,  -8.0566],\n",
      "         [ -6.1638,  -6.3513,  -6.2754,  ...,  -7.2270,  -5.3776,  -3.8213],\n",
      "         ...,\n",
      "         [ -8.2652,  -8.2429,  -8.0675,  ...,  -8.0490,  -7.0588,  -6.3984],\n",
      "         [ -8.8540,  -8.7789,  -8.6035,  ...,  -8.5413,  -7.3814,  -5.9726],\n",
      "         [ -8.5478,  -8.4396,  -8.3087,  ...,  -8.1462,  -7.5946,  -5.8600]],\n",
      "\n",
      "        [[ -5.5598,  -5.7435,  -5.4765,  ...,  -6.1031,  -4.4582,  -3.9923],\n",
      "         [-12.6826, -12.6599, -12.5679,  ...,  -9.9162,  -9.0292,  -9.6274],\n",
      "         [ -7.0774,  -7.0768,  -7.1042,  ...,  -7.5922,  -7.1292,  -4.5534],\n",
      "         ...,\n",
      "         [ -6.8250,  -6.9306,  -6.8207,  ...,  -6.8714,  -6.0847,  -5.4148],\n",
      "         [ -6.5423,  -6.6724,  -6.5817,  ...,  -7.0622,  -6.0336,  -4.2748],\n",
      "         [ -7.0492,  -7.1467,  -7.0132,  ...,  -7.0922,  -6.0686,  -4.5516]],\n",
      "\n",
      "        [[ -7.2315,  -7.3448,  -7.1768,  ...,  -6.8915,  -6.5381,  -5.1591],\n",
      "         [ -6.2260,  -6.2371,  -6.3603,  ...,  -6.5012,  -5.0518,  -5.2831],\n",
      "         [ -3.7200,  -4.0764,  -3.1775,  ...,  -3.5810,  -2.6528,  -1.7116],\n",
      "         ...,\n",
      "         [ -7.8240,  -7.9640,  -7.5098,  ...,  -8.5582,  -6.7965,  -9.2155],\n",
      "         [ -7.0794,  -7.0642,  -6.8076,  ...,  -7.9344,  -6.6112,  -9.3672],\n",
      "         [ -7.5691,  -7.6835,  -7.4340,  ...,  -7.8213,  -6.8825,  -6.4095]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5106,  -6.4650,  -6.4943,  ...,  -5.8018,  -5.6219,  -3.8970],\n",
      "         [-10.4057, -10.2516, -10.3757,  ...,  -8.5925,  -7.9932,  -7.5836],\n",
      "         [ -5.5498,  -5.6907,  -5.7188,  ...,  -5.8833,  -6.3433,  -3.6498],\n",
      "         ...,\n",
      "         [ -5.9304,  -6.1587,  -6.0558,  ...,  -6.0293,  -6.4397,  -4.3797],\n",
      "         [ -5.8658,  -5.9914,  -5.9143,  ...,  -5.9333,  -6.1154,  -4.2615],\n",
      "         [ -6.0519,  -6.2572,  -6.2118,  ...,  -6.6279,  -6.8106,  -3.8392]],\n",
      "\n",
      "        [[ -7.7997,  -7.8459,  -7.6923,  ...,  -7.2404,  -6.7496,  -4.7580],\n",
      "         [ -9.2275,  -9.4316,  -9.3684,  ...,  -9.0977,  -9.7474,  -7.8715],\n",
      "         [ -8.5735,  -8.6857,  -8.7728,  ...,  -9.5956,  -8.1295,  -4.1791],\n",
      "         ...,\n",
      "         [ -6.8587,  -6.9051,  -6.8577,  ...,  -6.8395,  -5.8300,  -4.5088],\n",
      "         [ -7.7732,  -7.9512,  -7.7401,  ...,  -6.7822,  -6.6354,  -5.4005],\n",
      "         [ -6.9169,  -7.1706,  -7.0270,  ...,  -6.9246,  -6.4912,  -5.6432]],\n",
      "\n",
      "        [[ -7.4692,  -7.5345,  -7.3600,  ...,  -7.0671,  -6.8289,  -6.0444],\n",
      "         [ -9.9986, -10.0609, -10.1710,  ...,  -9.2260,  -9.4182,  -9.1546],\n",
      "         [ -9.4188,  -9.6891,  -9.3420,  ...,  -9.9941,  -8.5806,  -9.2094],\n",
      "         ...,\n",
      "         [-10.3934, -10.3094, -10.4203,  ..., -10.1519,  -7.8215,  -7.2677],\n",
      "         [ -4.7555,  -4.7803,  -4.8585,  ...,  -4.0416,  -5.2965,  -3.1456],\n",
      "         [-16.4970, -17.0004, -16.6408,  ..., -16.8825, -14.3578, -13.6294]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8346675634384155\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.5135, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.1297,  -8.1770,  -8.1624,  ...,  -7.2518,  -7.2713,  -4.5861],\n",
      "         [-12.2785, -12.0703, -12.1560,  ..., -10.4534, -10.0751, -15.0321],\n",
      "         [ -6.8883,  -6.6167,  -6.2177,  ...,  -6.6396,  -5.7257,  -3.7713],\n",
      "         ...,\n",
      "         [ -6.7613,  -6.6953,  -6.5998,  ...,  -7.5743,  -6.6522,  -5.7752],\n",
      "         [ -7.5283,  -7.5286,  -7.3021,  ...,  -7.8309,  -6.6497,  -5.4541],\n",
      "         [ -7.5941,  -7.4726,  -7.3864,  ...,  -8.0663,  -7.1968,  -5.6407]],\n",
      "\n",
      "        [[ -6.8845,  -6.8693,  -6.8714,  ...,  -6.2898,  -6.1750,  -3.8517],\n",
      "         [ -7.3142,  -7.3207,  -7.3751,  ...,  -8.6616,  -8.0012,  -3.4204],\n",
      "         [ -6.8612,  -6.9892,  -6.9897,  ...,  -8.3860,  -7.4137,  -4.5828],\n",
      "         ...,\n",
      "         [ -5.2553,  -5.3075,  -5.3546,  ...,  -6.2495,  -5.8336,  -2.4160],\n",
      "         [ -5.4645,  -5.4631,  -5.5411,  ...,  -6.1552,  -6.1495,  -2.3558],\n",
      "         [ -5.5399,  -5.5634,  -5.5805,  ...,  -6.1454,  -6.0465,  -2.6031]],\n",
      "\n",
      "        [[ -6.5531,  -6.5226,  -6.5329,  ...,  -5.9371,  -5.6728,  -3.9388],\n",
      "         [ -6.6096,  -6.7255,  -6.6423,  ...,  -6.8276,  -6.2952,  -4.1786],\n",
      "         [-10.7876, -10.5972, -10.8114,  ...,  -7.7793,  -8.4684,  -7.9396],\n",
      "         ...,\n",
      "         [ -6.7523,  -6.8328,  -6.7808,  ...,  -6.7381,  -6.4509,  -4.0662],\n",
      "         [ -6.9595,  -7.0262,  -6.9503,  ...,  -6.8886,  -6.3872,  -3.7426],\n",
      "         [ -6.7989,  -6.9400,  -6.8612,  ...,  -7.0448,  -6.6638,  -3.5644]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4131,  -6.4356,  -6.3255,  ...,  -5.8799,  -5.7181,  -3.5468],\n",
      "         [ -7.9208,  -8.0499,  -7.8914,  ...,  -7.3915,  -7.0815,  -8.7659],\n",
      "         [ -9.0476,  -9.0962,  -8.6644,  ...,  -9.3389,  -8.4740,  -3.5755],\n",
      "         ...,\n",
      "         [ -4.3734,  -4.6517,  -4.3085,  ...,  -3.7676,  -4.9355,  -3.3078],\n",
      "         [ -4.2879,  -4.6035,  -4.2355,  ...,  -3.4054,  -4.9352,  -2.7489],\n",
      "         [ -2.6855,  -2.7678,  -2.6042,  ...,  -3.9817,  -3.6649,   2.3513]],\n",
      "\n",
      "        [[ -7.1865,  -7.1604,  -7.1230,  ...,  -6.4675,  -6.6014,  -4.2396],\n",
      "         [-12.9588, -13.0239, -12.9759,  ...,  -9.6627, -11.0732, -11.1522],\n",
      "         [ -4.8609,  -5.0522,  -5.0138,  ...,  -5.0697,  -6.6237,  -2.8380],\n",
      "         ...,\n",
      "         [ -6.1711,  -6.2534,  -6.2536,  ...,  -6.4340,  -7.3360,  -4.3612],\n",
      "         [ -5.9181,  -5.9544,  -5.8492,  ...,  -6.2573,  -6.9804,  -4.7818],\n",
      "         [ -6.1408,  -6.2384,  -6.1753,  ...,  -6.1334,  -7.2255,  -4.3322]],\n",
      "\n",
      "        [[ -6.6952,  -6.6593,  -6.6705,  ...,  -6.0361,  -5.8482,  -4.1213],\n",
      "         [ -5.9628,  -5.9905,  -6.0887,  ...,  -7.6387,  -6.5545,  -3.0795],\n",
      "         [ -7.8047,  -7.7502,  -7.7903,  ...,  -9.1285,  -8.3445,  -5.7882],\n",
      "         ...,\n",
      "         [ -5.2297,  -5.3340,  -5.3918,  ...,  -6.3474,  -5.3438,  -2.8977],\n",
      "         [ -5.7163,  -5.7263,  -5.7880,  ...,  -6.6327,  -6.0080,  -2.9250],\n",
      "         [ -4.8385,  -4.9146,  -4.9531,  ...,  -5.8441,  -5.0962,  -2.3209]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 3.513472318649292\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0870, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7557,  -6.7141,  -6.7246,  ...,  -6.1661,  -6.0357,  -3.8545],\n",
      "         [ -5.0744,  -5.0578,  -5.2525,  ...,  -6.1207,  -5.4817,  -1.9842],\n",
      "         [ -6.7573,  -6.8421,  -6.9309,  ...,  -8.2943,  -7.2316,  -2.7658],\n",
      "         ...,\n",
      "         [ -5.4296,  -5.5103,  -5.5888,  ...,  -6.2481,  -5.5311,  -2.4905],\n",
      "         [ -5.8148,  -5.8620,  -6.0273,  ...,  -6.4366,  -5.6587,  -3.1959],\n",
      "         [ -5.8043,  -5.8046,  -5.9396,  ...,  -6.5253,  -5.7800,  -2.9225]],\n",
      "\n",
      "        [[ -6.8076,  -6.8448,  -6.7800,  ...,  -6.0799,  -5.8901,  -4.2389],\n",
      "         [-12.5241, -12.4873, -12.5458,  ..., -11.1834,  -9.5073, -13.7575],\n",
      "         [ -5.1868,  -5.6199,  -5.0860,  ...,  -5.8242,  -3.8762, -10.7168],\n",
      "         ...,\n",
      "         [-10.0110, -10.1728,  -9.9540,  ..., -10.0851,  -7.8443,  -8.8273],\n",
      "         [-13.3826, -13.5094, -13.7398,  ..., -14.4087, -11.7358, -11.6921],\n",
      "         [-13.2840, -13.4016, -13.7201,  ..., -10.3414, -11.2793, -10.9217]],\n",
      "\n",
      "        [[ -6.8247,  -6.8462,  -6.8513,  ...,  -6.7135,  -6.4824,  -3.7829],\n",
      "         [ -9.1390,  -9.0227,  -9.0968,  ...,  -7.4633,  -7.6953,  -9.5404],\n",
      "         [ -7.0674,  -7.1589,  -7.1605,  ...,  -7.6445,  -6.9508,  -4.5854],\n",
      "         ...,\n",
      "         [ -8.4934,  -8.7464,  -8.3851,  ...,  -9.4794,  -7.3798,  -4.0263],\n",
      "         [ -7.0794,  -7.1234,  -7.1283,  ...,  -7.7660,  -6.7655,  -4.3783],\n",
      "         [ -7.5700,  -7.7492,  -7.6579,  ...,  -7.9849,  -7.5144,  -3.8699]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6839,  -6.6602,  -6.6526,  ...,  -6.1484,  -5.8593,  -4.1475],\n",
      "         [-13.1979, -13.6179, -13.1161,  ..., -13.1140, -11.0079, -13.8145],\n",
      "         [ -4.5133,  -4.8249,  -4.6284,  ...,  -4.8471,  -5.2595,  -4.3938],\n",
      "         ...,\n",
      "         [ -5.0904,  -4.9702,  -4.9746,  ...,  -5.2207,  -4.7825,  -2.8538],\n",
      "         [-10.5526, -11.0148, -10.2985,  ..., -10.4738, -10.6982,  -9.3892],\n",
      "         [-12.3098, -12.3139, -12.3210,  ..., -10.9233,  -9.6522, -11.0945]],\n",
      "\n",
      "        [[ -6.6203,  -6.6121,  -6.6348,  ...,  -6.0749,  -5.9202,  -3.8339],\n",
      "         [ -6.2556,  -6.3487,  -6.4373,  ...,  -7.2630,  -6.0435,  -2.9503],\n",
      "         [ -5.6511,  -5.5762,  -5.6372,  ...,  -6.6052,  -5.7837,  -2.6449],\n",
      "         ...,\n",
      "         [ -5.3383,  -5.3509,  -5.5241,  ...,  -6.0528,  -5.7107,  -2.1999],\n",
      "         [ -4.8328,  -4.8311,  -4.9477,  ...,  -5.7276,  -5.2268,  -1.6170],\n",
      "         [ -5.2945,  -5.2403,  -5.4213,  ...,  -6.0895,  -5.7303,  -1.7615]],\n",
      "\n",
      "        [[ -6.5508,  -6.4903,  -6.4536,  ...,  -5.9248,  -5.5313,  -4.1633],\n",
      "         [ -5.3745,  -5.7197,  -5.4641,  ...,  -5.2113,  -6.1989,  -4.4231],\n",
      "         [-17.4298, -17.5686, -17.1588,  ..., -16.0267, -14.4146, -15.3876],\n",
      "         ...,\n",
      "         [ -5.3374,  -5.5327,  -5.3393,  ...,  -5.3961,  -4.9855,  -5.5159],\n",
      "         [ -7.2533,  -7.2106,  -7.1558,  ...,  -7.0955,  -6.0092,  -7.4153],\n",
      "         [ -6.1147,  -6.2104,  -6.2145,  ...,  -6.0294,  -5.6140,  -6.3561]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.0870020389556885\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9818, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3213,  -6.2738,  -6.2559,  ...,  -5.6967,  -5.4369,  -3.6192],\n",
      "         [ -6.2500,  -6.2782,  -6.1659,  ...,  -7.0499,  -6.1683,  -3.1150],\n",
      "         [ -5.8360,  -5.9654,  -5.9055,  ...,  -6.4517,  -6.3426,  -2.5445],\n",
      "         ...,\n",
      "         [ -5.9142,  -5.9896,  -5.9612,  ...,  -6.4237,  -5.9711,  -2.5566],\n",
      "         [ -6.2202,  -6.2935,  -6.3006,  ...,  -6.8742,  -6.3198,  -3.3874],\n",
      "         [ -6.0487,  -6.1253,  -6.1297,  ...,  -6.4653,  -6.1465,  -2.5568]],\n",
      "\n",
      "        [[ -7.1195,  -7.1518,  -7.0670,  ...,  -6.7688,  -6.9074,  -3.8911],\n",
      "         [-13.5627, -13.4837, -13.6021,  ...,  -9.0512, -11.7227,  -9.4272],\n",
      "         [ -5.2152,  -5.3775,  -5.4725,  ...,  -5.3101,  -6.9530,  -3.7106],\n",
      "         ...,\n",
      "         [ -5.8226,  -5.8517,  -5.8212,  ...,  -5.8430,  -6.9342,  -3.7373],\n",
      "         [ -5.9578,  -5.9667,  -6.0094,  ...,  -5.9753,  -7.1364,  -3.5476],\n",
      "         [ -5.7190,  -5.7049,  -5.8115,  ...,  -5.8343,  -6.8611,  -3.2889]],\n",
      "\n",
      "        [[ -7.5723,  -7.5292,  -7.5213,  ...,  -7.4828,  -7.4470,  -4.1459],\n",
      "         [-12.6559, -12.6856, -12.6230,  ...,  -8.6463,  -9.2098,  -8.8637],\n",
      "         [ -4.3399,  -4.4450,  -4.4766,  ...,  -4.2020,  -5.2994,  -3.2029],\n",
      "         ...,\n",
      "         [ -4.9209,  -4.9182,  -4.8952,  ...,  -4.5054,  -5.3943,  -2.4710],\n",
      "         [ -4.7576,  -4.7819,  -4.8057,  ...,  -4.3638,  -5.3653,  -2.9669],\n",
      "         [ -4.2639,  -4.3675,  -4.3269,  ...,  -4.1419,  -4.9669,  -3.1978]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4044,  -6.6138,  -6.4800,  ...,  -7.3290,  -5.5865,  -4.3810],\n",
      "         [-10.8919, -10.9441, -11.1982,  ...,  -7.7326,  -5.7842,  -8.1773],\n",
      "         [ -6.2396,  -6.2045,  -6.1920,  ...,  -7.0314,  -5.4595,  -4.1564],\n",
      "         ...,\n",
      "         [ -5.3048,  -5.2879,  -5.2188,  ...,  -6.0235,  -4.5467,  -3.5831],\n",
      "         [ -6.1466,  -6.1877,  -6.1185,  ...,  -6.8267,  -5.5274,  -4.1770],\n",
      "         [ -5.9734,  -6.0660,  -5.9591,  ...,  -6.5752,  -4.7107,  -4.3122]],\n",
      "\n",
      "        [[ -5.9534,  -5.9563,  -5.8291,  ...,  -5.9085,  -5.5577,  -3.4662],\n",
      "         [ -8.8351,  -8.7691,  -8.7060,  ...,  -7.2641,  -7.3370,  -5.8070],\n",
      "         [ -4.8266,  -4.9884,  -5.0165,  ...,  -5.1587,  -6.1932,  -2.6755],\n",
      "         ...,\n",
      "         [ -4.7920,  -4.9141,  -4.8481,  ...,  -5.1839,  -5.4232,  -3.4595],\n",
      "         [ -4.7316,  -4.8854,  -4.8187,  ...,  -5.1271,  -5.6072,  -3.0645],\n",
      "         [ -4.4699,  -4.6528,  -4.6856,  ...,  -4.9766,  -5.8501,  -2.1183]],\n",
      "\n",
      "        [[ -6.3411,  -6.2455,  -6.2592,  ...,  -5.6183,  -5.5097,  -3.9500],\n",
      "         [ -0.4078,  -0.6554,  -0.3658,  ...,  -0.7958,  -1.2124,   0.2674],\n",
      "         [ -7.3196,  -7.6810,  -7.0478,  ...,  -6.4045,  -4.6147,  -4.2233],\n",
      "         ...,\n",
      "         [ -5.9943,  -6.1825,  -5.9243,  ...,  -6.7092,  -5.0666,  -3.3492],\n",
      "         [ -5.8050,  -5.9479,  -5.7705,  ...,  -6.8132,  -5.2714,  -3.3105],\n",
      "         [ -6.1085,  -6.2712,  -5.9789,  ...,  -6.5392,  -4.7776,  -2.8670]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.981829285621643\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8261, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1712,  -7.1294,  -7.0857,  ...,  -6.2915,  -6.0291,  -4.1567],\n",
      "         [ -7.3054,  -7.8533,  -7.5900,  ...,  -8.1148,  -6.8988,  -2.4450],\n",
      "         [ -6.0157,  -5.7256,  -5.8173,  ...,  -5.9559,  -3.9256,  -3.4843],\n",
      "         ...,\n",
      "         [ -7.6464,  -7.5400,  -7.4331,  ...,  -7.7074,  -6.0238,  -5.1348],\n",
      "         [ -2.3544,  -2.4152,  -2.2195,  ...,  -1.6717,  -1.5303,  -3.6660],\n",
      "         [ -2.7284,  -2.6401,  -2.8071,  ...,  -3.1314,  -2.3029,  -4.2181]],\n",
      "\n",
      "        [[ -6.5014,  -6.4697,  -6.4445,  ...,  -5.8599,  -5.8100,  -3.8629],\n",
      "         [ -5.2956,  -5.0964,  -5.1853,  ...,  -6.1756,  -5.0815,  -1.9742],\n",
      "         [ -5.8173,  -5.6730,  -5.6200,  ...,  -6.7062,  -5.8996,  -2.9292],\n",
      "         ...,\n",
      "         [ -4.8621,  -4.7586,  -4.7701,  ...,  -5.4397,  -5.1274,  -1.0528],\n",
      "         [ -4.7372,  -4.6987,  -4.6796,  ...,  -5.1773,  -4.7447,  -1.7630],\n",
      "         [ -4.2885,  -4.2746,  -4.2744,  ...,  -4.8807,  -4.4718,  -1.3586]],\n",
      "\n",
      "        [[ -6.5523,  -6.7443,  -6.4688,  ...,  -4.9411,  -6.7424,  -3.9895],\n",
      "         [-12.5601, -12.2590, -12.4345,  ..., -10.0528, -10.4936,  -9.6284],\n",
      "         [ -4.7301,  -4.9332,  -4.8889,  ...,  -4.6807,  -7.1397,  -3.9207],\n",
      "         ...,\n",
      "         [ -5.2254,  -5.4213,  -5.3001,  ...,  -4.7443,  -6.7896,  -4.2451],\n",
      "         [ -5.3257,  -5.4020,  -5.4306,  ...,  -4.6687,  -6.4616,  -3.6403],\n",
      "         [ -5.4106,  -5.6266,  -5.7872,  ...,  -5.0344,  -7.7212,  -2.3313]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7326,  -6.7947,  -6.8680,  ...,  -7.2909,  -6.6639,  -3.2513],\n",
      "         [-13.3916, -12.8427, -13.1643,  ...,  -8.9866, -10.2692, -11.4316],\n",
      "         [ -6.3652,  -6.5062,  -6.4946,  ...,  -7.0500,  -6.5738,  -4.3355],\n",
      "         ...,\n",
      "         [ -6.4683,  -6.5531,  -6.6056,  ...,  -7.0160,  -6.5310,  -2.9240],\n",
      "         [ -6.5573,  -6.6670,  -6.7047,  ...,  -7.3860,  -6.8874,  -3.9857],\n",
      "         [ -6.6296,  -6.8173,  -6.7074,  ...,  -7.2380,  -6.4933,  -4.1982]],\n",
      "\n",
      "        [[ -7.0555,  -7.0133,  -7.0432,  ...,  -5.9875,  -6.5506,  -3.7833],\n",
      "         [-12.3690, -12.4270, -12.6140,  ...,  -9.6140, -11.2481,  -8.8163],\n",
      "         [ -3.9313,  -4.1229,  -4.0465,  ...,  -4.4604,  -5.5673,  -3.1517],\n",
      "         ...,\n",
      "         [ -5.3858,  -5.6152,  -5.6464,  ...,  -5.3901,  -6.6454,  -3.3734],\n",
      "         [ -4.3420,  -4.4261,  -4.4539,  ...,  -4.8157,  -5.4220,  -2.5447],\n",
      "         [ -4.7343,  -4.9437,  -4.8225,  ...,  -4.9905,  -5.9748,  -3.4896]],\n",
      "\n",
      "        [[ -9.1548,  -9.5632,  -9.2151,  ...,  -9.0774,  -8.7130,  -7.2573],\n",
      "         [ -7.8803,  -7.8360,  -8.0159,  ...,  -7.9549,  -7.6384,  -5.9932],\n",
      "         [ -7.9275,  -7.8536,  -7.6159,  ...,  -8.2620,  -4.8355,  -7.8444],\n",
      "         ...,\n",
      "         [ -5.1474,  -5.5195,  -5.1563,  ...,  -5.3862,  -5.1468,  -4.4075],\n",
      "         [ -7.5258,  -8.1412,  -7.8867,  ...,  -8.0479,  -7.7340,  -7.1577],\n",
      "         [ -7.7470,  -8.1406,  -7.9890,  ...,  -8.6383,  -8.0992,  -5.2075]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 1.8261191844940186\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3298, grad_fn=<NllLossBackward0>), logits=tensor([[[-7.0030e+00, -6.8113e+00, -6.8003e+00,  ..., -6.3217e+00,\n",
      "          -6.0858e+00, -4.8205e+00],\n",
      "         [-1.3450e+01, -1.2624e+01, -1.3190e+01,  ..., -1.0748e+01,\n",
      "          -1.0835e+01, -1.1541e+01],\n",
      "         [-5.0613e+00, -5.0385e+00, -5.1245e+00,  ..., -5.2459e+00,\n",
      "          -6.3224e+00, -4.1224e+00],\n",
      "         ...,\n",
      "         [-5.6363e+00, -5.4965e+00, -5.6031e+00,  ..., -5.2486e+00,\n",
      "          -6.0909e+00, -4.7866e+00],\n",
      "         [-5.8703e+00, -5.7695e+00, -5.8108e+00,  ..., -5.3939e+00,\n",
      "          -6.3538e+00, -3.4927e+00],\n",
      "         [-5.3566e+00, -5.3282e+00, -5.3490e+00,  ..., -4.8434e+00,\n",
      "          -5.6848e+00, -4.2949e+00]],\n",
      "\n",
      "        [[-6.8913e+00, -6.9998e+00, -6.8957e+00,  ..., -6.6639e+00,\n",
      "          -6.0038e+00, -4.8101e+00],\n",
      "         [-1.4607e+01, -1.4587e+01, -1.4423e+01,  ..., -1.2341e+01,\n",
      "          -9.8447e+00, -1.2410e+01],\n",
      "         [-8.0213e+00, -8.1904e+00, -8.3608e+00,  ..., -6.0414e+00,\n",
      "          -6.2315e+00, -9.9492e+00],\n",
      "         ...,\n",
      "         [-5.9458e+00, -6.3421e+00, -6.0470e+00,  ..., -7.3246e+00,\n",
      "          -4.2144e+00, -6.2405e+00],\n",
      "         [-6.3794e+00, -6.5606e+00, -6.4371e+00,  ..., -7.1519e+00,\n",
      "          -4.5571e+00, -7.0398e+00],\n",
      "         [-6.0720e+00, -6.3055e+00, -6.1889e+00,  ..., -6.4437e+00,\n",
      "          -4.0615e+00, -6.0603e+00]],\n",
      "\n",
      "        [[-6.9246e+00, -7.0490e+00, -6.9630e+00,  ..., -6.5313e+00,\n",
      "          -6.0402e+00, -4.2317e+00],\n",
      "         [-1.4359e+01, -1.4132e+01, -1.4353e+01,  ..., -1.2972e+01,\n",
      "          -1.1464e+01, -1.4341e+01],\n",
      "         [-1.0688e+00, -1.2741e+00, -7.9872e-01,  ..., -8.5179e-03,\n",
      "          -1.7779e-01, -3.3283e+00],\n",
      "         ...,\n",
      "         [-1.5394e+00, -1.9696e+00, -1.4800e+00,  ..., -9.5760e-01,\n",
      "          -2.3639e+00, -3.4410e+00],\n",
      "         [-1.3174e+01, -1.3110e+01, -1.3414e+01,  ..., -1.1627e+01,\n",
      "          -1.2098e+01, -1.0627e+01],\n",
      "         [-1.2905e+01, -1.3362e+01, -1.3098e+01,  ..., -1.2156e+01,\n",
      "          -1.1300e+01, -7.1916e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.0291e+00, -7.0462e+00, -6.9951e+00,  ..., -6.3723e+00,\n",
      "          -6.2935e+00, -4.0690e+00],\n",
      "         [-1.4479e+01, -1.4471e+01, -1.4630e+01,  ..., -1.3451e+01,\n",
      "          -1.3659e+01, -1.0225e+01],\n",
      "         [-1.1547e+01, -1.1471e+01, -1.1560e+01,  ..., -1.1143e+01,\n",
      "          -1.2023e+01, -1.0189e+01],\n",
      "         ...,\n",
      "         [-6.8214e+00, -6.9591e+00, -6.8427e+00,  ..., -7.1265e+00,\n",
      "          -6.0087e+00, -4.1817e+00],\n",
      "         [-6.7586e+00, -6.9937e+00, -6.8914e+00,  ..., -7.2593e+00,\n",
      "          -5.7611e+00, -2.6716e+00],\n",
      "         [-7.0828e+00, -7.3068e+00, -7.1685e+00,  ..., -7.5723e+00,\n",
      "          -6.1450e+00, -3.3343e+00]],\n",
      "\n",
      "        [[-6.9479e+00, -6.9580e+00, -6.8348e+00,  ..., -6.4131e+00,\n",
      "          -6.0796e+00, -3.9404e+00],\n",
      "         [-1.4794e+01, -1.5084e+01, -1.4813e+01,  ..., -1.3253e+01,\n",
      "          -1.2676e+01, -1.2178e+01],\n",
      "         [-1.0089e+01, -1.0349e+01, -1.0501e+01,  ..., -9.6621e+00,\n",
      "          -7.9121e+00, -9.7022e+00],\n",
      "         ...,\n",
      "         [-7.6440e+00, -7.7478e+00, -7.5560e+00,  ..., -8.5836e+00,\n",
      "          -6.8399e+00, -5.8569e+00],\n",
      "         [-6.1391e+00, -6.2696e+00, -6.1880e+00,  ..., -7.1260e+00,\n",
      "          -5.7503e+00, -5.0324e+00],\n",
      "         [-7.0406e+00, -7.1863e+00, -7.0847e+00,  ..., -8.0789e+00,\n",
      "          -6.5383e+00, -4.8145e+00]],\n",
      "\n",
      "        [[-6.4924e+00, -6.4908e+00, -6.4958e+00,  ..., -5.8754e+00,\n",
      "          -5.7139e+00, -3.7566e+00],\n",
      "         [-6.7072e+00, -6.6145e+00, -6.7261e+00,  ..., -7.6922e+00,\n",
      "          -7.1784e+00, -3.0924e+00],\n",
      "         [-7.0217e+00, -7.0571e+00, -7.1317e+00,  ..., -7.9324e+00,\n",
      "          -7.4298e+00, -2.9809e+00],\n",
      "         ...,\n",
      "         [-5.7932e+00, -5.8647e+00, -5.9069e+00,  ..., -6.5762e+00,\n",
      "          -6.1272e+00, -2.3833e+00],\n",
      "         [-5.3430e+00, -5.3686e+00, -5.4154e+00,  ..., -6.2727e+00,\n",
      "          -5.6069e+00, -2.2401e+00],\n",
      "         [-5.3298e+00, -5.4460e+00, -5.4787e+00,  ..., -6.1651e+00,\n",
      "          -5.9109e+00, -2.2993e+00]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.3297581672668457\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0943, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4925,  -7.4668,  -7.4868,  ...,  -6.7545,  -6.3781,  -4.8481],\n",
      "         [-12.8263, -12.9284, -12.7526,  ...,  -9.2882, -10.2609,  -7.7633],\n",
      "         [ -5.3165,  -5.4568,  -5.4191,  ...,  -6.1113,  -6.8613,  -3.3677],\n",
      "         ...,\n",
      "         [ -5.7105,  -5.7191,  -5.5545,  ...,  -7.0118,  -6.6661,  -4.1378],\n",
      "         [ -5.7457,  -5.9196,  -5.7179,  ...,  -6.1384,  -6.8418,  -4.9813],\n",
      "         [ -5.3270,  -5.4121,  -5.3305,  ...,  -5.6963,  -6.3338,  -4.1913]],\n",
      "\n",
      "        [[ -6.2700,  -6.2367,  -6.2539,  ...,  -5.5982,  -5.5673,  -3.6256],\n",
      "         [ -9.6669,  -9.8442,  -9.6412,  ...,  -6.7430,  -7.0350,  -9.7148],\n",
      "         [ -5.1836,  -5.1402,  -5.2939,  ...,  -5.5928,  -6.0336,  -3.2466],\n",
      "         ...,\n",
      "         [ -5.7076,  -5.6836,  -5.7726,  ...,  -5.8575,  -6.1617,  -4.5064],\n",
      "         [ -5.5711,  -5.4909,  -5.6341,  ...,  -5.7731,  -6.0986,  -3.6302],\n",
      "         [ -5.5789,  -5.5272,  -5.6991,  ...,  -5.6139,  -5.8770,  -3.9298]],\n",
      "\n",
      "        [[ -8.0447,  -7.9558,  -7.9295,  ...,  -7.0339,  -7.2570,  -4.3718],\n",
      "         [-12.2460, -12.2615, -12.4164,  ..., -11.6038,  -9.4623,  -9.8009],\n",
      "         [-15.0311, -15.1284, -15.0695,  ..., -12.7918, -12.5003, -18.0674],\n",
      "         ...,\n",
      "         [ -6.6771,  -6.7431,  -6.7595,  ...,  -6.2904,  -6.1899,  -3.7977],\n",
      "         [ -5.6212,  -5.5687,  -5.4799,  ...,  -5.6763,  -4.9225,  -2.4426],\n",
      "         [ -7.6604,  -7.7990,  -7.8365,  ...,  -7.6131,  -7.1894,  -4.1983]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.1593,  -6.0951,  -6.1418,  ...,  -5.4766,  -5.4432,  -3.5542],\n",
      "         [-12.4323, -12.2539, -12.2379,  ...,  -9.2237,  -9.7248, -10.3335],\n",
      "         [ -4.5185,  -4.5801,  -4.6724,  ...,  -4.4829,  -6.0793,  -3.2954],\n",
      "         ...,\n",
      "         [ -4.8506,  -4.9591,  -5.0397,  ...,  -4.8518,  -6.3041,  -4.2893],\n",
      "         [ -5.4798,  -5.5700,  -5.5929,  ...,  -5.6483,  -6.5199,  -4.4721],\n",
      "         [ -5.4091,  -5.5547,  -5.5613,  ...,  -5.7289,  -7.2677,  -4.8682]],\n",
      "\n",
      "        [[ -7.7890,  -7.7748,  -7.7143,  ...,  -7.0561,  -6.8142,  -4.5691],\n",
      "         [-15.6687, -15.3650, -15.5767,  ..., -13.8278, -12.6366, -13.3142],\n",
      "         [ -9.4774,  -9.4501,  -9.7597,  ..., -10.2843,  -8.0279,  -8.6918],\n",
      "         ...,\n",
      "         [-14.6134, -14.8893, -14.5517,  ..., -12.4068, -10.4524, -10.5659],\n",
      "         [-16.3707, -16.5403, -16.3099,  ..., -14.0009, -12.1933, -14.1467],\n",
      "         [-12.5095, -12.4608, -12.7541,  ...,  -9.5762,  -8.8516,  -7.6570]],\n",
      "\n",
      "        [[ -6.4606,  -6.4576,  -6.3741,  ...,  -5.8902,  -5.5939,  -3.6968],\n",
      "         [-11.0830, -10.5819, -10.6285,  ...,  -8.6734,  -8.8675,  -6.5960],\n",
      "         [ -6.7045,  -6.4950,  -6.4957,  ...,  -5.9284,  -4.6745,  -8.4002],\n",
      "         ...,\n",
      "         [ -5.1457,  -5.2535,  -5.1132,  ...,  -4.8330,  -3.8598,  -4.0829],\n",
      "         [ -4.9766,  -5.1930,  -5.0464,  ...,  -5.2315,  -3.7917,  -3.7964],\n",
      "         [ -5.8014,  -5.9819,  -5.8033,  ...,  -5.8494,  -4.3662,  -2.9472]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 1, Loss: 2.094327449798584\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0184, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0032,  -7.0668,  -7.0187,  ...,  -6.5688,  -6.3168,  -4.1349],\n",
      "         [ -3.6434,  -3.9319,  -4.2683,  ...,  -6.0043,  -5.7793,  -5.6495],\n",
      "         [ -5.5968,  -5.6106,  -5.8159,  ...,  -5.5471,  -4.8122,  -8.3586],\n",
      "         ...,\n",
      "         [ -7.5489,  -7.9573,  -7.5218,  ...,  -7.5473,  -7.2410,  -9.4207],\n",
      "         [ -6.9312,  -7.1456,  -6.9740,  ...,  -7.0226,  -6.4280,  -8.0996],\n",
      "         [-12.2283, -12.3435, -12.3738,  ..., -12.2349, -11.2250,  -9.5848]],\n",
      "\n",
      "        [[ -7.8013,  -7.8160,  -7.7452,  ...,  -7.0982,  -6.7336,  -4.5843],\n",
      "         [-11.3920, -11.4940, -11.2800,  ...,  -9.1946, -10.1011,  -7.2757],\n",
      "         [ -6.1402,  -6.6236,  -6.3911,  ...,  -5.7151,  -4.8291,  -5.4531],\n",
      "         ...,\n",
      "         [ -8.7361,  -9.1407,  -9.0725,  ...,  -9.9130,  -7.4498,  -5.2750],\n",
      "         [-12.0627, -12.2771, -12.2079,  ..., -11.5495,  -8.8447,  -8.4107],\n",
      "         [-11.9214, -12.0213, -11.7653,  ..., -10.7202,  -8.8505,  -9.6203]],\n",
      "\n",
      "        [[ -7.6695,  -7.6531,  -7.5894,  ...,  -7.0980,  -6.6378,  -4.9264],\n",
      "         [ -7.5062,  -7.6195,  -7.6560,  ...,  -6.2933,  -5.3149,  -8.1713],\n",
      "         [ -5.7837,  -5.6262,  -5.5852,  ...,  -6.3739,  -5.2219,  -5.9745],\n",
      "         ...,\n",
      "         [ -8.3705,  -8.3286,  -8.2331,  ...,  -8.2203,  -8.3220,  -8.1986],\n",
      "         [ -7.5740,  -7.5082,  -7.2529,  ...,  -7.6983,  -7.9829,  -6.5422],\n",
      "         [ -6.1409,  -6.0135,  -5.7756,  ...,  -5.9665,  -7.0052,  -6.4864]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5777,  -6.5736,  -6.5487,  ...,  -5.8469,  -5.5144,  -3.5867],\n",
      "         [-11.1562, -11.3391, -11.5633,  ..., -11.0717,  -8.6714,  -4.6801],\n",
      "         [-12.8369, -12.5682, -13.0575,  ..., -10.9544,  -9.6841,  -7.9615],\n",
      "         ...,\n",
      "         [ -8.0108,  -8.1383,  -8.0555,  ...,  -7.5596,  -5.6912,  -3.1918],\n",
      "         [ -8.4751,  -8.6423,  -8.4088,  ...,  -8.0193,  -6.3314,  -2.9732],\n",
      "         [ -8.4058,  -8.5177,  -8.4071,  ...,  -8.4160,  -6.4077,  -2.8623]],\n",
      "\n",
      "        [[ -6.6751,  -6.6589,  -6.6404,  ...,  -6.0907,  -5.8122,  -4.0861],\n",
      "         [-11.0910, -11.3936, -11.1337,  ..., -10.8932,  -9.0450,  -8.0612],\n",
      "         [-13.7023, -13.7687, -13.9352,  ..., -13.7052, -10.3492, -10.0211],\n",
      "         ...,\n",
      "         [ -5.7767,  -5.8401,  -5.6826,  ...,  -6.1143,  -4.3865,  -2.9407],\n",
      "         [ -5.2114,  -5.1716,  -4.9407,  ...,  -5.3631,  -4.0440,  -3.1191],\n",
      "         [ -6.9304,  -7.1138,  -6.8879,  ...,  -7.7344,  -6.1974,  -4.8811]],\n",
      "\n",
      "        [[ -6.6635,  -6.6333,  -6.6221,  ...,  -6.1629,  -5.8922,  -4.1733],\n",
      "         [-10.4810,  -9.9617, -10.3742,  ..., -10.7888,  -9.6258, -11.8064],\n",
      "         [-11.2061, -11.3820, -11.0645,  ..., -10.0742,  -8.8388, -11.8789],\n",
      "         ...,\n",
      "         [ -3.9818,  -4.4595,  -4.2080,  ...,  -5.0032,  -3.0230,  -6.6176],\n",
      "         [ -6.4160,  -6.7426,  -6.3930,  ...,  -7.6101,  -5.0095,  -5.5104],\n",
      "         [ -2.6206,  -2.9860,  -2.6181,  ...,  -2.7292,  -1.9784,  -0.2045]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.018383264541626\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3426, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8908,  -6.8868,  -6.9494,  ...,  -6.3064,  -6.1855,  -4.4602],\n",
      "         [-11.6248, -11.5817, -11.5400,  ...,  -7.5677,  -9.6455,  -9.0423],\n",
      "         [ -5.2349,  -5.2996,  -5.3432,  ...,  -5.4950,  -6.1411,  -3.9772],\n",
      "         ...,\n",
      "         [ -5.6644,  -5.7667,  -5.7174,  ...,  -5.3615,  -6.0656,  -3.7278],\n",
      "         [ -6.3911,  -6.5460,  -6.5878,  ...,  -6.6080,  -7.2686,  -3.1053],\n",
      "         [ -4.7728,  -4.9290,  -4.8568,  ...,  -5.0219,  -5.3774,  -4.1268]],\n",
      "\n",
      "        [[ -6.5383,  -6.4686,  -6.5220,  ...,  -5.7803,  -6.0702,  -3.7684],\n",
      "         [-10.8072, -10.4787, -11.0311,  ...,  -8.0575,  -9.5461,  -8.4962],\n",
      "         [ -5.1387,  -5.2920,  -5.3547,  ...,  -5.4251,  -6.2260,  -4.4558],\n",
      "         ...,\n",
      "         [ -5.1770,  -5.2827,  -5.2537,  ...,  -4.9424,  -6.4299,  -3.2862],\n",
      "         [ -5.3520,  -5.3825,  -5.4524,  ...,  -5.0694,  -6.4666,  -3.5837],\n",
      "         [ -5.2501,  -5.3383,  -5.3715,  ...,  -5.2264,  -6.2200,  -4.7431]],\n",
      "\n",
      "        [[-12.9372, -13.1298, -13.0664,  ..., -11.4997, -12.4481,  -6.3967],\n",
      "         [-13.0762, -13.2687, -13.1388,  ..., -10.9463, -11.8218, -10.1566],\n",
      "         [ -5.0681,  -5.3024,  -5.3880,  ...,  -6.0758,  -7.6096,  -2.9909],\n",
      "         ...,\n",
      "         [ -5.4382,  -5.7148,  -5.5675,  ...,  -5.8331,  -6.9209,  -3.6733],\n",
      "         [ -4.4382,  -4.7208,  -4.6088,  ...,  -5.1276,  -6.0692,  -2.3299],\n",
      "         [ -5.8415,  -5.8420,  -5.9384,  ...,  -6.5580,  -7.0550,  -3.0336]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3685,  -7.4812,  -7.4162,  ...,  -7.3640,  -6.5189,  -3.8797],\n",
      "         [-13.5934, -13.4154, -13.6630,  ..., -10.5474, -10.1035, -13.2313],\n",
      "         [ -6.2944,  -6.4033,  -6.6699,  ...,  -7.0798,  -6.9027,  -4.1590],\n",
      "         ...,\n",
      "         [ -6.3741,  -6.5622,  -6.7101,  ...,  -7.0423,  -6.5930,  -4.0059],\n",
      "         [ -6.5952,  -6.8062,  -6.8644,  ...,  -7.3198,  -6.1612,  -4.3508],\n",
      "         [ -6.2864,  -6.4699,  -6.5333,  ...,  -6.6246,  -6.3595,  -3.9723]],\n",
      "\n",
      "        [[ -7.4642,  -7.5466,  -7.4131,  ...,  -6.9267,  -6.2672,  -4.9794],\n",
      "         [-15.1971, -15.4518, -15.5837,  ..., -13.1582, -11.6762, -11.8430],\n",
      "         [-11.5468, -11.5616, -10.9528,  ..., -10.2733, -10.3157,  -6.8344],\n",
      "         ...,\n",
      "         [ -3.9980,  -3.8736,  -3.5381,  ...,  -4.8738,  -1.3839,  -4.4905],\n",
      "         [ -6.0351,  -6.2127,  -5.7533,  ...,  -6.3990,  -4.2815,  -6.8536],\n",
      "         [ -3.2265,  -3.3231,  -3.0556,  ...,  -4.1043,  -1.1079,  -2.4083]],\n",
      "\n",
      "        [[ -6.5111,  -6.4678,  -6.4524,  ...,  -6.1667,  -5.8751,  -3.5835],\n",
      "         [ -7.0466,  -7.0344,  -7.1422,  ...,  -7.7747,  -7.6865,  -3.5913],\n",
      "         [ -7.2420,  -7.4386,  -7.4264,  ...,  -8.6318,  -7.6465,  -3.0752],\n",
      "         ...,\n",
      "         [ -5.7175,  -5.7442,  -5.8741,  ...,  -6.4108,  -5.7441,  -3.4158],\n",
      "         [ -5.7303,  -5.8608,  -5.9231,  ...,  -6.6161,  -5.9381,  -2.6317],\n",
      "         [ -5.1099,  -5.1417,  -5.2009,  ...,  -5.8764,  -5.1848,  -2.5154]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.3425604104995728\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2308, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6682,  -6.6315,  -6.6383,  ...,  -5.9952,  -5.7888,  -4.0004],\n",
      "         [-11.8774, -11.8912, -12.0171,  ...,  -9.4330, -10.2598,  -8.3145],\n",
      "         [ -5.5456,  -5.6901,  -5.7343,  ...,  -5.9105,  -6.1370,  -4.0745],\n",
      "         ...,\n",
      "         [ -5.6109,  -5.8432,  -5.7852,  ...,  -6.0386,  -6.4968,  -3.9962],\n",
      "         [ -5.6713,  -5.7970,  -5.8209,  ...,  -5.8745,  -6.4083,  -3.7198],\n",
      "         [ -5.2782,  -5.4902,  -5.4466,  ...,  -5.6971,  -6.6119,  -3.3593]],\n",
      "\n",
      "        [[ -6.5941,  -6.5875,  -6.4761,  ...,  -6.1597,  -5.7294,  -4.4550],\n",
      "         [-11.8154, -12.1734, -11.7696,  ..., -11.6414,  -8.4442, -11.2944],\n",
      "         [ -7.3034,  -7.2914,  -7.1642,  ...,  -7.6536,  -5.5229,  -3.3851],\n",
      "         ...,\n",
      "         [ -1.5490,  -1.8784,  -1.5992,  ...,  -0.9354,  -3.1606,  -3.3687],\n",
      "         [ -1.1870,  -1.5492,  -1.1993,  ...,  -0.7432,  -2.7037,  -3.0515],\n",
      "         [ -1.4902,  -1.7587,  -1.5934,  ...,  -0.9379,  -2.8276,  -3.5745]],\n",
      "\n",
      "        [[ -6.2852,  -6.2716,  -6.2552,  ...,  -5.7852,  -5.4909,  -3.7745],\n",
      "         [ -5.9521,  -5.9648,  -6.0495,  ...,  -6.8882,  -5.9363,  -2.7306],\n",
      "         [ -6.4975,  -6.6030,  -6.5919,  ...,  -8.0661,  -6.9014,  -4.0945],\n",
      "         ...,\n",
      "         [ -4.9431,  -4.9537,  -5.0190,  ...,  -5.8866,  -5.2115,  -2.2864],\n",
      "         [ -4.8630,  -5.0019,  -4.9788,  ...,  -5.5020,  -5.4349,  -2.7146],\n",
      "         [ -5.0974,  -5.1923,  -5.1950,  ...,  -6.0108,  -5.7149,  -2.7118]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6257,  -6.5924,  -6.5588,  ...,  -5.9608,  -5.6807,  -3.9223],\n",
      "         [-10.9502, -10.7502, -10.6472,  ..., -10.9971,  -8.7183,  -9.2880],\n",
      "         [ -3.8589,  -3.8458,  -3.8074,  ...,  -4.8818,  -4.5001,  -1.7566],\n",
      "         ...,\n",
      "         [ -6.0559,  -6.0955,  -6.0519,  ...,  -6.2106,  -6.0766,  -4.2266],\n",
      "         [ -5.2478,  -5.3633,  -5.2161,  ...,  -5.3999,  -5.0168,  -3.4421],\n",
      "         [ -6.5912,  -6.6632,  -6.6678,  ...,  -6.7185,  -5.9792,  -5.3828]],\n",
      "\n",
      "        [[ -6.9651,  -6.9014,  -6.8684,  ...,  -6.4503,  -6.2437,  -4.3524],\n",
      "         [-11.6799, -12.4089, -12.1245,  ..., -12.4759,  -9.9601, -12.2776],\n",
      "         [-10.9789, -11.4246, -11.0444,  ..., -11.6324,  -8.5642, -10.1573],\n",
      "         ...,\n",
      "         [ -9.9806, -10.2897,  -9.9517,  ...,  -9.5348,  -9.4807,  -7.8211],\n",
      "         [ -7.5774,  -7.5930,  -7.1990,  ...,  -8.1302,  -8.0264,  -5.7020],\n",
      "         [-15.2880, -15.7022, -15.4489,  ..., -16.3539, -12.9572, -12.6331]],\n",
      "\n",
      "        [[ -6.5746,  -6.4960,  -6.4976,  ...,  -5.7891,  -5.6064,  -4.0241],\n",
      "         [-11.5239, -11.3114, -11.1328,  ...,  -8.6686,  -9.8338,  -6.8127],\n",
      "         [ -4.5948,  -4.7313,  -4.5850,  ...,  -4.4241,  -5.5741,  -3.5028],\n",
      "         ...,\n",
      "         [ -4.6345,  -4.7585,  -4.6461,  ...,  -4.1502,  -5.6453,  -3.5254],\n",
      "         [ -4.4520,  -4.4463,  -4.4361,  ...,  -4.3973,  -5.3880,  -3.4193],\n",
      "         [ -4.9457,  -4.9329,  -4.8289,  ...,  -4.2944,  -5.1961,  -4.4599]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.230762243270874\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4268, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8516,  -6.8559,  -6.7966,  ...,  -6.3289,  -5.9424,  -4.1063],\n",
      "         [ -9.7842, -10.1235,  -9.6934,  ...,  -9.5897,  -8.0669,  -7.4499],\n",
      "         [ -7.9312,  -8.1179,  -8.2524,  ...,  -8.7036,  -6.8835,  -9.7876],\n",
      "         ...,\n",
      "         [-10.7432, -10.9918, -11.0215,  ...,  -9.5592,  -9.2009, -10.3601],\n",
      "         [ -8.0582,  -8.0532,  -8.0600,  ...,  -7.0200,  -6.0770,  -6.1496],\n",
      "         [-13.2770, -13.6346, -13.6471,  ..., -14.0624,  -9.1136,  -9.5396]],\n",
      "\n",
      "        [[ -6.5693,  -6.5420,  -6.5698,  ...,  -5.8406,  -5.7093,  -3.8482],\n",
      "         [-12.3459, -12.5921, -12.5747,  ...,  -8.9921, -10.2101,  -9.3545],\n",
      "         [ -4.9323,  -5.1992,  -5.1697,  ...,  -5.3781,  -6.3368,  -3.9555],\n",
      "         ...,\n",
      "         [ -4.8969,  -5.0879,  -4.9017,  ...,  -4.1123,  -5.7856,  -3.7651],\n",
      "         [ -4.6615,  -4.8027,  -4.8750,  ...,  -4.6393,  -6.6153,  -4.3522],\n",
      "         [ -5.9331,  -6.0237,  -6.0913,  ...,  -6.0153,  -6.3710,  -3.9045]],\n",
      "\n",
      "        [[ -7.9823,  -8.0869,  -8.0507,  ...,  -7.6818,  -7.3035,  -4.8507],\n",
      "         [ -5.6608,  -5.4892,  -5.5380,  ...,  -7.3016,  -6.5258,  -4.4253],\n",
      "         [ -8.6834,  -8.4929,  -8.4614,  ...,  -8.0537,  -7.4295,  -8.5356],\n",
      "         ...,\n",
      "         [ -4.4288,  -4.2812,  -4.2173,  ...,  -4.2821,  -3.4708,  -5.6547],\n",
      "         [ -2.9732,  -2.8877,  -2.8379,  ...,  -2.9182,  -1.2755,  -0.0282],\n",
      "         [ -6.9750,  -7.0976,  -6.7971,  ...,  -7.0351,  -6.9974,  -5.2801]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.0163,  -7.9452,  -7.8723,  ...,  -7.3933,  -6.9938,  -5.5818],\n",
      "         [-14.2558, -14.7047, -14.5896,  ..., -13.8007, -12.2213, -12.7960],\n",
      "         [ -3.5869,  -3.7856,  -3.8356,  ...,  -4.1988,  -3.7735,  -7.1857],\n",
      "         ...,\n",
      "         [ -5.1596,  -5.3164,  -5.2431,  ...,  -6.1837,  -4.2495,  -7.4300],\n",
      "         [ -5.4548,  -5.8376,  -5.2260,  ...,  -5.4585,  -4.8430,  -6.5441],\n",
      "         [ -6.0202,  -6.2416,  -6.2296,  ...,  -7.1874,  -5.1760,  -6.6908]],\n",
      "\n",
      "        [[ -7.0680,  -7.0654,  -7.0538,  ...,  -6.2991,  -6.1534,  -4.2043],\n",
      "         [ -8.3399,  -8.4187,  -8.4522,  ...,  -8.1260,  -7.8283,  -3.7349],\n",
      "         [ -2.6754,  -2.8892,  -2.7462,  ...,  -4.8748,  -3.7081,  -3.7109],\n",
      "         ...,\n",
      "         [ -7.9142,  -7.8828,  -7.6255,  ...,  -7.7073,  -7.3196,  -3.7160],\n",
      "         [ -8.6090,  -8.6679,  -8.5221,  ...,  -8.6229,  -7.9262,  -4.4574],\n",
      "         [ -8.7289,  -8.8119,  -8.6434,  ...,  -8.9615,  -8.1183,  -4.9826]],\n",
      "\n",
      "        [[ -6.7027,  -6.6567,  -6.6718,  ...,  -6.0939,  -5.9811,  -4.0265],\n",
      "         [ -7.2531,  -7.4223,  -7.2850,  ...,  -8.6749,  -7.6114,  -3.9236],\n",
      "         [ -7.0057,  -7.1220,  -7.0355,  ...,  -8.1562,  -6.6280,  -4.5079],\n",
      "         ...,\n",
      "         [ -5.0682,  -5.0898,  -5.1365,  ...,  -5.8198,  -5.5719,  -1.5486],\n",
      "         [ -5.2663,  -5.2079,  -5.3199,  ...,  -6.0933,  -5.8172,  -1.7425],\n",
      "         [ -5.2471,  -5.2814,  -5.3567,  ...,  -5.9239,  -5.6541,  -1.4858]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.426789402961731\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7572, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1890,  -7.1868,  -7.1514,  ...,  -6.5952,  -6.4315,  -4.3934],\n",
      "         [ -8.9719,  -8.9318,  -9.1218,  ..., -10.0216,  -9.4612,  -6.0923],\n",
      "         [-10.8059, -10.8786, -10.4826,  ..., -10.6826,  -9.8169,  -9.9021],\n",
      "         ...,\n",
      "         [ -5.5473,  -5.3979,  -5.6378,  ...,  -6.0610,  -6.5996,  -2.5038],\n",
      "         [-14.7086, -14.8325, -14.9411,  ..., -15.4843, -12.8006,  -7.8718],\n",
      "         [-12.1220, -12.7607, -12.5666,  ..., -10.0261, -10.2637, -10.8830]],\n",
      "\n",
      "        [[ -7.3632,  -7.3774,  -7.3442,  ...,  -7.0030,  -6.6066,  -4.3855],\n",
      "         [-10.0609,  -9.8730,  -9.8965,  ..., -10.9835,  -8.8569,  -7.3209],\n",
      "         [ -2.1417,  -2.5517,  -2.3375,  ...,  -1.6667,  -2.9321,  -3.4083],\n",
      "         ...,\n",
      "         [ -7.5499,  -7.6229,  -7.3622,  ...,  -7.8104,  -6.8743,  -9.6204],\n",
      "         [ -9.0284,  -9.5705,  -8.9251,  ...,  -9.6085,  -7.9089, -10.8466],\n",
      "         [-11.2002, -11.1728, -11.4281,  ...,  -8.6620,  -7.4938,  -9.2707]],\n",
      "\n",
      "        [[ -6.6593,  -6.7004,  -6.7350,  ...,  -6.0645,  -6.0016,  -3.4856],\n",
      "         [ -6.4988,  -6.5465,  -6.4840,  ...,  -7.5205,  -7.6239,  -2.5192],\n",
      "         [ -7.1995,  -7.1930,  -7.1166,  ...,  -8.7923,  -7.2961,  -3.8098],\n",
      "         ...,\n",
      "         [ -5.3258,  -5.4057,  -5.4454,  ...,  -6.1421,  -5.7320,  -2.0086],\n",
      "         [ -5.4798,  -5.4702,  -5.5480,  ...,  -6.3682,  -6.1333,  -1.4654],\n",
      "         [ -4.5252,  -4.6779,  -4.6121,  ...,  -5.1252,  -5.4733,  -1.5097]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4971,  -7.4381,  -7.4434,  ...,  -6.9126,  -6.6122,  -4.7257],\n",
      "         [ -7.3819,  -7.5231,  -7.3871,  ...,  -7.6330,  -7.1531,  -6.5256],\n",
      "         [ -7.7766,  -8.1035,  -8.0662,  ...,  -9.2693,  -7.1719,  -8.4875],\n",
      "         ...,\n",
      "         [ -4.3491,  -4.8188,  -4.5139,  ...,  -4.1118,  -5.3908,  -3.8719],\n",
      "         [ -6.5636,  -7.0060,  -6.6237,  ...,  -5.6304,  -5.9672,  -8.0002],\n",
      "         [-13.7188, -14.0095, -13.8182,  ..., -14.4641, -11.8137, -10.1700]],\n",
      "\n",
      "        [[ -7.6656,  -7.6569,  -7.5775,  ...,  -7.0590,  -6.3789,  -5.1039],\n",
      "         [-16.4605, -15.9893, -16.4404,  ..., -14.8913, -13.8193, -15.2932],\n",
      "         [-11.5335, -11.7068, -11.6982,  ..., -11.6891,  -8.8689,  -5.4448],\n",
      "         ...,\n",
      "         [ -5.6185,  -5.6569,  -5.8412,  ...,  -5.2767,  -4.0046,  -7.9925],\n",
      "         [-10.7073, -10.4938, -10.6657,  ...,  -8.3792,  -8.6684,  -8.1367],\n",
      "         [-12.4315, -12.9682, -12.7981,  ..., -10.4188,  -7.2806, -12.6983]],\n",
      "\n",
      "        [[ -7.0025,  -7.0396,  -6.9556,  ...,  -6.2817,  -6.2204,  -4.0971],\n",
      "         [-12.6854, -12.6462, -12.7311,  ..., -11.6135, -10.5991, -10.7620],\n",
      "         [ -4.6031,  -4.7393,  -4.7732,  ...,  -5.3213,  -5.9447,  -2.9446],\n",
      "         ...,\n",
      "         [ -4.2946,  -4.3232,  -4.2888,  ...,  -5.0118,  -5.3504,  -1.7803],\n",
      "         [ -5.4141,  -5.5204,  -5.5391,  ...,  -5.7011,  -5.9703,  -3.6554],\n",
      "         [ -4.6367,  -4.7972,  -4.7649,  ...,  -5.3048,  -5.7814,  -3.2540]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.75724458694458\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9575, grad_fn=<NllLossBackward0>), logits=tensor([[[-10.8173, -10.9275, -11.0084,  ..., -10.8211, -11.1228,  -4.1926],\n",
      "         [-12.4878, -12.6937, -12.5819,  ...,  -8.7624, -10.8783, -10.7513],\n",
      "         [ -5.5373,  -5.7571,  -5.8429,  ...,  -7.1898,  -7.9133,  -3.4081],\n",
      "         ...,\n",
      "         [ -5.8010,  -6.0363,  -6.0107,  ...,  -7.4269,  -7.7480,  -3.5574],\n",
      "         [ -6.0184,  -6.2070,  -6.2982,  ...,  -7.2893,  -6.9824,  -3.6418],\n",
      "         [ -5.8486,  -5.8957,  -5.9812,  ...,  -6.6676,  -6.5409,  -3.4512]],\n",
      "\n",
      "        [[ -7.1967,  -7.1723,  -7.0689,  ...,  -6.5210,  -6.2073,  -4.6337],\n",
      "         [-11.3557, -11.2964, -11.3176,  ...,  -9.0246,  -8.7589, -10.0506],\n",
      "         [-10.9342, -10.9893, -10.9421,  ..., -10.2779,  -8.3574, -15.1709],\n",
      "         ...,\n",
      "         [ -5.0129,  -5.1223,  -5.0645,  ...,  -5.6303,  -4.8304,  -4.1791],\n",
      "         [ -5.4162,  -5.7021,  -5.4578,  ...,  -5.5938,  -5.0763,  -2.6501],\n",
      "         [ -6.0396,  -6.3024,  -6.1311,  ...,  -6.3738,  -5.5027,  -4.7131]],\n",
      "\n",
      "        [[ -7.4113,  -7.4404,  -7.3317,  ...,  -7.0506,  -6.5236,  -4.3599],\n",
      "         [ -9.7483,  -9.8909,  -9.5831,  ...,  -7.2289,  -8.0423,  -7.4404],\n",
      "         [-13.0249, -13.1613, -13.3208,  ..., -10.7129, -10.6174,  -8.7740],\n",
      "         ...,\n",
      "         [ -3.5190,  -3.8141,  -3.4219,  ...,  -4.2306,  -3.1040,  -6.3922],\n",
      "         [ -5.9910,  -6.1095,  -5.8133,  ...,  -6.1356,  -4.6562,  -6.7476],\n",
      "         [ -4.1296,  -4.3852,  -4.2017,  ...,  -4.6891,  -3.4609,  -6.7039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9679,  -6.9609,  -6.8919,  ...,  -6.3926,  -5.9349,  -4.4081],\n",
      "         [ -7.8233,  -7.7308,  -7.7351,  ...,  -8.9359,  -6.1639,  -5.4675],\n",
      "         [ -5.2226,  -5.6772,  -5.2717,  ...,  -8.3154,  -6.1382,  -4.9207],\n",
      "         ...,\n",
      "         [ -6.7099,  -6.9854,  -6.9616,  ...,  -7.8845,  -6.1932,  -4.9810],\n",
      "         [ -7.8071,  -8.0771,  -7.3170,  ...,  -8.5466,  -6.5274,  -7.3989],\n",
      "         [ -7.0666,  -7.1219,  -6.4712,  ...,  -6.9208,  -5.8121,  -8.1850]],\n",
      "\n",
      "        [[ -6.6004,  -6.5577,  -6.5208,  ...,  -5.8303,  -5.6359,  -3.9187],\n",
      "         [ -6.6862,  -6.6620,  -6.6074,  ...,  -5.7458,  -6.1429,  -3.7439],\n",
      "         [ -6.6468,  -6.9662,  -6.8240,  ...,  -7.8214,  -6.2186,  -7.3428],\n",
      "         ...,\n",
      "         [ -5.9509,  -6.2369,  -6.0778,  ...,  -6.8030,  -5.1546,  -4.5958],\n",
      "         [ -6.0099,  -6.1857,  -6.1490,  ...,  -6.6108,  -4.7670,  -4.6316],\n",
      "         [ -6.8211,  -7.0825,  -6.9394,  ...,  -7.6594,  -5.5294,  -5.0127]],\n",
      "\n",
      "        [[ -7.4005,  -7.4361,  -7.3582,  ...,  -6.6775,  -6.9359,  -4.8906],\n",
      "         [ -8.4466,  -8.6049,  -8.3619,  ..., -10.5437,  -7.1621,  -4.2888],\n",
      "         [-16.2982, -16.1872, -15.9171,  ..., -14.7640, -13.0536, -12.2942],\n",
      "         ...,\n",
      "         [ -4.4144,  -4.6316,  -4.5169,  ...,  -5.8436,  -4.8615,  -7.8290],\n",
      "         [ -4.9838,  -5.0294,  -4.9596,  ...,  -5.9695,  -5.4542,  -7.9235],\n",
      "         [ -6.1768,  -6.4029,  -6.2107,  ...,  -6.0810,  -5.6970,  -6.2178]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.957532286643982\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7376, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5658,  -6.5611,  -6.5706,  ...,  -6.1189,  -6.0318,  -3.3935],\n",
      "         [ -6.1952,  -6.1790,  -6.2967,  ...,  -7.5190,  -6.8074,  -2.4568],\n",
      "         [ -5.6291,  -5.6304,  -5.6183,  ...,  -6.5728,  -6.0549,  -2.0794],\n",
      "         ...,\n",
      "         [ -5.0546,  -5.0853,  -5.1624,  ...,  -5.8931,  -5.3185,  -1.5865],\n",
      "         [ -5.2172,  -5.2099,  -5.2424,  ...,  -6.2685,  -5.6368,  -2.1111],\n",
      "         [ -5.3723,  -5.3448,  -5.3858,  ...,  -5.9095,  -5.7294,  -1.6562]],\n",
      "\n",
      "        [[ -6.7506,  -6.7358,  -6.7855,  ...,  -6.0503,  -6.0326,  -3.7479],\n",
      "         [-14.5681, -14.4468, -14.9647,  ..., -12.6407, -11.5402,  -9.7610],\n",
      "         [ -5.3103,  -5.4442,  -5.4558,  ...,  -6.1379,  -6.7548,  -2.7526],\n",
      "         ...,\n",
      "         [ -5.3682,  -5.4115,  -5.4278,  ...,  -5.9213,  -6.3051,  -2.8689],\n",
      "         [ -5.3185,  -5.4493,  -5.4644,  ...,  -5.6810,  -6.3463,  -2.5465],\n",
      "         [ -4.9617,  -5.0881,  -5.0408,  ...,  -5.7435,  -6.1704,  -2.0796]],\n",
      "\n",
      "        [[ -6.8403,  -6.8341,  -6.8302,  ...,  -6.3256,  -6.0544,  -3.9033],\n",
      "         [ -5.8822,  -5.9409,  -6.1235,  ...,  -7.1213,  -6.7663,  -2.4889],\n",
      "         [ -7.6859,  -7.7186,  -7.7186,  ...,  -8.5776,  -7.5104,  -4.4756],\n",
      "         ...,\n",
      "         [ -5.2130,  -5.2739,  -5.3110,  ...,  -6.0177,  -5.6297,  -1.2647],\n",
      "         [ -5.2032,  -5.1678,  -5.2533,  ...,  -6.0978,  -5.6056,  -1.7663],\n",
      "         [ -5.8926,  -5.8925,  -5.9888,  ...,  -6.7549,  -6.0322,  -2.6673]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8526,  -6.8574,  -6.8409,  ...,  -5.9020,  -5.8281,  -3.8616],\n",
      "         [-11.2896, -11.1508, -11.3578,  ...,  -9.0286, -10.6135,  -7.5302],\n",
      "         [ -4.9368,  -5.0943,  -5.1095,  ...,  -5.8262,  -6.5112,  -3.2651],\n",
      "         ...,\n",
      "         [ -5.1805,  -5.2848,  -5.2175,  ...,  -5.3595,  -6.1194,  -4.1536],\n",
      "         [ -5.4648,  -5.5802,  -5.5682,  ...,  -5.8431,  -6.1730,  -3.5327],\n",
      "         [ -5.6556,  -5.7676,  -5.6948,  ...,  -5.9479,  -6.5307,  -4.1678]],\n",
      "\n",
      "        [[ -7.0361,  -7.0149,  -6.9320,  ...,  -6.3025,  -5.9871,  -4.0989],\n",
      "         [  0.1792,   0.4503,   0.1204,  ...,   0.1197,  -0.6085,   3.4038],\n",
      "         [-12.9019, -13.2589, -13.2729,  ..., -14.0456, -11.6968,  -5.4025],\n",
      "         ...,\n",
      "         [ -5.6848,  -5.9228,  -6.0392,  ...,  -5.4663,  -5.3747,  -3.1565],\n",
      "         [ -6.3901,  -6.4584,  -6.6757,  ...,  -5.9967,  -6.2795,  -3.5488],\n",
      "         [ -6.5958,  -6.6210,  -6.7550,  ...,  -5.8325,  -6.1786,  -4.1662]],\n",
      "\n",
      "        [[ -7.7057,  -7.7565,  -7.5544,  ...,  -7.2288,  -6.9600,  -5.4990],\n",
      "         [ -3.1877,  -3.1725,  -3.1070,  ...,  -3.7157,  -3.4717,  -5.8708],\n",
      "         [ -8.1333,  -8.1282,  -7.7098,  ...,  -7.6728,  -8.8681,  -5.5692],\n",
      "         ...,\n",
      "         [-13.4620, -13.3790, -12.9025,  ..., -10.8301, -10.6126, -12.6393],\n",
      "         [ -9.7149,  -9.3546,  -9.3979,  ...,  -8.3812,  -9.4336,  -9.2393],\n",
      "         [-12.4072, -12.4215, -12.4614,  ..., -11.4002,  -9.2254, -10.0430]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.7376283407211304\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8085, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7867,  -6.7708,  -6.7369,  ...,  -6.1613,  -5.8295,  -3.9905],\n",
      "         [ -6.4173,  -6.3389,  -6.2878,  ...,  -7.4394,  -6.3698,  -6.8130],\n",
      "         [ -6.8716,  -6.8498,  -6.8375,  ...,  -7.2748,  -5.9681,  -5.3250],\n",
      "         ...,\n",
      "         [ -4.3538,  -4.4769,  -4.0691,  ...,  -5.0312,  -3.8469,  -2.2229],\n",
      "         [ -4.8905,  -5.0291,  -4.8126,  ...,  -5.7396,  -4.4776,  -3.2800],\n",
      "         [ -4.8101,  -4.8257,  -4.6576,  ...,  -5.9774,  -4.1896,  -3.2155]],\n",
      "\n",
      "        [[ -6.8460,  -6.7964,  -6.8407,  ...,  -6.0167,  -5.9612,  -3.9951],\n",
      "         [-11.9515, -11.5295, -11.6883,  ...,  -9.4199, -10.7374,  -9.0531],\n",
      "         [ -4.2148,  -4.3822,  -4.3587,  ...,  -4.8043,  -6.1259,  -3.8917],\n",
      "         ...,\n",
      "         [ -4.5017,  -4.6486,  -4.4906,  ...,  -4.7111,  -6.1067,  -2.3194],\n",
      "         [ -5.0505,  -5.1043,  -5.0781,  ...,  -5.4704,  -5.9670,  -3.9252],\n",
      "         [ -5.0769,  -5.1977,  -5.0857,  ...,  -5.0624,  -5.7242,  -4.0713]],\n",
      "\n",
      "        [[ -6.7439,  -6.7294,  -6.7212,  ...,  -6.0278,  -5.8725,  -3.8872],\n",
      "         [ -7.8702,  -8.1399,  -7.9474,  ...,  -7.6122,  -7.3674,  -4.5516],\n",
      "         [ -1.9806,  -1.4064,  -1.7113,  ...,  -2.0529,  -1.3718,  -1.0125],\n",
      "         ...,\n",
      "         [ -6.3939,  -6.5276,  -6.3374,  ...,  -7.0635,  -6.5326,  -4.7510],\n",
      "         [ -6.6458,  -6.6966,  -6.5499,  ...,  -6.6957,  -6.5435,  -4.1320],\n",
      "         [ -7.0284,  -7.0206,  -7.0207,  ...,  -7.3414,  -6.7527,  -4.4506]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7297,  -6.7519,  -6.6942,  ...,  -6.0811,  -5.9322,  -4.1412],\n",
      "         [ -9.7447,  -9.4143,  -9.2400,  ...,  -8.9412,  -7.2601,  -6.8694],\n",
      "         [ -2.8489,  -3.0714,  -2.9815,  ...,  -3.9471,  -1.1058,  -2.7623],\n",
      "         ...,\n",
      "         [ -5.3145,  -5.3191,  -5.4604,  ...,  -4.9534,  -5.6682,  -6.0141],\n",
      "         [ -6.1037,  -6.3187,  -6.2019,  ...,  -6.8134,  -5.7796,  -4.4935],\n",
      "         [ -6.3679,  -6.4385,  -6.3948,  ...,  -6.9485,  -5.8077,  -4.4211]],\n",
      "\n",
      "        [[ -7.3630,  -7.2484,  -7.2864,  ...,  -6.3121,  -6.5465,  -4.3711],\n",
      "         [-14.0010, -13.6846, -13.5503,  ..., -11.1967, -11.0017, -10.5170],\n",
      "         [ -5.3234,  -5.4911,  -5.4954,  ...,  -5.5447,  -6.5249,  -3.2680],\n",
      "         ...,\n",
      "         [ -4.7192,  -4.8544,  -4.9134,  ...,  -5.3176,  -5.7414,  -3.6122],\n",
      "         [ -4.9117,  -4.9917,  -5.1029,  ...,  -5.6398,  -6.1617,  -3.6205],\n",
      "         [ -4.6119,  -4.8025,  -4.7706,  ...,  -5.2405,  -5.9814,  -3.1176]],\n",
      "\n",
      "        [[ -6.5295,  -6.4801,  -6.5114,  ...,  -5.7563,  -5.7266,  -3.8642],\n",
      "         [ -9.2584,  -9.2484,  -8.9404,  ...,  -6.4249,  -7.5624,  -8.2478],\n",
      "         [ -5.8213,  -6.0289,  -6.1210,  ...,  -6.5908,  -6.8070,  -3.8872],\n",
      "         ...,\n",
      "         [ -5.5489,  -5.7610,  -5.7962,  ...,  -6.0171,  -6.8475,  -3.3507],\n",
      "         [ -5.5861,  -5.6529,  -5.7190,  ...,  -6.0131,  -6.1203,  -3.5803],\n",
      "         [ -5.5925,  -5.7355,  -5.7933,  ...,  -5.9108,  -6.3734,  -3.0629]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.8085389137268066\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.9972, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8577,  -6.7559,  -6.7591,  ...,  -5.9787,  -5.7715,  -3.9982],\n",
      "         [ -4.8399,  -4.8099,  -4.8284,  ...,  -3.4688,  -3.8725,  -3.8856],\n",
      "         [-11.4689, -11.8217, -11.6988,  ..., -10.6754, -11.5558,  -7.0998],\n",
      "         ...,\n",
      "         [ -7.7025,  -7.6619,  -7.4204,  ...,  -5.6420,  -4.5321,  -7.3760],\n",
      "         [ -8.6883,  -8.5373,  -8.4594,  ...,  -7.0477,  -5.8528,  -7.0927],\n",
      "         [ -7.3087,  -7.3301,  -7.2466,  ...,  -6.0144,  -5.8461,  -5.6611]],\n",
      "\n",
      "        [[ -7.3567,  -7.3665,  -7.2949,  ...,  -6.8062,  -6.4276,  -4.4376],\n",
      "         [ -4.4027,  -4.4145,  -4.1084,  ...,  -5.0545,  -3.9352,  -4.7786],\n",
      "         [ -4.7250,  -4.6662,  -4.6305,  ...,  -6.3822,  -3.8511,  -3.4993],\n",
      "         ...,\n",
      "         [ -5.5603,  -5.8630,  -5.5044,  ...,  -5.8415,  -5.2038,  -5.2473],\n",
      "         [ -4.4380,  -4.6611,  -4.3437,  ...,  -4.3751,  -3.6610,  -4.2485],\n",
      "         [ -5.2321,  -5.4210,  -5.1628,  ...,  -5.6619,  -4.8428,  -5.1350]],\n",
      "\n",
      "        [[ -7.7679,  -7.7812,  -7.7208,  ...,  -6.9575,  -7.0112,  -4.9169],\n",
      "         [ -8.7235,  -8.5630,  -8.8828,  ...,  -8.5407,  -9.2794,  -4.9458],\n",
      "         [ -7.7715,  -8.0735,  -8.4488,  ...,  -9.6206,  -7.9536,  -8.1872],\n",
      "         ...,\n",
      "         [ -5.0191,  -5.0880,  -5.1382,  ...,  -5.3559,  -5.7750,  -1.9516],\n",
      "         [ -5.2840,  -5.3807,  -5.4496,  ...,  -5.4402,  -6.0606,  -2.4552],\n",
      "         [ -5.6345,  -5.6375,  -5.7099,  ...,  -5.8631,  -5.7217,  -2.8902]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2804,  -7.2299,  -7.2893,  ...,  -6.3730,  -6.3649,  -4.3757],\n",
      "         [-15.6692, -15.6340, -15.6370,  ..., -14.6057, -11.8163, -16.0029],\n",
      "         [ -7.9788,  -7.9044,  -7.8417,  ...,  -7.1012,  -7.4320,  -6.9868],\n",
      "         ...,\n",
      "         [ -4.9916,  -5.1830,  -5.5631,  ...,  -5.4177,  -5.9140,  -5.3890],\n",
      "         [ -5.3505,  -5.6066,  -5.9991,  ...,  -5.4471,  -6.9448,  -6.3618],\n",
      "         [ -5.3834,  -5.6418,  -5.9626,  ...,  -5.8317,  -5.8160,  -6.7387]],\n",
      "\n",
      "        [[ -6.4578,  -6.4348,  -6.4861,  ...,  -5.7141,  -5.5890,  -3.7476],\n",
      "         [-13.3829, -13.4614, -13.4355,  ..., -11.0373, -11.1409,  -9.5069],\n",
      "         [ -4.7915,  -4.9208,  -5.0112,  ...,  -5.0527,  -6.5399,  -2.9660],\n",
      "         ...,\n",
      "         [ -5.5159,  -5.6923,  -5.7395,  ...,  -5.4410,  -6.7288,  -3.8332],\n",
      "         [ -5.2937,  -5.4455,  -5.5350,  ...,  -5.6443,  -6.6372,  -3.0001],\n",
      "         [ -5.6109,  -5.6446,  -5.6764,  ...,  -5.4967,  -6.3070,  -3.5686]],\n",
      "\n",
      "        [[ -9.4577,  -9.5103,  -9.4018,  ...,  -9.0037,  -8.9131,  -5.6812],\n",
      "         [-14.2640, -13.6519, -14.0925,  ..., -12.9235, -11.1884, -10.6139],\n",
      "         [-16.4191, -15.8013, -16.0994,  ..., -13.8042, -11.6958, -11.8020],\n",
      "         ...,\n",
      "         [ -5.1809,  -6.1873,  -5.9235,  ...,  -7.4961,  -7.7423,  -3.8267],\n",
      "         [-11.3417, -11.2434, -11.6230,  ...,  -8.6468,  -9.8102,  -7.0329],\n",
      "         [-12.3387, -12.4619, -12.5370,  ..., -10.9757,  -9.6892,  -7.8133]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.9972018003463745\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1301, grad_fn=<NllLossBackward0>), logits=tensor([[[ -5.6259,  -5.8819,  -5.6602,  ...,  -5.7343,  -5.3761,  -1.7928],\n",
      "         [-11.8894, -12.0658, -12.2314,  ...,  -9.4508,  -7.9479, -10.2257],\n",
      "         [ -5.1699,  -5.2706,  -5.3360,  ...,  -5.4331,  -6.0713,  -2.3898],\n",
      "         ...,\n",
      "         [ -5.5783,  -5.6796,  -5.5982,  ...,  -5.8651,  -6.3813,  -2.5156],\n",
      "         [ -4.2240,  -4.3188,  -4.2532,  ...,  -4.7428,  -5.5967,  -1.9524],\n",
      "         [ -5.5611,  -5.5984,  -5.4981,  ...,  -5.8548,  -5.7516,  -3.1064]],\n",
      "\n",
      "        [[ -7.7303,  -7.6564,  -7.6491,  ...,  -7.1299,  -6.6664,  -5.4337],\n",
      "         [ -5.3164,  -5.5430,  -5.3434,  ...,  -4.6728,  -4.9798,  -4.7643],\n",
      "         [ -7.1958,  -7.3102,  -6.5435,  ...,  -5.2549,  -4.2870, -10.9108],\n",
      "         ...,\n",
      "         [-10.6643, -10.7200, -10.2072,  ...,  -9.0118,  -8.9515,  -3.4858],\n",
      "         [-12.1338, -11.8797, -11.5436,  ...,  -9.5556,  -9.4077,  -8.5770],\n",
      "         [-10.3214, -10.3152,  -9.8039,  ..., -10.2156,  -9.2629, -11.2505]],\n",
      "\n",
      "        [[ -7.3609,  -7.3913,  -7.3596,  ...,  -6.6357,  -6.7746,  -4.0887],\n",
      "         [-15.3379, -15.1616, -15.1433,  ..., -12.8931, -14.8922, -12.4731],\n",
      "         [ -5.0107,  -5.3921,  -5.3602,  ...,  -5.5294,  -7.4911,  -2.8958],\n",
      "         ...,\n",
      "         [ -6.2184,  -6.4403,  -6.4329,  ...,  -6.3373,  -7.5870,  -3.0908],\n",
      "         [ -5.4298,  -5.6580,  -5.5499,  ...,  -5.9065,  -7.3917,  -2.5145],\n",
      "         [ -6.3288,  -6.4994,  -6.5240,  ...,  -6.1065,  -7.6751,  -3.2385]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8803,  -6.8927,  -6.8765,  ...,  -6.3931,  -5.9733,  -4.2605],\n",
      "         [-12.4027, -12.0738, -12.3349,  ..., -12.4897,  -9.6049, -10.7733],\n",
      "         [ -7.6308,  -7.9765,  -8.3672,  ...,  -6.8211,  -5.6822,  -8.4823],\n",
      "         ...,\n",
      "         [ -7.9149,  -8.0435,  -7.9796,  ...,  -7.9321,  -6.1727,  -5.4230],\n",
      "         [ -7.2213,  -7.2728,  -7.2498,  ...,  -7.5002,  -5.5592,  -5.2882],\n",
      "         [-12.6630, -13.0093, -12.6090,  ..., -11.0337,  -8.6420, -10.0707]],\n",
      "\n",
      "        [[ -7.2202,  -7.3696,  -7.2046,  ...,  -6.1916,  -5.7807,  -4.8494],\n",
      "         [ -8.4884,  -8.3573,  -8.6402,  ...,  -8.8222,  -8.3253,  -5.1819],\n",
      "         [ -2.5513,  -2.6885,  -2.9397,  ...,  -2.2755,  -2.2809,  -2.6328],\n",
      "         ...,\n",
      "         [ -3.0394,  -3.3677,  -3.2765,  ...,  -4.3863,  -2.4230,  -4.1430],\n",
      "         [ -5.3647,  -5.5007,  -5.3597,  ...,  -5.1721,  -5.2173,  -5.0986],\n",
      "         [ -6.7912,  -6.8695,  -6.8166,  ...,  -7.5542,  -6.1426,  -5.9632]],\n",
      "\n",
      "        [[ -6.4229,  -6.5968,  -6.4640,  ...,  -6.5725,  -6.5323,  -3.4794],\n",
      "         [-11.2752, -11.6873, -11.4261,  ...,  -8.4465, -10.0305, -10.3197],\n",
      "         [ -5.5372,  -5.5563,  -5.5917,  ...,  -5.9022,  -5.6481,  -3.8613],\n",
      "         ...,\n",
      "         [ -5.3022,  -5.3194,  -5.3814,  ...,  -6.0744,  -5.1686,  -3.4156],\n",
      "         [ -5.6652,  -5.6974,  -5.6645,  ...,  -6.3230,  -6.0064,  -1.9236],\n",
      "         [ -5.8016,  -5.9092,  -5.8550,  ...,  -6.6983,  -5.8443,  -2.6117]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.130110025405884\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1441, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7100,  -6.7011,  -6.6113,  ...,  -6.2779,  -5.7171,  -4.3280],\n",
      "         [ -7.4885,  -7.5287,  -7.4216,  ...,  -7.4806,  -6.4033,  -8.5205],\n",
      "         [ -8.3835,  -8.8145,  -8.4733,  ...,  -9.5305,  -9.2591,  -6.8355],\n",
      "         ...,\n",
      "         [ -9.5009,  -9.1316,  -8.9662,  ..., -10.4459,  -8.4274,  -8.6536],\n",
      "         [ -6.8269,  -7.0383,  -6.7803,  ...,  -7.1450,  -4.5274,  -5.6592],\n",
      "         [-12.3520, -12.1221, -12.3430,  ..., -10.4911, -10.9754,  -8.9002]],\n",
      "\n",
      "        [[ -6.6944,  -6.6957,  -6.6389,  ...,  -6.3554,  -6.4471,  -3.7522],\n",
      "         [ -6.3149,  -6.3639,  -6.5475,  ...,  -7.5766,  -6.3609,  -7.6502],\n",
      "         [-10.9493, -11.3673, -11.1815,  ..., -10.7670, -11.1865, -11.4168],\n",
      "         ...,\n",
      "         [ -7.7688,  -8.1755,  -7.7556,  ...,  -6.6703,  -7.6111,  -7.6321],\n",
      "         [ -5.8793,  -6.1198,  -6.1364,  ...,  -5.2468,  -5.8989,  -4.5075],\n",
      "         [-12.4526, -12.0938, -12.1007,  ...,  -9.6806,  -9.6206, -10.0640]],\n",
      "\n",
      "        [[ -6.4853,  -6.4729,  -6.4685,  ...,  -5.8821,  -5.6763,  -3.8360],\n",
      "         [ -5.7587,  -5.5572,  -5.6127,  ...,  -6.7759,  -5.9840,  -3.3711],\n",
      "         [ -4.0658,  -4.0952,  -4.1119,  ...,  -6.0753,  -4.5542,  -1.7613],\n",
      "         ...,\n",
      "         [ -5.0301,  -5.0157,  -5.1166,  ...,  -6.2363,  -5.6084,  -2.4601],\n",
      "         [ -3.7401,  -3.8030,  -3.8061,  ...,  -5.6211,  -4.5099,  -1.2981],\n",
      "         [ -4.8560,  -4.8319,  -4.9836,  ...,  -6.0011,  -5.2988,  -2.3099]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4179,  -6.3835,  -6.4252,  ...,  -5.8148,  -5.5518,  -3.6757],\n",
      "         [-11.0228, -10.7566, -11.0933,  ...,  -8.2126,  -9.9180,  -7.5172],\n",
      "         [ -5.5427,  -5.6907,  -5.7711,  ...,  -5.9078,  -6.9018,  -3.5697],\n",
      "         ...,\n",
      "         [ -5.4528,  -5.5294,  -5.5655,  ...,  -5.4281,  -6.1971,  -3.6169],\n",
      "         [ -5.2449,  -5.3844,  -5.3100,  ...,  -5.4886,  -5.9805,  -3.8546],\n",
      "         [ -5.4236,  -5.5644,  -5.6388,  ...,  -5.9127,  -6.1758,  -3.1920]],\n",
      "\n",
      "        [[ -6.5161,  -6.4894,  -6.4961,  ...,  -5.8499,  -5.7338,  -3.9399],\n",
      "         [ -8.4340,  -8.2805,  -8.2463,  ...,  -5.3391,  -8.1787,  -6.8290],\n",
      "         [ -6.9917,  -7.0927,  -7.0442,  ...,  -7.1650,  -6.7998,  -4.1617],\n",
      "         ...,\n",
      "         [ -6.7569,  -6.8227,  -6.8350,  ...,  -7.0808,  -5.9947,  -3.8684],\n",
      "         [ -7.4961,  -7.6291,  -7.6179,  ...,  -7.5968,  -7.2292,  -5.1034],\n",
      "         [ -6.3797,  -6.5181,  -6.5837,  ...,  -6.5882,  -6.3806,  -3.2385]],\n",
      "\n",
      "        [[ -6.5845,  -6.5535,  -6.5393,  ...,  -6.0019,  -5.6879,  -3.8264],\n",
      "         [ -6.3247,  -6.1742,  -6.3524,  ...,  -6.8761,  -6.4631,  -2.6077],\n",
      "         [ -5.5237,  -5.5061,  -5.5717,  ...,  -6.0253,  -5.3386,  -4.1342],\n",
      "         ...,\n",
      "         [ -5.5343,  -5.5529,  -5.6235,  ...,  -5.9524,  -5.9279,  -2.3245],\n",
      "         [ -5.6094,  -5.5240,  -5.6205,  ...,  -6.1320,  -5.7940,  -2.6434],\n",
      "         [ -5.7623,  -5.7585,  -5.8216,  ...,  -6.5345,  -6.0749,  -2.6344]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.1441266536712646\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.1537, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.7680,  -7.7132,  -7.6902,  ...,  -7.1840,  -6.6013,  -5.0287],\n",
      "         [-12.4059, -12.0353, -11.8468,  ..., -12.1452,  -9.3130,  -9.8145],\n",
      "         [ -5.4329,  -5.1999,  -5.5374,  ...,  -7.5008,  -4.4567,  -9.5437],\n",
      "         ...,\n",
      "         [-10.2187, -10.0730,  -9.9058,  ...,  -8.7294,  -6.3449, -10.5897],\n",
      "         [ -5.5161,  -5.7330,  -5.0430,  ...,  -4.7532,  -3.9062,  -5.9940],\n",
      "         [-11.7620, -11.8849, -11.3963,  ..., -10.9350,  -9.0354,  -9.8837]],\n",
      "\n",
      "        [[ -6.8773,  -6.8644,  -6.8851,  ...,  -6.2576,  -6.0895,  -4.0288],\n",
      "         [ -7.0545,  -7.0664,  -7.1662,  ...,  -8.2138,  -7.5617,  -3.6072],\n",
      "         [ -5.2196,  -5.2770,  -5.2998,  ...,  -6.4375,  -5.9239,  -2.5819],\n",
      "         ...,\n",
      "         [ -5.6877,  -5.6322,  -5.6852,  ...,  -6.4131,  -5.9832,  -2.2566],\n",
      "         [ -5.0992,  -5.0620,  -5.1449,  ...,  -5.6576,  -5.5366,  -1.7816],\n",
      "         [ -5.5610,  -5.5442,  -5.5809,  ...,  -6.3563,  -5.6680,  -2.0212]],\n",
      "\n",
      "        [[ -7.2986,  -7.3553,  -7.3435,  ...,  -6.4790,  -6.2725,  -4.1471],\n",
      "         [ -9.9854, -10.2588,  -9.8683,  ...,  -6.7855,  -9.1595,  -6.8572],\n",
      "         [ -4.4252,  -4.4749,  -4.5708,  ...,  -5.5150,  -6.9053,  -3.4148],\n",
      "         ...,\n",
      "         [ -5.5412,  -5.6317,  -5.6972,  ...,  -6.3777,  -6.8667,  -2.7600],\n",
      "         [ -5.1787,  -5.2420,  -5.3200,  ...,  -5.7768,  -6.6633,  -4.1412],\n",
      "         [ -6.0830,  -6.2320,  -6.2293,  ...,  -6.6682,  -7.1000,  -4.9082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.1410,  -8.1930,  -7.9847,  ...,  -7.6090,  -7.0404,  -2.9540],\n",
      "         [-14.6271, -14.8865, -14.6234,  ..., -13.3348, -11.0894,  -8.5686],\n",
      "         [-13.9961, -14.2995, -14.0746,  ..., -13.0198, -10.6473,  -8.1625],\n",
      "         ...,\n",
      "         [ -5.1019,  -5.2727,  -4.9788,  ...,  -4.9565,  -4.4047,  -4.5027],\n",
      "         [ -5.9806,  -6.3148,  -5.8708,  ...,  -5.7111,  -5.8061,  -4.4992],\n",
      "         [ -7.6363,  -7.9662,  -7.6306,  ...,  -7.4917,  -6.5184,  -4.4714]],\n",
      "\n",
      "        [[ -6.1055,  -6.0686,  -6.0612,  ...,  -5.3783,  -5.7680,  -3.4225],\n",
      "         [-11.0449, -10.7768, -10.8510,  ...,  -8.0063,  -8.8890, -11.4612],\n",
      "         [ -5.1884,  -5.3711,  -5.4012,  ...,  -5.5271,  -6.8328,  -3.8246],\n",
      "         ...,\n",
      "         [ -4.9478,  -5.0083,  -5.0283,  ...,  -5.2890,  -6.1830,  -3.8730],\n",
      "         [ -5.1540,  -5.3619,  -5.4616,  ...,  -5.1635,  -6.8306,  -3.1162],\n",
      "         [ -5.4779,  -5.4815,  -5.5124,  ...,  -5.4645,  -6.2871,  -3.4871]],\n",
      "\n",
      "        [[ -6.3874,  -6.3497,  -6.3630,  ...,  -5.7389,  -5.5323,  -3.8377],\n",
      "         [-12.6638, -12.7966, -12.7999,  ..., -10.7702, -10.9072,  -7.6073],\n",
      "         [ -5.5044,  -5.5824,  -5.5963,  ...,  -5.6487,  -6.2632,  -3.5808],\n",
      "         ...,\n",
      "         [ -5.4298,  -5.4567,  -5.4214,  ...,  -5.1744,  -5.9630,  -3.2550],\n",
      "         [ -5.8171,  -5.9180,  -5.9051,  ...,  -6.2018,  -6.6390,  -4.0624],\n",
      "         [ -6.1451,  -6.2013,  -6.2391,  ...,  -6.2080,  -6.5153,  -3.3517]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.1537073850631714\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6688, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2796,  -6.2415,  -6.2990,  ...,  -5.5373,  -5.5258,  -3.5176],\n",
      "         [-14.4769, -14.1851, -14.1502,  ..., -12.2659, -12.9282,  -9.1454],\n",
      "         [ -5.7711,  -6.0492,  -5.9855,  ...,  -5.5492,  -6.7339,  -3.9769],\n",
      "         ...,\n",
      "         [ -5.3757,  -5.4783,  -5.4130,  ...,  -5.4379,  -6.1633,  -4.4137],\n",
      "         [ -5.9133,  -6.0454,  -6.0515,  ...,  -5.6109,  -6.1382,  -3.7289],\n",
      "         [ -5.3709,  -5.4991,  -5.4427,  ...,  -5.3985,  -6.5064,  -3.7103]],\n",
      "\n",
      "        [[ -7.4776,  -7.6790,  -7.5310,  ...,  -6.9217,  -6.5620,  -5.8169],\n",
      "         [-14.5266, -14.5389, -14.7063,  ..., -12.1755,  -9.4616, -15.7596],\n",
      "         [ -9.2041,  -9.3833,  -9.1981,  ...,  -8.1602,  -5.9713,  -7.4065],\n",
      "         ...,\n",
      "         [-12.6174, -13.2723, -12.8089,  ..., -11.9928, -10.4868,  -8.3694],\n",
      "         [ -6.4882,  -6.5622,  -6.5634,  ...,  -5.5455,  -3.7582,  -6.8119],\n",
      "         [ -7.0258,  -7.2174,  -7.1175,  ...,  -6.5488,  -6.1095,  -6.8558]],\n",
      "\n",
      "        [[ -8.8338,  -8.9541,  -8.8259,  ...,  -7.9532,  -7.8563,  -5.3727],\n",
      "         [ -8.7959,  -9.5431,  -9.2318,  ...,  -9.1590, -10.5084,  -3.7367],\n",
      "         [-10.0910,  -9.7436, -10.3943,  ...,  -9.1687,  -7.8847, -10.2994],\n",
      "         ...,\n",
      "         [ -6.5318,  -6.7361,  -6.6731,  ...,  -6.8813,  -6.4452,  -5.6154],\n",
      "         [ -4.7125,  -4.8564,  -5.2506,  ...,  -4.7037,  -6.1722,  -8.3527],\n",
      "         [ -6.5766,  -6.9042,  -6.9589,  ...,  -6.4938,  -6.6361,  -7.6694]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.7404,  -7.7569,  -7.6465,  ...,  -7.1585,  -6.3564,  -4.9240],\n",
      "         [-13.3309, -13.3803, -13.4021,  ..., -13.5917, -11.9926, -13.6512],\n",
      "         [ -8.8671,  -9.0137,  -8.8206,  ...,  -8.2824,  -7.7313,  -6.3453],\n",
      "         ...,\n",
      "         [-12.3569, -12.5205, -12.0374,  ...,  -9.1127,  -7.7518, -11.8225],\n",
      "         [ -8.3868,  -8.6190,  -8.1328,  ...,  -7.6569,  -5.8539,  -6.9969],\n",
      "         [-12.2280, -12.7000, -12.2843,  ..., -11.2672,  -8.9430, -10.4178]],\n",
      "\n",
      "        [[ -7.0528,  -7.1465,  -7.0265,  ...,  -6.4889,  -6.3779,  -4.1863],\n",
      "         [ -6.7383,  -6.6385,  -6.5335,  ...,  -6.4669,  -6.0336,  -1.3871],\n",
      "         [ -3.4291,  -3.4883,  -3.7239,  ...,  -2.7812,  -4.8186,  -4.6657],\n",
      "         ...,\n",
      "         [ -8.8855,  -8.6689,  -9.0393,  ...,  -8.6295,  -8.2332,  -4.0609],\n",
      "         [ -7.5396,  -7.6950,  -7.3639,  ...,  -6.9669,  -6.6021,  -5.6542],\n",
      "         [-13.7897, -14.4566, -13.9907,  ..., -13.9166, -13.5906,  -9.8459]],\n",
      "\n",
      "        [[ -6.9412,  -6.9928,  -6.8602,  ...,  -6.4088,  -5.8842,  -4.3796],\n",
      "         [-15.2987, -15.4815, -15.5333,  ..., -13.6012, -11.4311, -10.3917],\n",
      "         [-11.4369, -11.5444, -11.8619,  ..., -10.6568,  -9.8086,  -6.7179],\n",
      "         ...,\n",
      "         [-10.5241, -10.4630, -10.7891,  ..., -11.3753,  -8.2442, -14.1702],\n",
      "         [-11.2048, -11.3684, -11.5963,  ...,  -8.8636,  -8.5931,  -9.7203],\n",
      "         [-11.0217, -11.4699, -11.6593,  ..., -10.3615,  -8.9600,  -6.3620]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6688119173049927\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5921, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9991,  -6.9319,  -6.9438,  ...,  -6.1579,  -6.1882,  -4.1857],\n",
      "         [-11.8186, -11.6492, -11.3530,  ...,  -9.0638,  -8.3831, -10.8231],\n",
      "         [ -4.4948,  -4.5917,  -4.7114,  ...,  -5.1547,  -6.1969,  -2.3096],\n",
      "         ...,\n",
      "         [ -5.1037,  -5.1077,  -5.2366,  ...,  -5.1442,  -6.2861,  -3.4528],\n",
      "         [ -4.9111,  -5.0071,  -5.0385,  ...,  -4.8783,  -6.0124,  -3.8742],\n",
      "         [ -5.9652,  -6.1070,  -6.1267,  ...,  -5.5429,  -6.6295,  -4.2102]],\n",
      "\n",
      "        [[ -6.5205,  -6.4466,  -6.4705,  ...,  -5.7666,  -5.5117,  -3.8358],\n",
      "         [-10.7437, -10.4518, -11.3071,  ...,  -7.8220, -10.1472,  -8.5261],\n",
      "         [ -5.4621,  -5.5663,  -5.6221,  ...,  -5.5535,  -6.7022,  -3.2108],\n",
      "         ...,\n",
      "         [ -5.9277,  -6.0899,  -6.1591,  ...,  -5.8867,  -6.7589,  -3.7838],\n",
      "         [ -6.0777,  -6.0777,  -6.1390,  ...,  -6.1622,  -6.7804,  -4.0088],\n",
      "         [ -6.0987,  -6.1973,  -6.1737,  ...,  -6.0435,  -6.7766,  -4.1575]],\n",
      "\n",
      "        [[ -6.2999,  -6.2106,  -6.2413,  ...,  -5.6004,  -5.3592,  -3.7206],\n",
      "         [-10.5949, -10.6799, -10.0787,  ...,  -6.8407,  -8.4727,  -9.0141],\n",
      "         [ -4.4250,  -4.5831,  -4.6677,  ...,  -5.1595,  -6.4014,  -2.7535],\n",
      "         ...,\n",
      "         [ -5.0142,  -5.1670,  -5.1827,  ...,  -5.1088,  -6.0425,  -2.8363],\n",
      "         [ -4.6218,  -4.6191,  -4.6999,  ...,  -4.7636,  -6.0135,  -2.8697],\n",
      "         [ -5.4760,  -5.5997,  -5.5792,  ...,  -5.6720,  -6.6848,  -3.2756]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5344,  -6.4917,  -6.5338,  ...,  -5.8004,  -5.7295,  -3.9229],\n",
      "         [-14.8072, -14.2588, -14.4763,  ..., -12.5910, -11.3514, -11.3109],\n",
      "         [ -4.3032,  -4.4313,  -4.5326,  ...,  -4.4277,  -5.8218,  -2.3829],\n",
      "         ...,\n",
      "         [ -5.0828,  -5.2802,  -5.3796,  ...,  -5.4112,  -6.6187,  -2.1143],\n",
      "         [ -4.3921,  -4.5025,  -4.5422,  ...,  -4.2063,  -5.8902,  -3.1510],\n",
      "         [ -5.0698,  -5.1867,  -5.1940,  ...,  -5.0581,  -6.0046,  -3.1128]],\n",
      "\n",
      "        [[ -7.2625,  -7.3782,  -7.3435,  ...,  -6.7028,  -6.3160,  -4.3806],\n",
      "         [-11.0834, -10.8463, -11.2247,  ..., -10.9967,  -9.8761,  -8.2874],\n",
      "         [ -7.7307,  -8.2646,  -7.8949,  ...,  -6.3821,  -4.7104,  -7.2389],\n",
      "         ...,\n",
      "         [ -1.5518,  -1.5016,  -1.5647,  ...,  -2.2019,  -1.7903,   0.1190],\n",
      "         [ -2.0099,  -1.8756,  -1.9104,  ...,  -2.5740,  -2.4543,  -1.1900],\n",
      "         [ -4.3563,  -4.3612,  -4.4585,  ...,  -4.5341,  -4.3618,  -1.5598]],\n",
      "\n",
      "        [[ -7.5006,  -7.5135,  -7.5431,  ...,  -7.1251,  -6.9217,  -4.6869],\n",
      "         [ -8.7863,  -8.7307,  -8.8210,  ...,  -8.9038,  -7.7100,  -5.4776],\n",
      "         [ -8.9664,  -9.0027,  -9.1625,  ...,  -9.0501,  -7.9748,  -9.4423],\n",
      "         ...,\n",
      "         [ -6.1529,  -6.1915,  -6.4757,  ...,  -6.3212,  -6.1038,  -4.3343],\n",
      "         [ -6.6501,  -6.6488,  -6.8527,  ...,  -6.3942,  -6.2584,  -3.6113],\n",
      "         [ -6.6813,  -6.8694,  -7.0004,  ...,  -7.0941,  -6.5055,  -4.0309]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5921269655227661\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0772, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7732,  -6.6696,  -6.6950,  ...,  -5.8661,  -5.7803,  -4.1070],\n",
      "         [-12.8136, -12.6365, -12.5665,  ..., -10.9503, -10.6951,  -9.7178],\n",
      "         [ -3.9756,  -4.1101,  -4.1525,  ...,  -4.4903,  -5.9133,  -2.7589],\n",
      "         ...,\n",
      "         [ -4.9702,  -5.0803,  -5.0229,  ...,  -5.2037,  -5.9953,  -2.9110],\n",
      "         [ -4.3522,  -4.3457,  -4.5377,  ...,  -4.8376,  -5.5949,  -2.9805],\n",
      "         [ -4.3322,  -4.4584,  -4.3996,  ...,  -4.6517,  -5.9555,  -3.0276]],\n",
      "\n",
      "        [[ -6.6407,  -6.5573,  -6.5284,  ...,  -6.0558,  -5.6475,  -3.9087],\n",
      "         [ -6.4090,  -6.3288,  -5.8516,  ...,  -6.0174,  -5.5414,  -3.3853],\n",
      "         [ -1.9802,  -2.1226,  -1.5835,  ...,  -2.6897,  -1.2591,   0.3336],\n",
      "         ...,\n",
      "         [ -5.7831,  -5.8927,  -5.8487,  ...,  -5.9471,  -5.8823,  -2.4713],\n",
      "         [ -5.8003,  -5.8417,  -5.6314,  ...,  -5.5492,  -5.4799,  -2.6414],\n",
      "         [ -6.6152,  -6.7326,  -6.5892,  ...,  -6.6194,  -6.5402,  -3.2191]],\n",
      "\n",
      "        [[ -6.2026,  -6.1231,  -6.1418,  ...,  -5.4746,  -5.2019,  -3.7589],\n",
      "         [-14.1424, -14.0301, -14.0319,  ..., -10.5210,  -9.3385, -11.5467],\n",
      "         [ -5.0379,  -5.2563,  -5.1774,  ...,  -5.1258,  -6.2435,  -3.0775],\n",
      "         ...,\n",
      "         [ -5.2933,  -5.4724,  -5.3992,  ...,  -5.4636,  -6.2009,  -3.7259],\n",
      "         [ -5.5691,  -5.7103,  -5.7675,  ...,  -5.4282,  -6.5878,  -3.9368],\n",
      "         [ -5.3793,  -5.5241,  -5.4740,  ...,  -5.5030,  -6.1909,  -4.1897]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.9875,  -8.0125,  -7.9828,  ...,  -6.9702,  -6.9689,  -4.7953],\n",
      "         [-13.3803, -13.0628, -13.0293,  ..., -11.1295, -12.7974, -10.8541],\n",
      "         [ -7.3831,  -7.5130,  -7.1324,  ...,  -7.7246,  -7.1709,  -7.2710],\n",
      "         ...,\n",
      "         [ -7.2771,  -7.2097,  -6.8137,  ...,  -6.5753,  -5.1405,  -4.6501],\n",
      "         [ -7.7958,  -7.8034,  -7.7510,  ...,  -6.4548,  -6.4766,  -5.4774],\n",
      "         [-12.7323, -13.3916, -13.3004,  ..., -12.8589, -12.3102, -11.2615]],\n",
      "\n",
      "        [[ -7.6526,  -7.7863,  -7.6053,  ...,  -7.9411,  -6.3266,  -5.9435],\n",
      "         [ -3.3391,  -3.0508,  -3.2224,  ...,  -2.7875,  -3.6129,  -5.7541],\n",
      "         [ -9.9712, -10.2343,  -9.7668,  ...,  -9.9600,  -7.7238, -11.7396],\n",
      "         ...,\n",
      "         [ -4.3097,  -4.1912,  -3.9815,  ...,  -4.8933,  -3.9419,  -6.2922],\n",
      "         [ -6.4734,  -6.3815,  -6.1838,  ...,  -6.2184,  -5.3659,  -8.4537],\n",
      "         [ -6.6801,  -6.7403,  -6.6105,  ...,  -6.5674,  -5.9708,  -7.4421]],\n",
      "\n",
      "        [[ -6.7308,  -6.8274,  -6.7862,  ...,  -6.2588,  -5.9085,  -4.0344],\n",
      "         [-13.0035, -12.7598, -13.0617,  ..., -14.3117, -10.7993, -12.7413],\n",
      "         [ -6.4522,  -6.9981,  -7.0527,  ...,  -7.5284,  -6.2870,  -9.0808],\n",
      "         ...,\n",
      "         [ -1.9657,  -2.0572,  -2.1310,  ...,  -2.5868,  -3.2449,  -3.8124],\n",
      "         [ -6.0963,  -5.9737,  -6.1066,  ...,  -5.2296,  -6.9286,  -6.0172],\n",
      "         [-13.4976, -13.8519, -14.0331,  ..., -13.4087, -11.2626, -11.1819]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.0772302150726318\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.1915, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.2094,  -9.1410,  -9.0222,  ...,  -8.9899,  -8.2649,  -5.1950],\n",
      "         [ -8.1556,  -8.0657,  -8.0805,  ...,  -8.6566,  -6.2939,  -5.3014],\n",
      "         [ -7.0124,  -7.0743,  -7.0134,  ...,  -8.2726,  -4.2954,  -7.1376],\n",
      "         ...,\n",
      "         [ -7.8198,  -8.1822,  -7.9919,  ...,  -7.2489,  -8.1563,  -4.6188],\n",
      "         [ -9.8164,  -9.7889,  -9.9738,  ...,  -9.3745,  -7.1523,  -9.6864],\n",
      "         [-11.9615, -12.3776, -12.1392,  ..., -12.6782, -10.1543,  -9.2805]],\n",
      "\n",
      "        [[-11.3623, -11.2852, -11.0129,  ..., -10.2493, -11.5173, -10.5028],\n",
      "         [-12.5673, -12.6367, -12.5469,  ..., -10.0619,  -9.8442, -11.1623],\n",
      "         [ -5.0558,  -5.3362,  -5.3849,  ...,  -5.2322,  -6.3495,  -6.1540],\n",
      "         ...,\n",
      "         [ -4.9994,  -5.1391,  -5.1301,  ...,  -4.2059,  -6.4037,  -5.0262],\n",
      "         [ -4.8945,  -5.0140,  -5.1048,  ...,  -4.4512,  -5.4115,  -5.3392],\n",
      "         [ -5.6146,  -5.8934,  -5.9201,  ...,  -5.8989,  -6.9009,  -5.5285]],\n",
      "\n",
      "        [[ -7.2671,  -7.2703,  -7.0904,  ...,  -6.8741,  -6.2602,  -4.3485],\n",
      "         [ -4.3967,  -4.5956,  -4.1767,  ...,  -5.9227,  -4.2628,  -3.7280],\n",
      "         [ -5.9371,  -6.3491,  -6.2015,  ...,  -5.4960,  -6.0886,  -6.9551],\n",
      "         ...,\n",
      "         [ -5.2924,  -5.5912,  -5.3407,  ...,  -5.8617,  -5.2164,  -5.2869],\n",
      "         [ -6.5951,  -6.6883,  -6.6356,  ...,  -8.3954,  -6.1758,  -7.0426],\n",
      "         [ -3.5112,  -3.4063,  -3.5319,  ...,  -4.3789,  -2.0734,  -1.9181]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6511,  -7.7275,  -7.6487,  ...,  -7.0924,  -6.8756,  -4.2968],\n",
      "         [ -6.5949,  -6.4873,  -6.6072,  ...,  -5.9197,  -5.7970,  -5.6119],\n",
      "         [ -7.4128,  -7.8416,  -7.5412,  ...,  -8.0457,  -7.4043,  -8.8209],\n",
      "         ...,\n",
      "         [ -7.1365,  -7.0061,  -7.0126,  ...,  -6.7073,  -6.3645,  -5.3806],\n",
      "         [ -7.5374,  -7.4302,  -7.3751,  ...,  -6.3771,  -6.3966,  -4.3710],\n",
      "         [-11.8064, -12.4694, -11.7741,  ..., -11.9816, -10.3155, -10.6966]],\n",
      "\n",
      "        [[ -7.3125,  -7.2953,  -7.2727,  ...,  -6.5931,  -6.3886,  -4.3359],\n",
      "         [ -7.9964,  -8.0983,  -8.2213,  ...,  -7.0152,  -6.1573,  -9.6257],\n",
      "         [ -9.3061,  -9.2418,  -9.3368,  ...,  -8.9275,  -5.2400,  -5.5398],\n",
      "         ...,\n",
      "         [ -2.3124,  -2.5752,  -2.1372,  ...,  -4.2940,  -2.2089,  -3.4425],\n",
      "         [ -5.5761,  -5.9094,  -5.6941,  ...,  -6.6911,  -4.0553,  -3.9916],\n",
      "         [-11.4794, -11.9258, -11.7465,  ..., -11.2651,  -8.4290,  -9.9758]],\n",
      "\n",
      "        [[ -7.6443,  -7.7130,  -7.5887,  ...,  -7.1109,  -6.6690,  -4.6614],\n",
      "         [-13.0906, -13.2171, -12.9344,  ..., -11.3751, -10.8788, -10.8606],\n",
      "         [ -5.0670,  -5.3687,  -5.1515,  ...,  -3.7943,  -1.8792,  -4.4000],\n",
      "         ...,\n",
      "         [ -2.8190,  -2.8878,  -2.9340,  ...,  -3.4420,  -3.2533,   0.9103],\n",
      "         [-13.6147, -13.4099, -13.2247,  ..., -11.0132, -10.3375,  -9.8335],\n",
      "         [-14.4761, -14.6518, -14.5586,  ..., -12.9815, -11.6298,  -9.2927]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.1914629936218262\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6915, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8896,  -6.8709,  -6.8794,  ...,  -6.3305,  -6.2832,  -3.6184],\n",
      "         [ -6.2321,  -6.0522,  -6.3092,  ...,  -7.6261,  -7.2494,  -3.4972],\n",
      "         [ -9.2283,  -9.5348,  -9.5989,  ..., -10.1918,  -5.3354,  -7.2608],\n",
      "         ...,\n",
      "         [ -5.2158,  -5.2677,  -5.3812,  ...,  -5.8308,  -5.3844,  -1.5327],\n",
      "         [ -5.5079,  -5.6505,  -5.7024,  ...,  -5.9380,  -5.6219,  -1.2410],\n",
      "         [ -6.5068,  -6.5409,  -6.7069,  ...,  -6.6443,  -6.3323,  -2.7666]],\n",
      "\n",
      "        [[ -6.7888,  -6.8995,  -6.7819,  ...,  -6.1725,  -6.1431,  -3.4170],\n",
      "         [ -6.4662,  -6.5088,  -6.5069,  ...,  -6.7771,  -5.5670,  -5.8553],\n",
      "         [ -3.1798,  -3.4461,  -3.5215,  ...,  -2.5346,  -3.6441,  -6.2615],\n",
      "         ...,\n",
      "         [ -2.7168,  -2.8686,  -2.5661,  ...,  -1.5905,  -4.0734,   1.5291],\n",
      "         [ -3.9122,  -4.0154,  -3.7551,  ...,  -3.5049,  -5.2287,  -2.8508],\n",
      "         [ -5.8033,  -5.7795,  -5.6959,  ...,  -5.2942,  -6.0927,  -2.9808]],\n",
      "\n",
      "        [[ -6.3021,  -6.2631,  -6.2875,  ...,  -5.6805,  -5.4890,  -3.7757],\n",
      "         [-12.1744, -11.9411, -11.8520,  ...,  -8.8410,  -9.1286,  -7.2768],\n",
      "         [ -5.7711,  -5.8925,  -5.9338,  ...,  -5.8451,  -6.1482,  -3.7492],\n",
      "         ...,\n",
      "         [ -6.0703,  -6.0875,  -6.0931,  ...,  -6.0620,  -5.7760,  -2.8369],\n",
      "         [ -6.5907,  -6.6560,  -6.6570,  ...,  -6.7766,  -6.5511,  -2.6651],\n",
      "         [ -6.1476,  -6.1066,  -6.2368,  ...,  -6.2412,  -6.1969,  -4.0123]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6797,  -6.6262,  -6.6510,  ...,  -5.8620,  -5.8251,  -3.9254],\n",
      "         [-11.7291, -11.6062, -11.5698,  ...,  -8.0539,  -9.4587, -11.1072],\n",
      "         [ -3.9474,  -4.1978,  -4.1919,  ...,  -4.0507,  -5.9736,  -1.9057],\n",
      "         ...,\n",
      "         [ -4.6132,  -4.6599,  -4.6437,  ...,  -4.5982,  -5.6116,  -3.1964],\n",
      "         [ -4.4934,  -4.5792,  -4.5979,  ...,  -4.3714,  -5.8891,  -2.0802],\n",
      "         [ -4.8325,  -4.8618,  -4.8309,  ...,  -4.8600,  -5.9986,  -3.5193]],\n",
      "\n",
      "        [[ -7.1662,  -7.2282,  -7.0683,  ...,  -6.6053,  -6.3473,  -4.6397],\n",
      "         [ -7.3753,  -7.6457,  -7.2804,  ...,  -9.2869,  -5.2081,  -7.1017],\n",
      "         [ -8.6149,  -8.6192,  -8.4870,  ...,  -8.0525,  -8.0537,  -4.7547],\n",
      "         ...,\n",
      "         [ -9.5547,  -9.7539,  -9.6819,  ...,  -9.1827,  -5.9623,  -7.3103],\n",
      "         [-14.8939, -15.1423, -14.5928,  ..., -14.1330, -11.5369, -12.4675],\n",
      "         [-11.5514, -11.4739, -11.7853,  ..., -10.4817,  -9.2173,  -5.5583]],\n",
      "\n",
      "        [[ -6.9409,  -7.0046,  -6.8634,  ...,  -6.4693,  -5.8859,  -3.7305],\n",
      "         [-15.7651, -15.7408, -15.7806,  ..., -14.5399, -12.0380, -10.0494],\n",
      "         [ -4.2551,  -4.1443,  -4.4159,  ...,  -4.3822,  -2.7287,  -4.9786],\n",
      "         ...,\n",
      "         [-12.5581, -12.1732, -12.7215,  ...,  -8.6722,  -9.6783, -10.2671],\n",
      "         [-14.2371, -14.1981, -14.0591,  ..., -12.1929, -10.2171,  -9.0240],\n",
      "         [-14.8897, -15.3806, -14.9339,  ..., -11.3030, -12.0868, -10.5634]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6915398836135864\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8708, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0290,  -7.1010,  -7.0679,  ...,  -6.5257,  -6.6028,  -4.6483],\n",
      "         [-11.3367, -11.1270, -11.1790,  ...,  -9.4324, -10.5487,  -8.2137],\n",
      "         [ -1.1584,  -1.2419,  -1.3389,  ...,  -2.3370,  -2.3755,  -1.2697],\n",
      "         ...,\n",
      "         [ -7.9573,  -8.1283,  -7.8107,  ...,  -8.2807,  -7.0186,  -6.6143],\n",
      "         [ -5.4247,  -6.0349,  -5.3616,  ...,  -6.0954,  -4.7309,  -3.4447],\n",
      "         [-12.4506, -12.7751, -12.5115,  ..., -10.0341,  -9.3673,  -9.7047]],\n",
      "\n",
      "        [[ -7.6388,  -7.5864,  -7.5511,  ...,  -6.8801,  -6.5468,  -4.0559],\n",
      "         [-16.3014, -15.9259, -15.9075,  ..., -15.4955, -14.2398, -13.0744],\n",
      "         [-11.6868, -11.6866, -11.7885,  ..., -11.2967, -10.0056, -10.3039],\n",
      "         ...,\n",
      "         [ -9.4716,  -9.7910,  -9.8396,  ...,  -9.1856,  -8.6804,  -8.2761],\n",
      "         [ -6.3139,  -6.5192,  -5.8773,  ...,  -5.9104,  -4.3398,  -5.2432],\n",
      "         [-11.1943, -11.1449, -11.0788,  ..., -10.0088,  -8.4097,  -9.2963]],\n",
      "\n",
      "        [[ -6.6076,  -6.5829,  -6.5941,  ...,  -5.9015,  -5.6974,  -3.8725],\n",
      "         [ -5.2955,  -5.3842,  -5.3593,  ...,  -6.4852,  -6.3565,  -2.9546],\n",
      "         [ -4.6129,  -4.6830,  -4.7478,  ...,  -4.6829,  -5.3533,  -2.1484],\n",
      "         ...,\n",
      "         [ -4.9220,  -4.9602,  -4.9930,  ...,  -5.1676,  -5.4944,  -2.5031],\n",
      "         [ -5.1080,  -5.1742,  -5.2535,  ...,  -5.6991,  -5.6816,  -1.7275],\n",
      "         [ -4.8968,  -4.8796,  -4.9376,  ...,  -5.1717,  -5.8213,  -2.1917]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.0249,  -8.0922,  -8.0292,  ...,  -7.0897,  -7.0504,  -4.3718],\n",
      "         [-11.4123, -11.6147, -11.5532,  ..., -10.7734,  -9.0210,  -5.1459],\n",
      "         [ -8.2593,  -8.3764,  -8.3133,  ...,  -8.1865,  -7.1529,  -6.0824],\n",
      "         ...,\n",
      "         [-10.9059, -11.0396, -10.8546,  ...,  -7.4454,  -8.7475,  -6.6643],\n",
      "         [ -5.4702,  -5.9646,  -5.6504,  ...,  -4.6955,  -4.1920,  -3.0251],\n",
      "         [ -6.3303,  -6.5167,  -6.4340,  ...,  -5.2397,  -5.3376,  -3.8715]],\n",
      "\n",
      "        [[ -8.4931,  -8.4139,  -8.3608,  ...,  -7.9165,  -7.6625,  -4.9858],\n",
      "         [-14.7920, -14.9567, -14.8647,  ..., -13.2376, -11.9140, -13.1070],\n",
      "         [-11.8357, -12.2903, -12.2831,  ..., -11.7932, -10.0028, -10.6905],\n",
      "         ...,\n",
      "         [ -5.4655,  -5.4250,  -4.7632,  ...,  -6.0755,  -5.7153,  -1.9067],\n",
      "         [ -3.1711,  -3.6620,  -2.8790,  ...,  -4.6967,  -4.1326,  -2.1346],\n",
      "         [-13.7241, -14.1802, -13.7077,  ..., -12.6378, -11.2690, -11.3305]],\n",
      "\n",
      "        [[ -6.3633,  -6.3841,  -6.3287,  ...,  -5.9182,  -5.6536,  -3.5157],\n",
      "         [ -9.4911,  -9.5225,  -9.2165,  ...,  -5.5238,  -7.7031,  -9.3803],\n",
      "         [ -6.0632,  -6.1115,  -6.0668,  ...,  -6.6998,  -5.9226,  -4.0484],\n",
      "         ...,\n",
      "         [ -5.8852,  -5.9332,  -5.8579,  ...,  -6.4515,  -5.8399,  -2.9534],\n",
      "         [ -6.6841,  -6.8218,  -6.6407,  ...,  -7.6433,  -6.6975,  -3.6081],\n",
      "         [ -6.0020,  -6.1227,  -6.0297,  ...,  -6.7406,  -5.6487,  -3.7134]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.8708361387252808\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6455, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5824,  -6.6101,  -6.5764,  ...,  -6.0685,  -5.8816,  -4.0464],\n",
      "         [ -8.2573,  -8.5164,  -8.0631,  ...,  -7.7461,  -7.6408,  -6.0557],\n",
      "         [ -7.2337,  -7.5969,  -7.5818,  ...,  -8.3015,  -8.1817,  -5.2282],\n",
      "         ...,\n",
      "         [ -7.1724,  -7.4717,  -7.3430,  ...,  -7.0803,  -6.4588,  -3.7905],\n",
      "         [ -7.4179,  -7.5984,  -7.6255,  ...,  -7.0012,  -6.5933,  -4.7213],\n",
      "         [ -7.5188,  -7.6827,  -7.6019,  ...,  -7.3194,  -7.1120,  -5.4575]],\n",
      "\n",
      "        [[ -6.3994,  -6.3488,  -6.3522,  ...,  -5.6490,  -5.7554,  -3.8633],\n",
      "         [ -8.0597,  -7.7991,  -8.1910,  ...,  -8.3475,  -8.6778,  -5.7359],\n",
      "         [ -9.4633,  -9.3215,  -9.4118,  ...,  -9.5805,  -8.4610,  -8.1105],\n",
      "         ...,\n",
      "         [ -5.2506,  -5.3408,  -5.3795,  ...,  -5.8414,  -6.0129,  -2.3101],\n",
      "         [ -4.9156,  -5.0112,  -5.0540,  ...,  -5.3395,  -5.2195,  -2.3635],\n",
      "         [ -5.4603,  -5.4255,  -5.5583,  ...,  -5.6082,  -6.1446,  -3.3286]],\n",
      "\n",
      "        [[ -7.6351,  -7.6980,  -7.6382,  ...,  -7.0929,  -6.8608,  -5.0950],\n",
      "         [ -7.0336,  -7.0147,  -6.9048,  ...,  -7.5293,  -6.1498,  -5.4860],\n",
      "         [ -6.8623,  -7.4095,  -7.0789,  ...,  -7.1986,  -5.3460,  -8.6419],\n",
      "         ...,\n",
      "         [-11.8986, -11.6967, -11.9532,  ..., -10.9197,  -8.1283, -11.1891],\n",
      "         [ -7.6547,  -7.6055,  -7.6797,  ...,  -8.0850,  -5.8013,  -8.2118],\n",
      "         [-11.5109, -11.3562, -11.5653,  ...,  -7.4475,  -7.9054,  -7.9655]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3713,  -6.3726,  -6.4232,  ...,  -5.8071,  -5.6746,  -3.3304],\n",
      "         [ -6.1525,  -6.1309,  -6.2962,  ...,  -6.8772,  -6.5261,  -3.2695],\n",
      "         [ -6.0659,  -6.2692,  -6.2100,  ...,  -6.4793,  -7.1010,  -4.1275],\n",
      "         ...,\n",
      "         [ -4.8403,  -4.8333,  -4.9595,  ...,  -5.3006,  -5.3693,  -0.6914],\n",
      "         [ -2.5352,  -2.6646,  -2.5591,  ...,  -3.0924,  -3.8342,  -0.5326],\n",
      "         [ -5.1502,  -5.1576,  -5.2386,  ...,  -5.6001,  -5.7632,  -2.0661]],\n",
      "\n",
      "        [[ -6.2230,  -6.1642,  -6.1677,  ...,  -5.5546,  -5.4406,  -3.8160],\n",
      "         [-14.2196, -13.7578, -13.8273,  ..., -11.4821, -11.7312, -10.4482],\n",
      "         [ -4.7436,  -4.7764,  -4.8493,  ...,  -5.3964,  -6.4442,  -2.6357],\n",
      "         ...,\n",
      "         [ -4.5272,  -4.6805,  -4.6586,  ...,  -4.6565,  -5.6559,  -2.8447],\n",
      "         [ -4.9114,  -4.9474,  -4.9758,  ...,  -5.1782,  -5.9798,  -3.9183],\n",
      "         [ -4.9677,  -4.9769,  -5.1333,  ...,  -5.3249,  -6.0466,  -3.8524]],\n",
      "\n",
      "        [[ -7.8263,  -7.8061,  -7.7187,  ...,  -7.0713,  -6.8795,  -3.8568],\n",
      "         [ -7.8201,  -7.6715,  -7.7657,  ...,  -7.5517,  -7.8013,  -1.4434],\n",
      "         [-11.3572, -11.1702, -11.3542,  ..., -11.0904,  -8.8765,  -6.5616],\n",
      "         ...,\n",
      "         [ -6.8897,  -7.2396,  -6.9398,  ...,  -6.9574,  -5.0185,  -3.5802],\n",
      "         [ -8.7407,  -8.6141,  -8.5441,  ...,  -7.7590,  -5.7119,  -5.0839],\n",
      "         [-12.9908, -13.0340, -12.8347,  ..., -11.7287, -11.6077,  -9.2030]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6454764604568481\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3374, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7596,  -6.8230,  -6.7855,  ...,  -6.0476,  -5.9338,  -3.6597],\n",
      "         [ -7.6578,  -7.4694,  -7.7951,  ...,  -7.9458,  -6.2030,  -5.6245],\n",
      "         [ -5.2193,  -4.7781,  -4.7407,  ...,  -4.5986,  -3.7855,  -6.7489],\n",
      "         ...,\n",
      "         [ -7.0084,  -6.9326,  -6.9989,  ...,  -6.6992,  -6.5751,  -2.7524],\n",
      "         [ -4.6932,  -4.6284,  -4.7293,  ...,  -5.0631,  -4.9555,  -0.2408],\n",
      "         [ -6.2142,  -6.0536,  -6.1898,  ...,  -6.0133,  -6.0374,  -2.8961]],\n",
      "\n",
      "        [[ -6.9339,  -6.8925,  -6.9166,  ...,  -6.2550,  -6.1638,  -3.8766],\n",
      "         [ -7.5811,  -7.5486,  -7.8110,  ...,  -8.8833,  -8.1642,  -5.6199],\n",
      "         [ -7.0787,  -7.1385,  -7.2492,  ...,  -8.4925,  -7.4312,  -4.9969],\n",
      "         ...,\n",
      "         [ -5.5510,  -5.6439,  -5.8058,  ...,  -6.4777,  -6.4601,  -2.3783],\n",
      "         [ -5.4867,  -5.4991,  -5.6091,  ...,  -6.0537,  -6.0269,  -1.9570],\n",
      "         [ -5.6481,  -5.6819,  -5.7206,  ...,  -6.7807,  -6.1727,  -2.2643]],\n",
      "\n",
      "        [[ -6.2728,  -6.2081,  -6.2373,  ...,  -5.5705,  -5.3873,  -3.7059],\n",
      "         [-13.9921, -13.2353, -13.9000,  ...,  -9.5337, -10.6391, -11.8474],\n",
      "         [ -5.1127,  -5.3121,  -5.4271,  ...,  -5.2231,  -6.3245,  -3.4625],\n",
      "         ...,\n",
      "         [ -5.0755,  -5.2073,  -5.2603,  ...,  -5.2937,  -6.1027,  -3.7504],\n",
      "         [ -5.7459,  -5.8094,  -5.8960,  ...,  -5.8247,  -6.6694,  -3.3396],\n",
      "         [ -5.9581,  -6.0362,  -6.0792,  ...,  -5.9761,  -6.9224,  -3.5669]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2278,  -6.1382,  -6.1940,  ...,  -5.4660,  -5.4018,  -3.5358],\n",
      "         [-14.4304, -13.8373, -14.2641,  ..., -10.4664, -10.4868, -13.2878],\n",
      "         [ -4.2838,  -4.4112,  -4.4638,  ...,  -4.6871,  -6.2692,  -1.8082],\n",
      "         ...,\n",
      "         [ -4.6338,  -4.6808,  -4.7732,  ...,  -4.6363,  -6.2788,  -2.3523],\n",
      "         [ -5.0353,  -5.1442,  -5.2194,  ...,  -5.3040,  -6.1121,  -3.6017],\n",
      "         [ -5.6443,  -5.7627,  -5.7347,  ...,  -5.8656,  -6.6644,  -3.6592]],\n",
      "\n",
      "        [[ -6.5083,  -6.4592,  -6.4800,  ...,  -5.8052,  -5.6275,  -3.8996],\n",
      "         [-11.6737, -11.7173, -11.5823,  ...,  -9.6366,  -9.2304,  -8.3121],\n",
      "         [ -5.0398,  -5.2129,  -5.2143,  ...,  -5.4375,  -5.9159,  -3.4793],\n",
      "         ...,\n",
      "         [ -5.0279,  -5.1829,  -5.1114,  ...,  -4.7683,  -5.5254,  -4.0964],\n",
      "         [ -5.0026,  -5.0600,  -5.0904,  ...,  -4.9996,  -6.0023,  -3.7289],\n",
      "         [ -4.8807,  -5.0172,  -4.9510,  ...,  -5.2255,  -5.5887,  -3.6593]],\n",
      "\n",
      "        [[ -6.4223,  -6.3389,  -6.3978,  ...,  -5.6783,  -5.6153,  -3.6925],\n",
      "         [-12.2097, -12.2047, -11.9316,  ..., -10.4691, -10.3628,  -9.3064],\n",
      "         [ -4.9854,  -5.2656,  -5.2080,  ...,  -5.5237,  -6.8590,  -3.3782],\n",
      "         ...,\n",
      "         [ -5.3126,  -5.4320,  -5.4731,  ...,  -5.3737,  -6.0519,  -2.7098],\n",
      "         [ -4.9979,  -5.1923,  -5.2214,  ...,  -5.0712,  -6.3059,  -2.8318],\n",
      "         [ -5.9036,  -5.9044,  -5.8874,  ...,  -5.8707,  -6.8136,  -3.9323]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.3373817205429077\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.1481, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6243,  -6.5690,  -6.6070,  ...,  -5.8123,  -5.8211,  -3.6607],\n",
      "         [ -7.7193,  -7.4408,  -7.6549,  ...,  -7.8214,  -8.8351,  -2.9460],\n",
      "         [ -6.8292,  -6.7680,  -6.8100,  ...,  -6.9413,  -7.3118,  -4.4461],\n",
      "         ...,\n",
      "         [ -5.0049,  -5.0280,  -5.1239,  ...,  -5.1735,  -5.7073,  -2.1658],\n",
      "         [ -4.9157,  -4.9061,  -4.9340,  ...,  -4.9466,  -5.3100,  -2.3900],\n",
      "         [ -4.9477,  -5.0143,  -4.9579,  ...,  -5.2320,  -6.0470,  -1.5795]],\n",
      "\n",
      "        [[ -6.6052,  -6.5760,  -6.5780,  ...,  -5.9232,  -5.7725,  -3.7456],\n",
      "         [ -5.4548,  -5.3390,  -5.5519,  ...,  -6.2093,  -6.3337,  -1.3757],\n",
      "         [ -5.5466,  -5.2978,  -5.7014,  ...,  -6.9749,  -6.9548,  -3.2768],\n",
      "         ...,\n",
      "         [ -4.7385,  -4.8168,  -4.8933,  ...,  -5.1061,  -5.6062,  -1.0370],\n",
      "         [ -4.8117,  -4.7656,  -4.9165,  ...,  -5.3353,  -5.4938,  -1.5275],\n",
      "         [ -5.3487,  -5.3828,  -5.4168,  ...,  -5.7433,  -5.5561,  -1.9694]],\n",
      "\n",
      "        [[ -9.2570,  -9.9427,  -9.2601,  ...,  -7.9395,  -8.7778,  -9.4668],\n",
      "         [-12.5855, -12.2863, -12.4419,  ...,  -8.6654, -10.3964, -11.0719],\n",
      "         [ -3.8700,  -4.0904,  -4.2624,  ...,  -4.7622,  -6.4813,  -3.2128],\n",
      "         ...,\n",
      "         [ -4.6124,  -4.7820,  -4.7959,  ...,  -5.6348,  -6.6963,  -4.6208],\n",
      "         [ -4.0268,  -4.2325,  -4.2033,  ...,  -4.5213,  -5.8332,  -3.0129],\n",
      "         [ -5.6096,  -5.8679,  -5.8584,  ...,  -5.7303,  -6.6685,  -4.2036]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.2257,  -8.3839,  -8.1831,  ...,  -7.6945,  -6.8923,  -4.4587],\n",
      "         [ -9.5571,  -9.9793,  -9.9080,  ...,  -8.5899,  -6.8293,  -7.5545],\n",
      "         [-10.2129, -10.1731, -10.1267,  ...,  -8.4793,  -7.2629,  -9.6333],\n",
      "         ...,\n",
      "         [ -5.1255,  -5.5572,  -5.4700,  ...,  -4.2834,  -5.0558,  -6.1867],\n",
      "         [ -6.6024,  -7.0950,  -6.8551,  ...,  -7.0178,  -6.2145,  -5.7545],\n",
      "         [ -7.4271,  -7.6116,  -7.5514,  ...,  -7.0637,  -5.5194,  -6.1778]],\n",
      "\n",
      "        [[ -7.7319,  -7.7478,  -7.7440,  ...,  -7.2509,  -6.9108,  -5.7722],\n",
      "         [ -8.3737,  -8.3028,  -8.1131,  ...,  -7.8866,  -7.8241,  -8.7200],\n",
      "         [ -6.2255,  -6.4806,  -6.3947,  ...,  -8.3199,  -4.4017,  -7.5220],\n",
      "         ...,\n",
      "         [-12.2880, -12.5052, -12.1400,  ..., -10.2397,  -8.8501, -11.9108],\n",
      "         [ -4.4912,  -4.4315,  -4.5381,  ...,  -6.5228,  -5.9007,  -6.3682],\n",
      "         [-12.8138, -12.9415, -12.6264,  ..., -10.6296, -12.1240, -10.9284]],\n",
      "\n",
      "        [[ -6.3603,  -6.3117,  -6.3421,  ...,  -5.6747,  -5.5241,  -3.7923],\n",
      "         [-16.4131, -15.8581, -16.2696,  ..., -13.9037, -14.2607, -11.0719],\n",
      "         [ -5.5142,  -5.5386,  -5.6514,  ...,  -5.4740,  -6.8378,  -3.3486],\n",
      "         ...,\n",
      "         [ -5.5526,  -5.6953,  -5.7024,  ...,  -5.3723,  -6.2549,  -3.5235],\n",
      "         [ -6.2660,  -6.3654,  -6.3746,  ...,  -6.2233,  -6.7929,  -3.5012],\n",
      "         [ -6.1505,  -6.2343,  -6.2565,  ...,  -6.0693,  -6.7171,  -3.9043]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.1481391191482544\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.0087, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7114,  -6.6687,  -6.6855,  ...,  -6.0203,  -6.0627,  -3.8799],\n",
      "         [ -7.4850,  -7.4720,  -7.7908,  ...,  -9.2678,  -8.2745,  -3.1489],\n",
      "         [ -6.0595,  -5.9432,  -5.9694,  ...,  -7.2491,  -6.9278,  -4.1213],\n",
      "         ...,\n",
      "         [ -5.0621,  -5.0423,  -5.1396,  ...,  -5.8010,  -5.4032,  -2.4818],\n",
      "         [ -5.4073,  -5.4150,  -5.5693,  ...,  -6.4014,  -6.1974,  -2.6178],\n",
      "         [ -5.0606,  -5.0945,  -5.1864,  ...,  -6.1184,  -5.4491,  -2.8559]],\n",
      "\n",
      "        [[ -8.1546,  -8.0199,  -8.0818,  ...,  -7.2255,  -7.1050,  -4.2859],\n",
      "         [-11.6485, -11.5228, -11.6250,  ...,  -7.5403,  -9.7857,  -9.1841],\n",
      "         [ -4.5912,  -4.8509,  -4.9497,  ...,  -5.3416,  -6.2628,  -3.0294],\n",
      "         ...,\n",
      "         [ -4.3370,  -4.5654,  -4.6780,  ...,  -5.2680,  -6.5027,  -3.1371],\n",
      "         [ -4.5817,  -4.8421,  -4.8208,  ...,  -5.6290,  -6.5672,  -3.0699],\n",
      "         [ -5.0236,  -5.1234,  -5.3447,  ...,  -5.5847,  -6.5098,  -3.5944]],\n",
      "\n",
      "        [[ -6.3838,  -6.3554,  -6.3862,  ...,  -5.7077,  -5.7014,  -3.9381],\n",
      "         [ -7.2650,  -7.2026,  -7.4432,  ...,  -7.9963,  -8.1874,  -3.6163],\n",
      "         [ -5.8833,  -6.0128,  -6.0323,  ...,  -6.4540,  -7.2060,  -3.8040],\n",
      "         ...,\n",
      "         [ -4.9715,  -4.9141,  -5.0232,  ...,  -5.8119,  -5.9666,  -1.7262],\n",
      "         [ -5.0581,  -4.9339,  -5.1459,  ...,  -5.4084,  -6.1753,  -2.1643],\n",
      "         [ -4.5568,  -4.5748,  -4.5443,  ...,  -5.2780,  -5.6364,  -1.6273]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -4.9260,  -4.9045,  -5.0225,  ...,  -5.7581,  -5.3770,  -2.0296],\n",
      "         [ -6.1260,  -5.9959,  -6.2696,  ...,  -7.4866,  -6.6633,  -2.6066],\n",
      "         [ -6.3637,  -6.2786,  -6.4264,  ...,  -7.1894,  -6.6453,  -4.1359],\n",
      "         ...,\n",
      "         [ -4.9037,  -4.8604,  -5.0030,  ...,  -5.9380,  -5.2244,  -2.3815],\n",
      "         [ -4.6206,  -4.6127,  -4.7680,  ...,  -5.6729,  -5.1066,  -2.5056],\n",
      "         [ -4.7264,  -4.6850,  -4.8160,  ...,  -5.7138,  -5.1722,  -1.6588]],\n",
      "\n",
      "        [[ -6.3064,  -6.2327,  -6.2892,  ...,  -5.5709,  -5.4739,  -3.8042],\n",
      "         [ -2.4845,  -2.5978,  -2.6141,  ...,  -3.4383,  -1.8439,  -4.0674],\n",
      "         [ -5.6033,  -5.8568,  -6.4227,  ...,  -6.2672,  -4.7028,  -1.3664],\n",
      "         ...,\n",
      "         [ -3.7123,  -3.5617,  -3.7207,  ...,  -3.8668,  -3.2586,  -1.3248],\n",
      "         [ -3.2539,  -3.2934,  -3.4296,  ...,  -3.5826,  -3.4128,  -1.3181],\n",
      "         [ -4.5613,  -4.5742,  -4.6729,  ...,  -4.5136,  -3.8859,  -2.4123]],\n",
      "\n",
      "        [[ -8.3391,  -8.3116,  -8.0516,  ...,  -7.1149,  -6.9470,  -5.5202],\n",
      "         [-10.2689, -10.4308, -10.6545,  ...,  -8.6670,  -8.7342, -10.8156],\n",
      "         [ -7.5946,  -7.5924,  -7.9918,  ...,  -8.8561,  -7.6262,  -6.3972],\n",
      "         ...,\n",
      "         [ -7.3441,  -7.5373,  -7.5523,  ...,  -7.3946,  -6.7363,  -7.0878],\n",
      "         [ -7.1701,  -7.2605,  -7.3326,  ...,  -7.4994,  -6.7898,  -6.6255],\n",
      "         [ -7.2299,  -7.5256,  -7.5578,  ...,  -7.7514,  -6.9301,  -6.2756]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 3.008700370788574\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8754, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4914,  -7.5658,  -7.4711,  ...,  -6.9682,  -6.4407,  -4.7551],\n",
      "         [-16.9056, -16.9244, -17.0943,  ..., -15.1758, -12.8236, -12.9035],\n",
      "         [ -5.7928,  -5.9196,  -6.2847,  ...,  -5.3013,  -3.5276,  -5.5911],\n",
      "         ...,\n",
      "         [ -7.9130,  -8.5235,  -8.2724,  ...,  -8.1729,  -7.0558,  -8.2807],\n",
      "         [ -7.0119,  -7.5523,  -7.1976,  ...,  -6.8593,  -6.4909,  -7.2834],\n",
      "         [ -6.0524,  -6.3482,  -6.2802,  ...,  -6.5906,  -6.2430,  -5.8086]],\n",
      "\n",
      "        [[ -6.4105,  -6.3810,  -6.3356,  ...,  -5.6354,  -5.8156,  -3.6749],\n",
      "         [ -6.9264,  -6.8196,  -7.2124,  ...,  -7.7775,  -7.4031,  -3.3690],\n",
      "         [ -5.9940,  -5.8514,  -6.2189,  ...,  -6.2265,  -5.9061,  -3.3105],\n",
      "         ...,\n",
      "         [ -5.2918,  -5.2704,  -5.4002,  ...,  -5.9901,  -5.7601,  -1.9250],\n",
      "         [ -5.1964,  -5.2402,  -5.4361,  ...,  -5.7081,  -5.2488,  -2.6196],\n",
      "         [ -4.9266,  -5.0026,  -5.1585,  ...,  -6.0048,  -5.2345,  -2.3899]],\n",
      "\n",
      "        [[ -7.0600,  -7.0274,  -7.0405,  ...,  -6.2536,  -6.1315,  -4.0480],\n",
      "         [-11.0860, -11.2966, -11.3581,  ...,  -8.6385,  -8.4959,  -8.8284],\n",
      "         [ -4.2394,  -4.4776,  -4.4710,  ...,  -4.5190,  -6.4119,  -2.0113],\n",
      "         ...,\n",
      "         [ -5.6913,  -5.9060,  -5.8935,  ...,  -5.6658,  -6.5181,  -1.9949],\n",
      "         [ -5.6435,  -5.9273,  -5.8769,  ...,  -5.6300,  -6.9774,  -2.5115],\n",
      "         [ -5.5703,  -5.7422,  -5.7390,  ...,  -5.5609,  -6.5493,  -2.7454]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-11.2308, -10.8720, -11.1300,  ..., -11.3395, -11.8039,  -6.4957],\n",
      "         [-11.5057, -11.7465, -11.8498,  ..., -10.0692, -10.4820,  -9.1375],\n",
      "         [ -4.0781,  -4.1342,  -4.2268,  ...,  -5.3579,  -6.0183,  -2.6288],\n",
      "         ...,\n",
      "         [ -5.2480,  -5.3623,  -5.3926,  ...,  -6.0646,  -6.7979,  -1.9424],\n",
      "         [ -4.2139,  -4.3371,  -4.3143,  ...,  -5.2641,  -5.7326,  -2.0430],\n",
      "         [ -3.1370,  -3.2726,  -3.3120,  ...,  -4.0188,  -5.0124,  -2.4799]],\n",
      "\n",
      "        [[ -7.4243,  -7.4221,  -7.3496,  ...,  -6.5597,  -6.4625,  -4.3334],\n",
      "         [ -7.7740,  -7.8161,  -7.9284,  ...,  -8.4550,  -7.4964,  -6.4199],\n",
      "         [ -6.8098,  -6.8760,  -7.0100,  ...,  -6.6572,  -6.2676,  -4.3913],\n",
      "         ...,\n",
      "         [ -7.9734,  -8.0443,  -8.0341,  ...,  -8.3234,  -7.5647,  -4.6733],\n",
      "         [ -8.1377,  -8.2478,  -8.2516,  ...,  -8.6059,  -7.3046,  -4.9886],\n",
      "         [ -7.9025,  -7.9511,  -7.9508,  ...,  -8.3764,  -6.6884,  -4.9693]],\n",
      "\n",
      "        [[ -7.5898,  -7.6253,  -7.5531,  ...,  -6.8251,  -6.5101,  -4.6389],\n",
      "         [-12.6377, -12.7210, -12.6669,  ..., -11.3246,  -9.9189, -12.3367],\n",
      "         [ -4.7509,  -4.6937,  -4.5949,  ...,  -4.7651,  -3.6832,  -4.4698],\n",
      "         ...,\n",
      "         [ -7.8896,  -8.0517,  -7.8464,  ...,  -8.7554,  -6.8040,  -8.2404],\n",
      "         [ -6.7126,  -7.1154,  -6.7077,  ...,  -7.2192,  -5.8027,  -7.2053],\n",
      "         [ -8.3440,  -8.5764,  -8.4988,  ...,  -9.1400,  -7.2580,  -7.8472]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.8753670454025269\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3773, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.5118,  -8.5722,  -8.4638,  ...,  -8.1636,  -7.5675,  -3.9937],\n",
      "         [-10.1540, -10.4136, -10.1398,  ...,  -9.9787,  -8.1716,  -9.1760],\n",
      "         [ -9.1826,  -9.4231,  -9.1657,  ...,  -8.3692,  -8.1135,  -7.6863],\n",
      "         ...,\n",
      "         [ -3.9890,  -4.1964,  -3.7807,  ...,  -5.3762,  -4.9283,  -4.0696],\n",
      "         [ -8.1091,  -8.0827,  -7.7455,  ...,  -7.1517,  -6.8837,  -5.6361],\n",
      "         [-11.7163, -11.7347, -11.7294,  ..., -10.9657, -10.1023,  -7.6721]],\n",
      "\n",
      "        [[ -6.4928,  -6.4805,  -6.4531,  ...,  -5.7991,  -5.6928,  -3.5591],\n",
      "         [ -7.7182,  -7.6408,  -7.8696,  ...,  -8.1108,  -8.8135,  -4.1750],\n",
      "         [ -7.8213,  -7.9082,  -7.8693,  ...,  -8.0238,  -9.2338,  -4.6043],\n",
      "         ...,\n",
      "         [ -4.9743,  -5.0222,  -5.0736,  ...,  -5.7242,  -5.4845,  -1.3266],\n",
      "         [ -6.3018,  -6.4695,  -6.3308,  ...,  -7.0075,  -6.9081,  -2.2928],\n",
      "         [ -5.6272,  -5.6288,  -5.6253,  ...,  -5.9085,  -5.9757,  -1.8245]],\n",
      "\n",
      "        [[ -6.8001,  -6.8241,  -6.8599,  ...,  -6.2281,  -6.1613,  -3.6974],\n",
      "         [ -9.6367,  -9.4173,  -9.5510,  ...,  -9.8803,  -9.7712,  -5.7394],\n",
      "         [ -6.1707,  -6.2619,  -6.5057,  ...,  -6.1301,  -6.9228,  -2.2046],\n",
      "         ...,\n",
      "         [ -5.1852,  -5.2632,  -5.2861,  ...,  -5.8418,  -6.2820,  -1.2136],\n",
      "         [ -5.2733,  -5.3187,  -5.3773,  ...,  -5.6890,  -6.2231,  -1.9500],\n",
      "         [ -5.8894,  -5.9054,  -6.0285,  ...,  -6.3640,  -6.8605,  -2.2195]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7115,  -6.7203,  -6.7012,  ...,  -6.0645,  -5.8977,  -4.1197],\n",
      "         [ -8.0977,  -8.0161,  -8.3705,  ...,  -7.9272,  -8.1440,  -4.8696],\n",
      "         [ -7.1613,  -7.3080,  -7.3548,  ...,  -7.4337,  -7.1049,  -4.5280],\n",
      "         ...,\n",
      "         [ -5.3414,  -5.3741,  -5.5186,  ...,  -5.8582,  -5.7847,  -2.3827],\n",
      "         [ -5.5790,  -5.6056,  -5.6933,  ...,  -5.9715,  -5.5781,  -2.8240],\n",
      "         [ -5.3891,  -5.3224,  -5.4705,  ...,  -5.7353,  -5.6110,  -2.6117]],\n",
      "\n",
      "        [[ -6.4428,  -6.3885,  -6.4165,  ...,  -5.8972,  -5.7058,  -3.7517],\n",
      "         [ -8.3223,  -8.2838,  -8.4242,  ...,  -9.2056,  -9.4734,  -5.6106],\n",
      "         [ -6.2846,  -6.4969,  -6.5187,  ...,  -6.4730,  -7.6686,  -5.2729],\n",
      "         ...,\n",
      "         [ -5.6181,  -5.8320,  -5.8101,  ...,  -6.3325,  -6.1526,  -2.5190],\n",
      "         [ -5.2691,  -5.4633,  -5.5087,  ...,  -6.0985,  -5.7734,  -2.6709],\n",
      "         [ -5.6261,  -5.6957,  -5.7734,  ...,  -5.9349,  -6.2397,  -2.0962]],\n",
      "\n",
      "        [[ -6.4959,  -6.5095,  -6.4923,  ...,  -5.7127,  -5.8545,  -3.6867],\n",
      "         [-12.4206, -11.9040, -12.2236,  ...,  -8.7968, -10.1601,  -8.1548],\n",
      "         [ -3.8056,  -4.0353,  -4.1426,  ...,  -4.7977,  -6.2074,  -3.3651],\n",
      "         ...,\n",
      "         [ -5.5854,  -5.8453,  -5.8722,  ...,  -5.7788,  -6.4432,  -3.9718],\n",
      "         [ -5.3944,  -5.5151,  -5.5181,  ...,  -5.6462,  -6.9398,  -4.0346],\n",
      "         [ -4.9162,  -4.9987,  -5.0980,  ...,  -5.0896,  -6.5101,  -2.4554]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.377326488494873\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4710, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5739,  -6.5365,  -6.5311,  ...,  -5.6321,  -5.5470,  -3.5541],\n",
      "         [ -5.5178,  -5.4093,  -5.5547,  ...,  -6.1866,  -5.3999,  -2.7259],\n",
      "         [ -4.9741,  -4.3773,  -4.5781,  ...,  -4.2175,  -3.9897,  -4.6747],\n",
      "         ...,\n",
      "         [ -6.4496,  -6.3040,  -6.2996,  ...,  -6.3000,  -5.7762,  -3.4210],\n",
      "         [ -6.3702,  -6.2499,  -6.3589,  ...,  -6.3194,  -6.0010,  -2.8415],\n",
      "         [ -6.7263,  -6.5955,  -6.6428,  ...,  -6.5078,  -6.1922,  -3.3448]],\n",
      "\n",
      "        [[ -6.8421,  -6.7773,  -6.7903,  ...,  -5.9459,  -5.8266,  -3.8371],\n",
      "         [-10.9876, -11.2892, -10.5535,  ...,  -9.5736,  -8.7694,  -7.5998],\n",
      "         [ -3.7151,  -3.9310,  -3.7826,  ...,  -2.6464,  -2.3197,  -0.4141],\n",
      "         ...,\n",
      "         [ -6.9681,  -7.0245,  -6.8673,  ...,  -6.9326,  -6.8053,  -5.2282],\n",
      "         [ -6.8455,  -6.8754,  -6.8004,  ...,  -6.9443,  -6.3937,  -4.8260],\n",
      "         [  0.2912,  -0.0607,   0.0552,  ...,  -1.7413,   0.5826,  -0.8678]],\n",
      "\n",
      "        [[ -6.2202,  -6.2013,  -6.1629,  ...,  -5.5164,  -5.5613,  -3.9935],\n",
      "         [-13.1754, -13.3308, -13.1199,  ..., -10.8316, -10.4478,  -9.9801],\n",
      "         [ -4.4681,  -4.6501,  -4.6723,  ...,  -4.8862,  -6.3251,  -3.3346],\n",
      "         ...,\n",
      "         [ -4.4629,  -4.5421,  -4.5580,  ...,  -3.9184,  -5.8300,  -3.1653],\n",
      "         [ -4.8269,  -4.9244,  -4.9878,  ...,  -4.9928,  -6.1902,  -4.2950],\n",
      "         [ -4.4943,  -4.5710,  -4.6331,  ...,  -4.9150,  -5.7785,  -4.3290]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.6194,  -7.6633,  -7.5854,  ...,  -7.0580,  -6.7281,  -4.5818],\n",
      "         [-10.9165, -11.1140, -10.6364,  ...,  -8.2479, -10.4315,  -4.0272],\n",
      "         [ -8.0521,  -8.2559,  -7.6560,  ...,  -8.0820,  -5.5913,  -3.2530],\n",
      "         ...,\n",
      "         [ -7.5418,  -7.5587,  -7.6778,  ...,  -6.6252,  -5.0793,  -7.3458],\n",
      "         [ -9.8922, -10.3864, -10.0204,  ...,  -9.7165, -10.1740,  -4.9420],\n",
      "         [-13.7425, -14.2605, -13.9189,  ..., -12.3107, -11.9053,  -9.7620]],\n",
      "\n",
      "        [[ -6.9072,  -6.8954,  -6.9115,  ...,  -5.9596,  -6.0256,  -3.9263],\n",
      "         [-13.1905, -13.3390, -13.2755,  ..., -11.6262, -10.2543,  -9.5906],\n",
      "         [ -4.5483,  -4.5504,  -4.7214,  ...,  -4.5438,  -6.2214,  -3.7319],\n",
      "         ...,\n",
      "         [ -5.2653,  -5.2719,  -5.4006,  ...,  -5.2101,  -6.4336,  -5.1453],\n",
      "         [ -4.4567,  -4.4286,  -4.5640,  ...,  -4.6151,  -6.2584,  -3.4378],\n",
      "         [ -5.3222,  -5.2904,  -5.4797,  ...,  -5.1147,  -5.9094,  -5.0792]],\n",
      "\n",
      "        [[ -6.2131,  -6.1451,  -6.1769,  ...,  -5.5861,  -5.2483,  -3.6879],\n",
      "         [-10.9021, -11.0223, -11.1024,  ...,  -8.9294, -10.5663,  -7.1583],\n",
      "         [ -5.0019,  -5.0929,  -5.1295,  ...,  -5.1883,  -6.4309,  -3.4012],\n",
      "         ...,\n",
      "         [ -5.2649,  -5.2976,  -5.3150,  ...,  -5.5544,  -6.4255,  -4.2996],\n",
      "         [ -5.2314,  -5.4333,  -5.4412,  ...,  -5.6886,  -6.1345,  -4.1688],\n",
      "         [ -4.7006,  -4.8030,  -4.8258,  ...,  -4.9774,  -6.0948,  -4.0178]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.4709949493408203\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8371, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7038,  -6.6383,  -6.6427,  ...,  -5.8172,  -5.8372,  -3.7967],\n",
      "         [-10.7439, -11.1458, -11.0259,  ...,  -8.7944,  -9.6215,  -8.8708],\n",
      "         [ -4.1290,  -4.2271,  -4.6346,  ...,  -4.9541,  -6.1339,  -3.1547],\n",
      "         ...,\n",
      "         [ -4.4184,  -4.5406,  -4.4468,  ...,  -4.5134,  -6.1898,  -3.4417],\n",
      "         [ -3.8684,  -3.9526,  -4.0762,  ...,  -4.4870,  -5.4852,  -3.4214],\n",
      "         [ -5.5849,  -5.5319,  -5.7158,  ...,  -5.8136,  -6.4334,  -5.2928]],\n",
      "\n",
      "        [[ -7.1305,  -7.1662,  -7.1129,  ...,  -6.6431,  -6.4506,  -4.4057],\n",
      "         [-10.2350,  -9.9162, -10.1251,  ...,  -6.9189,  -7.7302,  -9.9902],\n",
      "         [ -6.5150,  -6.7373,  -6.7111,  ...,  -6.9403,  -6.7999,  -3.9349],\n",
      "         ...,\n",
      "         [ -6.5864,  -6.8567,  -6.7806,  ...,  -7.0775,  -6.5635,  -3.7491],\n",
      "         [ -7.8391,  -8.0724,  -8.1455,  ...,  -7.6821,  -7.2633,  -3.4593],\n",
      "         [ -7.3435,  -7.6085,  -7.5080,  ...,  -7.2246,  -7.1991,  -3.6615]],\n",
      "\n",
      "        [[ -7.7050,  -7.7135,  -7.7229,  ...,  -7.1308,  -6.7431,  -4.3682],\n",
      "         [-10.2528, -10.1058, -10.2088,  ..., -11.5827,  -8.0912,  -5.2484],\n",
      "         [ -8.5750,  -8.6433,  -8.8051,  ...,  -8.7911,  -7.9433,  -4.7641],\n",
      "         ...,\n",
      "         [ -4.7475,  -4.9008,  -5.1700,  ...,  -7.0145,  -5.1578,  -2.4653],\n",
      "         [-13.0886, -13.3024, -13.2946,  ..., -11.6673,  -9.1941, -12.0839],\n",
      "         [-16.2252, -16.6415, -16.4715,  ..., -15.5466, -13.2770, -10.9505]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5449,  -6.5076,  -6.4961,  ...,  -5.8002,  -5.7629,  -3.9279],\n",
      "         [ -5.0192,  -4.7707,  -5.0449,  ...,  -6.2779,  -6.4425,  -2.8970],\n",
      "         [ -4.1486,  -4.1748,  -4.3067,  ...,  -6.2030,  -4.8904,  -1.6448],\n",
      "         ...,\n",
      "         [ -4.2403,  -4.1974,  -4.3468,  ...,  -5.2253,  -4.9866,  -1.2956],\n",
      "         [ -4.8782,  -4.9374,  -5.0389,  ...,  -6.4432,  -5.8640,  -1.5228],\n",
      "         [ -4.4500,  -4.4642,  -4.6121,  ...,  -5.3843,  -5.4170,  -1.8347]],\n",
      "\n",
      "        [[ -6.7047,  -6.6772,  -6.7030,  ...,  -5.8452,  -5.8817,  -3.6653],\n",
      "         [ -7.0128,  -6.8474,  -7.0958,  ...,  -7.0697,  -7.3027,  -2.8107],\n",
      "         [ -7.1974,  -6.8468,  -7.3060,  ...,  -7.1538,  -7.9538,  -3.4730],\n",
      "         ...,\n",
      "         [ -5.7847,  -5.7866,  -5.9183,  ...,  -5.9640,  -6.2827,  -1.4164],\n",
      "         [ -5.3345,  -5.2787,  -5.4317,  ...,  -5.5085,  -6.0008,  -1.8503],\n",
      "         [ -5.5855,  -5.5337,  -5.6724,  ...,  -5.6353,  -6.0085,  -1.8210]],\n",
      "\n",
      "        [[ -7.7028,  -7.6923,  -7.6375,  ...,  -7.6241,  -6.8970,  -4.9075],\n",
      "         [ -5.4726,  -5.7561,  -5.6828,  ...,  -6.0653,  -5.0106,  -7.9548],\n",
      "         [-14.0696, -14.4752, -14.1384,  ..., -11.7792,  -9.4589, -16.3413],\n",
      "         ...,\n",
      "         [ -6.5874,  -6.7378,  -6.7878,  ...,  -7.8438,  -6.6101,  -6.0314],\n",
      "         [ -6.2585,  -6.2410,  -6.3567,  ...,  -7.1990,  -5.8712,  -6.9635],\n",
      "         [ -6.4711,  -6.6108,  -6.5294,  ...,  -7.6788,  -6.1794,  -5.9658]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.837131381034851\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2110, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.1691,  -9.3969,  -8.9987,  ...,  -9.6832,  -6.9224,  -6.8179],\n",
      "         [ -7.9121,  -8.4647,  -8.7424,  ...,  -7.0999,  -5.8036,  -5.8851],\n",
      "         [ -2.7475,  -2.6053,  -2.8403,  ...,  -2.0129,  -0.2160,  -5.6806],\n",
      "         ...,\n",
      "         [ -0.8050,  -1.6814,  -0.9760,  ...,  -2.9092,   0.1414,  -4.5108],\n",
      "         [-12.1177, -12.4927, -12.3612,  ..., -12.6315,  -9.1708,  -7.3012],\n",
      "         [ -8.1537,  -8.5770,  -8.4610,  ...,  -9.5841,  -3.8630,  -5.4526]],\n",
      "\n",
      "        [[ -7.1887,  -7.2334,  -7.0822,  ...,  -6.8280,  -6.4507,  -4.8952],\n",
      "         [ -7.2246,  -7.2920,  -7.4910,  ...,  -7.4326,  -6.2156,  -7.5468],\n",
      "         [-10.2815, -10.3121, -10.3482,  ...,  -9.1039,  -7.3324, -11.7027],\n",
      "         ...,\n",
      "         [ -3.0656,  -3.1152,  -3.1854,  ...,  -2.7367,  -2.4203,  -4.5198],\n",
      "         [ -5.5946,  -5.6498,  -5.7316,  ...,  -7.3461,  -5.6208,  -3.2515],\n",
      "         [ -6.6293,  -6.9274,  -6.7697,  ...,  -6.6246,  -5.6956,  -5.8523]],\n",
      "\n",
      "        [[ -6.6642,  -6.6996,  -6.6191,  ...,  -6.2153,  -5.8189,  -4.1473],\n",
      "         [ -6.9085,  -7.1018,  -7.2576,  ...,  -7.2990,  -5.6022,  -8.5560],\n",
      "         [-11.3722, -11.4908, -11.3704,  ...,  -9.4824,  -8.3340, -11.3455],\n",
      "         ...,\n",
      "         [ -5.9681,  -6.4033,  -6.3091,  ...,  -5.4288,  -3.2688, -10.0198],\n",
      "         [ -6.8831,  -7.0792,  -6.8940,  ...,  -6.6111,  -5.8625,  -6.5842],\n",
      "         [ -6.3234,  -6.5319,  -6.3939,  ...,  -6.0171,  -4.9304,  -5.4761]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.5777,  -7.6738,  -7.5262,  ...,  -6.8466,  -6.7866,  -4.7423],\n",
      "         [ -5.4822,  -5.3976,  -5.4584,  ...,  -6.6882,  -7.3986,  -1.6194],\n",
      "         [ -9.3861,  -9.4544,  -9.5690,  ...,  -9.1471,  -8.0487,  -8.6268],\n",
      "         ...,\n",
      "         [-10.7107, -11.2928, -10.9741,  ...,  -9.1658,  -8.5889,  -6.5413],\n",
      "         [-11.5535, -11.8859, -12.0102,  ..., -12.1208,  -8.3339,  -1.7296],\n",
      "         [-12.4203, -13.0299, -12.8147,  ..., -12.6204,  -9.3971,  -7.4828]],\n",
      "\n",
      "        [[ -6.2938,  -6.2344,  -6.2486,  ...,  -5.4763,  -5.5009,  -3.5693],\n",
      "         [-11.5588, -11.5826, -11.4549,  ...,  -8.8801,  -9.8615,  -8.1096],\n",
      "         [ -4.7890,  -4.9950,  -5.0642,  ...,  -5.4845,  -7.0841,  -3.2957],\n",
      "         ...,\n",
      "         [ -5.5510,  -5.6779,  -5.7689,  ...,  -5.5590,  -6.6549,  -4.4225],\n",
      "         [ -5.5614,  -5.6086,  -5.7238,  ...,  -5.7465,  -6.7713,  -4.0841],\n",
      "         [ -4.9871,  -5.0960,  -5.1525,  ...,  -4.8150,  -6.6520,  -3.4268]],\n",
      "\n",
      "        [[ -8.9481,  -8.8831,  -8.9177,  ...,  -8.4168,  -8.0742,  -5.7951],\n",
      "         [-11.9697, -11.7180, -11.9300,  ..., -10.7337, -10.1214, -11.6696],\n",
      "         [ -7.6376,  -7.1312,  -7.4150,  ...,  -6.4799,  -8.1962,  -4.8342],\n",
      "         ...,\n",
      "         [ -5.8836,  -6.0073,  -5.8127,  ...,  -5.4458,  -5.9155,  -4.5645],\n",
      "         [ -8.8998,  -9.0280,  -8.8540,  ...,  -7.4926,  -8.6546,  -6.6763],\n",
      "         [ -8.9360,  -8.9272,  -9.3319,  ...,  -9.7731,  -6.3007,  -7.0920]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.2110347747802734\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2577, grad_fn=<NllLossBackward0>), logits=tensor([[[-6.4908e+00, -6.4189e+00, -6.4311e+00,  ..., -5.7251e+00,\n",
      "          -5.5007e+00, -3.8696e+00],\n",
      "         [-1.2760e+01, -1.2292e+01, -1.2578e+01,  ..., -9.0274e+00,\n",
      "          -1.0956e+01, -9.9219e+00],\n",
      "         [-5.4738e+00, -5.6024e+00, -5.6449e+00,  ..., -5.2082e+00,\n",
      "          -7.0366e+00, -3.7080e+00],\n",
      "         ...,\n",
      "         [-5.7114e+00, -5.6420e+00, -5.7931e+00,  ..., -5.5038e+00,\n",
      "          -6.9149e+00, -3.9786e+00],\n",
      "         [-5.8916e+00, -5.7804e+00, -5.8439e+00,  ..., -5.3529e+00,\n",
      "          -6.7485e+00, -3.8857e+00],\n",
      "         [-6.7102e+00, -6.6961e+00, -6.8626e+00,  ..., -6.4133e+00,\n",
      "          -7.3074e+00, -4.5998e+00]],\n",
      "\n",
      "        [[-8.0847e+00, -8.0793e+00, -7.9824e+00,  ..., -7.5637e+00,\n",
      "          -7.8606e+00, -4.1987e+00],\n",
      "         [-8.1137e+00, -7.8103e+00, -7.8077e+00,  ..., -8.1100e+00,\n",
      "          -7.1708e+00,  6.7711e-03],\n",
      "         [-8.0305e+00, -7.7900e+00, -7.8536e+00,  ..., -8.0378e+00,\n",
      "          -8.8290e+00, -5.5013e+00],\n",
      "         ...,\n",
      "         [-7.3142e+00, -7.3872e+00, -7.5823e+00,  ..., -5.7467e+00,\n",
      "          -7.6139e+00, -9.4799e+00],\n",
      "         [-1.4540e+01, -1.4442e+01, -1.4605e+01,  ..., -1.1728e+01,\n",
      "          -1.3099e+01, -1.2348e+01],\n",
      "         [-1.0793e+01, -1.1338e+01, -1.0717e+01,  ..., -9.3158e+00,\n",
      "          -9.3288e+00, -6.6674e+00]],\n",
      "\n",
      "        [[-7.7081e+00, -7.8843e+00, -7.7580e+00,  ..., -7.3135e+00,\n",
      "          -7.2157e+00, -5.2964e+00],\n",
      "         [-5.6439e+00, -5.4516e+00, -5.8072e+00,  ..., -5.4669e+00,\n",
      "          -4.2920e+00, -5.9286e+00],\n",
      "         [-7.5551e+00, -7.9183e+00, -8.2465e+00,  ..., -8.1847e+00,\n",
      "          -6.9668e+00, -7.1356e+00],\n",
      "         ...,\n",
      "         [-7.6317e+00, -7.8983e+00, -7.4988e+00,  ..., -7.4212e+00,\n",
      "          -7.9795e+00, -3.4030e+00],\n",
      "         [-9.9919e+00, -1.0205e+01, -1.0080e+01,  ..., -8.5381e+00,\n",
      "          -8.7623e+00, -8.2311e+00],\n",
      "         [-1.1718e+01, -1.2042e+01, -1.1794e+01,  ..., -1.0771e+01,\n",
      "          -9.8573e+00, -8.4234e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.8037e+00, -6.7649e+00, -6.7686e+00,  ..., -6.1126e+00,\n",
      "          -6.0530e+00, -3.7151e+00],\n",
      "         [-8.4492e+00, -8.8590e+00, -8.5929e+00,  ..., -8.5307e+00,\n",
      "          -8.3921e+00, -3.4117e+00],\n",
      "         [-1.3018e+01, -1.3170e+01, -1.2815e+01,  ..., -1.0348e+01,\n",
      "          -1.0194e+01, -1.0019e+01],\n",
      "         ...,\n",
      "         [-6.8414e+00, -7.0303e+00, -6.7836e+00,  ..., -6.5044e+00,\n",
      "          -6.6768e+00, -2.0280e+00],\n",
      "         [-6.6854e+00, -6.8811e+00, -6.6326e+00,  ..., -6.4657e+00,\n",
      "          -6.3506e+00, -9.6743e-01],\n",
      "         [-6.8188e+00, -7.0490e+00, -6.7943e+00,  ..., -6.5536e+00,\n",
      "          -6.8242e+00, -2.3639e+00]],\n",
      "\n",
      "        [[-6.6247e+00, -6.5644e+00, -6.5868e+00,  ..., -5.8699e+00,\n",
      "          -5.8243e+00, -3.9270e+00],\n",
      "         [-1.3031e+01, -1.3180e+01, -1.3069e+01,  ..., -9.5419e+00,\n",
      "          -8.7590e+00, -9.5395e+00],\n",
      "         [-5.0601e+00, -4.9893e+00, -5.1448e+00,  ..., -5.3015e+00,\n",
      "          -6.3526e+00, -3.5028e+00],\n",
      "         ...,\n",
      "         [-5.3620e+00, -5.6215e+00, -5.4921e+00,  ..., -4.6369e+00,\n",
      "          -6.0953e+00, -3.0317e+00],\n",
      "         [-4.8606e+00, -4.9222e+00, -4.9748e+00,  ..., -4.9848e+00,\n",
      "          -6.1509e+00, -2.9440e+00],\n",
      "         [-4.6516e+00, -4.7475e+00, -4.7410e+00,  ..., -4.5196e+00,\n",
      "          -5.7376e+00, -3.2639e+00]],\n",
      "\n",
      "        [[-6.8751e+00, -6.8556e+00, -6.8455e+00,  ..., -6.3485e+00,\n",
      "          -5.9664e+00, -4.1806e+00],\n",
      "         [-1.4692e+01, -1.4924e+01, -1.4717e+01,  ..., -1.2584e+01,\n",
      "          -1.3459e+01, -1.1174e+01],\n",
      "         [-9.9726e+00, -1.0253e+01, -1.0607e+01,  ..., -1.0362e+01,\n",
      "          -8.2125e+00, -4.3990e+00],\n",
      "         ...,\n",
      "         [-8.3375e+00, -8.6561e+00, -8.0089e+00,  ..., -9.4578e+00,\n",
      "          -7.7084e+00, -5.6256e+00],\n",
      "         [-2.9726e+00, -3.2090e+00, -2.8744e+00,  ..., -3.4448e+00,\n",
      "          -2.5052e+00, -3.6534e+00],\n",
      "         [-9.7588e+00, -1.0045e+01, -9.7558e+00,  ..., -1.1805e+01,\n",
      "          -9.0019e+00, -8.3276e+00]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.2577333450317383\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5825, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0086,  -6.9455,  -6.9830,  ...,  -5.9929,  -6.1275,  -3.6265],\n",
      "         [-13.6693, -13.5778, -13.4744,  ..., -11.1690, -10.1531, -10.1427],\n",
      "         [ -4.0367,  -4.3529,  -4.3401,  ...,  -4.5382,  -6.2169,  -3.0039],\n",
      "         ...,\n",
      "         [ -5.3185,  -5.5333,  -5.5130,  ...,  -5.3224,  -7.4320,  -3.4638],\n",
      "         [ -5.3814,  -5.3832,  -5.4682,  ...,  -5.2431,  -6.6134,  -3.8563],\n",
      "         [ -4.7434,  -4.9020,  -4.8417,  ...,  -4.9097,  -6.1521,  -2.9577]],\n",
      "\n",
      "        [[ -6.5336,  -6.5122,  -6.4674,  ...,  -5.8838,  -5.8409,  -3.8282],\n",
      "         [ -8.6426,  -8.6580,  -8.7895,  ...,  -9.4511,  -9.8592,  -5.1397],\n",
      "         [ -7.8314,  -7.8629,  -7.9477,  ...,  -8.2228,  -8.8554,  -6.1027],\n",
      "         ...,\n",
      "         [ -5.2306,  -5.2358,  -5.3857,  ...,  -5.4358,  -6.2847,  -2.6869],\n",
      "         [ -5.4970,  -5.4752,  -5.5326,  ...,  -5.8683,  -5.9652,  -2.8325],\n",
      "         [ -5.6227,  -5.5946,  -5.7400,  ...,  -6.0263,  -6.1644,  -2.7353]],\n",
      "\n",
      "        [[ -7.9847,  -7.9752,  -7.9973,  ...,  -7.6713,  -7.4225,  -4.7545],\n",
      "         [ -6.9517,  -6.8916,  -6.8820,  ...,  -6.6846,  -6.6949,  -4.2874],\n",
      "         [ -5.3023,  -5.3251,  -5.2039,  ...,  -4.7383,  -4.3800,  -3.0247],\n",
      "         ...,\n",
      "         [-11.0223, -11.2642, -11.3337,  ...,  -8.6661, -11.1390, -10.4119],\n",
      "         [-10.6944, -10.6991, -10.6223,  ..., -10.9800, -10.2746,  -7.4717],\n",
      "         [-11.4516, -11.5762, -11.4272,  ..., -12.3868, -10.4816,  -8.2265]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7102,  -6.6926,  -6.7025,  ...,  -6.0569,  -5.7170,  -3.8878],\n",
      "         [-12.3680, -12.0808, -11.9049,  ...,  -9.0357, -10.3821, -10.6030],\n",
      "         [ -4.7694,  -4.9739,  -4.9136,  ...,  -4.8318,  -6.9761,  -1.9483],\n",
      "         ...,\n",
      "         [ -4.6573,  -4.7588,  -4.8168,  ...,  -5.0283,  -6.5202,  -3.4939],\n",
      "         [ -4.8844,  -4.8303,  -4.9443,  ...,  -5.2472,  -5.9544,  -4.6675],\n",
      "         [ -4.4864,  -4.4780,  -4.4436,  ...,  -4.5815,  -6.1343,  -3.9884]],\n",
      "\n",
      "        [[ -6.8755,  -6.8065,  -6.8559,  ...,  -6.2374,  -6.2697,  -3.9706],\n",
      "         [ -6.4405,  -6.1455,  -6.4360,  ...,  -7.1006,  -7.9031,  -2.0925],\n",
      "         [ -5.0794,  -5.0772,  -4.9623,  ...,  -5.2293,  -5.3970,  -4.0264],\n",
      "         ...,\n",
      "         [ -5.4099,  -5.2731,  -5.3450,  ...,  -5.2574,  -5.8946,  -2.7146],\n",
      "         [ -5.4447,  -5.3127,  -5.4764,  ...,  -5.6728,  -5.6369,  -2.9558],\n",
      "         [ -5.0991,  -4.9269,  -5.0966,  ...,  -5.1464,  -6.1541,  -1.9586]],\n",
      "\n",
      "        [[ -6.9909,  -6.9861,  -7.0714,  ...,  -6.0075,  -6.1764,  -3.6641],\n",
      "         [-14.6494, -14.2113, -14.4934,  ..., -10.6469, -11.6145, -11.6189],\n",
      "         [ -5.1975,  -5.3180,  -5.5716,  ...,  -5.2910,  -7.0788,  -3.4598],\n",
      "         ...,\n",
      "         [ -4.6146,  -4.6254,  -4.6653,  ...,  -4.5370,  -6.4640,  -3.4725],\n",
      "         [ -5.3679,  -5.5170,  -5.5703,  ...,  -5.4517,  -6.3719,  -3.2969],\n",
      "         [ -5.9053,  -5.9866,  -6.1137,  ...,  -6.2112,  -6.8582,  -3.6583]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5824737548828125\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.4446, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9196,  -6.8493,  -6.8481,  ...,  -5.9914,  -6.1405,  -4.2036],\n",
      "         [ -7.3274,  -7.0197,  -7.2540,  ...,  -8.0260,  -8.5576,  -4.6406],\n",
      "         [ -7.5092,  -7.7906,  -7.7379,  ...,  -9.4978,  -7.9268,  -5.7376],\n",
      "         ...,\n",
      "         [ -5.9934,  -5.9626,  -5.9986,  ...,  -5.8782,  -6.1233,  -3.7298],\n",
      "         [ -5.5125,  -5.5007,  -5.5218,  ...,  -5.4608,  -5.9556,  -3.2153],\n",
      "         [ -5.2807,  -5.3497,  -5.4438,  ...,  -5.4649,  -6.5651,  -2.1720]],\n",
      "\n",
      "        [[ -6.4804,  -6.4418,  -6.4019,  ...,  -5.7279,  -5.4767,  -3.8358],\n",
      "         [ -6.7558,  -7.0074,  -6.7630,  ...,  -6.7393,  -6.8220,  -4.3756],\n",
      "         [ -9.9875, -10.0786,  -9.9000,  ...,  -8.7918,  -8.3613,  -7.1155],\n",
      "         ...,\n",
      "         [ -6.1734,  -6.3287,  -6.3532,  ...,  -6.2901,  -5.8556,  -3.8151],\n",
      "         [ -6.0747,  -6.0400,  -6.1151,  ...,  -5.7231,  -5.3966,  -3.2452],\n",
      "         [ -6.1409,  -6.2836,  -6.3796,  ...,  -6.3853,  -6.2617,  -3.2579]],\n",
      "\n",
      "        [[ -9.6237,  -9.8088,  -9.9045,  ...,  -8.6870,  -8.8210,  -5.2572],\n",
      "         [-12.4936, -12.5620, -12.3698,  ...,  -9.4045,  -9.6038, -10.6954],\n",
      "         [ -4.3972,  -4.5956,  -4.6040,  ...,  -4.7942,  -6.9658,  -2.4949],\n",
      "         ...,\n",
      "         [ -4.4569,  -4.6759,  -4.5552,  ...,  -3.7377,  -6.4417,  -2.8463],\n",
      "         [ -4.4317,  -4.6127,  -4.5971,  ...,  -3.7024,  -6.2176,  -1.5546],\n",
      "         [ -5.2101,  -5.3266,  -5.2964,  ...,  -4.8690,  -6.4349,  -3.0103]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.9157,  -8.0831,  -7.9339,  ...,  -7.4842,  -7.0323,  -4.2051],\n",
      "         [ -7.1158,  -7.2689,  -7.1768,  ...,  -6.3751,  -7.2122,  -3.9862],\n",
      "         [ -8.1432,  -7.6008,  -8.0449,  ...,  -9.0524,  -5.5844,  -6.3538],\n",
      "         ...,\n",
      "         [ -4.4918,  -4.6576,  -4.5671,  ...,  -5.6404,  -4.7634,  -4.2183],\n",
      "         [ -9.2994,  -9.7622,  -9.2347,  ...,  -9.5160,  -8.4386,  -6.8274],\n",
      "         [-10.2632, -10.7341, -10.5544,  ...,  -9.9476,  -9.2229, -10.1046]],\n",
      "\n",
      "        [[ -9.6575,  -9.7662,  -9.9176,  ...,  -9.5584, -10.3946,  -4.2893],\n",
      "         [-13.9978, -14.2049, -14.2796,  ..., -12.2936, -11.8503, -11.9964],\n",
      "         [ -4.8778,  -4.9807,  -5.1501,  ...,  -5.5057,  -6.8532,  -3.4897],\n",
      "         ...,\n",
      "         [ -5.0864,  -5.1639,  -5.4089,  ...,  -5.4035,  -6.7239,  -3.6001],\n",
      "         [ -5.0186,  -5.0730,  -5.2382,  ...,  -5.2353,  -6.1196,  -3.4456],\n",
      "         [ -5.7326,  -5.7175,  -5.8637,  ...,  -6.1426,  -7.2195,  -3.9535]],\n",
      "\n",
      "        [[ -6.6782,  -6.6617,  -6.6374,  ...,  -5.8435,  -5.9966,  -3.5666],\n",
      "         [ -6.6667,  -6.6987,  -6.7796,  ...,  -7.6421,  -7.2998,  -2.3829],\n",
      "         [ -7.3462,  -7.5725,  -7.4584,  ...,  -8.0499,  -6.8794,  -4.8429],\n",
      "         ...,\n",
      "         [ -5.7139,  -5.7743,  -5.8692,  ...,  -6.4117,  -6.0283,  -1.4153],\n",
      "         [ -5.9473,  -6.0774,  -6.1465,  ...,  -6.4317,  -5.6092,  -2.2886],\n",
      "         [ -5.4890,  -5.5716,  -5.6824,  ...,  -6.0337,  -6.0287,  -1.0395]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 3.4446234703063965\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4229, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.6391,  -7.6601,  -7.7120,  ...,  -7.1627,  -6.9008,  -4.1297],\n",
      "         [ -7.5810,  -8.3885,  -8.2377,  ...,  -6.8880,  -6.4089,  -7.0219],\n",
      "         [ -5.2342,  -5.7716,  -5.6535,  ...,  -5.1877,  -5.5216,  -7.1485],\n",
      "         ...,\n",
      "         [ -6.5339,  -7.3630,  -6.7134,  ...,  -6.8374,  -6.4013,  -4.4605],\n",
      "         [ -5.2938,  -5.2804,  -5.1183,  ...,  -3.9400,  -5.6810,  -3.4065],\n",
      "         [-12.2963, -12.6118, -12.4351,  ..., -10.4845, -11.1390, -11.8760]],\n",
      "\n",
      "        [[ -6.7148,  -6.7144,  -6.6834,  ...,  -5.9383,  -5.8302,  -3.9968],\n",
      "         [-12.4479, -12.3881, -12.5907,  ...,  -8.8884,  -9.4674, -10.5138],\n",
      "         [ -4.9771,  -5.1980,  -5.1705,  ...,  -5.6256,  -6.7555,  -2.7669],\n",
      "         ...,\n",
      "         [ -4.9447,  -5.0309,  -4.9882,  ...,  -5.0313,  -6.0470,  -2.7579],\n",
      "         [ -5.1366,  -5.3006,  -5.2406,  ...,  -5.4823,  -5.7663,  -3.2904],\n",
      "         [ -5.1333,  -5.2658,  -5.2576,  ...,  -5.2961,  -6.2093,  -2.4955]],\n",
      "\n",
      "        [[ -9.9318, -10.1427, -10.0539,  ...,  -9.9889,  -8.7738,  -6.6054],\n",
      "         [ -6.4518,  -6.2821,  -6.5019,  ...,  -5.7888,  -5.1317,  -5.5461],\n",
      "         [ -9.7234,  -9.8021,  -9.4928,  ...,  -8.7248,  -6.2765,  -8.3424],\n",
      "         ...,\n",
      "         [-14.2189, -13.8049, -14.3286,  ..., -11.6719, -10.9753, -14.0534],\n",
      "         [ -9.0573,  -8.9096,  -8.8147,  ...,  -8.6501,  -8.1151,  -8.4055],\n",
      "         [-10.5331, -10.9953, -10.3948,  ..., -10.1125,  -8.5035, -10.1719]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7162,  -6.6387,  -6.6577,  ...,  -5.9960,  -6.0241,  -3.6204],\n",
      "         [ -6.9639,  -6.8487,  -7.2206,  ...,  -7.2553,  -7.8849,  -2.6135],\n",
      "         [ -7.1663,  -7.2855,  -7.3839,  ...,  -7.9828,  -8.5737,  -3.4429],\n",
      "         ...,\n",
      "         [ -4.4213,  -4.4960,  -4.6556,  ...,  -5.0980,  -5.4477,  -1.1457],\n",
      "         [ -5.1356,  -5.2076,  -5.3045,  ...,  -5.9244,  -6.2658,  -1.4506],\n",
      "         [ -5.4086,  -5.3395,  -5.5136,  ...,  -5.9801,  -6.1044,  -1.9028]],\n",
      "\n",
      "        [[ -8.7774,  -8.9843,  -8.9053,  ...,  -8.0423,  -8.0435,  -5.4520],\n",
      "         [ -6.9536,  -6.9434,  -6.8990,  ...,  -9.3959,  -9.2960, -10.3067],\n",
      "         [ -9.0742,  -9.3281,  -9.1555,  ...,  -8.8834,  -9.6131,  -6.4837],\n",
      "         ...,\n",
      "         [ -5.1857,  -5.5948,  -5.2235,  ...,  -6.2441,  -5.9744,  -3.0345],\n",
      "         [ -7.1828,  -7.2895,  -7.2224,  ...,  -8.4161,  -8.0576,  -5.8364],\n",
      "         [ -6.9044,  -7.4869,  -7.2724,  ...,  -7.0179,  -7.4707,  -7.3847]],\n",
      "\n",
      "        [[ -7.6059,  -7.6241,  -7.5603,  ...,  -7.1045,  -6.5254,  -3.8254],\n",
      "         [-15.3762, -15.5465, -15.6743,  ..., -14.9703, -12.9851,  -9.9757],\n",
      "         [-11.3386, -11.0910, -11.6047,  ..., -13.3813, -10.1490, -13.6753],\n",
      "         ...,\n",
      "         [ -6.3332,  -6.5370,  -6.3829,  ...,  -6.3183,  -3.9896,  -5.3361],\n",
      "         [ -9.1614,  -9.4091,  -9.5307,  ...,  -8.6759,  -6.6813,  -5.7071],\n",
      "         [-14.1377, -14.8089, -14.5591,  ..., -16.5541, -11.2989,  -3.6209]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.422895073890686\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4475, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.4265,  -8.4570,  -8.3683,  ...,  -7.8663,  -7.5419,  -5.3868],\n",
      "         [ -9.1033,  -9.8401,  -9.6786,  ...,  -8.3192,  -7.4119,  -9.8470],\n",
      "         [-13.6538, -13.7747, -13.7094,  ..., -12.1522,  -9.9025,  -9.5998],\n",
      "         ...,\n",
      "         [ -2.4502,  -2.8251,  -2.9645,  ...,  -3.0063,  -2.6263,  -3.7127],\n",
      "         [ -6.3042,  -5.9144,  -6.5370,  ...,  -6.8352,  -5.9354,  -5.1148],\n",
      "         [-12.5345, -12.6498, -12.6479,  ..., -10.8366,  -8.4143, -11.8164]],\n",
      "\n",
      "        [[ -6.9181,  -6.8454,  -6.8793,  ...,  -5.9212,  -6.0126,  -4.1648],\n",
      "         [-15.0856, -14.6411, -14.6616,  ..., -12.8779, -12.3848, -10.5514],\n",
      "         [ -4.7990,  -4.8473,  -4.9522,  ...,  -4.6485,  -6.3555,  -4.1798],\n",
      "         ...,\n",
      "         [ -5.0441,  -5.0493,  -5.1542,  ...,  -4.8686,  -6.4070,  -4.1696],\n",
      "         [ -5.2831,  -5.2593,  -5.3810,  ...,  -5.1305,  -6.2625,  -4.6905],\n",
      "         [ -4.6205,  -4.6046,  -4.6438,  ...,  -4.6696,  -5.8679,  -3.8061]],\n",
      "\n",
      "        [[ -7.6472,  -7.7891,  -7.6873,  ...,  -7.0118,  -6.7715,  -5.4425],\n",
      "         [-14.5717, -14.1297, -14.3871,  ..., -13.3315, -12.3765, -13.3346],\n",
      "         [ -9.5307,  -9.7656,  -9.8348,  ..., -10.4685,  -8.4943,  -7.1609],\n",
      "         ...,\n",
      "         [-12.3678, -12.6375, -12.2040,  ..., -11.3118, -10.1618,  -9.1240],\n",
      "         [-11.3040, -11.2357, -11.0719,  ..., -10.0245,  -9.2620, -11.2439],\n",
      "         [-12.0571, -12.3442, -12.1292,  ..., -11.3421, -10.0602,  -9.8186]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.4499,  -8.3702,  -8.2722,  ...,  -7.9618,  -7.5753,  -4.6470],\n",
      "         [ -8.0570,  -8.0735,  -8.1239,  ...,  -7.0039,  -6.5961,  -6.1508],\n",
      "         [-12.1416, -11.9422, -12.2307,  ..., -11.6929, -10.1792,  -9.1949],\n",
      "         ...,\n",
      "         [ -7.4095,  -7.1837,  -7.4223,  ...,  -6.7510,  -7.1156,  -5.3376],\n",
      "         [ -7.8122,  -7.6863,  -7.8013,  ...,  -7.1864,  -7.0598,  -5.7446],\n",
      "         [ -9.2251,  -9.0749,  -9.1585,  ...,  -8.5473,  -7.9803,  -4.9652]],\n",
      "\n",
      "        [[ -6.8287,  -6.8459,  -6.7114,  ...,  -6.4140,  -5.8015,  -4.3290],\n",
      "         [ -9.6812,  -9.6866,  -9.6000,  ..., -10.0850,  -7.4808,  -9.4565],\n",
      "         [ -3.6414,  -3.8235,  -3.8635,  ...,  -4.1106,  -2.5753,  -1.9631],\n",
      "         ...,\n",
      "         [ -6.9320,  -7.1046,  -7.0957,  ...,  -6.2792,  -6.6007,  -5.3306],\n",
      "         [ -9.5278,  -9.7624,  -9.4770,  ...,  -9.2918,  -8.6458,  -4.7877],\n",
      "         [-13.5600, -13.6239, -13.4345,  ..., -11.7119,  -9.1544, -10.5472]],\n",
      "\n",
      "        [[ -7.4388,  -7.3051,  -7.2852,  ...,  -6.3509,  -6.5076,  -4.4338],\n",
      "         [-11.2383, -11.3553, -11.1475,  ...,  -7.4327,  -7.7616, -10.2354],\n",
      "         [ -4.5838,  -4.5810,  -4.7675,  ...,  -5.3002,  -6.6030,  -2.8330],\n",
      "         ...,\n",
      "         [ -5.1355,  -5.0479,  -5.2243,  ...,  -5.2698,  -6.3620,  -3.6071],\n",
      "         [ -5.0354,  -5.0987,  -5.3019,  ...,  -5.2997,  -6.4674,  -2.7010],\n",
      "         [ -4.5472,  -4.7804,  -4.9043,  ...,  -5.2573,  -6.8919,  -3.7425]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.4474704265594482\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4202, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3576,  -6.3328,  -6.3389,  ...,  -5.6705,  -5.5015,  -3.7952],\n",
      "         [ -9.1892,  -9.2195,  -9.3221,  ...,  -6.2291,  -7.2043,  -8.6902],\n",
      "         [ -5.0822,  -5.2763,  -5.2967,  ...,  -5.5582,  -6.4651,  -3.2457],\n",
      "         ...,\n",
      "         [ -5.5201,  -5.6752,  -5.6915,  ...,  -5.3295,  -6.9304,  -3.2170],\n",
      "         [ -5.6358,  -5.8578,  -5.8911,  ...,  -5.4765,  -6.7752,  -4.1038],\n",
      "         [ -5.0535,  -5.1672,  -5.2469,  ...,  -5.0436,  -6.5544,  -3.2678]],\n",
      "\n",
      "        [[ -7.4868,  -7.5061,  -7.4183,  ...,  -6.7823,  -6.2729,  -5.0447],\n",
      "         [ -4.8249,  -5.4171,  -5.1053,  ...,  -4.1870,  -4.4142,  -4.3977],\n",
      "         [-14.3449, -14.4030, -14.3615,  ..., -12.6204, -11.1798,  -9.1207],\n",
      "         ...,\n",
      "         [ -7.4627,  -7.5687,  -7.4082,  ...,  -6.9442,  -4.4854,  -7.1047],\n",
      "         [ -5.7576,  -5.9577,  -6.0822,  ...,  -5.7755,  -5.1914,  -5.1610],\n",
      "         [-15.3794, -15.2175, -15.1083,  ..., -14.7721, -10.4454, -12.0424]],\n",
      "\n",
      "        [[ -6.5148,  -6.4762,  -6.4665,  ...,  -5.7377,  -5.6672,  -3.8574],\n",
      "         [-13.1886, -12.9733, -12.9479,  ..., -10.4102, -11.2764, -10.7781],\n",
      "         [ -4.4163,  -4.6808,  -4.6542,  ...,  -5.0852,  -6.6061,  -3.0522],\n",
      "         ...,\n",
      "         [ -4.3520,  -4.5515,  -4.5267,  ...,  -4.3208,  -5.4716,  -3.9315],\n",
      "         [ -4.0309,  -4.1085,  -4.1008,  ...,  -4.1545,  -5.7553,  -3.1788],\n",
      "         [ -4.2957,  -4.5915,  -4.4071,  ...,  -3.7792,  -5.6308,  -2.6285]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5595,  -6.5212,  -6.5205,  ...,  -5.6845,  -5.6222,  -3.8680],\n",
      "         [-14.2894, -13.7204, -13.9291,  ..., -11.6561, -11.0929, -11.3736],\n",
      "         [ -5.2440,  -5.3599,  -5.4350,  ...,  -5.0643,  -6.7839,  -3.0108],\n",
      "         ...,\n",
      "         [ -6.3463,  -6.3579,  -6.5465,  ...,  -6.2454,  -7.3571,  -4.0105],\n",
      "         [ -5.4447,  -5.5994,  -5.6987,  ...,  -5.2911,  -6.5273,  -4.0365],\n",
      "         [ -5.6669,  -5.7614,  -5.8236,  ...,  -5.4989,  -6.5229,  -3.9237]],\n",
      "\n",
      "        [[ -7.2134,  -7.2455,  -7.1629,  ...,  -6.6818,  -6.1391,  -4.6572],\n",
      "         [-16.5872, -16.4340, -16.6844,  ..., -15.1532, -13.2022, -11.1113],\n",
      "         [ -6.0048,  -5.5124,  -5.7477,  ...,  -4.7893,  -3.8735,  -5.8134],\n",
      "         ...,\n",
      "         [ -5.3933,  -5.4289,  -5.7142,  ...,  -4.4104,  -4.0749,  -2.4188],\n",
      "         [ -5.9867,  -5.9097,  -6.3140,  ...,  -5.6121,  -4.9592,  -2.6140],\n",
      "         [ -5.9954,  -6.1383,  -6.2154,  ...,  -6.0163,  -5.2619,  -3.1406]],\n",
      "\n",
      "        [[ -6.6386,  -6.6107,  -6.6076,  ...,  -6.0770,  -5.9990,  -3.9600],\n",
      "         [ -5.1631,  -5.0497,  -5.4177,  ...,  -5.9987,  -6.8822,  -2.1776],\n",
      "         [ -5.6740,  -5.4108,  -5.6643,  ...,  -5.8809,  -6.0584,  -3.6730],\n",
      "         ...,\n",
      "         [ -5.3698,  -5.3891,  -5.5246,  ...,  -5.3107,  -5.7330,  -2.8245],\n",
      "         [ -5.4805,  -5.4044,  -5.5598,  ...,  -5.5032,  -6.1570,  -2.1098],\n",
      "         [ -5.0106,  -5.0609,  -5.1947,  ...,  -5.1471,  -5.8984,  -2.7906]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.4202120304107666\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2990, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0899,  -7.1374,  -7.0759,  ...,  -6.4878,  -6.2376,  -4.8854],\n",
      "         [-15.3660, -15.2480, -15.3250,  ..., -11.8091, -12.0122, -13.5513],\n",
      "         [-15.5006, -15.6516, -15.5494,  ..., -13.2462, -11.3179, -15.2677],\n",
      "         ...,\n",
      "         [ -4.9657,  -5.2771,  -5.0581,  ...,  -4.7980,  -4.3593,  -5.1226],\n",
      "         [ -5.7694,  -6.1066,  -5.7940,  ...,  -5.5899,  -4.7788,  -5.8950],\n",
      "         [ -6.6601,  -6.7512,  -6.7789,  ...,  -5.9289,  -5.2549,  -4.5473]],\n",
      "\n",
      "        [[ -8.7371,  -8.6912,  -8.5824,  ...,  -7.7023,  -7.9735,  -5.0333],\n",
      "         [-12.8084, -12.4657, -12.3875,  ..., -10.4655, -11.8925, -12.8712],\n",
      "         [ -5.9798,  -6.2265,  -6.3189,  ...,  -6.2755,  -8.2644,  -3.3454],\n",
      "         ...,\n",
      "         [ -5.1479,  -5.2153,  -5.5076,  ...,  -6.0158,  -7.5713,  -3.2595],\n",
      "         [ -5.2053,  -5.3448,  -5.3943,  ...,  -5.5126,  -7.3116,  -2.7752],\n",
      "         [ -4.9662,  -5.2125,  -5.1848,  ...,  -4.9269,  -6.7427,  -2.6977]],\n",
      "\n",
      "        [[ -7.3473,  -7.4070,  -7.2713,  ...,  -6.8254,  -6.2088,  -4.5363],\n",
      "         [ -8.6618,  -8.8337,  -8.8224,  ...,  -8.2735,  -9.2837,  -9.3270],\n",
      "         [ -8.3361,  -8.8012,  -8.2774,  ...,  -8.5791,  -5.7480, -10.0222],\n",
      "         ...,\n",
      "         [ -6.0596,  -6.3242,  -6.2456,  ...,  -5.8043,  -4.3109,  -6.6035],\n",
      "         [ -6.5028,  -6.9401,  -6.6275,  ...,  -6.2408,  -4.9945,  -0.1299],\n",
      "         [-13.2256, -13.1848, -13.2113,  ..., -11.8144,  -9.3732,  -9.5275]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.6857,  -8.6895,  -8.6219,  ...,  -7.7618,  -7.4527,  -4.4759],\n",
      "         [ -9.7183, -10.0402,  -9.7106,  ...,  -8.4585,  -9.0295,  -7.1357],\n",
      "         [-11.5494, -12.1607, -12.2046,  ..., -11.2264,  -9.6398, -10.9210],\n",
      "         ...,\n",
      "         [ -5.3275,  -5.3343,  -5.7398,  ...,  -5.2109,  -5.5638,  -5.2569],\n",
      "         [ -6.9240,  -6.9193,  -6.8815,  ...,  -6.2404,  -5.0310,  -6.3583],\n",
      "         [ -7.5216,  -7.5222,  -7.5307,  ...,  -6.9908,  -6.1973,  -5.5069]],\n",
      "\n",
      "        [[ -7.6672,  -7.7017,  -7.5857,  ...,  -7.1591,  -6.6228,  -5.0087],\n",
      "         [-12.8922, -13.1637, -12.9946,  ..., -11.8363, -12.7754,  -9.3089],\n",
      "         [ -4.1515,  -4.1453,  -4.1208,  ...,  -4.2747,  -3.8352,  -5.5882],\n",
      "         ...,\n",
      "         [-11.3842, -11.7826, -11.3048,  ..., -10.8764, -10.3557,  -8.2154],\n",
      "         [ -6.8061,  -6.9333,  -6.8271,  ...,  -6.1475,  -6.4409,  -4.7755],\n",
      "         [-12.3132, -12.7564, -12.3605,  ..., -11.9562, -11.4623,  -8.6326]],\n",
      "\n",
      "        [[ -6.3795,  -6.3652,  -6.2957,  ...,  -6.0664,  -5.9434,  -3.4256],\n",
      "         [-10.7720, -10.7077, -10.9016,  ...,  -9.7529,  -9.1571, -10.1658],\n",
      "         [ -5.2648,  -5.3022,  -5.4337,  ...,  -5.5543,  -6.3629,  -3.9034],\n",
      "         ...,\n",
      "         [ -4.9207,  -4.9358,  -4.9698,  ...,  -5.0118,  -5.6444,  -3.8706],\n",
      "         [ -5.4885,  -5.5336,  -5.6189,  ...,  -5.8703,  -6.1733,  -4.2647],\n",
      "         [ -5.5798,  -5.6263,  -5.7054,  ...,  -5.6719,  -6.5088,  -4.7471]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.2990171909332275\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0120, grad_fn=<NllLossBackward0>), logits=tensor([[[-14.3893, -14.5298, -14.2384,  ..., -11.9790, -12.2083, -14.6611],\n",
      "         [-12.5839, -12.7961, -12.7762,  ..., -10.9316, -10.5195,  -9.2214],\n",
      "         [ -4.2496,  -4.4847,  -4.4617,  ...,  -4.4545,  -5.9094,  -3.2230],\n",
      "         ...,\n",
      "         [ -5.5950,  -5.6578,  -5.6670,  ...,  -6.0107,  -6.1283,  -4.6979],\n",
      "         [ -5.3129,  -5.5635,  -5.5661,  ...,  -5.7701,  -5.7431,  -4.5756],\n",
      "         [ -4.8045,  -5.0177,  -4.9617,  ...,  -4.9174,  -6.4286,  -3.1556]],\n",
      "\n",
      "        [[ -6.7615,  -6.7288,  -6.7519,  ...,  -5.9895,  -5.9432,  -3.7975],\n",
      "         [ -6.7365,  -6.4526,  -6.8019,  ...,  -7.2532,  -6.8927,  -0.6554],\n",
      "         [ -6.9424,  -6.8774,  -7.1365,  ...,  -7.1026,  -6.9949,  -3.6725],\n",
      "         ...,\n",
      "         [ -5.1193,  -5.1307,  -5.3425,  ...,  -5.6565,  -5.4920,  -1.8281],\n",
      "         [ -4.9640,  -4.9179,  -5.1070,  ...,  -5.1101,  -5.2636,  -1.2718],\n",
      "         [ -5.5512,  -5.4402,  -5.6587,  ...,  -5.7933,  -5.7842,  -2.1917]],\n",
      "\n",
      "        [[ -7.9068,  -7.6960,  -7.6997,  ...,  -6.7598,  -6.6562,  -5.1033],\n",
      "         [-12.8482, -12.5342, -12.7917,  ...,  -8.5850, -10.9897, -12.8926],\n",
      "         [ -5.2503,  -5.2527,  -5.3885,  ...,  -5.6035,  -6.8116,  -3.1404],\n",
      "         ...,\n",
      "         [ -5.6295,  -5.7553,  -5.7313,  ...,  -5.6420,  -5.3350,  -4.0867],\n",
      "         [ -5.4478,  -5.5070,  -5.5786,  ...,  -5.5479,  -6.2756,  -3.7703],\n",
      "         [ -5.4648,  -5.5888,  -5.5509,  ...,  -5.7276,  -6.8070,  -4.0320]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6431,  -6.5749,  -6.6000,  ...,  -5.9208,  -5.7763,  -3.9044],\n",
      "         [ -8.0632,  -7.8411,  -7.9095,  ...,  -6.9208,  -7.1227,  -4.7850],\n",
      "         [ -6.3448,  -6.3294,  -6.5221,  ...,  -6.7688,  -7.2674,  -3.5301],\n",
      "         ...,\n",
      "         [ -6.0687,  -6.1550,  -6.1965,  ...,  -6.5284,  -6.5530,  -3.9972],\n",
      "         [ -6.6542,  -6.7568,  -6.7787,  ...,  -7.1030,  -7.6118,  -4.1032],\n",
      "         [ -6.2323,  -6.2966,  -6.3356,  ...,  -6.4806,  -6.7901,  -3.2951]],\n",
      "\n",
      "        [[ -8.6859,  -8.7369,  -8.6153,  ...,  -7.7625,  -7.4225,  -5.5700],\n",
      "         [ -4.0109,  -3.9641,  -3.6011,  ...,  -3.2235,  -3.4976,  -4.5124],\n",
      "         [-13.3088, -13.0231, -13.2726,  ..., -11.0400,  -9.7877, -10.0273],\n",
      "         ...,\n",
      "         [-15.8147, -15.8223, -15.9519,  ..., -11.7867, -12.2020, -11.8472],\n",
      "         [-10.7165, -10.7771, -10.9960,  ...,  -9.7271,  -7.7622,  -9.2819],\n",
      "         [-12.0971, -12.0918, -12.1663,  ..., -10.6887,  -8.1192, -12.0480]],\n",
      "\n",
      "        [[ -7.7766,  -7.6940,  -7.7042,  ...,  -7.6958,  -6.6592,  -4.8955],\n",
      "         [ -7.7753,  -7.9276,  -7.8427,  ...,  -7.7075,  -7.3726,  -3.6890],\n",
      "         [ -5.4890,  -6.1549,  -6.0831,  ...,  -7.3002,  -4.9250,   0.1964],\n",
      "         ...,\n",
      "         [-10.0046,  -9.2673,  -9.7307,  ...,  -8.0706,  -6.9858,  -3.7124],\n",
      "         [-14.0967, -13.4936, -13.4770,  ..., -11.7330, -12.7637, -11.1780],\n",
      "         [-13.5349, -13.9702, -13.8654,  ..., -12.4866, -10.7935, -11.7357]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.01200270652771\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6430, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3881,  -6.3748,  -6.3664,  ...,  -5.9290,  -5.8017,  -3.4579],\n",
      "         [ -7.3222,  -7.3348,  -7.5551,  ...,  -7.9690,  -8.7820,  -3.5663],\n",
      "         [ -6.6043,  -6.3999,  -6.5465,  ...,  -6.8597,  -7.7702,  -2.7193],\n",
      "         ...,\n",
      "         [ -5.5204,  -5.4841,  -5.6526,  ...,  -6.1633,  -6.5897,  -1.6084],\n",
      "         [ -5.5669,  -5.6142,  -5.7501,  ...,  -6.2736,  -6.0944,  -2.9691],\n",
      "         [ -5.9569,  -5.9868,  -6.1600,  ...,  -6.5774,  -6.6603,  -3.1677]],\n",
      "\n",
      "        [[ -6.6304,  -6.6433,  -6.6258,  ...,  -5.8805,  -5.7694,  -3.8879],\n",
      "         [-11.1454, -11.4395, -11.2167,  ..., -10.8716, -10.3910,  -7.0933],\n",
      "         [ -6.0756,  -6.3493,  -6.1564,  ...,  -6.8199,  -5.7453,  -5.0440],\n",
      "         ...,\n",
      "         [ -6.2142,  -6.3203,  -6.4080,  ...,  -6.6468,  -5.9853,  -4.4656],\n",
      "         [ -5.8134,  -5.8759,  -5.8920,  ...,  -5.8562,  -5.3603,  -4.1798],\n",
      "         [ -6.0325,  -6.1178,  -6.1372,  ...,  -6.2835,  -6.0896,  -3.9622]],\n",
      "\n",
      "        [[ -7.1586,  -7.1315,  -7.0672,  ...,  -6.5542,  -6.2019,  -3.9638],\n",
      "         [ -9.4703,  -9.3418,  -9.5655,  ...,  -9.6514,  -8.7247,  -6.3411],\n",
      "         [ -9.0273,  -9.0129,  -9.2276,  ...,  -8.0999,  -8.1333,  -4.0926],\n",
      "         ...,\n",
      "         [ -5.6079,  -5.6782,  -5.9024,  ...,  -6.2024,  -5.8267,  -3.4458],\n",
      "         [ -5.8828,  -5.9837,  -6.0792,  ...,  -6.4373,  -6.2760,  -3.7013],\n",
      "         [ -5.6680,  -5.8504,  -5.7216,  ...,  -6.0575,  -6.1263,  -3.7553]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5359,  -6.4646,  -6.5139,  ...,  -5.7777,  -5.6577,  -3.8243],\n",
      "         [-13.2500, -12.7909, -13.3218,  ...,  -9.4439, -10.8063,  -8.3971],\n",
      "         [ -5.2537,  -5.4503,  -5.5788,  ...,  -5.3715,  -6.8893,  -3.8832],\n",
      "         ...,\n",
      "         [ -5.0706,  -5.1236,  -5.3133,  ...,  -5.0019,  -5.9090,  -3.1291],\n",
      "         [ -5.2535,  -5.3514,  -5.5089,  ...,  -5.6331,  -6.4592,  -3.0871],\n",
      "         [ -5.0718,  -5.1868,  -5.2917,  ...,  -5.0651,  -6.1528,  -3.1463]],\n",
      "\n",
      "        [[ -6.4251,  -6.4123,  -6.4092,  ...,  -5.6088,  -5.7047,  -3.8498],\n",
      "         [-16.4377, -15.7884, -16.0173,  ..., -13.0751, -13.9392, -10.9222],\n",
      "         [ -5.3559,  -5.4798,  -5.5527,  ...,  -5.4634,  -6.7146,  -3.1684],\n",
      "         ...,\n",
      "         [ -5.3617,  -5.4697,  -5.5629,  ...,  -5.2726,  -6.7956,  -2.8670],\n",
      "         [ -5.3481,  -5.4457,  -5.5133,  ...,  -5.1509,  -6.6977,  -3.5923],\n",
      "         [ -5.8492,  -5.9078,  -5.9179,  ...,  -5.5767,  -6.4543,  -4.2296]],\n",
      "\n",
      "        [[ -6.9277,  -6.8845,  -6.8652,  ...,  -6.2223,  -6.1309,  -3.9808],\n",
      "         [-10.8348, -11.0472, -10.6593,  ..., -10.7113,  -9.0337,  -7.7788],\n",
      "         [ -9.9248, -10.5260, -10.2794,  ...,  -9.0949, -10.9761,  -2.9830],\n",
      "         ...,\n",
      "         [ -7.6433,  -7.7568,  -7.7292,  ...,  -7.7483,  -6.9283,  -4.6396],\n",
      "         [ -7.7327,  -7.7367,  -7.7062,  ...,  -7.9314,  -7.1898,  -4.9357],\n",
      "         [ -7.9456,  -7.9410,  -7.9281,  ...,  -7.7227,  -7.9853,  -5.1107]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6430413722991943\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8087, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.7549,  -7.8090,  -7.7831,  ...,  -7.3557,  -7.0094,  -5.3674],\n",
      "         [ -8.5131,  -8.8497,  -8.7304,  ...,  -7.3348,  -7.8956,  -7.0205],\n",
      "         [ -7.1446,  -7.2472,  -7.5425,  ...,  -7.0153,  -5.3254,  -5.0834],\n",
      "         ...,\n",
      "         [ -6.6057,  -6.5945,  -6.8287,  ...,  -6.9808,  -6.1208,  -6.5944],\n",
      "         [ -5.1704,  -5.0967,  -5.1830,  ...,  -4.6027,  -4.9401,  -7.2994],\n",
      "         [ -7.3096,  -7.3027,  -7.6332,  ...,  -7.0319,  -6.3621,  -6.7381]],\n",
      "\n",
      "        [[ -7.2963,  -7.3334,  -7.2193,  ...,  -6.7105,  -6.4110,  -4.1982],\n",
      "         [ -7.5025,  -7.5656,  -7.5202,  ...,  -7.7436,  -6.6759,  -3.1507],\n",
      "         [ -8.8737,  -9.1091,  -9.1460,  ...,  -9.7606,  -5.8347,  -9.3515],\n",
      "         ...,\n",
      "         [ -8.5722,  -8.7180,  -8.5684,  ...,  -7.9191,  -6.3422,  -7.4468],\n",
      "         [ -9.3610,  -9.3914,  -9.4617,  ...,  -9.3441,  -7.6323,  -7.3972],\n",
      "         [-11.9590, -11.5909, -11.7469,  ...,  -9.1695,  -8.2739,  -7.1244]],\n",
      "\n",
      "        [[ -6.3611,  -6.3211,  -6.3350,  ...,  -5.6667,  -5.5258,  -3.8813],\n",
      "         [-10.9012, -10.5070, -10.9402,  ...,  -7.6305,  -9.7910,  -5.7493],\n",
      "         [ -4.8480,  -4.9491,  -5.0337,  ...,  -4.8228,  -6.4305,  -3.1859],\n",
      "         ...,\n",
      "         [ -4.3777,  -4.4564,  -4.4278,  ...,  -4.5501,  -6.2446,  -2.8744],\n",
      "         [ -6.0924,  -6.1661,  -6.1395,  ...,  -6.1639,  -7.0839,  -3.9339],\n",
      "         [ -4.7775,  -4.9672,  -4.9448,  ...,  -5.0933,  -6.5585,  -3.8771]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.3296,  -8.4938,  -8.3823,  ...,  -7.9195,  -7.5257,  -5.9311],\n",
      "         [ -5.3932,  -5.7228,  -5.3612,  ...,  -4.2954,  -3.9383,  -5.5198],\n",
      "         [ -8.9020,  -8.9937,  -8.8566,  ...,  -9.0895,  -6.2630,  -9.2152],\n",
      "         ...,\n",
      "         [ -9.9583, -10.0763,  -9.6347,  ...,  -7.8376,  -6.9152,  -7.3808],\n",
      "         [-11.2350, -11.4088, -11.0527,  ...,  -8.8744,  -8.5805,  -6.5636],\n",
      "         [-13.7098, -14.0995, -13.6784,  ..., -13.6038, -10.4230,  -8.6724]],\n",
      "\n",
      "        [[ -6.9648,  -6.8765,  -6.9126,  ...,  -6.2335,  -6.4163,  -3.6126],\n",
      "         [ -7.5892,  -7.2872,  -7.6467,  ...,  -7.8714,  -8.3322,  -2.5699],\n",
      "         [ -7.9410,  -7.6548,  -7.9626,  ...,  -8.0706,  -8.2317,  -5.0960],\n",
      "         ...,\n",
      "         [ -5.2805,  -5.1294,  -5.3363,  ...,  -5.6554,  -6.1516,  -1.9238],\n",
      "         [ -5.5047,  -5.3499,  -5.5335,  ...,  -5.6962,  -5.8335,  -2.8908],\n",
      "         [ -6.1159,  -5.9979,  -6.1963,  ...,  -6.1873,  -6.6365,  -2.6772]],\n",
      "\n",
      "        [[ -6.9806,  -7.0134,  -6.9143,  ...,  -6.4564,  -6.1759,  -4.3899],\n",
      "         [ -6.2585,  -6.0894,  -6.3396,  ...,  -7.0649,  -5.3684,  -4.2006],\n",
      "         [ -7.5372,  -7.5209,  -7.2512,  ...,  -7.3849,  -5.8147,  -2.9990],\n",
      "         ...,\n",
      "         [ -5.1046,  -5.3377,  -5.3664,  ...,  -6.1883,  -5.1080,  -4.1716],\n",
      "         [ -9.2693,  -9.3456,  -9.3082,  ...,  -8.3763,  -6.6895,   0.1939],\n",
      "         [-12.5588, -12.6039, -12.9585,  ..., -11.7025,  -9.6672,  -7.8083]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.808736801147461\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8593, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3942,  -6.3629,  -6.3862,  ...,  -5.7587,  -5.5875,  -3.7964],\n",
      "         [-14.0279, -13.4689, -13.9335,  ..., -10.5961, -10.2675,  -9.1083],\n",
      "         [ -5.4892,  -5.5110,  -5.5942,  ...,  -5.7049,  -6.2157,  -3.9128],\n",
      "         ...,\n",
      "         [ -5.6868,  -5.6819,  -5.7640,  ...,  -5.5428,  -6.2642,  -4.2520],\n",
      "         [ -5.4723,  -5.4844,  -5.5829,  ...,  -5.5062,  -6.5335,  -4.0440],\n",
      "         [ -5.9739,  -6.0121,  -6.1234,  ...,  -5.8721,  -6.4958,  -4.3475]],\n",
      "\n",
      "        [[ -6.9266,  -6.9059,  -6.8733,  ...,  -6.1274,  -6.2345,  -3.9470],\n",
      "         [ -5.3732,  -5.1757,  -5.4775,  ...,  -4.7992,  -6.3361,  -3.1639],\n",
      "         [ -3.3716,  -3.2952,  -3.5505,  ...,  -3.6984,  -4.3552,   1.8846],\n",
      "         ...,\n",
      "         [ -5.3663,  -5.2820,  -5.6485,  ...,  -5.2566,  -6.2822,  -2.1513],\n",
      "         [ -5.9039,  -5.7133,  -5.8379,  ...,  -5.3853,  -6.2339,  -3.2173],\n",
      "         [ -5.9524,  -5.8188,  -6.0894,  ...,  -6.1225,  -6.4940,  -2.2213]],\n",
      "\n",
      "        [[ -6.1782,  -6.1216,  -6.1168,  ...,  -5.5650,  -5.2918,  -3.9410],\n",
      "         [ -9.9231,  -9.4874,  -9.5830,  ...,  -6.8513,  -8.1567,  -7.5926],\n",
      "         [ -4.7375,  -4.7386,  -4.9048,  ...,  -4.9688,  -6.3470,  -2.5845],\n",
      "         ...,\n",
      "         [ -5.4483,  -5.4703,  -5.4954,  ...,  -5.4695,  -6.2435,  -3.8382],\n",
      "         [ -5.9784,  -6.1100,  -6.1255,  ...,  -6.1750,  -6.3597,  -3.8272],\n",
      "         [ -5.4321,  -5.4101,  -5.5308,  ...,  -5.3760,  -5.8807,  -3.7728]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6551,  -6.6686,  -6.6902,  ...,  -5.9732,  -5.7474,  -4.1053],\n",
      "         [-12.6955, -12.6979, -12.5159,  ..., -10.4701, -10.7346,  -9.4623],\n",
      "         [ -4.7060,  -4.7897,  -4.9331,  ...,  -5.5189,  -7.4918,  -1.8176],\n",
      "         ...,\n",
      "         [ -5.1819,  -5.1906,  -5.2528,  ...,  -5.2201,  -7.1126,  -3.6548],\n",
      "         [ -5.6943,  -5.7775,  -5.8093,  ...,  -6.1602,  -7.5661,  -2.2264],\n",
      "         [ -5.9281,  -6.0102,  -5.9610,  ...,  -6.3266,  -7.3780,  -3.2667]],\n",
      "\n",
      "        [[ -6.6255,  -6.5790,  -6.5890,  ...,  -6.0093,  -5.9177,  -3.5069],\n",
      "         [ -8.2244,  -8.2759,  -8.5186,  ...,  -9.1794,  -9.1199,  -4.1825],\n",
      "         [ -7.2807,  -7.3136,  -7.5660,  ...,  -8.3242,  -7.5865,  -4.8472],\n",
      "         ...,\n",
      "         [ -5.7379,  -5.6701,  -5.8866,  ...,  -6.1811,  -6.4189,  -3.2672],\n",
      "         [ -4.9698,  -4.9724,  -5.2635,  ...,  -6.0680,  -5.9438,  -1.1765],\n",
      "         [ -4.7885,  -4.8058,  -4.9402,  ...,  -5.1589,  -5.5300,  -1.5710]],\n",
      "\n",
      "        [[ -6.6016,  -6.5427,  -6.5236,  ...,  -6.0395,  -5.7737,  -4.0108],\n",
      "         [-12.6148, -12.2811, -12.4143,  ...,  -9.6834,  -9.7745, -11.6932],\n",
      "         [ -6.3868,  -6.4857,  -6.3980,  ...,  -6.6178,  -6.4537,  -4.7328],\n",
      "         ...,\n",
      "         [ -6.1481,  -6.3955,  -6.2712,  ...,  -5.9243,  -5.7169,  -4.3585],\n",
      "         [ -6.2614,  -6.4913,  -6.3314,  ...,  -6.7819,  -6.1388,  -4.9080],\n",
      "         [ -6.3142,  -6.5076,  -6.3711,  ...,  -6.1653,  -5.8090,  -4.4779]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.859290599822998\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9036, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4753,  -6.4567,  -6.4585,  ...,  -5.8864,  -5.6284,  -3.9567],\n",
      "         [-12.0761, -11.6630, -11.6884,  ...,  -9.8068, -10.4911,  -8.1410],\n",
      "         [ -5.5896,  -5.7161,  -5.7609,  ...,  -5.9380,  -6.8519,  -2.9229],\n",
      "         ...,\n",
      "         [ -5.7868,  -5.9180,  -5.9163,  ...,  -5.7205,  -6.7456,  -3.6441],\n",
      "         [ -5.5963,  -5.6389,  -5.6671,  ...,  -5.9501,  -6.7044,  -4.5644],\n",
      "         [ -5.4508,  -5.5376,  -5.5518,  ...,  -5.3389,  -6.3260,  -3.6898]],\n",
      "\n",
      "        [[ -6.5738,  -6.5752,  -6.5575,  ...,  -6.0864,  -5.9987,  -4.0843],\n",
      "         [-14.5202, -14.6543, -14.5666,  ..., -14.3039, -14.1143, -13.7916],\n",
      "         [ -9.3745,  -9.5759,  -9.5179,  ...,  -8.9467,  -9.7435,  -7.0656],\n",
      "         ...,\n",
      "         [ -5.2222,  -5.2583,  -5.1553,  ...,  -5.5741,  -5.7205,  -2.8114],\n",
      "         [ -6.3785,  -6.4006,  -6.3701,  ...,  -6.4488,  -6.4306,  -2.9774],\n",
      "         [ -7.7069,  -7.7977,  -7.8255,  ...,  -7.7704,  -7.5663,  -4.6498]],\n",
      "\n",
      "        [[ -7.5627,  -7.6206,  -7.5434,  ...,  -6.5839,  -6.8792,  -4.2787],\n",
      "         [-10.5802, -11.1839, -10.9622,  ..., -10.5219,  -7.5168, -10.7001],\n",
      "         [ -8.5950,  -8.9973,  -8.2841,  ...,  -9.3329,  -8.7917,  -5.9644],\n",
      "         ...,\n",
      "         [-11.6777, -12.4290, -12.0889,  ..., -11.4905, -11.0151, -11.3514],\n",
      "         [ -6.3491,  -6.4775,  -6.5264,  ...,  -5.4656,  -5.1478,  -6.6470],\n",
      "         [-11.3841, -11.7486, -11.5597,  ..., -10.5888,  -9.2994,  -8.0643]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4756,  -7.6112,  -7.5242,  ...,  -6.6687,  -6.7825,  -4.2373],\n",
      "         [-10.6822, -11.1128, -11.1784,  ...,  -9.5458,  -9.2573,  -7.8635],\n",
      "         [ -7.4380,  -7.8897,  -8.1004,  ...,  -8.5541,  -5.0666, -12.3921],\n",
      "         ...,\n",
      "         [ -6.6271,  -7.0752,  -7.0308,  ...,  -7.9882,  -6.3038,  -7.3292],\n",
      "         [ -6.4700,  -6.7430,  -6.8144,  ...,  -7.0322,  -6.3117,  -4.6875],\n",
      "         [ -5.6453,  -5.8909,  -5.9980,  ...,  -6.5260,  -5.6550,  -5.6228]],\n",
      "\n",
      "        [[ -6.5998,  -6.5700,  -6.5918,  ...,  -5.8502,  -5.7144,  -3.7276],\n",
      "         [-11.8062, -11.6102, -11.7616,  ...,  -9.9761,  -9.5811, -13.1792],\n",
      "         [ -5.8644,  -5.8911,  -6.0878,  ...,  -5.9316,  -7.6674,  -3.0120],\n",
      "         ...,\n",
      "         [ -5.1802,  -5.2396,  -5.4202,  ...,  -5.1451,  -7.0965,  -2.9838],\n",
      "         [ -5.0870,  -5.0367,  -5.2778,  ...,  -5.1349,  -6.6800,  -3.2802],\n",
      "         [ -5.5381,  -5.6369,  -5.7872,  ...,  -5.7855,  -6.5559,  -3.8311]],\n",
      "\n",
      "        [[ -7.5973,  -7.6375,  -7.5219,  ...,  -6.2001,  -7.0705,  -4.2475],\n",
      "         [ -8.9263,  -9.0464,  -9.1874,  ...,  -7.2580,  -8.6306,  -5.8366],\n",
      "         [ -4.3403,  -4.3365,  -4.4641,  ...,  -4.5591,  -6.6629,  -1.9497],\n",
      "         ...,\n",
      "         [ -6.5114,  -6.7094,  -6.7455,  ...,  -6.3783,  -8.4211,  -2.1857],\n",
      "         [ -4.4910,  -4.7124,  -4.6673,  ...,  -3.8017,  -6.7563,  -2.1226],\n",
      "         [ -4.8065,  -4.9095,  -4.9093,  ...,  -3.8353,  -6.8030,  -2.9112]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.9036020040512085\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9053, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.6468,  -7.7273,  -7.6830,  ...,  -7.1257,  -6.4349,  -5.0165],\n",
      "         [-10.0439,  -9.8906,  -9.7223,  ...,  -9.6851,  -7.6558, -10.1565],\n",
      "         [ -3.0205,  -3.0451,  -3.0643,  ...,  -2.0573,  -1.5288,  -4.2661],\n",
      "         ...,\n",
      "         [ -5.0749,  -5.4939,  -5.2206,  ...,  -5.8107,  -3.0189,  -5.4031],\n",
      "         [ -3.8139,  -4.1664,  -4.0524,  ...,  -3.8494,  -2.4473,  -4.3973],\n",
      "         [ -3.7465,  -4.1748,  -4.2920,  ...,  -5.1537,  -0.7617,  -3.3644]],\n",
      "\n",
      "        [[ -7.5834,  -7.5385,  -7.4994,  ...,  -6.4808,  -6.5777,  -4.2451],\n",
      "         [-18.2252, -18.1210, -17.9953,  ..., -15.8699, -15.1507, -13.3764],\n",
      "         [ -5.4587,  -5.5392,  -5.7300,  ...,  -5.6966,  -6.9478,  -2.1853],\n",
      "         ...,\n",
      "         [ -5.8149,  -5.8811,  -6.0315,  ...,  -4.9856,  -7.1794,  -3.1139],\n",
      "         [ -4.8887,  -4.9979,  -5.1093,  ...,  -4.7684,  -6.7191,  -2.5682],\n",
      "         [ -5.1667,  -5.3154,  -5.4806,  ...,  -4.9732,  -6.8319,  -2.3591]],\n",
      "\n",
      "        [[ -7.0400,  -7.0475,  -6.9916,  ...,  -6.5369,  -6.2120,  -4.1664],\n",
      "         [ -5.2638,  -5.1693,  -5.3962,  ...,  -6.1355,  -5.4440,  -2.3699],\n",
      "         [-14.4071, -15.0019, -14.2303,  ..., -13.6529, -12.1457, -14.1441],\n",
      "         ...,\n",
      "         [ -8.3784,  -8.7141,  -8.4226,  ...,  -7.7802,  -7.5839,  -5.6898],\n",
      "         [-10.1419, -10.2511, -10.0171,  ..., -10.7415,  -8.7952,  -8.0779],\n",
      "         [-13.0641, -12.7563, -13.2533,  ..., -11.0733,  -9.3902,  -8.5182]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8082,  -6.8162,  -6.8564,  ...,  -6.0990,  -6.1454,  -3.3079],\n",
      "         [ -6.9093,  -6.5439,  -6.9809,  ...,  -7.5965,  -7.0910,  -5.1650],\n",
      "         [ -6.8745,  -6.7231,  -6.8403,  ...,  -7.3262,  -7.0553,  -4.0525],\n",
      "         ...,\n",
      "         [ -5.6794,  -5.6436,  -5.7504,  ...,  -5.4767,  -5.8728,  -3.2556],\n",
      "         [ -5.4812,  -5.4962,  -5.6889,  ...,  -5.6288,  -5.6822,  -3.0322],\n",
      "         [ -5.4113,  -5.3860,  -5.5756,  ...,  -5.5382,  -6.0147,  -2.3594]],\n",
      "\n",
      "        [[ -6.9193,  -6.9086,  -6.9004,  ...,  -6.1661,  -6.1163,  -3.4585],\n",
      "         [ -7.7460,  -7.6338,  -7.7265,  ...,  -8.6648,  -8.7599,  -2.3530],\n",
      "         [ -7.8973,  -7.8301,  -7.9981,  ...,  -8.3810,  -8.9961,  -1.2826],\n",
      "         ...,\n",
      "         [ -6.0986,  -6.1071,  -6.2082,  ...,  -5.8711,  -6.0769,  -0.7012],\n",
      "         [ -5.5391,  -5.5220,  -5.7518,  ...,  -6.0358,  -6.0608,  -0.8911],\n",
      "         [ -5.8270,  -5.7764,  -5.9588,  ...,  -6.1502,  -6.0525,  -1.7077]],\n",
      "\n",
      "        [[ -6.8487,  -6.8564,  -6.8140,  ...,  -6.2502,  -5.9745,  -4.1770],\n",
      "         [-10.8762, -10.5768, -10.6066,  ...,  -8.9044,  -9.5184,  -9.9091],\n",
      "         [ -5.9039,  -6.1807,  -6.2100,  ...,  -6.0682,  -6.8798,  -1.8266],\n",
      "         ...,\n",
      "         [ -5.7928,  -6.0058,  -5.9888,  ...,  -6.1560,  -6.6744,  -3.1594],\n",
      "         [ -5.5155,  -5.7827,  -5.8096,  ...,  -5.7394,  -6.6575,  -2.5861],\n",
      "         [ -5.6639,  -5.8707,  -5.8199,  ...,  -5.9732,  -6.6285,  -2.4434]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.9053303003311157\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0652, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1069,  -7.1780,  -7.1235,  ...,  -6.6196,  -6.4016,  -4.0525],\n",
      "         [ -5.8513,  -5.4661,  -5.7402,  ...,  -7.0576,  -4.4451,  -4.8121],\n",
      "         [-12.7179, -12.6264, -12.7141,  ..., -10.4354,  -9.4256, -11.1013],\n",
      "         ...,\n",
      "         [ -7.6198,  -7.7715,  -7.6610,  ...,  -7.6620,  -7.1408,  -5.9184],\n",
      "         [ -3.6097,  -3.5754,  -3.5872,  ...,  -2.8830,  -3.5011,  -1.6454],\n",
      "         [-11.7022, -11.9823, -11.8343,  ..., -11.3468,  -8.9620,  -6.2399]],\n",
      "\n",
      "        [[ -6.8350,  -6.9189,  -6.8670,  ...,  -6.2167,  -6.1508,  -4.3081],\n",
      "         [ -6.3201,  -6.3048,  -6.3118,  ...,  -6.4220,  -5.6944,  -3.3138],\n",
      "         [ -9.6652,  -9.8278,  -9.7891,  ...,  -8.4858,  -7.3040,  -6.0563],\n",
      "         ...,\n",
      "         [  2.3135,   2.1573,   2.4258,  ...,   1.7000,   1.3891,   0.9041],\n",
      "         [ -5.8100,  -5.7659,  -5.7843,  ...,  -6.3872,  -5.6670,  -3.6517],\n",
      "         [ -5.4920,  -5.7071,  -5.5389,  ...,  -6.2263,  -5.1290,  -3.8118]],\n",
      "\n",
      "        [[ -7.3294,  -7.3193,  -7.2275,  ...,  -6.7397,  -6.4500,  -4.0214],\n",
      "         [ -8.3860,  -8.0761,  -8.5049,  ...,  -6.6549,  -7.0781,  -8.3296],\n",
      "         [ -4.5561,  -4.4840,  -4.5049,  ...,  -3.8931,  -3.5224,  -6.1761],\n",
      "         ...,\n",
      "         [ -4.9050,  -4.6254,  -4.7931,  ...,  -6.4818,  -5.2325,  -5.5008],\n",
      "         [-11.3818, -11.1467, -11.1714,  ..., -10.8670,  -9.3280,  -7.5835],\n",
      "         [-11.2474, -11.4282, -11.1733,  ..., -11.8723,  -8.4720,  -5.7103]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.1872,  -8.1586,  -8.0776,  ...,  -7.5114,  -7.0264,  -5.3258],\n",
      "         [ -7.0416,  -7.2825,  -7.1004,  ...,  -8.0443,  -7.1735,  -8.9123],\n",
      "         [ -4.9082,  -5.0979,  -4.7640,  ...,  -6.2677,  -5.6159,  -6.8810],\n",
      "         ...,\n",
      "         [ -5.5756,  -5.7836,  -5.8101,  ...,  -6.4470,  -3.7520,  -4.4409],\n",
      "         [ -7.6269,  -7.5798,  -7.6237,  ...,  -8.0380,  -4.4634,  -3.5665],\n",
      "         [-11.2377, -11.0986, -11.4926,  ...,  -9.4683,  -7.3740,  -8.1948]],\n",
      "\n",
      "        [[ -6.6025,  -6.5342,  -6.5606,  ...,  -5.8196,  -5.7959,  -3.7758],\n",
      "         [ -7.4670,  -7.3425,  -7.5213,  ...,  -8.0782,  -7.9240,  -5.5260],\n",
      "         [ -5.0170,  -4.7748,  -4.9309,  ...,  -5.0518,  -4.9299,  -1.5512],\n",
      "         ...,\n",
      "         [ -5.4541,  -5.3630,  -5.4630,  ...,  -5.1231,  -5.6821,  -2.1956],\n",
      "         [ -5.1027,  -4.9138,  -5.0398,  ...,  -5.2015,  -5.6127,  -1.4558],\n",
      "         [ -5.6856,  -5.5719,  -5.6969,  ...,  -5.6145,  -5.9393,  -2.3022]],\n",
      "\n",
      "        [[ -7.8131,  -7.8547,  -7.7566,  ...,  -7.2218,  -6.8345,  -4.9157],\n",
      "         [ -8.4886,  -8.6618,  -8.4314,  ...,  -9.6375,  -9.5962,  -4.4003],\n",
      "         [ -7.4561,  -7.2636,  -7.2349,  ...,  -6.5758,  -7.0746,  -5.4001],\n",
      "         ...,\n",
      "         [ -7.3849,  -7.8324,  -7.6717,  ...,  -7.7997,  -6.6049,  -8.0059],\n",
      "         [ -8.4469,  -8.7515,  -8.5484,  ...,  -7.8978,  -7.0977, -11.5762],\n",
      "         [ -7.8337,  -8.2022,  -8.0120,  ...,  -7.8662,  -6.8593,  -7.2174]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.0652413368225098\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0808, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3070,  -6.2799,  -6.2953,  ...,  -5.6454,  -5.5365,  -3.6335],\n",
      "         [-11.0578, -11.0005, -11.0025,  ...,  -9.9560,  -9.7553,  -5.9768],\n",
      "         [ -5.6488,  -5.6952,  -5.7932,  ...,  -5.8573,  -6.8747,  -3.8062],\n",
      "         ...,\n",
      "         [ -5.6427,  -5.8207,  -5.8516,  ...,  -5.4281,  -7.1876,  -3.4701],\n",
      "         [ -5.8240,  -5.8674,  -5.9232,  ...,  -5.4814,  -6.8381,  -3.9503],\n",
      "         [ -4.7390,  -4.7877,  -4.7943,  ...,  -4.9440,  -6.1756,  -3.2097]],\n",
      "\n",
      "        [[ -8.8151,  -8.7073,  -8.7679,  ...,  -7.2130,  -7.4502,  -5.4090],\n",
      "         [-13.0400, -13.1556, -13.0711,  ..., -11.7952, -10.2636,  -8.7398],\n",
      "         [ -4.6484,  -4.6064,  -4.8594,  ...,  -5.1216,  -6.4069,  -2.9362],\n",
      "         ...,\n",
      "         [ -4.4741,  -4.4278,  -4.5143,  ...,  -4.7429,  -5.6634,  -2.9481],\n",
      "         [ -4.5977,  -4.5158,  -4.4648,  ...,  -4.8297,  -6.2385,  -3.8274],\n",
      "         [ -5.5417,  -5.5434,  -5.5257,  ...,  -5.4272,  -6.2713,  -3.7726]],\n",
      "\n",
      "        [[ -7.5815,  -7.5612,  -7.5579,  ...,  -7.1166,  -6.9005,  -4.0691],\n",
      "         [ -9.4734,  -9.8381,  -9.6491,  ...,  -9.3147,  -9.2972,  -7.9335],\n",
      "         [-10.0888, -10.2402, -10.4448,  ...,  -9.1099,  -9.0843,  -9.4442],\n",
      "         ...,\n",
      "         [-12.7667, -13.1291, -13.0695,  ..., -11.8811, -10.9959,  -9.1055],\n",
      "         [ -7.8553,  -7.7479,  -7.7029,  ...,  -7.0236,  -7.5157,  -2.4029],\n",
      "         [-13.1070, -12.9606, -12.9733,  ..., -10.4604, -11.9435,  -9.6351]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9786,  -6.9769,  -6.9311,  ...,  -6.2285,  -5.9700,  -4.2221],\n",
      "         [ -8.0669,  -7.6638,  -7.8455,  ...,  -5.6144,  -6.3086,  -6.7137],\n",
      "         [ -4.4726,  -4.6020,  -4.5474,  ...,  -3.4465,  -3.3496,  -1.7340],\n",
      "         ...,\n",
      "         [ -7.6004,  -7.6790,  -7.6061,  ...,  -7.4350,  -6.8793,  -3.6149],\n",
      "         [ -8.1663,  -8.3133,  -8.2280,  ...,  -7.7357,  -7.4100,  -3.5253],\n",
      "         [ -8.2010,  -8.2554,  -8.3093,  ...,  -7.8287,  -7.1570,  -4.2000]],\n",
      "\n",
      "        [[ -7.2997,  -7.3185,  -7.2096,  ...,  -6.5902,  -6.6539,  -4.4334],\n",
      "         [-12.4938, -12.8415, -12.7908,  ..., -10.5508, -12.2886, -11.6750],\n",
      "         [ -8.5294,  -7.8720,  -8.1915,  ...,  -5.8891,  -9.4481,  -8.5550],\n",
      "         ...,\n",
      "         [ -5.1351,  -5.1437,  -5.4976,  ...,  -4.9919,  -6.0330,  -4.8365],\n",
      "         [ -7.1709,  -7.2457,  -7.4752,  ...,  -6.6759,  -7.0745,  -5.4118],\n",
      "         [ -6.7285,  -6.8170,  -6.8327,  ...,  -6.6820,  -6.8406,  -5.5988]],\n",
      "\n",
      "        [[ -7.7186,  -7.7613,  -7.6539,  ...,  -6.8841,  -6.8478,  -3.2451],\n",
      "         [-11.0979, -11.1539, -11.0780,  ...,  -9.8467,  -8.8448,  -2.6600],\n",
      "         [ -5.8496,  -6.1619,  -6.0902,  ...,  -6.3207,  -5.2324,  -2.6996],\n",
      "         ...,\n",
      "         [ -4.5831,  -5.0729,  -4.5161,  ...,  -5.2582,  -3.8390,  -1.5332],\n",
      "         [ -9.9557, -10.0997,  -9.8013,  ...,  -9.4218,  -8.7215,  -6.0076],\n",
      "         [-12.9705, -12.8863, -13.0048,  ..., -10.7946,  -9.0556,  -8.6603]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.08076810836792\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7196, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9628,  -6.9899,  -6.9761,  ...,  -6.5341,  -6.1497,  -4.3231],\n",
      "         [-13.2196, -13.6325, -13.4924,  ..., -12.1509, -12.2133,  -9.9698],\n",
      "         [-10.6256, -10.7051, -10.7535,  ...,  -9.1834,  -9.0014,  -9.4974],\n",
      "         ...,\n",
      "         [ -6.9626,  -7.0226,  -7.0815,  ...,  -8.2498,  -7.6837,  -6.0009],\n",
      "         [ -6.0461,  -6.2067,  -6.2818,  ...,  -6.3524,  -6.1950,  -3.6241],\n",
      "         [ -4.5383,  -4.6927,  -4.6842,  ...,  -4.6608,  -4.4487,  -1.9251]],\n",
      "\n",
      "        [[ -6.6151,  -6.5863,  -6.5697,  ...,  -5.8698,  -5.7142,  -3.7891],\n",
      "         [ -9.7311,  -9.6294,  -9.7534,  ..., -10.4799, -10.4611,  -3.7456],\n",
      "         [-11.3559, -11.2857, -11.6589,  ...,  -9.7658,  -9.7332,  -8.5408],\n",
      "         ...,\n",
      "         [ -7.0122,  -6.9607,  -6.8884,  ...,  -6.9030,  -8.1828,  -5.2692],\n",
      "         [ -7.7423,  -7.7453,  -7.6569,  ...,  -7.9479,  -7.6141,  -5.2603],\n",
      "         [ -7.6007,  -7.6225,  -7.5816,  ...,  -7.8711,  -7.0162,  -3.7602]],\n",
      "\n",
      "        [[ -8.6008,  -8.6820,  -8.5429,  ...,  -7.7170,  -8.6690,  -3.8206],\n",
      "         [ -8.2990,  -8.0623,  -8.3588,  ...,  -6.3506,  -6.8739,  -6.7151],\n",
      "         [-12.5689, -12.8022, -12.7631,  ...,  -9.9768,  -9.6697,  -7.3536],\n",
      "         ...,\n",
      "         [ -8.5254,  -8.5897,  -8.2139,  ...,  -7.5769,  -7.3998,  -2.8997],\n",
      "         [ -0.7016,  -0.4100,  -0.4441,  ...,  -0.4619,  -0.4851,   0.5177],\n",
      "         [-16.5765, -16.8972, -16.7912,  ..., -15.2114, -14.7177, -11.8654]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.1047,  -8.0791,  -8.1236,  ...,  -7.1918,  -7.4660,  -4.8486],\n",
      "         [-14.7236, -14.4068, -14.4770,  ..., -12.8766, -11.7008, -10.4078],\n",
      "         [ -4.8328,  -4.7648,  -4.9986,  ...,  -5.7911,  -7.1588,  -2.1489],\n",
      "         ...,\n",
      "         [ -5.5966,  -5.6953,  -5.6923,  ...,  -6.5234,  -7.1732,  -3.5282],\n",
      "         [ -4.6180,  -4.6726,  -4.7093,  ...,  -5.1548,  -5.6937,  -2.4063],\n",
      "         [ -5.3725,  -5.5217,  -5.4273,  ...,  -5.8162,  -6.9241,  -3.8370]],\n",
      "\n",
      "        [[ -6.9241,  -6.8719,  -6.8881,  ...,  -6.1999,  -6.1902,  -3.5805],\n",
      "         [ -5.4327,  -5.2581,  -5.3728,  ...,  -6.2971,  -6.9182,  -1.6717],\n",
      "         [-11.4156, -11.1099, -11.5130,  ...,  -8.7533, -11.6344,  -9.8481],\n",
      "         ...,\n",
      "         [ -6.1952,  -6.0988,  -6.2127,  ...,  -6.2958,  -6.4782,  -1.4382],\n",
      "         [ -5.9459,  -5.9468,  -6.0442,  ...,  -6.2523,  -6.4474,  -1.5453],\n",
      "         [ -5.3455,  -5.3221,  -5.4458,  ...,  -5.4024,  -5.5994,  -0.9592]],\n",
      "\n",
      "        [[ -7.4674,  -7.5190,  -7.4131,  ...,  -6.3636,  -6.5940,  -4.5399],\n",
      "         [-14.8628, -14.7467, -15.1555,  ..., -13.4856, -11.4618, -11.5096],\n",
      "         [ -9.9348,  -9.6828, -10.3533,  ..., -10.1052,  -9.1664, -11.0794],\n",
      "         ...,\n",
      "         [-14.1291, -14.4733, -14.3240,  ..., -11.1879, -13.0494,  -9.5589],\n",
      "         [ -7.6920,  -8.2581,  -8.5203,  ...,  -5.1863,  -6.4874,  -5.7193],\n",
      "         [-12.0050, -12.3427, -12.0610,  ..., -10.8434, -11.4091,  -8.1338]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.7195656299591064\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9564, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8574,  -6.8906,  -6.9158,  ...,  -6.2228,  -6.1070,  -3.9017],\n",
      "         [ -7.2975,  -7.4882,  -7.3946,  ...,  -7.4821,  -5.0735,  -8.7169],\n",
      "         [ -2.7481,  -2.4915,  -2.9780,  ...,  -2.8234,  -1.5998,  -4.8862],\n",
      "         ...,\n",
      "         [ -5.6744,  -5.6945,  -5.8780,  ...,  -4.6813,  -4.5689,  -8.0925],\n",
      "         [ -5.3273,  -5.3125,  -5.4471,  ...,  -4.2883,  -4.5445,  -8.0178],\n",
      "         [ -5.3582,  -5.2923,  -5.5087,  ...,  -5.2089,  -4.6437,  -6.3541]],\n",
      "\n",
      "        [[-10.2500,  -9.9498,  -9.7694,  ...,  -9.3810, -10.6994,  -7.6219],\n",
      "         [-13.4733, -13.9594, -13.7478,  ...,  -9.6131, -10.8264, -10.7319],\n",
      "         [ -4.5989,  -4.7428,  -4.7538,  ...,  -5.6703,  -6.7563,  -2.9949],\n",
      "         ...,\n",
      "         [ -5.5350,  -5.5435,  -5.6680,  ...,  -6.1219,  -6.9358,  -3.6821],\n",
      "         [ -4.5775,  -4.7086,  -4.8191,  ...,  -5.6593,  -6.6448,  -3.8401],\n",
      "         [ -4.8332,  -4.9724,  -5.0511,  ...,  -5.9686,  -6.2366,  -3.7812]],\n",
      "\n",
      "        [[ -9.7758,  -9.7746,  -9.6181,  ...,  -8.3627,  -8.7658,  -6.0759],\n",
      "         [ -9.9661,  -9.7667,  -9.8999,  ...,  -6.6828,  -9.0730,  -8.2824],\n",
      "         [ -5.0089,  -5.1920,  -5.3323,  ...,  -5.9409,  -8.1968,  -2.5763],\n",
      "         ...,\n",
      "         [ -5.8684,  -5.9190,  -5.9161,  ...,  -6.1546,  -7.6040,  -3.8884],\n",
      "         [ -5.4900,  -5.5384,  -5.5807,  ...,  -5.3924,  -6.8119,  -3.2902],\n",
      "         [ -5.3269,  -5.5111,  -5.5477,  ...,  -5.1565,  -7.3630,  -2.5229]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4148,  -6.3835,  -6.3733,  ...,  -5.6181,  -5.4474,  -3.4391],\n",
      "         [ -8.3491,  -8.3603,  -8.2960,  ...,  -7.5696,  -8.2706,  -5.4917],\n",
      "         [ -5.8827,  -6.0775,  -6.1043,  ...,  -5.5000,  -6.4932,  -5.1100],\n",
      "         ...,\n",
      "         [ -6.3816,  -6.4518,  -6.2627,  ...,  -5.8214,  -6.2518,  -3.8337],\n",
      "         [ -6.8790,  -6.9113,  -6.6371,  ...,  -6.1068,  -6.9467,  -2.9607],\n",
      "         [ -7.2483,  -7.2982,  -7.2842,  ...,  -6.5473,  -6.8879,  -4.3865]],\n",
      "\n",
      "        [[ -6.9209,  -6.8963,  -6.9044,  ...,  -6.0221,  -5.9732,  -4.1252],\n",
      "         [-10.3950, -10.8311, -10.5011,  ...,  -9.7838,  -8.5763,  -9.5259],\n",
      "         [ -5.5962,  -5.7451,  -5.8861,  ...,  -5.8492,  -7.3201,  -3.1426],\n",
      "         ...,\n",
      "         [ -5.1713,  -5.2368,  -5.2964,  ...,  -5.1188,  -6.2621,  -4.1569],\n",
      "         [ -5.4035,  -5.5335,  -5.4883,  ...,  -5.4559,  -6.7447,  -3.7935],\n",
      "         [ -6.1846,  -6.3853,  -6.3293,  ...,  -6.0896,  -6.9881,  -4.2347]],\n",
      "\n",
      "        [[ -6.9827,  -6.9565,  -6.9782,  ...,  -6.1769,  -6.4870,  -3.6465],\n",
      "         [ -7.6255,  -7.3821,  -7.7957,  ...,  -7.5329,  -7.0177,  -4.0046],\n",
      "         [ -7.2592,  -7.1119,  -7.4601,  ...,  -7.5697,  -7.2447,  -5.0898],\n",
      "         ...,\n",
      "         [ -5.9497,  -5.8613,  -6.0869,  ...,  -5.9901,  -6.4104,  -2.2365],\n",
      "         [ -5.6354,  -5.5324,  -5.6856,  ...,  -5.7579,  -6.0314,  -1.6812],\n",
      "         [ -5.7919,  -5.7539,  -5.9303,  ...,  -6.0703,  -6.5136,  -2.4400]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.9564262628555298\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1380, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.9046,  -7.8586,  -7.8921,  ...,  -7.1238,  -6.9433,  -4.6588],\n",
      "         [-12.2079, -11.8847, -11.8343,  ...,  -9.7992,  -9.1104,  -9.3277],\n",
      "         [ -4.9344,  -5.0119,  -5.1379,  ...,  -5.4467,  -6.8197,  -3.7581],\n",
      "         ...,\n",
      "         [ -4.1977,  -4.1956,  -4.2959,  ...,  -4.4718,  -5.7239,  -4.4491],\n",
      "         [ -4.7342,  -4.7088,  -4.7539,  ...,  -4.8371,  -6.6527,  -3.8230],\n",
      "         [ -5.4930,  -5.5358,  -5.5425,  ...,  -5.2393,  -6.2037,  -4.2223]],\n",
      "\n",
      "        [[ -7.4180,  -7.3603,  -7.4222,  ...,  -6.5671,  -6.8046,  -4.2781],\n",
      "         [ -7.7476,  -7.3562,  -7.7796,  ...,  -7.8223,  -9.6367,  -1.6249],\n",
      "         [ -7.2549,  -7.0850,  -7.2616,  ...,  -7.6034,  -8.5034,  -3.8286],\n",
      "         ...,\n",
      "         [ -5.7095,  -5.5770,  -5.7446,  ...,  -6.2368,  -6.5197,  -2.4279],\n",
      "         [ -6.3909,  -6.1936,  -6.3889,  ...,  -6.3665,  -6.5715,  -2.9864],\n",
      "         [ -5.5568,  -5.4494,  -5.6358,  ...,  -5.9875,  -6.3233,  -1.5041]],\n",
      "\n",
      "        [[ -6.9039,  -6.9549,  -6.8786,  ...,  -6.3938,  -6.1895,  -4.3063],\n",
      "         [ -4.5147,  -4.7704,  -4.3368,  ...,  -5.9647,  -3.2786,  -5.8015],\n",
      "         [-10.4623, -10.3204, -10.6269,  ...,  -8.9774,  -9.4628,  -9.6080],\n",
      "         ...,\n",
      "         [ -4.9866,  -4.9110,  -5.0003,  ...,  -4.7767,  -5.1256,  -2.6274],\n",
      "         [ -6.1768,  -6.2028,  -6.2541,  ...,  -5.5446,  -6.3426,  -3.9085],\n",
      "         [ -7.2617,  -7.3295,  -7.3888,  ...,  -7.5440,  -6.8388,  -4.9881]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.4361,  -8.4547,  -8.3825,  ...,  -7.8834,  -7.5819,  -4.2746],\n",
      "         [-16.8633, -16.7220, -16.5410,  ..., -15.5993, -14.2686,  -9.3904],\n",
      "         [ -6.6746,  -7.2430,  -6.9095,  ...,  -6.3067,  -6.6949,  -5.3641],\n",
      "         ...,\n",
      "         [ -7.6511,  -8.1616,  -7.8862,  ...,  -6.4256,  -8.8895,  -6.9164],\n",
      "         [-13.0620, -12.9722, -12.9979,  ..., -12.6819, -10.9974,  -7.3935],\n",
      "         [-14.4137, -14.4906, -14.4099,  ..., -10.9805, -11.9179,  -9.8772]],\n",
      "\n",
      "        [[ -6.6365,  -6.6144,  -6.6136,  ...,  -6.0443,  -5.7716,  -3.9670],\n",
      "         [-10.3488, -10.1074, -10.6948,  ...,  -7.0581,  -7.7623,  -7.3844],\n",
      "         [ -7.5169,  -7.6815,  -7.6801,  ...,  -7.6056,  -7.9485,  -3.2565],\n",
      "         ...,\n",
      "         [ -7.5982,  -7.8372,  -7.8123,  ...,  -7.6395,  -7.6849,  -4.1078],\n",
      "         [ -7.6588,  -7.8467,  -7.8672,  ...,  -7.6991,  -8.2615,  -3.2838],\n",
      "         [ -7.2561,  -7.4157,  -7.4917,  ...,  -7.2997,  -7.6060,  -3.0584]],\n",
      "\n",
      "        [[ -7.6375,  -7.4186,  -7.5388,  ...,  -6.6264,  -6.8242,  -4.3846],\n",
      "         [-10.4238, -10.1246, -10.2603,  ...,  -8.3787,  -8.6814,  -6.5448],\n",
      "         [ -5.2203,  -5.3922,  -5.4004,  ...,  -5.5360,  -6.9589,  -3.6695],\n",
      "         ...,\n",
      "         [ -5.6670,  -5.5820,  -5.6497,  ...,  -5.1846,  -6.7350,  -2.7140],\n",
      "         [ -5.1816,  -5.3341,  -5.4415,  ...,  -5.8678,  -7.3067,  -4.2828],\n",
      "         [ -5.5370,  -5.7040,  -5.7507,  ...,  -5.1685,  -6.4190,  -3.4481]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.1379706859588623\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1535, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8270,  -7.8983,  -7.8113,  ...,  -7.3009,  -6.8471,  -4.8305],\n",
      "         [ -4.7654,  -4.6503,  -4.6129,  ...,  -4.4465,  -5.5045,  -4.5315],\n",
      "         [ -9.4943,  -9.0476,  -9.2535,  ..., -10.7339,  -9.3588,  -5.8593],\n",
      "         ...,\n",
      "         [ -5.4819,  -6.1357,  -5.8213,  ...,  -7.4676,  -7.2729,  -1.5731],\n",
      "         [ -5.8832,  -6.1630,  -6.1471,  ...,  -7.5990,  -8.2976,  -2.7301],\n",
      "         [ -6.5773,  -6.8142,  -6.7629,  ...,  -7.1326,  -7.5559,  -4.7777]],\n",
      "\n",
      "        [[ -6.2477,  -6.2379,  -6.2570,  ...,  -5.4515,  -5.5837,  -3.6478],\n",
      "         [-12.7988, -12.9955, -12.8437,  ...,  -9.4544, -10.1004, -10.4431],\n",
      "         [ -5.3209,  -5.3406,  -5.5181,  ...,  -5.3115,  -6.8177,  -3.3337],\n",
      "         ...,\n",
      "         [ -5.7597,  -5.8774,  -5.9063,  ...,  -5.3671,  -6.9336,  -3.9642],\n",
      "         [ -5.2437,  -5.2260,  -5.4147,  ...,  -4.8578,  -6.4255,  -3.4443],\n",
      "         [ -5.4375,  -5.4838,  -5.4896,  ...,  -4.8585,  -6.5862,  -3.6044]],\n",
      "\n",
      "        [[ -8.3159,  -8.2390,  -8.1734,  ...,  -7.8378,  -7.0496,  -5.0303],\n",
      "         [-13.2317, -12.8482, -12.9000,  ..., -12.7417, -13.0590,  -9.7707],\n",
      "         [-14.3591, -14.1490, -14.4114,  ..., -11.7393, -11.5219, -13.9876],\n",
      "         ...,\n",
      "         [ -4.4545,  -4.4150,  -4.2816,  ...,  -4.2387,  -3.6463,  -4.9937],\n",
      "         [ -3.1163,  -3.4967,  -3.3544,  ...,  -3.8102,  -2.2563,  -4.7201],\n",
      "         [ -3.6196,  -3.8639,  -3.7390,  ...,  -3.8333,  -2.4793,  -4.9371]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0437,  -6.9678,  -7.0268,  ...,  -6.3157,  -6.3285,  -3.9998],\n",
      "         [ -6.2352,  -6.1481,  -6.3236,  ...,  -7.2734,  -7.1500,  -1.7575],\n",
      "         [ -7.3242,  -7.0454,  -7.6542,  ...,  -7.5609,  -7.6283,  -2.4209],\n",
      "         ...,\n",
      "         [ -5.0281,  -5.0454,  -5.1814,  ...,  -5.5404,  -5.6806,  -1.0349],\n",
      "         [ -4.9787,  -4.9849,  -5.1612,  ...,  -5.3868,  -5.4902,  -1.5948],\n",
      "         [ -5.7144,  -5.6721,  -5.8268,  ...,  -6.1792,  -6.2727,  -1.7469]],\n",
      "\n",
      "        [[ -6.8499,  -6.7591,  -6.8431,  ...,  -6.0953,  -6.0193,  -4.1091],\n",
      "         [-14.3528, -13.8444, -14.2177,  ..., -12.5652, -10.9573, -12.0531],\n",
      "         [ -5.5492,  -5.6452,  -5.7931,  ...,  -6.1548,  -7.3664,  -3.5690],\n",
      "         ...,\n",
      "         [ -5.1655,  -5.2590,  -5.4537,  ...,  -5.9058,  -7.1415,  -2.7791],\n",
      "         [ -5.1047,  -5.2666,  -5.3980,  ...,  -6.0517,  -6.8234,  -3.2654],\n",
      "         [ -5.2640,  -5.2548,  -5.3711,  ...,  -5.4811,  -6.4828,  -2.9257]],\n",
      "\n",
      "        [[ -6.9831,  -6.9786,  -6.9746,  ...,  -6.3792,  -6.1183,  -4.3374],\n",
      "         [-10.5075, -10.3375, -10.0445,  ...,  -9.8197, -10.5224,  -7.5625],\n",
      "         [-12.2481, -12.2876, -12.1742,  ..., -10.6629, -11.4529, -11.0163],\n",
      "         ...,\n",
      "         [ -6.6128,  -6.7106,  -6.5792,  ...,  -6.7877,  -6.5357,  -5.7513],\n",
      "         [ -5.8898,  -6.0760,  -5.8959,  ...,  -4.7272,  -5.6973,  -4.5188],\n",
      "         [ -7.1103,  -7.1864,  -7.2157,  ...,  -6.4767,  -7.3557,  -6.3861]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.1535489559173584\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8715, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.0918,  -8.1055,  -7.9985,  ...,  -7.0653,  -7.3177,  -5.0426],\n",
      "         [-12.0216, -11.9970, -11.8333,  ...,  -9.8312, -10.2505, -10.9812],\n",
      "         [ -4.2300,  -3.9747,  -4.0343,  ...,  -3.9792,  -4.5570,  -6.9454],\n",
      "         ...,\n",
      "         [ -5.6483,  -5.9474,  -5.8859,  ...,  -6.6631,  -5.9192,  -6.6006],\n",
      "         [ -4.5951,  -4.6333,  -4.6296,  ...,  -5.9571,  -4.4061,  -4.6991],\n",
      "         [-15.1143, -15.3892, -15.0287,  ..., -14.8026, -14.4036,  -9.9486]],\n",
      "\n",
      "        [[ -8.0426,  -7.9375,  -8.0456,  ...,  -7.1903,  -6.8947,  -4.7318],\n",
      "         [-14.3467, -14.1051, -14.4253,  ..., -12.6447, -12.2526, -11.9777],\n",
      "         [ -8.0516,  -7.9584,  -8.1992,  ...,  -7.5332,  -6.3197,  -7.9150],\n",
      "         ...,\n",
      "         [ -8.1468,  -8.3107,  -7.9906,  ...,  -7.1044,  -7.1452,  -4.6752],\n",
      "         [ -7.8986,  -7.9703,  -7.7547,  ...,  -6.4988,  -6.8566,  -4.1793],\n",
      "         [ -8.4646,  -8.3642,  -8.3036,  ...,  -7.4507,  -7.9357,  -4.6436]],\n",
      "\n",
      "        [[-11.7849, -12.0245, -11.9083,  ..., -10.7813, -11.2315,  -8.4709],\n",
      "         [-16.7281, -16.4707, -16.7966,  ..., -14.0324, -14.4375, -11.2673],\n",
      "         [ -4.8192,  -4.9912,  -4.9696,  ...,  -5.3251,  -7.3729,  -3.6152],\n",
      "         ...,\n",
      "         [ -6.1426,  -6.2526,  -6.4588,  ...,  -5.9810,  -7.7329,  -4.1152],\n",
      "         [ -5.0292,  -5.1545,  -5.1123,  ...,  -4.9209,  -6.0821,  -4.2615],\n",
      "         [ -5.6161,  -5.8736,  -5.8547,  ...,  -5.8686,  -6.8704,  -5.2659]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.1508,  -9.1012,  -8.9765,  ...,  -7.9316,  -8.2934,  -6.2330],\n",
      "         [-10.3826, -10.5882, -10.3944,  ...,  -7.8481,  -8.0869, -11.5225],\n",
      "         [ -4.2811,  -4.3481,  -4.5560,  ...,  -4.7100,  -6.4776,  -3.1157],\n",
      "         ...,\n",
      "         [ -4.0575,  -4.0560,  -4.1374,  ...,  -4.6625,  -6.0383,  -3.6355],\n",
      "         [ -4.5705,  -4.5172,  -4.6274,  ...,  -5.1536,  -6.3711,  -4.6783],\n",
      "         [ -4.6279,  -4.7838,  -4.7590,  ...,  -5.1825,  -5.8418,  -2.4903]],\n",
      "\n",
      "        [[ -6.9803,  -6.9467,  -6.9367,  ...,  -6.2378,  -6.1732,  -4.0671],\n",
      "         [ -8.8221,  -8.5279,  -8.9040,  ...,  -8.4061,  -9.5257,  -4.7503],\n",
      "         [ -7.6514,  -7.4325,  -7.7300,  ...,  -8.2685,  -7.9178,  -6.7264],\n",
      "         ...,\n",
      "         [ -5.3423,  -5.2606,  -5.4656,  ...,  -5.7694,  -6.3233,  -2.8036],\n",
      "         [ -5.2310,  -5.1456,  -5.3937,  ...,  -5.4059,  -5.9500,  -2.7711],\n",
      "         [ -5.3939,  -5.2742,  -5.4305,  ...,  -5.3375,  -5.9321,  -2.5074]],\n",
      "\n",
      "        [[ -7.6687,  -7.7629,  -7.6346,  ...,  -6.7984,  -7.3107,  -4.4508],\n",
      "         [ -7.3311,  -6.9445,  -7.2584,  ...,  -7.4342,  -7.0134,  -6.0980],\n",
      "         [ -4.0946,  -4.4773,  -4.0897,  ...,  -5.8672,  -3.7564,  -4.5244],\n",
      "         ...,\n",
      "         [ -8.3185,  -7.9611,  -7.9340,  ...,  -8.5005,  -5.7342,  -4.5085],\n",
      "         [-10.0882, -10.3320,  -9.9947,  ...,  -9.9800,  -9.4002, -10.8495],\n",
      "         [-13.2974, -13.5740, -13.0762,  ..., -12.4966, -13.4317,  -9.9778]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.8715267181396484\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0068, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0246,  -6.9555,  -7.0385,  ...,  -6.5569,  -6.2226,  -4.3648],\n",
      "         [-11.4078, -10.9015, -10.9626,  ...,  -9.6073,  -9.0646,  -7.8519],\n",
      "         [ -5.3763,  -5.3721,  -5.5230,  ...,  -5.7664,  -7.2235,  -3.6063],\n",
      "         ...,\n",
      "         [ -5.8034,  -5.8217,  -5.8945,  ...,  -5.9766,  -6.9476,  -3.8278],\n",
      "         [ -4.9623,  -4.9722,  -5.0547,  ...,  -5.5361,  -6.4027,  -3.7031],\n",
      "         [ -5.1890,  -5.1780,  -5.2099,  ...,  -5.5725,  -6.6214,  -3.2507]],\n",
      "\n",
      "        [[ -8.6467,  -8.8617,  -8.7882,  ...,  -8.0120,  -7.8309,  -6.9339],\n",
      "         [ -4.7574,  -5.3379,  -4.9708,  ...,  -5.7623,  -4.4055,  -6.8884],\n",
      "         [-11.9791, -12.3752, -12.3743,  ..., -13.2211, -10.9059, -12.0278],\n",
      "         ...,\n",
      "         [ -6.3055,  -6.2720,  -6.0727,  ...,  -6.5386,  -3.9394,  -8.2994],\n",
      "         [ -6.0512,  -6.4585,  -6.3395,  ...,  -7.4239,  -4.7161,  -8.6135],\n",
      "         [-13.0908, -12.8976, -13.0665,  ..., -10.2559, -11.3740, -11.6727]],\n",
      "\n",
      "        [[ -6.1571,  -6.1418,  -6.0794,  ...,  -5.5885,  -5.3453,  -3.6683],\n",
      "         [-11.5442, -11.1440, -11.1847,  ..., -10.4360, -10.0278,  -9.0371],\n",
      "         [ -6.1909,  -6.2982,  -6.3507,  ...,  -6.0014,  -6.6417,  -3.4030],\n",
      "         ...,\n",
      "         [ -5.8075,  -5.8773,  -5.8650,  ...,  -5.2564,  -6.3440,  -2.7820],\n",
      "         [ -6.1788,  -6.3471,  -6.3134,  ...,  -6.3354,  -6.6944,  -3.3566],\n",
      "         [ -6.2051,  -6.3629,  -6.3388,  ...,  -6.0803,  -6.1836,  -2.8081]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8707,  -6.8710,  -6.8067,  ...,  -6.2769,  -6.1822,  -4.0781],\n",
      "         [ -6.3714,  -6.2242,  -6.4210,  ...,  -6.1206,  -6.2775,  -2.4229],\n",
      "         [-11.7418, -11.6886, -11.7170,  ..., -10.6711, -10.5570,  -1.8969],\n",
      "         ...,\n",
      "         [ -6.0283,  -6.1214,  -6.0042,  ...,  -6.7308,  -5.4547,  -4.3605],\n",
      "         [ -8.2167,  -8.2884,  -8.3290,  ...,  -8.1714,  -7.6387,  -5.5564],\n",
      "         [ -8.3829,  -8.5548,  -8.6716,  ...,  -8.4660,  -8.6669,  -5.0635]],\n",
      "\n",
      "        [[ -6.5923,  -6.6491,  -6.6159,  ...,  -5.7632,  -5.5558,  -3.8521],\n",
      "         [ -8.4175,  -8.6621,  -8.2057,  ...,  -6.9209,  -5.5526,  -7.0872],\n",
      "         [ -5.2314,  -5.0626,  -5.2922,  ...,  -5.6212,  -5.0556,  -7.7081],\n",
      "         ...,\n",
      "         [ -4.4772,  -4.2908,  -4.1756,  ...,  -4.9661,  -4.9584,  -6.0084],\n",
      "         [ -5.1772,  -5.1984,  -5.0840,  ...,  -5.4823,  -5.2691,  -6.1777],\n",
      "         [ -6.9835,  -6.9988,  -7.0472,  ...,  -7.8400,  -6.9314,  -5.9370]],\n",
      "\n",
      "        [[ -7.4321,  -7.5039,  -7.4653,  ...,  -6.6928,  -6.6540,  -3.7491],\n",
      "         [-12.2737, -12.7008, -12.6068,  ...,  -9.9909,  -9.0705, -11.1596],\n",
      "         [ -8.4175,  -8.7469,  -9.1836,  ...,  -7.8998,  -7.3974,  -8.1864],\n",
      "         ...,\n",
      "         [ -6.6045,  -6.6757,  -6.8510,  ...,  -7.5016,  -6.5681,  -3.9177],\n",
      "         [ -6.7992,  -6.8583,  -6.8061,  ...,  -7.6609,  -7.4737,  -4.1287],\n",
      "         [ -7.1367,  -7.2055,  -7.4893,  ...,  -7.6488,  -7.3895,  -5.2419]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.0068280696868896\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5710, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5594,  -6.5488,  -6.5481,  ...,  -5.8245,  -5.7530,  -3.9500],\n",
      "         [ -9.9951, -10.0271, -10.0244,  ...,  -6.9037,  -6.9187,  -9.1475],\n",
      "         [ -4.8232,  -4.9139,  -5.0184,  ...,  -5.1401,  -6.6333,  -3.3673],\n",
      "         ...,\n",
      "         [ -5.4503,  -5.4377,  -5.4674,  ...,  -5.4523,  -6.1827,  -4.1088],\n",
      "         [ -5.2747,  -5.3783,  -5.4372,  ...,  -5.6905,  -6.4906,  -3.9426],\n",
      "         [ -5.3968,  -5.4507,  -5.4514,  ...,  -5.5882,  -6.5169,  -3.3678]],\n",
      "\n",
      "        [[ -6.5088,  -6.4682,  -6.5039,  ...,  -5.8369,  -5.6789,  -3.8301],\n",
      "         [-13.8222, -13.4798, -13.6838,  ..., -10.5258, -11.1662,  -8.6670],\n",
      "         [ -5.1744,  -5.1649,  -5.2731,  ...,  -5.5558,  -7.0955,  -2.5760],\n",
      "         ...,\n",
      "         [ -5.1354,  -5.2591,  -5.3503,  ...,  -5.1784,  -6.5543,  -3.0184],\n",
      "         [ -5.8423,  -5.8930,  -5.9727,  ...,  -6.0449,  -6.9123,  -2.7541],\n",
      "         [ -5.7020,  -5.7714,  -5.7589,  ...,  -5.7543,  -6.5014,  -3.4731]],\n",
      "\n",
      "        [[ -6.5362,  -6.5036,  -6.5629,  ...,  -5.7868,  -5.9790,  -4.0153],\n",
      "         [-11.5907, -11.5458, -11.6463,  ...,  -8.8237,  -8.3917,  -9.0868],\n",
      "         [ -5.1225,  -5.2372,  -5.2815,  ...,  -5.0080,  -6.7830,  -3.1811],\n",
      "         ...,\n",
      "         [ -5.1472,  -4.9831,  -5.1846,  ...,  -4.8419,  -6.1432,  -3.9728],\n",
      "         [ -4.8046,  -4.8342,  -4.8572,  ...,  -4.3202,  -5.7894,  -3.2673],\n",
      "         [ -5.9609,  -5.9652,  -5.9708,  ...,  -5.7669,  -6.3498,  -3.7958]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8674,  -6.8739,  -6.7987,  ...,  -6.3803,  -5.7918,  -3.7818],\n",
      "         [ -6.0427,  -6.0767,  -5.9156,  ...,  -6.6516,  -4.4858,  -5.2746],\n",
      "         [-13.1576, -12.7146, -12.7559,  ..., -11.8880, -10.1932, -11.3529],\n",
      "         ...,\n",
      "         [-13.2092, -13.3458, -12.9400,  ..., -13.5616, -12.5919,  -8.5913],\n",
      "         [-13.2159, -13.0194, -12.9943,  ..., -13.0667, -11.9836, -10.4608],\n",
      "         [-10.6647, -10.5254, -10.5287,  ...,  -9.7753,  -7.4464,  -5.0753]],\n",
      "\n",
      "        [[ -7.4611,  -7.5329,  -7.4618,  ...,  -6.5645,  -6.4912,  -4.4094],\n",
      "         [-14.1755, -13.8026, -14.3346,  ..., -11.1020, -12.4573, -11.8462],\n",
      "         [-10.0471,  -9.9277, -10.4987,  ...,  -8.8443,  -8.8755, -10.3727],\n",
      "         ...,\n",
      "         [ -5.2369,  -5.2072,  -5.4832,  ...,  -5.1254,  -5.3311,  -1.9765],\n",
      "         [ -8.7002,  -8.9036,  -8.4658,  ...,  -7.3278,  -7.6977,  -3.8995],\n",
      "         [ -7.3106,  -7.3485,  -7.5359,  ...,  -6.8637,  -7.1420,  -2.8021]],\n",
      "\n",
      "        [[ -6.6689,  -6.5801,  -6.6264,  ...,  -6.0175,  -5.9119,  -4.0217],\n",
      "         [-11.3424, -11.5004, -11.5651,  ...,  -8.4783,  -8.4344,  -9.3445],\n",
      "         [ -4.7482,  -4.8076,  -4.9467,  ...,  -4.8261,  -6.6242,  -3.1815],\n",
      "         ...,\n",
      "         [ -5.9015,  -5.8814,  -6.1221,  ...,  -5.9968,  -7.3740,  -2.6530],\n",
      "         [ -5.2657,  -5.3408,  -5.4798,  ...,  -5.3232,  -6.5341,  -3.5590],\n",
      "         [ -4.6605,  -4.6949,  -4.8815,  ...,  -4.8045,  -6.9463,  -2.9422]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.570983648300171\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0380, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7092,  -6.7046,  -6.7460,  ...,  -6.1502,  -6.0352,  -4.1467],\n",
      "         [ -6.5119,  -6.2498,  -6.5165,  ...,  -7.2375,  -7.3187,  -2.7356],\n",
      "         [ -6.9624,  -6.9090,  -7.2093,  ...,  -7.1937,  -7.6648,  -6.2649],\n",
      "         ...,\n",
      "         [ -5.0758,  -4.9497,  -5.0988,  ...,  -5.4659,  -5.6072,  -2.8106],\n",
      "         [ -5.1632,  -4.9502,  -5.1862,  ...,  -5.1335,  -5.6265,  -3.3760],\n",
      "         [ -5.1915,  -5.0360,  -5.2473,  ...,  -5.4665,  -5.9616,  -3.2786]],\n",
      "\n",
      "        [[ -7.3030,  -7.4038,  -7.2976,  ...,  -6.5886,  -6.2413,  -4.7367],\n",
      "         [ -7.9404,  -8.2524,  -7.8912,  ...,  -9.0079,  -7.5157,  -6.4973],\n",
      "         [ -1.9162,  -2.1733,  -1.6139,  ...,  -2.1588,  -2.4994,  -2.0918],\n",
      "         ...,\n",
      "         [ -3.0181,  -3.0414,  -2.6912,  ...,  -3.5423,  -2.7582,  -3.4370],\n",
      "         [ -6.4043,  -6.5476,  -6.3755,  ...,  -6.8147,  -5.3074,  -6.4388],\n",
      "         [ -6.7356,  -6.5455,  -6.6672,  ...,  -6.4865,  -5.3623,  -5.8124]],\n",
      "\n",
      "        [[ -6.9501,  -7.0332,  -6.9646,  ...,  -6.0014,  -5.9999,  -3.8915],\n",
      "         [-12.5496, -13.0939, -12.3313,  ..., -11.2664,  -9.7516,  -5.7288],\n",
      "         [-13.2577, -13.8289, -13.2589,  ..., -11.8600,  -9.0307,  -8.4226],\n",
      "         ...,\n",
      "         [ -9.3587,  -9.5951,  -9.2271,  ...,  -7.6002,  -7.2340,  -5.0774],\n",
      "         [ -8.7858,  -8.9685,  -8.6313,  ...,  -7.1314,  -7.0204,  -5.2031],\n",
      "         [ -6.2354,  -6.5243,  -6.0336,  ...,  -4.7215,  -4.2999,  -4.5734]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2477,  -7.2292,  -7.1276,  ...,  -6.6643,  -6.1678,  -4.0999],\n",
      "         [-13.7022, -14.0165, -13.6862,  ..., -13.3894, -12.2668, -13.7258],\n",
      "         [-14.6388, -14.9292, -14.9138,  ..., -13.2561, -11.7306, -12.0922],\n",
      "         ...,\n",
      "         [-10.8940, -10.6675, -10.5215,  ...,  -9.8888,  -7.7032,  -8.1341],\n",
      "         [ -7.5981,  -7.5476,  -7.4347,  ...,  -6.7876,  -5.3674,  -5.7303],\n",
      "         [-12.4388, -11.8867, -12.2226,  ..., -10.1884,  -9.5626, -10.6687]],\n",
      "\n",
      "        [[ -7.5008,  -7.5060,  -7.3855,  ...,  -6.4771,  -6.3446,  -4.0342],\n",
      "         [-10.4434, -10.7795, -10.2089,  ...,  -9.8537,  -7.7822,  -5.1870],\n",
      "         [-10.4328, -10.4553, -10.5084,  ..., -10.8003,  -9.5971,  -6.0651],\n",
      "         ...,\n",
      "         [ -9.0702,  -9.0565,  -8.5291,  ...,  -7.0509,  -7.8432,  -3.7971],\n",
      "         [ -8.0589,  -8.0467,  -7.9426,  ...,  -7.4125,  -7.3997,  -4.1061],\n",
      "         [-13.8434, -13.9268, -13.6601,  ..., -12.0978,  -9.9652, -10.1002]],\n",
      "\n",
      "        [[ -6.0054,  -5.9258,  -5.8327,  ...,  -5.8248,  -5.2180,  -4.1088],\n",
      "         [-11.1223, -11.1038, -11.2187,  ...,  -9.2552,  -8.6404,  -7.8753],\n",
      "         [ -6.2895,  -6.4553,  -6.4891,  ...,  -6.5987,  -6.7499,  -3.9020],\n",
      "         ...,\n",
      "         [ -6.3999,  -6.4629,  -6.5030,  ...,  -6.4560,  -6.0781,  -3.8207],\n",
      "         [ -6.3458,  -6.4265,  -6.3071,  ...,  -6.4252,  -6.1935,  -4.3590],\n",
      "         [ -6.4942,  -6.5818,  -6.5559,  ...,  -6.9798,  -6.4859,  -3.6866]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.0379927158355713\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4380, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7923,  -6.8287,  -6.8319,  ...,  -6.0456,  -6.0620,  -4.2778],\n",
      "         [ -5.5805,  -5.3262,  -5.5214,  ...,  -5.5951,  -6.5976,  -2.2064],\n",
      "         [ -8.7781,  -9.2989,  -9.1667,  ...,  -9.2833,  -8.3966, -11.6557],\n",
      "         ...,\n",
      "         [ -4.9006,  -5.3558,  -5.1262,  ...,  -5.2120,  -5.2689,  -4.1134],\n",
      "         [ -3.7683,  -3.8969,  -3.8418,  ...,  -3.2506,  -3.5824,  -4.7058],\n",
      "         [ -6.7069,  -6.5441,  -6.7241,  ...,  -5.7418,  -5.6855,  -7.0942]],\n",
      "\n",
      "        [[ -7.4210,  -7.4079,  -7.3946,  ...,  -6.9072,  -6.6539,  -4.6969],\n",
      "         [-11.9506, -11.8971, -12.1416,  ..., -11.8111, -12.0505, -11.0897],\n",
      "         [ -9.9157, -10.3819, -10.1232,  ...,  -9.2525,  -8.0781,  -9.4553],\n",
      "         ...,\n",
      "         [ -3.8209,  -3.9951,  -4.0641,  ...,  -4.8877,  -3.2992,  -4.4595],\n",
      "         [ -3.9517,  -4.1546,  -4.1213,  ...,  -5.1618,  -3.8639,  -5.5265],\n",
      "         [ -6.2746,  -6.3000,  -6.3502,  ...,  -6.6925,  -5.7108,  -6.3284]],\n",
      "\n",
      "        [[ -6.4514,  -6.4163,  -6.4392,  ...,  -5.8004,  -5.6075,  -3.8438],\n",
      "         [-12.2094, -12.0681, -11.8804,  ...,  -9.1893, -10.0907,  -9.1696],\n",
      "         [ -6.4062,  -6.4253,  -6.4474,  ...,  -6.8676,  -6.6819,  -4.2126],\n",
      "         ...,\n",
      "         [ -7.0283,  -7.1201,  -7.1219,  ...,  -6.8970,  -6.6223,  -4.9932],\n",
      "         [ -6.9854,  -7.0857,  -7.0288,  ...,  -6.7138,  -6.7163,  -4.6734],\n",
      "         [ -7.2560,  -7.3132,  -7.3088,  ...,  -7.2714,  -7.0377,  -5.2420]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9194,  -7.0202,  -6.9604,  ...,  -6.2812,  -6.2895,  -4.0912],\n",
      "         [-10.1293, -10.2736,  -9.7900,  ...,  -8.1258,  -8.9129,  -7.6591],\n",
      "         [-12.9558, -13.2686, -13.2189,  ..., -11.5641, -12.0262, -13.1691],\n",
      "         ...,\n",
      "         [ -6.5317,  -6.4616,  -6.5503,  ...,  -6.6389,  -7.1395,  -3.5493],\n",
      "         [ -6.8111,  -6.6701,  -7.0138,  ...,  -6.6960,  -7.3065,  -5.1078],\n",
      "         [ -6.1522,  -6.0784,  -6.2621,  ...,  -6.3949,  -6.7802,  -3.3349]],\n",
      "\n",
      "        [[ -6.7121,  -6.6263,  -6.5940,  ...,  -5.9860,  -5.8033,  -4.0535],\n",
      "         [-11.7481, -11.6354, -11.7805,  ...,  -9.3003, -10.0480,  -7.3517],\n",
      "         [ -5.3328,  -5.3036,  -5.3581,  ...,  -5.6097,  -6.9085,  -3.0959],\n",
      "         ...,\n",
      "         [ -5.3732,  -5.3578,  -5.2992,  ...,  -5.1757,  -6.3336,  -3.6970],\n",
      "         [ -4.7917,  -4.7597,  -4.7732,  ...,  -5.1599,  -5.8630,  -3.7533],\n",
      "         [ -5.2259,  -5.2589,  -5.1937,  ...,  -5.5725,  -6.2366,  -3.7440]],\n",
      "\n",
      "        [[ -6.7923,  -6.7639,  -6.7485,  ...,  -6.2420,  -5.9379,  -4.1191],\n",
      "         [ -6.0420,  -6.1658,  -5.9599,  ...,  -6.5054,  -5.5596,  -5.9786],\n",
      "         [-11.8337, -11.9090, -11.8223,  ..., -10.6832,  -8.8507,  -9.9801],\n",
      "         ...,\n",
      "         [ -8.6068,  -8.5691,  -8.6306,  ...,  -8.0318,  -8.4200,  -6.0633],\n",
      "         [ -8.9570,  -8.9688,  -8.9974,  ...,  -8.7297,  -8.5812,  -6.9551],\n",
      "         [ -8.5635,  -8.4477,  -8.5917,  ...,  -8.0409,  -7.9807,  -6.9002]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.4379581212997437\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5073, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5460,  -7.5836,  -7.5317,  ...,  -6.9400,  -6.5686,  -5.1020],\n",
      "         [ -5.5287,  -5.4279,  -5.3013,  ...,  -4.3740,  -7.3511,  -2.9220],\n",
      "         [ -6.5171,  -7.1628,  -7.3266,  ...,  -6.2566,  -6.0362,  -6.1667],\n",
      "         ...,\n",
      "         [ -7.8888,  -8.0605,  -8.3172,  ...,  -9.3853,  -7.5855,  -6.0041],\n",
      "         [ -5.0004,  -5.7746,  -5.9984,  ...,  -6.8486,  -5.9704,  -5.4213],\n",
      "         [-11.7926, -11.6364, -11.9127,  ...,  -9.9317,  -9.8418, -11.2412]],\n",
      "\n",
      "        [[ -7.1119,  -7.1134,  -7.0143,  ...,  -6.6112,  -6.0900,  -3.8307],\n",
      "         [ -9.8181, -10.0579,  -9.6146,  ...,  -9.4585,  -7.6015,  -9.1178],\n",
      "         [-11.8467, -12.0637, -12.0192,  ..., -10.0207,  -8.3775, -11.1403],\n",
      "         ...,\n",
      "         [ -6.9484,  -7.0962,  -7.0821,  ...,  -6.7797,  -6.0928,  -3.8446],\n",
      "         [ -7.9597,  -8.1827,  -8.0804,  ...,  -7.4438,  -6.9175,  -5.5050],\n",
      "         [ -8.1904,  -8.3587,  -8.2605,  ...,  -7.5158,  -7.2959,  -5.4328]],\n",
      "\n",
      "        [[ -7.0458,  -7.0556,  -6.9851,  ...,  -6.5119,  -6.3236,  -4.4299],\n",
      "         [-10.9522, -11.4106, -11.0560,  ..., -12.3346,  -7.9363,  -8.1532],\n",
      "         [ -4.3166,  -4.9398,  -4.3150,  ...,  -6.7648,  -4.9470,  -3.6184],\n",
      "         ...,\n",
      "         [ -8.4123,  -8.5879,  -8.1257,  ...,  -8.1755,  -7.4715,  -5.5661],\n",
      "         [ -5.7473,  -6.2331,  -6.0210,  ...,  -6.5051,  -6.5894,  -6.2982],\n",
      "         [-12.1717, -12.4282, -12.6446,  ..., -10.3993, -10.0458,  -7.5095]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3789,  -6.3103,  -6.3127,  ...,  -5.3177,  -5.8283,  -3.6347],\n",
      "         [-12.7251, -12.8648, -12.6058,  ...,  -9.9363,  -9.7064,  -8.7497],\n",
      "         [ -4.7124,  -4.8795,  -4.8638,  ...,  -4.9515,  -6.4833,  -3.5494],\n",
      "         ...,\n",
      "         [ -4.8042,  -5.0028,  -4.8890,  ...,  -4.5752,  -5.8958,  -3.6647],\n",
      "         [ -5.1655,  -5.2919,  -5.3690,  ...,  -5.2159,  -6.4300,  -3.2153],\n",
      "         [ -4.5818,  -4.8602,  -4.7810,  ...,  -4.6241,  -6.4757,  -3.3716]],\n",
      "\n",
      "        [[ -7.0629,  -6.9993,  -7.0564,  ...,  -6.2165,  -6.2145,  -4.0861],\n",
      "         [-10.1867,  -9.7349, -10.4256,  ...,  -8.9759,  -9.4316,  -6.3503],\n",
      "         [ -5.2710,  -5.3557,  -5.5609,  ...,  -5.4035,  -6.8726,  -2.7035],\n",
      "         ...,\n",
      "         [ -4.2532,  -4.2053,  -4.2966,  ...,  -3.9144,  -5.8327,  -3.9477],\n",
      "         [ -5.2596,  -5.3924,  -5.4375,  ...,  -5.1205,  -6.7129,  -3.9880],\n",
      "         [ -5.9103,  -5.9781,  -6.0027,  ...,  -5.9587,  -6.4904,  -4.1934]],\n",
      "\n",
      "        [[ -7.3371,  -7.3362,  -7.2531,  ...,  -6.8804,  -6.5214,  -4.3756],\n",
      "         [ -7.1534,  -7.2712,  -7.2503,  ...,  -6.6256,  -5.8779,  -6.4490],\n",
      "         [ -9.7614,  -9.9534,  -9.5361,  ...,  -9.0278,  -7.8906, -12.8333],\n",
      "         ...,\n",
      "         [ -9.7942, -10.4395, -10.1855,  ...,  -8.5943,  -6.1962, -11.8029],\n",
      "         [-10.5301, -11.0916, -10.3701,  ...,  -9.9144,  -7.1026,  -7.5608],\n",
      "         [-12.8208, -12.4273, -12.4419,  ..., -10.2317,  -9.9964,  -8.5209]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5072788000106812\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6601, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3578,  -6.3252,  -6.3451,  ...,  -5.6677,  -5.5196,  -3.7765],\n",
      "         [-10.5851, -10.6233, -10.6024,  ...,  -8.3322,  -9.0862,  -7.8686],\n",
      "         [ -6.3648,  -6.4369,  -6.4496,  ...,  -6.9143,  -6.9199,  -4.1810],\n",
      "         ...,\n",
      "         [ -6.5895,  -6.6254,  -6.6995,  ...,  -6.9695,  -7.1793,  -4.3908],\n",
      "         [ -6.6747,  -6.6264,  -6.7625,  ...,  -6.9975,  -7.2155,  -4.3604],\n",
      "         [ -6.8231,  -6.8331,  -6.8943,  ...,  -7.2360,  -7.2586,  -3.9869]],\n",
      "\n",
      "        [[ -6.6696,  -6.6213,  -6.6270,  ...,  -6.0180,  -5.9010,  -4.1828],\n",
      "         [-11.7969, -11.4979, -11.5798,  ...,  -9.4902,  -9.1364, -10.1808],\n",
      "         [ -6.1931,  -6.3631,  -6.3081,  ...,  -6.7026,  -7.2817,  -3.5447],\n",
      "         ...,\n",
      "         [ -6.1374,  -6.2739,  -6.1546,  ...,  -6.3267,  -6.6522,  -4.8120],\n",
      "         [ -5.6589,  -5.6677,  -5.6609,  ...,  -5.9124,  -6.1804,  -3.9456],\n",
      "         [ -6.8615,  -6.8562,  -6.9103,  ...,  -7.0783,  -7.3197,  -4.5709]],\n",
      "\n",
      "        [[ -6.7473,  -6.7379,  -6.7899,  ...,  -6.2210,  -6.0148,  -3.8539],\n",
      "         [ -6.2169,  -6.1376,  -6.2792,  ...,  -6.8160,  -6.3785,  -2.9290],\n",
      "         [ -5.3635,  -5.2795,  -5.4352,  ...,  -6.6035,  -6.4122,  -4.2827],\n",
      "         ...,\n",
      "         [ -4.6647,  -4.6510,  -4.7563,  ...,  -5.7994,  -5.3461,  -2.0259],\n",
      "         [ -5.2507,  -5.2701,  -5.4074,  ...,  -6.1762,  -5.7426,  -2.7138],\n",
      "         [ -5.3269,  -5.2971,  -5.3830,  ...,  -6.1453,  -5.6522,  -1.7031]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0436,  -7.0084,  -7.0116,  ...,  -5.8808,  -6.1769,  -4.1349],\n",
      "         [-11.7758, -11.8479, -11.4087,  ...,  -8.8832,  -8.8967, -10.1177],\n",
      "         [ -5.4762,  -5.5200,  -5.6532,  ...,  -5.8821,  -7.2138,  -4.3730],\n",
      "         ...,\n",
      "         [ -6.6841,  -6.7216,  -6.7630,  ...,  -6.6370,  -7.5494,  -4.2683],\n",
      "         [ -5.4069,  -5.5065,  -5.5783,  ...,  -5.8325,  -6.7641,  -3.5710],\n",
      "         [ -6.4775,  -6.6356,  -6.6764,  ...,  -6.7689,  -7.3746,  -2.8630]],\n",
      "\n",
      "        [[ -7.6433,  -7.8636,  -7.6407,  ...,  -7.0324,  -6.6101,  -4.7016],\n",
      "         [ -7.8712,  -8.3034,  -7.7641,  ...,  -6.3586,  -7.9821,  -7.6492],\n",
      "         [ -8.1865,  -8.3113,  -8.5845,  ...,  -6.6737,  -6.9491,  -6.3397],\n",
      "         ...,\n",
      "         [ -6.3513,  -6.4944,  -6.2853,  ...,  -5.4782,  -7.0056,  -5.0629],\n",
      "         [ -7.5352,  -7.5616,  -7.4445,  ...,  -6.9199,  -6.4859,  -5.4735],\n",
      "         [ -7.0372,  -7.0541,  -6.9838,  ...,  -6.2615,  -6.7231,  -5.8255]],\n",
      "\n",
      "        [[ -8.4165,  -8.4308,  -8.4765,  ...,  -7.6463,  -7.4638,  -5.8094],\n",
      "         [-12.7935, -12.8186, -12.8423,  ..., -12.2370, -10.7149, -11.6870],\n",
      "         [ -2.7916,  -2.8007,  -2.7877,  ...,  -2.2824,  -3.0738,  -4.0918],\n",
      "         ...,\n",
      "         [ -5.2010,  -5.5436,  -5.2278,  ...,  -5.2029,  -3.9442,  -5.6227],\n",
      "         [ -6.4919,  -6.5121,  -6.5183,  ...,  -6.8441,  -4.7466,  -7.8831],\n",
      "         [ -6.7928,  -6.7264,  -6.7052,  ...,  -7.1184,  -5.0521,  -7.8855]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.660128116607666\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2183, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9633,  -6.8935,  -6.9318,  ...,  -6.0813,  -6.1554,  -3.8652],\n",
      "         [-10.5540, -10.8745, -10.2606,  ...,  -8.3580,  -8.0990,  -7.2033],\n",
      "         [ -4.6538,  -4.6379,  -4.7760,  ...,  -4.7630,  -6.0274,  -3.0947],\n",
      "         ...,\n",
      "         [ -4.4684,  -4.4016,  -4.6252,  ...,  -4.8170,  -6.0075,  -3.7787],\n",
      "         [ -5.8660,  -5.7692,  -5.8605,  ...,  -5.9348,  -6.9178,  -2.8389],\n",
      "         [ -4.8381,  -4.7335,  -4.9991,  ...,  -4.9294,  -6.0792,  -3.7769]],\n",
      "\n",
      "        [[ -6.5406,  -6.5534,  -6.5125,  ...,  -5.8650,  -5.8672,  -3.8235],\n",
      "         [ -6.1562,  -6.0484,  -6.2445,  ...,  -7.6664,  -6.8692,  -2.7558],\n",
      "         [ -6.3468,  -6.3152,  -6.5894,  ...,  -6.6966,  -7.0314,  -2.4853],\n",
      "         ...,\n",
      "         [ -4.5053,  -4.6153,  -4.6775,  ...,  -5.0076,  -5.2746,  -1.4699],\n",
      "         [ -5.2171,  -5.1773,  -5.2684,  ...,  -5.2253,  -6.1894,  -1.5783],\n",
      "         [ -4.5949,  -4.7127,  -4.7948,  ...,  -5.2078,  -5.4304,  -1.4185]],\n",
      "\n",
      "        [[ -6.8902,  -6.8977,  -6.8923,  ...,  -6.3174,  -6.2777,  -4.0812],\n",
      "         [ -6.2709,  -6.4387,  -6.4365,  ...,  -6.1602,  -5.8148,  -4.8491],\n",
      "         [ -7.7560,  -8.0240,  -7.9899,  ...,  -7.2130,  -5.8160,  -6.6627],\n",
      "         ...,\n",
      "         [ -6.2809,  -6.2685,  -6.3233,  ...,  -6.3144,  -5.6712,  -5.8063],\n",
      "         [ -5.7218,  -5.6417,  -5.7771,  ...,  -5.9608,  -5.3640,  -5.5782],\n",
      "         [ -7.0933,  -7.1556,  -7.0713,  ...,  -7.1935,  -6.6452,  -4.0267]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5064,  -6.4292,  -6.5024,  ...,  -5.6345,  -5.6776,  -3.6947],\n",
      "         [ -7.2203,  -6.9352,  -7.2571,  ...,  -7.1124,  -8.2445,  -5.5321],\n",
      "         [ -8.1346,  -7.9043,  -7.9546,  ...,  -8.2916,  -7.5839,  -6.6759],\n",
      "         ...,\n",
      "         [ -5.7247,  -5.6016,  -5.6570,  ...,  -5.0497,  -5.5670,  -3.5606],\n",
      "         [ -3.3156,  -3.3251,  -3.3543,  ...,  -3.6810,  -4.9143,  -1.6050],\n",
      "         [ -5.4708,  -5.2645,  -5.4292,  ...,  -5.1575,  -5.5847,  -3.2221]],\n",
      "\n",
      "        [[ -7.2028,  -7.2303,  -7.1327,  ...,  -6.5182,  -6.0368,  -3.9127],\n",
      "         [ -8.7369,  -8.6987,  -8.7946,  ...,  -8.6427,  -8.8278,  -3.5120],\n",
      "         [-13.5032, -13.0906, -13.3465,  ..., -13.6977, -13.5360,  -4.9987],\n",
      "         ...,\n",
      "         [-11.0206, -10.9716, -10.9535,  ..., -10.3159,  -7.4073,  -8.5435],\n",
      "         [ -5.8177,  -5.9507,  -5.8123,  ...,  -4.8794,  -3.6116,  -4.6121],\n",
      "         [-13.9889, -14.2172, -14.1369,  ..., -13.3823, -11.4377, -10.8100]],\n",
      "\n",
      "        [[ -7.6327,  -7.5244,  -7.5674,  ...,  -6.7180,  -6.5307,  -4.5348],\n",
      "         [ -9.9428,  -9.4988, -10.0175,  ...,  -7.5866,  -7.6868,  -6.3642],\n",
      "         [ -5.2971,  -5.3482,  -5.4041,  ...,  -5.7744,  -6.8644,  -3.4209],\n",
      "         ...,\n",
      "         [ -4.5508,  -4.6935,  -4.5415,  ...,  -4.0014,  -5.6417,  -3.0472],\n",
      "         [ -4.7030,  -4.6548,  -4.6067,  ...,  -4.7059,  -6.2330,  -4.3095],\n",
      "         [ -4.6708,  -4.7182,  -4.7309,  ...,  -4.5244,  -5.4130,  -3.2808]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.218278646469116\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.2141, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7316,  -6.6962,  -6.7129,  ...,  -5.9851,  -5.9290,  -3.7812],\n",
      "         [ -8.1903,  -8.0546,  -8.4126,  ...,  -9.1103,  -7.8822,  -6.4598],\n",
      "         [ -5.8567,  -5.8431,  -6.0822,  ...,  -6.2166,  -5.9199,  -3.6458],\n",
      "         ...,\n",
      "         [ -4.9597,  -4.8210,  -4.9966,  ...,  -5.6887,  -5.8355,  -2.4917],\n",
      "         [ -5.3766,  -5.4217,  -5.5740,  ...,  -5.5363,  -5.8170,  -2.9643],\n",
      "         [ -5.0573,  -4.9685,  -5.1218,  ...,  -5.4127,  -5.6276,  -2.4633]],\n",
      "\n",
      "        [[-11.1952, -11.6816, -11.3109,  ..., -12.1100, -11.1439,  -6.5144],\n",
      "         [-13.3854, -13.3629, -13.5048,  ..., -10.2445,  -9.5980, -11.6280],\n",
      "         [ -4.7993,  -4.8338,  -4.8685,  ...,  -5.8559,  -6.1507,  -3.8512],\n",
      "         ...,\n",
      "         [ -4.7970,  -4.8033,  -4.9080,  ...,  -5.4271,  -5.8591,  -4.5732],\n",
      "         [ -4.4796,  -4.4993,  -4.4917,  ...,  -5.4023,  -5.8361,  -3.6507],\n",
      "         [ -5.3635,  -5.2444,  -5.3226,  ...,  -5.7802,  -6.2482,  -4.4449]],\n",
      "\n",
      "        [[ -6.9595,  -6.9472,  -6.9466,  ...,  -6.2494,  -6.0935,  -4.5469],\n",
      "         [ -9.3513,  -9.1702,  -9.4654,  ...,  -8.1364,  -7.9786,  -6.0391],\n",
      "         [ -6.6060,  -6.6392,  -6.5525,  ...,  -7.0402,  -7.1400,  -5.2086],\n",
      "         ...,\n",
      "         [ -6.7761,  -6.6812,  -6.7230,  ...,  -7.0653,  -6.9001,  -5.5601],\n",
      "         [ -6.1598,  -6.2447,  -6.2097,  ...,  -6.6683,  -6.7494,  -4.9598],\n",
      "         [ -7.0274,  -7.1651,  -7.1223,  ...,  -7.2263,  -7.5155,  -4.9029]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6516,  -6.6544,  -6.6558,  ...,  -5.7884,  -6.0760,  -3.7750],\n",
      "         [-11.6276, -11.8551, -11.7491,  ...,  -7.0695,  -8.4689, -10.8595],\n",
      "         [ -5.5998,  -5.7593,  -5.9208,  ...,  -5.5743,  -7.0556,  -3.6148],\n",
      "         ...,\n",
      "         [ -5.2204,  -5.1906,  -5.2038,  ...,  -5.4019,  -6.1343,  -3.4708],\n",
      "         [ -5.6460,  -5.7815,  -5.8378,  ...,  -5.6366,  -6.8769,  -3.6057],\n",
      "         [ -5.7232,  -5.7901,  -5.8185,  ...,  -5.7750,  -7.0249,  -4.2310]],\n",
      "\n",
      "        [[ -6.9184,  -6.8822,  -6.9253,  ...,  -6.2062,  -6.2124,  -4.1788],\n",
      "         [ -8.6358,  -8.3630,  -8.6663,  ...,  -8.9262,  -8.5775,  -4.5732],\n",
      "         [ -9.3620,  -9.3381,  -9.3352,  ...,  -9.6806,  -9.2744,  -5.1266],\n",
      "         ...,\n",
      "         [ -5.0919,  -5.1241,  -5.2522,  ...,  -5.7673,  -5.2473,  -1.6878],\n",
      "         [ -5.0233,  -4.9873,  -5.1585,  ...,  -5.7008,  -5.8628,  -1.8800],\n",
      "         [ -5.7758,  -5.7313,  -5.9863,  ...,  -6.1633,  -6.4499,  -1.7640]],\n",
      "\n",
      "        [[ -7.0189,  -7.0568,  -7.0335,  ...,  -6.3533,  -6.1921,  -4.2064],\n",
      "         [-11.2299, -11.2697, -11.2168,  ...,  -9.9863, -10.2492,  -6.1051],\n",
      "         [-13.2137, -13.2622, -13.3105,  ..., -11.4385, -10.1009,  -7.2648],\n",
      "         ...,\n",
      "         [ -8.0217,  -7.8531,  -7.9078,  ...,  -8.8567,  -6.7272,  -3.7152],\n",
      "         [ -8.5049,  -8.4952,  -8.4051,  ...,  -8.9214,  -7.2492,  -5.1826],\n",
      "         [ -7.4363,  -7.5344,  -7.4872,  ...,  -8.1075,  -6.2387,  -5.3524]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 3.214085817337036\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6677, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.0726,  -5.9404,  -5.8664,  ...,  -5.9427,  -5.4463,  -3.7247],\n",
      "         [-11.8363, -11.4321, -11.5437,  ..., -10.0334,  -8.9622,  -8.7312],\n",
      "         [ -5.2680,  -5.3144,  -5.4751,  ...,  -5.6118,  -6.3860,  -2.6316],\n",
      "         ...,\n",
      "         [ -4.6101,  -4.6765,  -4.6746,  ...,  -4.9422,  -5.4491,  -3.8905],\n",
      "         [ -4.6054,  -4.6390,  -4.4868,  ...,  -4.4749,  -5.0452,  -3.7812],\n",
      "         [ -4.5620,  -4.5498,  -4.5796,  ...,  -4.6426,  -5.5078,  -4.1839]],\n",
      "\n",
      "        [[ -8.7490,  -8.7145,  -8.6514,  ...,  -8.0563,  -7.0138,  -5.5411],\n",
      "         [-12.9075, -12.9738, -13.0732,  ..., -13.1691, -10.7082, -10.3714],\n",
      "         [-11.7117, -11.7017, -11.9553,  ..., -11.0409,  -9.5794,  -9.1324],\n",
      "         ...,\n",
      "         [ -2.6007,  -2.7387,  -2.6601,  ...,  -2.5819,  -3.4750,  -2.3991],\n",
      "         [-14.1940, -14.2655, -13.6510,  ..., -11.2493, -12.7578, -12.2327],\n",
      "         [-11.5278, -11.4622, -11.5153,  ...,  -9.1966,  -8.5812,  -9.0701]],\n",
      "\n",
      "        [[ -8.3291,  -8.3805,  -8.3104,  ...,  -7.6619,  -7.5371,  -5.5689],\n",
      "         [-12.8701, -12.7965, -12.6923,  ..., -11.3216,  -9.9032, -13.0829],\n",
      "         [ -6.7322,  -6.8258,  -6.7976,  ...,  -6.0272,  -5.7710,  -8.8342],\n",
      "         ...,\n",
      "         [ -4.1392,  -4.1267,  -3.9847,  ...,  -4.7155,  -3.7782,  -6.2036],\n",
      "         [ -7.2795,  -7.5766,  -7.4311,  ...,  -7.9902,  -7.5330,  -5.3086],\n",
      "         [ -7.5695,  -7.7643,  -7.5459,  ...,  -8.4006,  -7.8109,  -6.9846]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.5009,  -7.5568,  -7.3886,  ...,  -7.0443,  -6.3495,  -4.7102],\n",
      "         [ -8.6245,  -8.9937,  -8.5777,  ...,  -8.7198,  -5.5865,  -9.6942],\n",
      "         [ -4.3774,  -4.6740,  -4.1570,  ...,  -4.4312,  -2.2390,  -6.0888],\n",
      "         ...,\n",
      "         [ -7.5678,  -7.8529,  -7.5115,  ...,  -7.0819,  -5.7052,  -4.4887],\n",
      "         [ -7.5361,  -7.7085,  -7.3748,  ...,  -7.7882,  -6.5658,  -4.0204],\n",
      "         [ -8.7402,  -8.9659,  -8.8749,  ...,  -8.3556,  -6.2564,  -6.6212]],\n",
      "\n",
      "        [[ -6.7309,  -6.7096,  -6.7279,  ...,  -5.9726,  -5.8916,  -4.1948],\n",
      "         [-12.3374, -11.8314, -12.0618,  ...,  -8.0098, -10.0449,  -7.9677],\n",
      "         [ -4.3340,  -4.5509,  -4.5464,  ...,  -5.0637,  -6.2330,  -3.4412],\n",
      "         ...,\n",
      "         [ -4.7278,  -4.7789,  -4.7760,  ...,  -4.8356,  -6.4009,  -3.5441],\n",
      "         [ -5.4914,  -5.5265,  -5.5419,  ...,  -5.8534,  -6.5749,  -3.2360],\n",
      "         [ -5.1730,  -5.2372,  -5.2402,  ...,  -5.4807,  -6.6517,  -3.3335]],\n",
      "\n",
      "        [[ -5.8621,  -5.8025,  -5.8402,  ...,  -5.2314,  -5.0095,  -3.3515],\n",
      "         [-11.0427, -10.6549, -11.0540,  ...,  -8.4273,  -8.0629, -10.0317],\n",
      "         [ -4.3327,  -4.3187,  -4.4991,  ...,  -5.2511,  -5.9412,  -3.0281],\n",
      "         ...,\n",
      "         [ -5.5791,  -5.5245,  -5.6221,  ...,  -5.6561,  -6.4774,  -2.8736],\n",
      "         [ -4.8274,  -4.8886,  -4.9909,  ...,  -5.1876,  -6.2310,  -3.7579],\n",
      "         [ -5.2562,  -5.2190,  -5.3377,  ...,  -4.9886,  -6.2318,  -3.8945]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6676653623580933\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.3939, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1136,  -6.9837,  -6.9843,  ...,  -6.1962,  -5.9995,  -3.9786],\n",
      "         [-11.7108, -11.5131, -11.3933,  ...,  -8.7934,  -9.2178,  -9.6492],\n",
      "         [ -4.4146,  -4.4762,  -4.5442,  ...,  -5.1115,  -6.4774,  -3.4063],\n",
      "         ...,\n",
      "         [ -3.9503,  -3.9878,  -3.9834,  ...,  -4.5136,  -5.4925,  -3.7430],\n",
      "         [ -5.2078,  -5.2344,  -5.1860,  ...,  -5.4112,  -5.9934,  -4.3195],\n",
      "         [ -4.7966,  -4.8732,  -4.8929,  ...,  -4.9647,  -6.1559,  -4.2700]],\n",
      "\n",
      "        [[ -7.3473,  -7.4590,  -7.3297,  ...,  -6.6249,  -6.5655,  -4.7708],\n",
      "         [ -9.9899, -10.2775, -10.2795,  ..., -10.5488,  -9.6645,  -8.7907],\n",
      "         [ -9.6124,  -9.5306,  -9.2241,  ..., -10.0936,  -7.3271,  -9.1171],\n",
      "         ...,\n",
      "         [ -7.9451,  -8.2521,  -8.2341,  ...,  -7.9626,  -9.2573,  -7.9585],\n",
      "         [ -5.8030,  -5.8071,  -5.8713,  ...,  -5.9325,  -5.9282,  -2.1231],\n",
      "         [-10.9524, -10.6180, -11.1467,  ...,  -8.1551,  -8.1633, -10.1195]],\n",
      "\n",
      "        [[ -7.7189,  -7.7793,  -7.6088,  ...,  -6.7976,  -6.8944,  -5.1777],\n",
      "         [-11.2477, -11.2054, -11.2105,  ..., -11.2540,  -9.5953, -10.2877],\n",
      "         [ -8.1110,  -7.9541,  -8.1358,  ...,  -8.2631,  -6.7049,  -9.0115],\n",
      "         ...,\n",
      "         [ -6.7454,  -6.8921,  -6.8318,  ...,  -6.0707,  -6.2636,  -5.3082],\n",
      "         [ -6.3797,  -6.4573,  -6.3219,  ...,  -5.5892,  -5.6594,  -5.8373],\n",
      "         [ -6.7335,  -6.9271,  -6.8722,  ...,  -6.4481,  -7.0909,  -5.8280]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3005,  -6.2565,  -6.2527,  ...,  -5.6049,  -5.3598,  -4.0131],\n",
      "         [-12.6203, -12.5297, -12.5524,  ...,  -9.1619,  -9.2369,  -8.7759],\n",
      "         [ -5.7700,  -5.8171,  -5.8409,  ...,  -6.1446,  -6.4442,  -4.3490],\n",
      "         ...,\n",
      "         [ -5.6529,  -5.5585,  -5.6068,  ...,  -5.5387,  -6.3046,  -4.4808],\n",
      "         [ -5.4616,  -5.4059,  -5.4062,  ...,  -5.5514,  -5.8801,  -4.8286],\n",
      "         [ -6.8639,  -6.8775,  -6.8020,  ...,  -7.0713,  -6.3232,  -4.6239]],\n",
      "\n",
      "        [[ -6.6181,  -6.5861,  -6.5984,  ...,  -5.9075,  -5.7480,  -3.9496],\n",
      "         [-12.6579, -12.4232, -12.1214,  ...,  -9.7625, -10.2843, -12.2289],\n",
      "         [ -5.4124,  -5.5571,  -5.4981,  ...,  -5.6449,  -6.6995,  -3.9119],\n",
      "         ...,\n",
      "         [ -5.4735,  -5.4847,  -5.5154,  ...,  -5.1197,  -6.3583,  -4.2504],\n",
      "         [ -5.7354,  -5.6716,  -5.7439,  ...,  -5.4718,  -6.5932,  -4.5665],\n",
      "         [ -6.1303,  -6.0253,  -6.1790,  ...,  -6.2485,  -6.7061,  -4.2590]],\n",
      "\n",
      "        [[ -6.3788,  -6.3655,  -6.3634,  ...,  -5.7556,  -5.5613,  -3.7556],\n",
      "         [ -7.6942,  -7.3333,  -7.4039,  ...,  -6.9741,  -7.4953,  -4.0501],\n",
      "         [ -5.2688,  -5.3869,  -5.3432,  ...,  -6.1873,  -5.1722,  -0.6558],\n",
      "         ...,\n",
      "         [ -8.1118,  -7.8242,  -7.8607,  ...,  -7.3746,  -7.2607,  -4.7551],\n",
      "         [ -7.4440,  -7.2541,  -7.4227,  ...,  -6.8698,  -7.0422,  -3.4501],\n",
      "         [ -7.5122,  -7.4481,  -7.5528,  ...,  -7.3394,  -7.6450,  -3.4894]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 3.3938865661621094\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.1743, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1392,  -7.0517,  -7.0247,  ...,  -6.1097,  -6.2908,  -4.3530],\n",
      "         [-20.0369, -19.9074, -19.6751,  ..., -17.7018, -16.9880, -13.4645],\n",
      "         [ -4.6707,  -4.8802,  -4.8860,  ...,  -5.0701,  -6.4218,  -3.5571],\n",
      "         ...,\n",
      "         [ -5.2194,  -5.2881,  -5.3116,  ...,  -5.2090,  -6.4958,  -4.2477],\n",
      "         [ -4.8425,  -4.9361,  -5.0420,  ...,  -4.3174,  -6.0022,  -4.4460],\n",
      "         [ -5.1195,  -5.3059,  -5.3263,  ...,  -4.6614,  -6.0234,  -3.5769]],\n",
      "\n",
      "        [[ -6.6641,  -6.6146,  -6.6120,  ...,  -5.9429,  -5.8265,  -4.0484],\n",
      "         [-17.3685, -16.9751, -16.8785,  ..., -15.0198, -14.4288, -14.8451],\n",
      "         [ -5.6848,  -5.7772,  -5.7784,  ...,  -5.8983,  -6.4682,  -4.2841],\n",
      "         ...,\n",
      "         [ -6.2095,  -6.3443,  -6.2675,  ...,  -6.1786,  -6.6725,  -4.1003],\n",
      "         [ -6.2202,  -6.2833,  -6.3034,  ...,  -5.9784,  -6.6738,  -4.5854],\n",
      "         [ -7.0284,  -6.9748,  -7.0554,  ...,  -6.9814,  -6.9483,  -5.3027]],\n",
      "\n",
      "        [[ -6.3692,  -6.3496,  -6.3808,  ...,  -5.6329,  -5.7992,  -3.6515],\n",
      "         [ -9.3115,  -8.7898,  -9.1368,  ...,  -6.2177,  -7.2335,  -6.7821],\n",
      "         [ -5.1690,  -5.3020,  -5.3250,  ...,  -5.6583,  -6.3242,  -2.1043],\n",
      "         ...,\n",
      "         [ -5.6447,  -5.8327,  -5.7719,  ...,  -5.7507,  -6.3194,  -2.5287],\n",
      "         [ -5.5031,  -5.6815,  -5.6544,  ...,  -5.9350,  -6.0216,  -2.1385],\n",
      "         [ -5.1659,  -5.3175,  -5.2730,  ...,  -5.4095,  -5.8803,  -1.9836]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.7749,  -8.9513,  -8.7869,  ...,  -7.5021,  -7.6275,  -5.7154],\n",
      "         [-12.4582, -12.3514, -12.2216,  ...,  -9.7584,  -9.5755,  -9.9879],\n",
      "         [ -4.9792,  -5.0748,  -5.1833,  ...,  -6.0060,  -7.4060,  -3.8076],\n",
      "         ...,\n",
      "         [ -5.7829,  -5.9603,  -5.8940,  ...,  -5.8804,  -6.9111,  -4.0495],\n",
      "         [ -4.1217,  -4.1903,  -4.2823,  ...,  -4.9670,  -5.9249,  -2.7133],\n",
      "         [ -4.2944,  -4.3661,  -4.4072,  ...,  -5.0627,  -6.6867,  -2.6908]],\n",
      "\n",
      "        [[ -6.5961,  -6.6006,  -6.5583,  ...,  -5.9665,  -5.7668,  -3.8441],\n",
      "         [-11.6750, -11.6695, -11.3739,  ...,  -9.7818,  -9.2905,  -9.1054],\n",
      "         [ -5.1148,  -5.2582,  -5.3128,  ...,  -5.7202,  -6.4031,  -3.2677],\n",
      "         ...,\n",
      "         [ -5.3346,  -5.4022,  -5.5741,  ...,  -5.3037,  -6.2394,  -3.4844],\n",
      "         [ -5.1307,  -5.2590,  -5.1633,  ...,  -5.5958,  -5.7797,  -3.5488],\n",
      "         [ -5.6503,  -5.7771,  -5.7301,  ...,  -5.4638,  -6.2046,  -3.3285]],\n",
      "\n",
      "        [[ -6.5695,  -6.5389,  -6.5472,  ...,  -5.8813,  -5.7206,  -3.7947],\n",
      "         [ -8.2987,  -8.3442,  -8.5959,  ...,  -6.3568,  -8.2325,  -4.2839],\n",
      "         [ -4.6339,  -4.2107,  -4.7234,  ...,  -5.4651,  -5.8222,  -7.4273],\n",
      "         ...,\n",
      "         [ -7.4340,  -7.3723,  -7.7442,  ...,  -6.6636,  -7.8537,  -4.0292],\n",
      "         [ -7.4944,  -7.4796,  -7.7405,  ...,  -7.0673,  -7.4988,  -3.6172],\n",
      "         [ -6.5328,  -6.5589,  -6.7002,  ...,  -6.6737,  -6.6265,  -3.9131]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.1742982864379883\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7539, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5453,  -6.5156,  -6.5456,  ...,  -5.9409,  -5.7746,  -3.8269],\n",
      "         [-12.3022, -12.5845, -11.9511,  ...,  -8.9644,  -7.8781,  -9.5528],\n",
      "         [ -4.1576,  -4.1744,  -4.2495,  ...,  -4.8096,  -6.3204,  -2.9839],\n",
      "         ...,\n",
      "         [ -4.3941,  -4.4143,  -4.4680,  ...,  -4.4017,  -5.8337,  -3.3865],\n",
      "         [ -4.7449,  -4.7780,  -4.8217,  ...,  -4.8658,  -6.3413,  -4.4371],\n",
      "         [ -5.2607,  -5.3578,  -5.2413,  ...,  -5.3956,  -6.2921,  -5.1273]],\n",
      "\n",
      "        [[ -6.9562,  -6.9818,  -6.9479,  ...,  -6.2823,  -6.2768,  -4.4572],\n",
      "         [-10.4828, -10.0882, -10.5249,  ...,  -8.1681,  -8.8244,  -6.7888],\n",
      "         [ -4.4736,  -4.5992,  -4.5296,  ...,  -5.1575,  -5.6515,  -3.4754],\n",
      "         ...,\n",
      "         [ -4.8189,  -4.9059,  -4.9012,  ...,  -4.8628,  -6.1213,  -3.5167],\n",
      "         [ -4.6832,  -4.7436,  -4.7474,  ...,  -4.7696,  -5.7320,  -3.3528],\n",
      "         [ -4.7357,  -4.7983,  -4.7509,  ...,  -4.9751,  -5.6413,  -3.2879]],\n",
      "\n",
      "        [[ -7.3018,  -7.2443,  -7.2826,  ...,  -6.3606,  -6.3608,  -4.4522],\n",
      "         [-10.9594, -11.1217, -10.6475,  ...,  -9.6333, -10.2559,  -7.9754],\n",
      "         [ -4.0013,  -4.0270,  -4.0376,  ...,  -4.0879,  -5.8184,  -3.4772],\n",
      "         ...,\n",
      "         [ -4.2620,  -4.2163,  -4.2228,  ...,  -3.7444,  -5.5713,  -3.3202],\n",
      "         [ -4.3998,  -4.3901,  -4.4340,  ...,  -4.1667,  -5.8613,  -2.7690],\n",
      "         [ -4.7885,  -4.8433,  -4.7743,  ...,  -4.5113,  -5.7567,  -3.2423]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5185,  -6.5048,  -6.5086,  ...,  -5.8589,  -5.8063,  -3.5805],\n",
      "         [ -6.2674,  -6.1462,  -6.4090,  ...,  -7.5455,  -7.2666,  -2.6307],\n",
      "         [ -5.3205,  -5.3561,  -5.5695,  ...,  -6.5736,  -6.7178,  -1.5417],\n",
      "         ...,\n",
      "         [ -5.4622,  -5.4076,  -5.5468,  ...,  -5.4832,  -5.5901,  -2.2652],\n",
      "         [ -4.7864,  -4.6685,  -4.8562,  ...,  -5.3940,  -5.8450,  -1.9149],\n",
      "         [ -5.8708,  -5.8079,  -5.9337,  ...,  -6.1021,  -6.4090,  -2.1643]],\n",
      "\n",
      "        [[ -7.0003,  -6.9157,  -6.8941,  ...,  -6.0966,  -6.1275,  -4.1986],\n",
      "         [-10.6753, -10.3752, -10.4757,  ...,  -8.0554,  -8.7569, -10.8706],\n",
      "         [ -5.4249,  -5.3934,  -5.5008,  ...,  -5.9507,  -6.8848,  -3.5991],\n",
      "         ...,\n",
      "         [ -5.2850,  -5.1813,  -5.1976,  ...,  -5.2306,  -6.3312,  -3.6355],\n",
      "         [ -5.0743,  -5.1274,  -5.2156,  ...,  -5.3663,  -6.8619,  -2.8055],\n",
      "         [ -5.0990,  -5.1807,  -5.2436,  ...,  -5.4103,  -6.1862,  -3.2911]],\n",
      "\n",
      "        [[ -6.4387,  -6.4037,  -6.3963,  ...,  -5.8249,  -5.7029,  -3.9164],\n",
      "         [ -6.0508,  -6.1841,  -6.2990,  ...,  -6.8700,  -6.5497,  -2.9914],\n",
      "         [ -5.8470,  -6.1039,  -6.1592,  ...,  -7.1378,  -6.8580,  -3.3643],\n",
      "         ...,\n",
      "         [ -4.6679,  -4.7402,  -4.7158,  ...,  -6.0578,  -5.4158,  -1.6399],\n",
      "         [ -3.8899,  -4.0384,  -4.0182,  ...,  -5.1336,  -5.0323,  -1.3543],\n",
      "         [ -4.8741,  -4.9772,  -4.9491,  ...,  -6.1159,  -5.6063,  -1.3605]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.7538565397262573\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.8254, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.1756,  -6.1439,  -6.1555,  ...,  -5.5409,  -5.4769,  -3.4753],\n",
      "         [ -5.8686,  -5.7508,  -5.9365,  ...,  -6.3414,  -7.3613,  -1.4457],\n",
      "         [ -5.4240,  -5.3599,  -5.6640,  ...,  -6.5709,  -7.2161,  -2.8991],\n",
      "         ...,\n",
      "         [ -5.3809,  -5.3392,  -5.4610,  ...,  -5.2391,  -5.9774,  -2.6434],\n",
      "         [ -4.5194,  -4.3982,  -4.5774,  ...,  -4.6485,  -5.3840,  -1.9808],\n",
      "         [ -5.2041,  -5.0826,  -5.2231,  ...,  -4.9807,  -5.8247,  -1.6297]],\n",
      "\n",
      "        [[-12.0141, -12.0208, -11.8923,  ..., -12.6914, -11.0906, -10.1090],\n",
      "         [-14.1937, -13.9907, -14.0708,  ..., -12.4285, -11.2653, -11.7214],\n",
      "         [ -3.8549,  -3.9126,  -3.9184,  ...,  -4.3793,  -6.0048,  -4.6749],\n",
      "         ...,\n",
      "         [ -3.9646,  -3.9406,  -3.8018,  ...,  -4.6600,  -5.5894,  -4.5804],\n",
      "         [ -3.6315,  -3.6989,  -3.5604,  ...,  -4.1656,  -5.3390,  -5.0358],\n",
      "         [ -4.7607,  -4.8442,  -4.8252,  ...,  -5.1597,  -6.0242,  -5.2269]],\n",
      "\n",
      "        [[ -6.2923,  -6.2594,  -6.2619,  ...,  -5.6980,  -5.5588,  -3.8757],\n",
      "         [ -9.5716,  -9.6052,  -9.5164,  ...,  -6.9589,  -6.9465,  -9.7211],\n",
      "         [ -4.5884,  -4.7089,  -4.8246,  ...,  -4.8161,  -6.3494,  -3.0317],\n",
      "         ...,\n",
      "         [ -5.4891,  -5.4455,  -5.6906,  ...,  -5.8622,  -6.9577,  -3.6178],\n",
      "         [ -5.1849,  -5.1996,  -5.2999,  ...,  -5.0980,  -5.9749,  -3.0469],\n",
      "         [ -4.8843,  -4.8888,  -4.9800,  ...,  -4.9249,  -5.6350,  -3.6252]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2191,  -6.1715,  -6.1294,  ...,  -5.8171,  -5.5390,  -3.3201],\n",
      "         [ -4.7980,  -5.0396,  -4.8765,  ...,  -5.9150,  -5.9988,  -3.3193],\n",
      "         [ -4.7823,  -4.7601,  -4.5362,  ...,  -5.9203,  -5.5078,  -0.8834],\n",
      "         ...,\n",
      "         [ -5.1940,  -5.1915,  -5.0331,  ...,  -5.4429,  -5.0550,  -2.3177],\n",
      "         [ -6.2332,  -6.2644,  -6.1317,  ...,  -6.8400,  -6.2815,  -1.4986],\n",
      "         [ -4.7644,  -4.8636,  -4.8431,  ...,  -5.6384,  -5.5016,  -1.5076]],\n",
      "\n",
      "        [[ -6.4509,  -6.4548,  -6.4301,  ...,  -5.8313,  -5.8669,  -3.2693],\n",
      "         [ -6.6700,  -6.5986,  -6.8240,  ...,  -7.1423,  -6.9576,  -0.8593],\n",
      "         [ -5.7396,  -5.8481,  -5.7244,  ...,  -6.8045,  -6.7782,  -0.2416],\n",
      "         ...,\n",
      "         [ -5.5868,  -5.6780,  -5.7894,  ...,  -5.9498,  -6.0072,  -0.9226],\n",
      "         [ -5.0621,  -5.1507,  -5.2167,  ...,  -5.9818,  -6.2248,  -1.2315],\n",
      "         [ -5.2261,  -5.1648,  -5.2910,  ...,  -5.6908,  -5.7608,  -1.4028]],\n",
      "\n",
      "        [[ -7.9498,  -8.0425,  -7.9555,  ...,  -7.2351,  -7.6409,  -4.5037],\n",
      "         [-14.4884, -14.6896, -14.6874,  ..., -12.9837, -12.3758, -12.9434],\n",
      "         [-11.3977, -11.5695, -11.6289,  ..., -12.1594, -10.9937,  -9.4297],\n",
      "         ...,\n",
      "         [ -6.6370,  -6.6842,  -6.7076,  ...,  -6.7876,  -5.4363,  -5.2262],\n",
      "         [ -6.2297,  -6.4029,  -6.2875,  ...,  -6.6591,  -5.6776,  -4.9417],\n",
      "         [ -7.3240,  -7.3467,  -7.3422,  ...,  -7.2772,  -6.0675,  -5.7360]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.8254002928733826\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8535, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.1154,  -6.1413,  -6.0853,  ...,  -5.6913,  -5.3306,  -3.5464],\n",
      "         [-11.6127, -11.6332, -11.8305,  ..., -10.8875,  -9.5905,  -7.3909],\n",
      "         [ -3.9949,  -4.1889,  -4.4039,  ...,  -5.4052,  -4.6324,  -3.2600],\n",
      "         ...,\n",
      "         [ -4.2558,  -4.3972,  -4.2064,  ...,  -4.2388,  -3.8993,  -3.0939],\n",
      "         [ -3.9120,  -4.0383,  -4.0068,  ...,  -3.9454,  -3.9867,  -2.0817],\n",
      "         [ -4.1103,  -4.2511,  -4.2544,  ...,  -4.5583,  -4.2790,  -2.3976]],\n",
      "\n",
      "        [[ -6.6722,  -6.6655,  -6.6620,  ...,  -5.9110,  -5.9397,  -3.8218],\n",
      "         [-10.1775, -10.5157, -10.1373,  ..., -10.5847,  -8.7503,  -7.7466],\n",
      "         [ -8.4737,  -8.4556,  -8.3591,  ...,  -9.7574,  -7.5138,  -7.7306],\n",
      "         ...,\n",
      "         [ -7.1315,  -7.3199,  -7.2040,  ...,  -8.0061,  -6.6998,  -5.7146],\n",
      "         [ -7.6074,  -7.7880,  -7.6988,  ...,  -8.1083,  -6.8724,  -4.9055],\n",
      "         [ -7.3516,  -7.3941,  -7.3527,  ...,  -8.0171,  -7.0501,  -4.1635]],\n",
      "\n",
      "        [[ -6.8091,  -6.7804,  -6.7673,  ...,  -6.1280,  -5.9890,  -4.0134],\n",
      "         [ -8.4607,  -8.4290,  -8.1599,  ...,  -9.1479,  -6.8131,  -4.0442],\n",
      "         [-11.9049, -12.1640, -12.1985,  ..., -12.2444,  -9.7895, -10.5119],\n",
      "         ...,\n",
      "         [ -8.6780,  -8.6962,  -8.4394,  ...,  -9.1540,  -7.3112,  -4.1189],\n",
      "         [ -8.9547,  -8.9199,  -8.7685,  ...,  -9.2207,  -7.7841,  -3.8747],\n",
      "         [ -8.0972,  -8.1219,  -8.0128,  ...,  -8.7323,  -7.1172,  -4.2122]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.7192,  -6.7770,  -6.6804,  ...,  -6.1012,  -5.9853,  -4.2521],\n",
      "         [-12.8443, -13.3294, -12.7932,  ..., -11.5965, -11.0233, -13.4608],\n",
      "         [ -4.9220,  -5.1391,  -4.9251,  ...,  -4.4583,  -5.6221,  -7.6074],\n",
      "         ...,\n",
      "         [ -5.7515,  -5.6411,  -5.2362,  ...,  -4.7829,  -5.6163,  -7.9340],\n",
      "         [-12.8907, -13.0314, -12.6538,  ..., -12.6888, -11.0689, -12.3242],\n",
      "         [-13.7774, -14.3537, -13.9278,  ..., -12.7463, -10.7634,  -7.1980]],\n",
      "\n",
      "        [[ -6.6238,  -6.5632,  -6.5427,  ...,  -6.1089,  -5.6100,  -3.7291],\n",
      "         [ -6.3700,  -6.3369,  -6.5509,  ...,  -6.5957,  -5.4510,  -4.5153],\n",
      "         [-13.2459, -13.2736, -13.0516,  ..., -11.6413,  -9.8435, -10.1349],\n",
      "         ...,\n",
      "         [-12.9081, -13.1318, -13.0625,  ..., -11.0789,  -9.8348, -11.1016],\n",
      "         [ -5.3698,  -5.4214,  -5.3934,  ...,  -5.8642,  -3.6468,  -4.5119],\n",
      "         [-12.8558, -13.1221, -13.2613,  ..., -11.5640,  -9.8497,  -6.9145]],\n",
      "\n",
      "        [[ -6.9314,  -6.9103,  -6.8613,  ...,  -6.1156,  -5.7636,  -3.7681],\n",
      "         [ -7.7051,  -7.6586,  -7.4962,  ...,  -5.8331,  -5.4760,  -2.9386],\n",
      "         [ -6.7835,  -6.9849,  -6.7724,  ...,  -5.0425,  -5.2444,  -0.6633],\n",
      "         ...,\n",
      "         [ -6.7936,  -6.8125,  -6.6182,  ...,  -5.8105,  -5.2078,  -3.0479],\n",
      "         [ -6.9756,  -7.0810,  -6.9089,  ...,  -5.4087,  -5.5725,  -2.4563],\n",
      "         [ -7.3946,  -7.4573,  -7.3396,  ...,  -6.0802,  -5.8003,  -2.7116]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.853511929512024\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.7403, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8924,  -7.8549,  -7.6437,  ...,  -7.5690,  -7.6251,  -6.2408],\n",
      "         [-10.8405, -11.2417, -10.9458,  ...,  -7.8284,  -8.7589, -11.2610],\n",
      "         [ -3.9506,  -4.0454,  -4.0478,  ...,  -4.1404,  -5.4538,  -4.6544],\n",
      "         ...,\n",
      "         [ -3.8256,  -3.7671,  -3.7140,  ...,  -3.5591,  -4.8537,  -3.8200],\n",
      "         [ -4.6296,  -4.6530,  -4.5883,  ...,  -4.3386,  -5.4649,  -4.4671],\n",
      "         [ -3.7607,  -3.8139,  -3.7369,  ...,  -3.6972,  -4.4937,  -3.8892]],\n",
      "\n",
      "        [[ -6.3285,  -6.2507,  -6.2756,  ...,  -5.5800,  -5.2785,  -3.7290],\n",
      "         [-12.1186, -12.0976, -11.9458,  ...,  -9.4774,  -8.2877,  -9.1340],\n",
      "         [ -4.3082,  -4.4366,  -4.5093,  ...,  -4.9941,  -5.8813,  -2.9748],\n",
      "         ...,\n",
      "         [ -3.6458,  -3.7072,  -3.7469,  ...,  -3.4951,  -5.0662,  -2.2919],\n",
      "         [ -5.8608,  -5.9494,  -5.9332,  ...,  -5.6863,  -6.2440,  -4.3679],\n",
      "         [ -3.8526,  -4.0108,  -3.9351,  ...,  -4.1931,  -5.5494,  -2.3908]],\n",
      "\n",
      "        [[ -6.7017,  -6.6467,  -6.6541,  ...,  -5.6447,  -5.9931,  -3.9127],\n",
      "         [-12.0160, -11.6437, -11.8813,  ...,  -8.2085,  -8.3192, -10.8123],\n",
      "         [ -5.8400,  -5.8646,  -5.9411,  ...,  -6.2094,  -6.8444,  -2.7842],\n",
      "         ...,\n",
      "         [ -5.4723,  -5.4939,  -5.5217,  ...,  -5.5594,  -6.1277,  -3.0345],\n",
      "         [ -5.6494,  -5.7148,  -5.7344,  ...,  -5.7177,  -6.2196,  -2.4049],\n",
      "         [ -5.5737,  -5.6378,  -5.7171,  ...,  -5.8256,  -6.1939,  -2.5621]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4192,  -6.3895,  -6.3762,  ...,  -5.7397,  -5.5952,  -3.7790],\n",
      "         [ -5.2321,  -4.8080,  -5.1456,  ...,  -5.3720,  -5.6549,  -3.4025],\n",
      "         [ -5.7689,  -5.8709,  -5.6754,  ...,  -5.8610,  -5.7129,  -5.2381],\n",
      "         ...,\n",
      "         [ -5.3494,  -5.4016,  -5.3639,  ...,  -5.6890,  -5.8381,  -3.6472],\n",
      "         [ -4.7119,  -4.9193,  -4.8366,  ...,  -5.4940,  -5.2345,  -3.2866],\n",
      "         [ -5.2484,  -5.2418,  -5.2344,  ...,  -5.6527,  -5.8692,  -3.2396]],\n",
      "\n",
      "        [[ -6.0681,  -6.0768,  -5.9727,  ...,  -5.5563,  -5.4713,  -3.3599],\n",
      "         [-12.5715, -12.4768, -12.8616,  ..., -10.8247,  -8.8965,  -9.4079],\n",
      "         [ -6.0212,  -6.0854,  -6.1637,  ...,  -6.5029,  -6.3788,  -4.3974],\n",
      "         ...,\n",
      "         [ -4.8219,  -4.9871,  -4.8584,  ...,  -5.3617,  -5.1667,  -3.9267],\n",
      "         [ -5.2586,  -5.3600,  -5.2882,  ...,  -5.3152,  -5.6856,  -3.3684],\n",
      "         [ -5.7535,  -5.7899,  -5.8057,  ...,  -5.8912,  -5.9346,  -3.5247]],\n",
      "\n",
      "        [[ -6.4068,  -6.1996,  -6.1947,  ...,  -6.3586,  -5.6527,  -3.0010],\n",
      "         [-12.3900, -11.8294, -11.9226,  ...,  -9.1317,  -9.2540, -11.8259],\n",
      "         [ -5.0428,  -5.2617,  -5.2566,  ...,  -5.6775,  -6.0786,  -3.8501],\n",
      "         ...,\n",
      "         [ -4.9552,  -5.0337,  -5.0827,  ...,  -5.8995,  -5.8260,  -3.7106],\n",
      "         [ -4.4996,  -4.5853,  -4.7208,  ...,  -5.0879,  -5.3886,  -3.7466],\n",
      "         [ -4.8722,  -4.9417,  -4.9558,  ...,  -5.3898,  -5.9375,  -3.4445]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.7403285503387451\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0381, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2489,  -7.2486,  -7.2151,  ...,  -6.7190,  -6.0903,  -4.3257],\n",
      "         [ -5.3868,  -5.3427,  -5.2872,  ...,  -4.7829,  -4.5080,  -3.7205],\n",
      "         [-12.0141, -11.9294, -11.6612,  ..., -10.3572,  -8.0186,  -8.2946],\n",
      "         ...,\n",
      "         [ -8.8781,  -9.3014,  -8.7717,  ...,  -7.7400,  -7.5065,  -5.7597],\n",
      "         [ -2.6280,  -2.7385,  -2.6367,  ...,  -1.3126,  -2.3015,  -0.5708],\n",
      "         [-11.1290, -11.0776, -11.0522,  ...,  -8.9683,  -7.1445,  -8.6396]],\n",
      "\n",
      "        [[ -7.9896,  -7.9853,  -7.9843,  ...,  -7.0782,  -6.8731,  -4.9843],\n",
      "         [-10.4637, -10.9669, -10.4165,  ...,  -7.5992,  -8.4363, -10.4469],\n",
      "         [ -3.7020,  -3.7366,  -3.8957,  ...,  -3.9851,  -5.5925,  -3.8558],\n",
      "         ...,\n",
      "         [ -4.3669,  -4.4675,  -4.4902,  ...,  -4.7012,  -5.7853,  -3.2112],\n",
      "         [ -3.9880,  -3.9597,  -4.0174,  ...,  -4.2437,  -4.9071,  -3.9997],\n",
      "         [ -3.7116,  -3.7788,  -3.7535,  ...,  -3.6762,  -4.8414,  -3.3316]],\n",
      "\n",
      "        [[ -7.5039,  -7.5211,  -7.4244,  ...,  -6.5966,  -6.5740,  -3.0282],\n",
      "         [-14.5465, -14.7407, -14.4208,  ..., -13.9438, -11.7162, -12.1837],\n",
      "         [ -8.9431,  -8.7733,  -8.8222,  ...,  -7.6668,  -7.9235,  -5.1952],\n",
      "         ...,\n",
      "         [-14.8264, -14.9901, -14.6900,  ..., -13.6734, -10.7731,  -5.1505],\n",
      "         [ -8.0304,  -8.0387,  -8.0847,  ...,  -7.0687,  -7.0795,  -4.8320],\n",
      "         [-15.1421, -15.2465, -14.8752,  ..., -13.4698, -11.7575,  -9.1349]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2016,  -7.1635,  -7.1422,  ...,  -6.3274,  -6.4073,  -4.1475],\n",
      "         [-12.4550, -12.3085, -12.2716,  ...,  -8.8767,  -9.1751, -11.6239],\n",
      "         [ -4.5830,  -4.7414,  -4.7273,  ...,  -5.1004,  -6.1527,  -4.0126],\n",
      "         ...,\n",
      "         [ -5.5369,  -5.6295,  -5.6187,  ...,  -5.5685,  -6.7048,  -4.2702],\n",
      "         [ -5.4497,  -5.6268,  -5.5575,  ...,  -5.6688,  -6.3176,  -3.6406],\n",
      "         [ -5.8799,  -5.9809,  -5.9908,  ...,  -5.9660,  -6.9825,  -4.4494]],\n",
      "\n",
      "        [[ -6.9966,  -7.0017,  -6.9605,  ...,  -6.4654,  -5.9761,  -4.8982],\n",
      "         [-11.2479, -11.0918, -11.3001,  ..., -10.2560,  -9.3915,  -9.6082],\n",
      "         [-10.8671, -11.0506, -10.7187,  ...,  -9.6880,  -7.5214,  -9.4100],\n",
      "         ...,\n",
      "         [-11.6712, -12.2844, -11.8894,  ...,  -9.5170,  -9.9908, -12.7987],\n",
      "         [-12.8072, -12.9695, -12.8936,  ..., -13.1643,  -9.6217, -11.8542],\n",
      "         [-14.1380, -14.3394, -14.4472,  ..., -11.3172, -10.5432,  -8.7882]],\n",
      "\n",
      "        [[ -6.3159,  -6.2861,  -6.2693,  ...,  -5.7790,  -5.6091,  -3.5330],\n",
      "         [ -6.2177,  -6.2413,  -6.0409,  ...,  -7.7533,  -7.0949,  -2.3768],\n",
      "         [-12.1103, -11.9585, -11.7477,  ..., -13.4271, -11.4441,  -7.9625],\n",
      "         ...,\n",
      "         [ -4.4979,  -4.4636,  -4.4474,  ...,  -5.1207,  -5.0725,  -1.3654],\n",
      "         [ -4.7703,  -4.6715,  -4.6824,  ...,  -5.1838,  -5.5025,  -1.3239],\n",
      "         [ -4.9840,  -4.8628,  -4.8666,  ...,  -5.7614,  -5.6956,  -1.3169]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.038093328475952\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.3069, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2883,  -6.2337,  -6.2597,  ...,  -5.6279,  -5.6070,  -3.9370],\n",
      "         [ -5.3104,  -5.2586,  -5.4071,  ...,  -5.9930,  -5.8104,  -1.3985],\n",
      "         [ -3.6485,  -3.7361,  -3.7211,  ...,  -4.1814,  -3.6397,  -0.1639],\n",
      "         ...,\n",
      "         [ -2.6776,  -2.7060,  -2.6700,  ...,  -3.1154,  -3.2672,  -1.4111],\n",
      "         [ -4.3648,  -4.3718,  -4.4350,  ...,  -4.7250,  -4.4805,  -2.5877],\n",
      "         [ -3.9350,  -3.8699,  -3.9133,  ...,  -4.2545,  -4.4833,  -1.4625]],\n",
      "\n",
      "        [[ -7.1405,  -7.1230,  -7.1057,  ...,  -6.5776,  -6.3500,  -4.4058],\n",
      "         [ -9.7163,  -9.8863,  -9.9608,  ..., -10.7473,  -8.0065, -11.1062],\n",
      "         [ -9.0468,  -9.1958,  -9.4396,  ...,  -8.6249,  -7.0393, -11.2926],\n",
      "         ...,\n",
      "         [-12.1173, -12.2257, -12.1361,  ...,  -9.9022, -10.0292,  -9.0607],\n",
      "         [ -8.4985,  -8.6554,  -8.2624,  ...,  -9.5581,  -8.4092, -11.8978],\n",
      "         [-11.1000, -11.6677, -11.8051,  ...,  -9.5553,  -9.2939,  -9.8369]],\n",
      "\n",
      "        [[ -7.4161,  -7.4498,  -7.3127,  ...,  -6.8219,  -7.4910,  -4.7888],\n",
      "         [-11.8763, -11.7343, -11.5960,  ...,  -9.1287, -10.1000, -11.6030],\n",
      "         [ -4.1871,  -4.3285,  -4.1729,  ...,  -4.6403,  -5.6985,  -3.4831],\n",
      "         ...,\n",
      "         [ -5.1146,  -5.2070,  -5.0623,  ...,  -4.6158,  -5.5115,  -4.2493],\n",
      "         [ -4.6854,  -4.7901,  -4.6643,  ...,  -4.6805,  -5.7122,  -3.4825],\n",
      "         [ -4.1118,  -4.1932,  -4.0159,  ...,  -3.7694,  -4.8941,  -2.6359]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.5382,  -7.5996,  -7.4209,  ...,  -7.1905,  -6.5822,  -5.5059],\n",
      "         [-12.4895, -12.3667, -12.3335,  ..., -12.0814,  -9.8673, -12.5355],\n",
      "         [ -5.6364,  -5.6352,  -5.5067,  ...,  -6.0750,  -4.6865,  -6.5799],\n",
      "         ...,\n",
      "         [ -3.1340,  -3.0176,  -3.0303,  ...,  -1.6885,  -1.2766,  -3.6998],\n",
      "         [-10.0113, -10.0503,  -9.7658,  ...,  -9.1132,  -7.0983,  -5.7176],\n",
      "         [-10.6329, -10.9681, -10.9440,  ...,  -8.2960,  -7.5505,  -6.5887]],\n",
      "\n",
      "        [[ -6.7137,  -6.6819,  -6.6777,  ...,  -6.0599,  -5.6726,  -3.8842],\n",
      "         [-11.2265, -11.4946, -11.6333,  ...,  -8.5839,  -7.0544,  -8.5677],\n",
      "         [ -6.6569,  -6.7716,  -6.7259,  ...,  -6.8097,  -6.6356,  -4.7521],\n",
      "         ...,\n",
      "         [ -6.6470,  -6.6195,  -6.6882,  ...,  -6.9383,  -6.1539,  -4.3310],\n",
      "         [ -6.5253,  -6.5670,  -6.5561,  ...,  -6.6466,  -5.9960,  -3.6562],\n",
      "         [ -7.0527,  -7.1166,  -7.0864,  ...,  -6.8934,  -6.2025,  -4.9342]],\n",
      "\n",
      "        [[ -7.1604,  -7.1774,  -7.1382,  ...,  -6.5272,  -6.3590,  -3.9138],\n",
      "         [-10.3148, -10.1998, -10.3202,  ...,  -9.5797,  -8.6863,  -8.5968],\n",
      "         [ -7.9234,  -7.9374,  -7.6791,  ...,  -8.7112,  -6.9464,  -7.8843],\n",
      "         ...,\n",
      "         [ -7.6230,  -7.7517,  -7.4524,  ...,  -8.2495,  -8.7886,  -4.2719],\n",
      "         [ -7.0618,  -7.0954,  -7.0368,  ...,  -6.8804,  -7.8475,  -4.9717],\n",
      "         [-13.8340, -13.4069, -13.6305,  ..., -10.5368, -10.7204, -12.1316]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 3.3068649768829346\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5071, grad_fn=<NllLossBackward0>), logits=tensor([[[ -5.8208,  -5.7999,  -5.5693,  ...,  -5.6544,  -5.2672,  -3.7757],\n",
      "         [-11.9003, -11.6064, -11.7820,  ..., -10.2100,  -9.9317,  -7.8857],\n",
      "         [ -5.6848,  -5.7414,  -5.7010,  ...,  -6.2507,  -6.6949,  -3.8047],\n",
      "         ...,\n",
      "         [ -4.9463,  -4.9492,  -4.7824,  ...,  -5.3281,  -6.1517,  -3.2630],\n",
      "         [ -5.3054,  -5.2954,  -5.1200,  ...,  -5.4941,  -6.0381,  -3.2149],\n",
      "         [ -5.2669,  -5.3865,  -5.2795,  ...,  -5.7265,  -6.8439,  -2.6635]],\n",
      "\n",
      "        [[ -7.2732,  -7.2893,  -7.2871,  ...,  -6.8342,  -6.5785,  -4.4711],\n",
      "         [-11.9845, -11.6707, -12.1803,  ..., -10.9173,  -8.9731, -12.2967],\n",
      "         [ -6.3580,  -6.2494,  -6.0684,  ...,  -4.2181,  -4.4336,  -9.0446],\n",
      "         ...,\n",
      "         [ -6.6286,  -6.5234,  -6.6086,  ...,  -6.7236,  -6.0350,  -5.5721],\n",
      "         [ -5.7602,  -5.5888,  -5.5490,  ...,  -5.7728,  -5.4693,  -4.4387],\n",
      "         [ -6.7937,  -6.9024,  -6.8349,  ...,  -6.1251,  -5.9199,  -4.4311]],\n",
      "\n",
      "        [[ -7.5288,  -7.4324,  -7.4342,  ...,  -6.9975,  -6.4996,  -4.9893],\n",
      "         [ -9.7049,  -9.4565, -10.0415,  ...,  -9.2738,  -9.2269, -10.3667],\n",
      "         [ -2.1482,  -2.4177,  -2.2560,  ...,  -2.6241,  -4.2973,  -3.2011],\n",
      "         ...,\n",
      "         [ -6.1405,  -6.3387,  -6.3221,  ...,  -6.4025,  -4.9547,  -5.9473],\n",
      "         [-12.7649, -12.7622, -12.6513,  ..., -11.9489, -12.2553,  -6.7684],\n",
      "         [-12.4286, -12.5775, -12.7975,  ..., -10.8143,  -9.5620,  -8.4118]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2857,  -6.2692,  -6.2773,  ...,  -5.6253,  -5.4581,  -3.7916],\n",
      "         [-10.4469,  -9.8900,  -9.9397,  ...,  -5.7763,  -6.9246,  -7.0796],\n",
      "         [ -4.2185,  -4.3931,  -4.4167,  ...,  -4.5121,  -5.6675,  -2.5601],\n",
      "         ...,\n",
      "         [ -5.1715,  -5.3017,  -5.3284,  ...,  -5.1286,  -5.9824,  -3.6715],\n",
      "         [ -4.7177,  -4.8353,  -4.8412,  ...,  -4.8507,  -5.2453,  -3.8022],\n",
      "         [ -5.0187,  -5.1530,  -5.2322,  ...,  -5.3042,  -5.4468,  -3.7233]],\n",
      "\n",
      "        [[ -6.9399,  -6.9945,  -6.9144,  ...,  -6.5741,  -6.3296,  -4.4394],\n",
      "         [ -3.8825,  -3.9600,  -3.9661,  ...,  -3.9839,  -5.4826,  -0.2031],\n",
      "         [ -2.6163,  -2.8528,  -2.7651,  ...,  -2.7506,  -2.1044,  -1.7912],\n",
      "         ...,\n",
      "         [ -4.0739,  -4.4212,  -4.3570,  ...,  -4.7578,  -4.0600,  -3.7865],\n",
      "         [ -5.9914,  -6.2217,  -6.1889,  ...,  -7.4041,  -6.3538,  -5.7143],\n",
      "         [ -7.4032,  -7.4973,  -7.6275,  ...,  -7.5004,  -7.2659,  -6.9025]],\n",
      "\n",
      "        [[ -6.2691,  -6.2397,  -6.2597,  ...,  -5.5501,  -5.4408,  -3.7061],\n",
      "         [-12.2929, -12.2851, -12.2013,  ...,  -9.5262, -10.3137,  -9.8657],\n",
      "         [ -5.4886,  -5.7320,  -5.6724,  ...,  -6.0271,  -6.2492,  -4.0645],\n",
      "         ...,\n",
      "         [ -5.0986,  -5.1357,  -5.1662,  ...,  -5.3351,  -6.1962,  -4.3480],\n",
      "         [ -4.7867,  -4.8832,  -4.8679,  ...,  -5.0283,  -5.4694,  -2.6024],\n",
      "         [ -5.1791,  -5.3008,  -5.2583,  ...,  -5.6155,  -5.8894,  -3.8310]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5071157217025757\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4173, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3073,  -6.3222,  -6.3809,  ...,  -5.8528,  -5.6822,  -3.8817],\n",
      "         [ -5.8911,  -5.8213,  -5.8836,  ...,  -6.5189,  -6.7387,  -3.1019],\n",
      "         [ -4.0011,  -3.9959,  -4.0530,  ...,  -4.9053,  -4.6403,  -3.2768],\n",
      "         ...,\n",
      "         [ -4.1788,  -4.3556,  -4.2848,  ...,  -5.1685,  -4.5700,  -2.6951],\n",
      "         [ -4.1355,  -4.1355,  -4.1696,  ...,  -5.1443,  -4.9331,  -2.2453],\n",
      "         [ -3.9394,  -3.9242,  -3.9862,  ...,  -4.9323,  -5.1277,  -2.4508]],\n",
      "\n",
      "        [[ -6.7081,  -6.9482,  -6.7650,  ...,  -6.4038,  -5.9771,  -3.5337],\n",
      "         [ -6.6760,  -7.1822,  -6.8455,  ...,  -7.5641,  -7.2638,  -6.8792],\n",
      "         [ -7.9324,  -7.5215,  -7.7050,  ...,  -6.2068,  -7.8018, -10.5771],\n",
      "         ...,\n",
      "         [ -5.3553,  -5.4930,  -5.4185,  ...,  -5.1548,  -5.6130,  -2.8741],\n",
      "         [ -6.7240,  -6.8804,  -6.8019,  ...,  -6.8474,  -6.5341,  -5.6171],\n",
      "         [-12.5271, -12.4842, -12.3020,  ..., -11.0007,  -9.1478, -10.1414]],\n",
      "\n",
      "        [[ -7.5679,  -7.7057,  -7.6592,  ...,  -7.2813,  -6.3711,  -6.3090],\n",
      "         [-12.2779, -12.6562, -12.4640,  ..., -14.0241, -10.7532, -13.1607],\n",
      "         [ -5.1536,  -5.6866,  -5.5707,  ...,  -7.8970,  -5.2178,  -6.6406],\n",
      "         ...,\n",
      "         [ -6.0771,  -6.1746,  -6.1867,  ...,  -7.1536,  -6.3983,  -5.0605],\n",
      "         [ -6.2805,  -6.3129,  -6.2219,  ...,  -6.9273,  -6.6259,  -3.5855],\n",
      "         [ -6.7630,  -6.7438,  -6.6822,  ...,  -7.5552,  -7.3766,  -3.7260]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.2338,  -7.1879,  -7.1772,  ...,  -6.3633,  -6.1196,  -4.2250],\n",
      "         [-19.9209, -19.7038, -19.8451,  ..., -16.3888, -16.7708, -13.0199],\n",
      "         [ -4.5955,  -4.8921,  -4.6867,  ...,  -5.0074,  -6.5435,  -3.5594],\n",
      "         ...,\n",
      "         [ -4.6604,  -4.7799,  -4.7134,  ...,  -4.8140,  -6.0585,  -4.5929],\n",
      "         [ -4.2926,  -4.4519,  -4.4559,  ...,  -4.4353,  -5.7842,  -3.4574],\n",
      "         [ -4.5350,  -4.6749,  -4.6199,  ...,  -4.4963,  -6.0852,  -3.9503]],\n",
      "\n",
      "        [[ -6.3012,  -6.2856,  -6.2985,  ...,  -5.7102,  -5.5607,  -3.6788],\n",
      "         [ -6.0736,  -5.9185,  -6.1594,  ...,  -7.1705,  -7.0217,  -3.2096],\n",
      "         [ -5.8436,  -5.9225,  -5.7185,  ...,  -6.5596,  -5.4543,  -3.1014],\n",
      "         ...,\n",
      "         [ -3.9331,  -4.0995,  -4.0086,  ...,  -5.2254,  -5.0296,  -1.6377],\n",
      "         [ -4.4186,  -4.4783,  -4.4536,  ...,  -5.3087,  -5.2530,  -2.8141],\n",
      "         [ -4.6969,  -4.7267,  -4.7196,  ...,  -5.0024,  -5.3239,  -2.1709]],\n",
      "\n",
      "        [[ -6.3979,  -6.4264,  -6.4076,  ...,  -5.8745,  -5.6666,  -3.7371],\n",
      "         [ -2.5470,  -2.7336,  -2.6977,  ...,  -3.7436,  -2.7840,  -3.7157],\n",
      "         [ -5.5297,  -5.6174,  -5.5889,  ...,  -6.7528,  -5.3337,  -4.7541],\n",
      "         ...,\n",
      "         [ -3.0607,  -3.0264,  -2.9493,  ...,  -3.8654,  -3.6015,  -2.5920],\n",
      "         [ -3.8543,  -3.9866,  -3.9600,  ...,  -4.5440,  -4.1197,  -2.8025],\n",
      "         [ -3.7372,  -3.9223,  -3.8624,  ...,  -4.0884,  -4.3805,  -1.9173]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.417289972305298\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3870, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4597,  -7.9189,  -7.4013,  ...,  -8.1951,  -7.7070,  -4.6566],\n",
      "         [-10.6547, -10.4849, -10.7232,  ...,  -8.5691,  -9.7913,  -8.0391],\n",
      "         [ -4.5260,  -4.6672,  -4.6110,  ...,  -5.5322,  -6.0840,  -3.4350],\n",
      "         ...,\n",
      "         [ -4.7632,  -4.8794,  -4.7647,  ...,  -5.2862,  -5.5426,  -4.3794],\n",
      "         [ -5.3342,  -5.4418,  -5.3397,  ...,  -6.3334,  -6.0950,  -4.0175],\n",
      "         [ -5.1882,  -5.2232,  -5.1431,  ...,  -5.7314,  -5.7495,  -4.8116]],\n",
      "\n",
      "        [[ -9.2249,  -9.6522,  -9.1864,  ...,  -9.8537,  -9.9487, -10.5604],\n",
      "         [-13.2208, -13.3819, -12.9549,  ..., -10.5400, -11.1637, -11.8164],\n",
      "         [ -3.4348,  -3.5921,  -3.4780,  ...,  -4.4162,  -4.7265,  -3.1065],\n",
      "         ...,\n",
      "         [ -3.9504,  -3.9491,  -3.9186,  ...,  -4.4318,  -5.6883,  -3.9297],\n",
      "         [ -4.5094,  -4.5179,  -4.4072,  ...,  -5.6911,  -5.8243,  -3.1168],\n",
      "         [ -4.8141,  -4.8596,  -4.9122,  ...,  -5.4260,  -5.6625,  -3.5622]],\n",
      "\n",
      "        [[ -7.4975,  -7.4981,  -7.4318,  ...,  -6.6941,  -6.4820,  -3.8813],\n",
      "         [-13.3375, -13.3985, -13.4772,  ..., -12.5705, -10.7687,  -6.3248],\n",
      "         [ -6.8174,  -7.2953,  -6.6241,  ...,  -7.6527,  -4.4585,  -4.2223],\n",
      "         ...,\n",
      "         [ -8.2656,  -8.2974,  -8.3565,  ...,  -8.8660,  -7.3121,  -4.2240],\n",
      "         [ -8.2306,  -8.2272,  -8.2820,  ...,  -8.6150,  -7.1422,  -3.8214],\n",
      "         [ -8.2916,  -8.3857,  -8.3812,  ...,  -8.8793,  -7.0164,  -3.8932]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4058,  -7.4502,  -7.3467,  ...,  -7.3238,  -6.2810,  -3.1784],\n",
      "         [ -6.2523,  -6.1270,  -6.1994,  ...,  -6.4102,  -5.1273,  -4.7053],\n",
      "         [-15.4770, -15.6453, -15.8441,  ..., -15.7339, -12.8123, -11.6128],\n",
      "         ...,\n",
      "         [ -8.2751,  -8.3333,  -8.0112,  ...,  -7.0371,  -6.4923,  -5.0160],\n",
      "         [ -5.7188,  -5.9034,  -5.3680,  ...,  -5.6615,  -3.3629,  -4.6512],\n",
      "         [-11.7205, -11.9281, -11.8940,  ..., -10.8548,  -9.0188,  -7.9649]],\n",
      "\n",
      "        [[ -8.0757,  -8.2451,  -8.0460,  ...,  -7.8626,  -7.4848,  -4.9509],\n",
      "         [-13.7057, -13.5286, -13.6219,  ..., -11.7818, -11.0363, -10.7003],\n",
      "         [ -3.2373,  -3.3900,  -3.3550,  ...,  -4.3255,  -5.9523,  -3.1551],\n",
      "         ...,\n",
      "         [ -3.5803,  -3.7123,  -3.6952,  ...,  -4.4381,  -5.3043,  -3.9556],\n",
      "         [ -3.2993,  -3.2579,  -3.2942,  ...,  -4.0695,  -4.8810,  -2.9226],\n",
      "         [ -3.7494,  -3.7233,  -3.8106,  ...,  -4.4931,  -5.4005,  -2.6278]],\n",
      "\n",
      "        [[ -6.9418,  -6.9238,  -6.9132,  ...,  -5.7697,  -6.1113,  -4.4037],\n",
      "         [-10.9090, -10.9171, -10.8239,  ...,  -8.8530,  -9.1065,  -8.8709],\n",
      "         [ -5.3927,  -5.4214,  -5.4472,  ...,  -4.3156,  -4.2982,  -4.9094],\n",
      "         ...,\n",
      "         [ -7.6309,  -7.9731,  -7.7338,  ...,  -7.2939,  -8.1157,  -2.2862],\n",
      "         [ -9.6460,  -9.9354,  -9.9447,  ...,  -9.2731,  -9.5766,  -7.2761],\n",
      "         [ -8.4841,  -8.8122,  -8.6394,  ...,  -8.3488,  -8.5570,  -4.8184]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.386953353881836\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0997, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.5096,  -8.5416,  -8.6096,  ...,  -7.8728,  -7.6971,  -5.4833],\n",
      "         [ -9.1762,  -9.2486,  -9.1712,  ...,  -9.8250,  -8.3788,  -9.1550],\n",
      "         [ -8.9255,  -8.8749,  -8.7774,  ...,  -9.6992,  -9.4556,  -8.0492],\n",
      "         ...,\n",
      "         [ -8.8844,  -9.0115,  -9.2621,  ...,  -8.5701,  -7.1881,  -8.0831],\n",
      "         [ -9.4818,  -9.5001,  -9.2135,  ...,  -9.4055,  -8.1463,  -7.1967],\n",
      "         [-10.7654, -10.3800, -10.8059,  ..., -11.2320,  -9.6785,  -8.8615]],\n",
      "\n",
      "        [[ -8.2620,  -8.2793,  -8.0513,  ...,  -7.9674,  -7.5343,  -5.8691],\n",
      "         [-11.9119, -12.4061, -12.1493,  ..., -10.5533,  -9.8789,  -7.7817],\n",
      "         [ -4.3892,  -4.5251,  -4.5173,  ...,  -5.1498,  -5.9165,  -2.3705],\n",
      "         ...,\n",
      "         [ -3.7770,  -3.8919,  -3.8734,  ...,  -4.3133,  -5.9514,  -3.1138],\n",
      "         [ -4.2352,  -4.2245,  -4.3136,  ...,  -5.2664,  -5.6353,  -3.2587],\n",
      "         [ -3.9138,  -3.8551,  -3.8800,  ...,  -4.4090,  -5.3233,  -3.2639]],\n",
      "\n",
      "        [[ -8.2288,  -8.3618,  -8.1085,  ...,  -7.6052,  -6.9926,  -5.6591],\n",
      "         [-14.3369, -14.3846, -14.2837,  ..., -11.2911,  -9.8300, -11.9646],\n",
      "         [ -9.3808,  -9.9114,  -9.7839,  ...,  -7.7035,  -6.4535, -10.0604],\n",
      "         ...,\n",
      "         [ -6.4412,  -7.2674,  -6.7920,  ...,  -6.6122,  -4.5421,  -5.1696],\n",
      "         [ -7.9416,  -8.4267,  -8.1400,  ...,  -7.9425,  -6.1604,  -6.8553],\n",
      "         [-10.8320, -11.1388, -11.1638,  ..., -10.0918,  -7.0401,  -7.9314]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6783,  -6.6558,  -6.6401,  ...,  -5.8144,  -5.9087,  -3.7219],\n",
      "         [-13.9970, -13.9442, -13.8550,  ..., -11.2866, -10.5581, -12.1028],\n",
      "         [ -4.7298,  -4.9982,  -4.8931,  ...,  -5.2482,  -5.7567,  -2.3787],\n",
      "         ...,\n",
      "         [ -3.9257,  -4.0484,  -3.9989,  ...,  -4.0147,  -4.7980,  -2.0121],\n",
      "         [ -4.5950,  -4.6944,  -4.6804,  ...,  -5.0754,  -5.6305,  -2.0908],\n",
      "         [ -5.3606,  -5.4818,  -5.4389,  ...,  -5.2874,  -5.5163,  -2.8175]],\n",
      "\n",
      "        [[ -7.4735,  -7.4998,  -7.4135,  ...,  -7.0038,  -6.7691,  -4.1387],\n",
      "         [ -5.8076,  -5.6837,  -5.7198,  ...,  -6.9161,  -7.8225,  -2.8665],\n",
      "         [ -6.2520,  -6.4839,  -6.2414,  ...,  -7.0911,  -7.7401,  -3.7615],\n",
      "         ...,\n",
      "         [ -4.8577,  -4.9622,  -4.9139,  ...,  -5.7430,  -5.9589,  -3.3222],\n",
      "         [ -4.4559,  -4.4331,  -4.4240,  ...,  -5.0069,  -5.6989,  -2.5905],\n",
      "         [ -4.0782,  -4.1781,  -4.0868,  ...,  -4.8680,  -5.3956,  -2.6428]],\n",
      "\n",
      "        [[ -6.4133,  -6.3917,  -6.3945,  ...,  -5.8092,  -5.6073,  -3.8218],\n",
      "         [-10.0957, -10.2888,  -9.7659,  ...,  -7.3996,  -7.0135,  -9.5356],\n",
      "         [ -4.5893,  -4.7915,  -4.6773,  ...,  -5.3453,  -5.9781,  -2.6955],\n",
      "         ...,\n",
      "         [ -4.4933,  -4.5791,  -4.5576,  ...,  -4.8462,  -5.5573,  -2.4861],\n",
      "         [ -3.5109,  -3.6249,  -3.6084,  ...,  -3.6597,  -4.8688,  -2.3431],\n",
      "         [ -4.9775,  -5.0554,  -5.0553,  ...,  -5.3313,  -6.3328,  -2.4292]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.0996816158294678\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6804, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3303,  -6.3094,  -6.3161,  ...,  -5.6097,  -5.8136,  -3.6408],\n",
      "         [-12.1116, -11.9589, -11.7740,  ...,  -8.4522,  -9.0078, -12.0136],\n",
      "         [ -3.4833,  -3.6240,  -3.5537,  ...,  -3.9623,  -5.3602,  -2.8358],\n",
      "         ...,\n",
      "         [ -3.8725,  -4.0247,  -3.8937,  ...,  -3.7418,  -4.9355,  -4.2888],\n",
      "         [ -4.6562,  -4.8653,  -4.8059,  ...,  -4.6939,  -6.1094,  -4.0801],\n",
      "         [ -4.5815,  -4.6804,  -4.5968,  ...,  -4.5507,  -5.8316,  -3.9666]],\n",
      "\n",
      "        [[-10.3660, -10.5422, -10.4030,  ..., -10.6306, -10.8959,  -5.9477],\n",
      "         [-10.9902, -11.0882, -10.7394,  ...,  -8.3449,  -7.9610, -10.9673],\n",
      "         [ -4.3280,  -4.5109,  -4.6107,  ...,  -5.2936,  -6.3408,  -2.7520],\n",
      "         ...,\n",
      "         [ -4.0224,  -4.2106,  -4.0238,  ...,  -4.2787,  -5.0347,  -2.3122],\n",
      "         [ -4.4963,  -4.6276,  -4.4748,  ...,  -5.0130,  -6.3381,  -2.7834],\n",
      "         [ -4.3492,  -4.3908,  -4.3301,  ...,  -4.9634,  -5.8345,  -2.8171]],\n",
      "\n",
      "        [[ -7.5533,  -7.4895,  -7.4745,  ...,  -7.1731,  -6.2906,  -3.8841],\n",
      "         [ -7.7296,  -8.0425,  -8.1216,  ...,  -8.5501,  -5.9283,  -4.7549],\n",
      "         [ -7.5798,  -8.2384,  -7.8116,  ...,  -7.7971,  -6.1204,  -5.4717],\n",
      "         ...,\n",
      "         [ -6.4569,  -6.7441,  -6.5599,  ...,  -7.0161,  -6.1224,  -5.4238],\n",
      "         [ -7.6793,  -7.8809,  -7.8318,  ...,  -7.8243,  -6.6428,  -5.1455],\n",
      "         [ -8.1449,  -8.4125,  -8.2543,  ...,  -8.3551,  -7.3270,  -5.7739]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.2872,  -8.3090,  -8.2164,  ...,  -7.4074,  -6.9546,  -4.6783],\n",
      "         [ -5.5891,  -5.4848,  -5.1893,  ...,  -5.8102,  -4.5099,  -3.3707],\n",
      "         [ -7.7559,  -8.0704,  -7.8499,  ...,  -7.4332,  -5.2754,  -6.4062],\n",
      "         ...,\n",
      "         [-12.5654, -12.5744, -12.3296,  ..., -11.8446,  -9.9444,  -8.9109],\n",
      "         [ -9.4332,  -9.6694,  -9.5196,  ...,  -9.9124,  -7.7835,  -8.7698],\n",
      "         [-10.6461, -10.6735, -11.5286,  ...,  -9.0616,  -7.5352,  -7.2102]],\n",
      "\n",
      "        [[ -8.2367,  -8.2700,  -8.0673,  ...,  -7.7063,  -7.1356,  -5.4885],\n",
      "         [-13.0223, -12.7635, -13.1225,  ..., -12.1661, -10.9529,  -9.9475],\n",
      "         [ -8.4255,  -8.1828,  -8.6990,  ...,  -8.0589,  -7.8648,  -7.5881],\n",
      "         ...,\n",
      "         [ -2.1560,  -2.5577,  -1.6332,  ...,  -2.7883,  -2.1956,  -4.3981],\n",
      "         [ -5.9770,  -6.3479,  -5.9596,  ...,  -7.3859,  -6.2066,  -4.0117],\n",
      "         [ -1.5530,  -1.8793,  -1.7899,  ...,  -2.6333,  -1.8918,  -0.6875]],\n",
      "\n",
      "        [[ -6.7939,  -6.8164,  -6.6471,  ...,  -6.1064,  -5.7995,  -2.9926],\n",
      "         [ -9.0599,  -9.1563,  -8.6749,  ...,  -7.6799,  -7.4417,  -7.7669],\n",
      "         [ -8.1436,  -8.2642,  -7.6263,  ...,  -7.7281,  -6.8656,  -5.4372],\n",
      "         ...,\n",
      "         [ -6.8407,  -7.1024,  -6.6967,  ...,  -7.0664,  -4.9122,  -0.7821],\n",
      "         [ -5.5409,  -5.6620,  -5.4968,  ...,  -5.0925,  -4.1173,  -3.2523],\n",
      "         [-11.6520, -11.5454, -11.8373,  ...,  -8.9556,  -9.5536,  -7.4264]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6803960800170898\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4978, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5884,  -6.5622,  -6.5305,  ...,  -5.8992,  -5.5874,  -4.0516],\n",
      "         [ -7.7934,  -7.7051,  -7.6611,  ...,  -7.4826,  -8.4446,  -5.9921],\n",
      "         [ -4.0375,  -3.9734,  -4.1015,  ...,  -4.3172,  -4.2614,  -2.6672],\n",
      "         ...,\n",
      "         [ -5.6019,  -5.6318,  -5.5474,  ...,  -5.3192,  -5.9139,  -4.2722],\n",
      "         [ -5.7292,  -5.7877,  -5.7389,  ...,  -5.3811,  -6.0926,  -3.5579],\n",
      "         [ -5.4472,  -5.5245,  -5.4532,  ...,  -5.1746,  -5.7548,  -3.2484]],\n",
      "\n",
      "        [[ -7.6545,  -7.6684,  -7.5988,  ...,  -6.9595,  -7.0074,  -4.4223],\n",
      "         [-14.7692, -14.3682, -14.3642,  ..., -13.7119, -13.0272, -10.8851],\n",
      "         [-10.6226, -10.5954, -10.4959,  ..., -10.2209,  -9.8428,  -7.8664],\n",
      "         ...,\n",
      "         [-16.3775, -16.0618, -15.7223,  ..., -13.6850, -12.4758, -14.0297],\n",
      "         [ -8.6624,  -9.2156,  -8.7995,  ...,  -8.2614,  -6.2426,  -8.1751],\n",
      "         [-13.5983, -13.9205, -13.3596,  ..., -13.2941, -10.2916,  -7.7877]],\n",
      "\n",
      "        [[ -7.7732,  -8.1237,  -7.8833,  ...,  -7.3236,  -7.1407,  -4.9687],\n",
      "         [ -9.4376,  -9.6214,  -9.8666,  ..., -10.6869,  -8.8651, -11.8374],\n",
      "         [ -3.7068,  -3.8415,  -4.1599,  ...,  -5.5869,  -5.5091,  -4.1167],\n",
      "         ...,\n",
      "         [ -4.9914,  -4.9043,  -4.8508,  ...,  -5.0291,  -6.7543,  -3.5614],\n",
      "         [ -3.0917,  -3.2006,  -2.9521,  ...,  -3.7400,  -4.5765,  -4.5165],\n",
      "         [ -5.8275,  -6.0873,  -5.9830,  ...,  -6.7535,  -6.0398,  -5.5310]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1883,  -7.1535,  -7.0433,  ...,  -6.4887,  -6.2514,  -4.1777],\n",
      "         [ -6.4583,  -6.5631,  -6.4946,  ...,  -6.3202,  -6.0695,  -5.7059],\n",
      "         [ -8.0883,  -8.1217,  -7.8019,  ...,  -6.4665,  -5.8368,  -5.7845],\n",
      "         ...,\n",
      "         [ -6.8671,  -6.9658,  -6.7961,  ...,  -7.2874,  -6.5688,  -7.3950],\n",
      "         [ -7.9753,  -8.1905,  -7.9645,  ...,  -7.8010,  -8.1726,  -5.3215],\n",
      "         [ -4.8416,  -4.8799,  -4.7247,  ...,  -5.8953,  -4.5769,  -4.2131]],\n",
      "\n",
      "        [[-12.1748, -12.5244, -12.0993,  ..., -10.7176, -11.5448,  -8.9910],\n",
      "         [-13.3874, -13.2126, -12.9692,  ..., -12.5999, -11.7588, -11.6855],\n",
      "         [ -4.1634,  -4.4405,  -4.3876,  ...,  -5.5888,  -6.5509,  -4.0712],\n",
      "         ...,\n",
      "         [ -4.2724,  -4.4965,  -4.4235,  ...,  -4.9067,  -6.2696,  -3.6419],\n",
      "         [ -3.5361,  -3.7668,  -3.6494,  ...,  -4.2236,  -5.9547,  -3.1985],\n",
      "         [ -3.9880,  -4.2297,  -4.0707,  ...,  -4.1028,  -5.3965,  -3.2740]],\n",
      "\n",
      "        [[ -7.2558,  -7.3201,  -7.2673,  ...,  -6.7221,  -6.6831,  -4.6201],\n",
      "         [-14.8622, -15.4619, -15.1583,  ..., -13.9689, -13.0050, -11.8546],\n",
      "         [ -7.1888,  -7.2416,  -7.1546,  ...,  -5.9115,  -5.6657,  -3.8763],\n",
      "         ...,\n",
      "         [-12.6519, -12.4554, -12.7446,  ..., -10.2762, -10.6590,  -9.1826],\n",
      "         [ -7.1344,  -7.2614,  -7.1681,  ...,  -6.6347,  -6.5258,  -7.3688],\n",
      "         [-10.7473, -10.4377, -10.5004,  ...,  -8.5879,  -8.1386,  -8.2774]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.4978376626968384\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3792, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1479,  -7.1240,  -7.0974,  ...,  -6.3842,  -6.2090,  -4.1395],\n",
      "         [-14.1402, -14.0414, -13.9815,  ..., -10.8422, -11.7210, -11.3297],\n",
      "         [ -3.7193,  -3.9575,  -3.9391,  ...,  -3.9500,  -4.9731,  -2.2630],\n",
      "         ...,\n",
      "         [ -4.6168,  -4.7911,  -4.7409,  ...,  -4.8814,  -5.1576,  -3.8733],\n",
      "         [ -3.6677,  -3.8687,  -3.7769,  ...,  -4.4348,  -4.8037,  -2.2265],\n",
      "         [ -4.4970,  -4.6798,  -4.5203,  ...,  -4.6157,  -5.1192,  -3.7977]],\n",
      "\n",
      "        [[ -6.1576,  -6.1510,  -6.1703,  ...,  -5.8960,  -5.7821,  -3.0433],\n",
      "         [ -6.6855,  -6.5457,  -6.7604,  ...,  -7.4491,  -7.3543,  -1.4377],\n",
      "         [ -5.4782,  -5.6147,  -5.7335,  ...,  -6.5487,  -6.3266,  -1.0152],\n",
      "         ...,\n",
      "         [ -4.9017,  -5.0448,  -4.9057,  ...,  -5.5771,  -5.8062,  -2.1529],\n",
      "         [ -3.7938,  -3.9386,  -3.8415,  ...,  -4.8306,  -4.8296,  -0.5540],\n",
      "         [ -4.8075,  -4.9544,  -4.8380,  ...,  -5.2298,  -5.5445,  -2.7513]],\n",
      "\n",
      "        [[-10.2354, -10.4722, -10.3328,  ...,  -9.3818, -10.0779,  -6.6162],\n",
      "         [-11.9476, -11.6145, -11.8205,  ...,  -8.8293,  -8.5808, -10.3864],\n",
      "         [ -3.4768,  -3.6771,  -3.6312,  ...,  -4.0338,  -5.4749,  -3.4786],\n",
      "         ...,\n",
      "         [ -3.1077,  -3.2564,  -3.2196,  ...,  -3.2681,  -5.2509,  -3.4677],\n",
      "         [ -3.8708,  -4.0928,  -4.0268,  ...,  -4.3705,  -5.4243,  -4.4637],\n",
      "         [ -4.0344,  -4.1321,  -4.1105,  ...,  -4.2043,  -5.4138,  -3.8510]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9576,  -6.8995,  -6.9160,  ...,  -6.3120,  -6.2506,  -4.1364],\n",
      "         [-11.0742, -10.5928, -10.7766,  ...,  -8.3950,  -8.6607,  -7.8374],\n",
      "         [ -5.4878,  -5.5954,  -5.6834,  ...,  -6.0557,  -6.4522,  -3.0771],\n",
      "         ...,\n",
      "         [ -4.3867,  -4.4528,  -4.2542,  ...,  -4.2979,  -5.5471,  -3.8346],\n",
      "         [ -4.8020,  -4.9321,  -4.8393,  ...,  -4.9038,  -5.6725,  -3.8434],\n",
      "         [ -5.2971,  -5.5190,  -5.3764,  ...,  -5.5095,  -6.2503,  -4.0488]],\n",
      "\n",
      "        [[ -6.2634,  -6.6625,  -5.9846,  ...,  -6.1417,  -7.4953,  -5.0752],\n",
      "         [-12.4788, -12.3388, -12.3895,  ...,  -9.1106,  -9.3146,  -9.0694],\n",
      "         [ -3.4697,  -3.6831,  -3.7222,  ...,  -4.0040,  -5.5116,  -2.9873],\n",
      "         ...,\n",
      "         [ -3.3992,  -3.6659,  -3.5947,  ...,  -3.8199,  -4.7318,  -3.4292],\n",
      "         [ -3.6876,  -3.9218,  -3.8978,  ...,  -4.3822,  -5.0637,  -3.7579],\n",
      "         [ -4.4280,  -4.6467,  -4.5798,  ...,  -4.4254,  -5.4455,  -3.2465]],\n",
      "\n",
      "        [[ -6.5457,  -6.5488,  -6.5254,  ...,  -6.0378,  -5.6332,  -4.4774],\n",
      "         [ -5.5124,  -5.4819,  -5.4354,  ...,  -6.3694,  -6.2430,  -0.4387],\n",
      "         [ -4.8498,  -4.8526,  -4.8066,  ...,  -5.3612,  -5.3463,  -1.3401],\n",
      "         ...,\n",
      "         [ -4.7772,  -4.9334,  -4.8274,  ...,  -5.7047,  -5.4104,  -3.1727],\n",
      "         [ -4.7065,  -4.9852,  -4.7756,  ...,  -5.4524,  -5.2852,  -4.2984],\n",
      "         [ -4.3859,  -4.6538,  -4.5449,  ...,  -5.4327,  -4.9891,  -2.9511]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.3791824579238892\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5378, grad_fn=<NllLossBackward0>), logits=tensor([[[ -5.5992,  -5.6432,  -5.4835,  ...,  -5.5099,  -5.2330,  -2.2398],\n",
      "         [-12.7220, -12.3870, -12.5576,  ...,  -9.6985,  -8.7125,  -9.8278],\n",
      "         [ -5.0699,  -5.2460,  -5.2641,  ...,  -5.4982,  -6.4712,  -2.6801],\n",
      "         ...,\n",
      "         [ -5.7292,  -5.8006,  -5.7296,  ...,  -6.2340,  -5.7000,  -3.1230],\n",
      "         [ -5.5843,  -5.6412,  -5.6444,  ...,  -5.6918,  -6.0138,  -2.7336],\n",
      "         [ -5.5107,  -5.5933,  -5.5452,  ...,  -5.8800,  -5.6643,  -3.0173]],\n",
      "\n",
      "        [[ -6.0733,  -6.0346,  -6.0468,  ...,  -5.4797,  -5.2860,  -3.6104],\n",
      "         [ -4.2841,  -4.6418,  -4.4733,  ...,  -5.5447,  -5.5842,  -5.7351],\n",
      "         [ -7.2732,  -7.3441,  -7.2944,  ...,  -7.3322,  -7.8944,  -7.0650],\n",
      "         ...,\n",
      "         [ -3.4995,  -3.7714,  -3.4122,  ...,  -4.2289,  -4.2833,  -3.4414],\n",
      "         [ -4.2242,  -4.4371,  -4.1609,  ...,  -5.3595,  -5.1551,  -5.2771],\n",
      "         [ -3.8435,  -3.9992,  -3.7673,  ...,  -4.6536,  -4.8347,  -4.6984]],\n",
      "\n",
      "        [[ -7.8753,  -7.9001,  -7.7779,  ...,  -6.7467,  -6.5270,  -4.0203],\n",
      "         [-16.4140, -16.1783, -16.1525,  ..., -12.5096, -12.3587, -10.8601],\n",
      "         [ -9.1546,  -9.4543,  -9.1638,  ...,  -8.3085,  -8.2016,  -8.9245],\n",
      "         ...,\n",
      "         [ -9.2318,  -9.3326,  -9.1170,  ...,  -8.9416,  -7.2682,  -6.0820],\n",
      "         [ -9.2237,  -9.2841,  -9.1726,  ...,  -9.0878,  -7.6947,  -5.6999],\n",
      "         [-10.0284, -10.0491,  -9.8696,  ...,  -9.7269,  -7.9901,  -5.8222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.9232,  -7.8947,  -7.8112,  ...,  -7.1519,  -7.1241,  -4.4420],\n",
      "         [-12.2942, -11.7335, -11.8380,  ..., -10.5006, -10.0361, -10.1558],\n",
      "         [-11.3602, -11.1099, -10.7938,  ..., -11.8398,  -9.9388,  -5.3231],\n",
      "         ...,\n",
      "         [ -5.0152,  -4.9387,  -4.6020,  ...,  -4.7304,  -4.5762,  -5.8916],\n",
      "         [ -6.1565,  -6.2727,  -6.0312,  ...,  -6.5478,  -6.3342,  -6.1602],\n",
      "         [ -5.9362,  -6.0928,  -5.9166,  ...,  -6.5906,  -6.0396,  -6.9263]],\n",
      "\n",
      "        [[ -8.1929,  -8.1718,  -8.0776,  ...,  -6.9693,  -7.2847,  -5.1313],\n",
      "         [-12.8775, -13.1914, -13.1662,  ..., -10.9723,  -8.6925,  -9.8706],\n",
      "         [ -4.5712,  -4.7984,  -4.6829,  ...,  -5.0544,  -5.9384,  -4.8915],\n",
      "         ...,\n",
      "         [ -3.9292,  -4.2227,  -4.0292,  ...,  -4.0357,  -5.8041,  -4.7959],\n",
      "         [ -3.6593,  -3.6970,  -3.4700,  ...,  -3.7326,  -4.4918,  -2.2424],\n",
      "         [ -3.4241,  -3.6296,  -3.5144,  ...,  -3.7234,  -5.0325,  -3.7722]],\n",
      "\n",
      "        [[ -6.8325,  -6.8630,  -6.7748,  ...,  -5.9224,  -6.2003,  -4.4451],\n",
      "         [ -8.5795,  -8.2627,  -8.7126,  ...,  -8.3529,  -8.6224,  -7.6981],\n",
      "         [ -5.8613,  -5.6895,  -5.9332,  ...,  -6.3155,  -5.5252,  -3.7343],\n",
      "         ...,\n",
      "         [ -3.2764,  -3.3969,  -3.2805,  ...,  -3.0546,  -3.0614,  -2.4181],\n",
      "         [ -4.8173,  -4.9728,  -4.9410,  ...,  -4.9307,  -3.9010,  -4.8551],\n",
      "         [ -6.3108,  -6.3127,  -6.3646,  ...,  -6.3493,  -5.1272,  -5.8735]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5378412008285522\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9943, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7235,  -6.7629,  -6.7729,  ...,  -6.1877,  -6.1684,  -3.3537],\n",
      "         [ -4.2658,  -4.1839,  -4.1093,  ...,  -4.8637,  -4.9159,  -0.7468],\n",
      "         [ -5.3800,  -5.2616,  -5.0798,  ...,  -6.1740,  -5.3373,  -0.9392],\n",
      "         ...,\n",
      "         [ -4.2182,  -4.2545,  -4.0388,  ...,  -4.4958,  -4.4768,  -1.2385],\n",
      "         [ -4.4024,  -4.3840,  -4.2948,  ...,  -4.7751,  -4.9543,  -1.6024],\n",
      "         [ -4.5519,  -4.4993,  -4.4496,  ...,  -4.9643,  -4.8739,  -1.6236]],\n",
      "\n",
      "        [[ -6.1347,  -6.1965,  -6.1769,  ...,  -5.7665,  -5.5957,  -3.5736],\n",
      "         [ -6.3353,  -6.3192,  -6.3641,  ...,  -7.4038,  -7.4370,  -4.7420],\n",
      "         [ -3.2386,  -3.4226,  -3.3100,  ...,  -4.2381,  -3.9378,  -2.5708],\n",
      "         ...,\n",
      "         [ -4.0990,  -4.2403,  -4.1068,  ...,  -4.8003,  -5.2860,  -2.7525],\n",
      "         [ -3.5922,  -3.7688,  -3.5576,  ...,  -3.7367,  -4.0766,  -3.1257],\n",
      "         [ -4.2860,  -4.4023,  -4.3416,  ...,  -4.9923,  -5.1644,  -3.2798]],\n",
      "\n",
      "        [[ -7.7252,  -7.8912,  -7.7300,  ...,  -7.1380,  -7.0045,  -5.0939],\n",
      "         [-13.7865, -13.5695, -13.7010,  ..., -10.5628, -10.5155, -12.4377],\n",
      "         [ -7.9561,  -7.9264,  -8.2606,  ...,  -7.7639,  -8.4606,  -8.9858],\n",
      "         ...,\n",
      "         [ -7.3704,  -7.1562,  -7.2142,  ...,  -7.5359,  -8.0495,  -8.7191],\n",
      "         [ -6.3524,  -6.2231,  -6.2767,  ...,  -6.4245,  -6.8607,  -5.1386],\n",
      "         [ -7.3496,  -7.1915,  -7.3360,  ...,  -7.3774,  -7.8287,  -7.3659]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.8326,  -7.9826,  -7.8726,  ...,  -7.5758,  -7.1522,  -4.3032],\n",
      "         [-15.0510, -14.9891, -15.0330,  ..., -14.1743, -13.0163, -11.8904],\n",
      "         [ -9.2868,  -9.4842,  -9.3335,  ...,  -9.2809,  -7.3759,  -1.5293],\n",
      "         ...,\n",
      "         [ -9.6102,  -9.5743,  -9.5787,  ...,  -8.2694,  -7.7600,  -5.2345],\n",
      "         [-10.2789, -10.4474, -10.1689,  ..., -11.0550,  -8.4359,  -3.0872],\n",
      "         [-14.6263, -14.7805, -14.6697,  ..., -13.3904, -11.5416,  -8.3904]],\n",
      "\n",
      "        [[ -8.4982,  -8.6133,  -8.5018,  ...,  -8.1513,  -7.6311,  -4.7996],\n",
      "         [-14.6536, -14.4553, -14.6167,  ..., -13.6406, -12.3816, -12.2795],\n",
      "         [ -7.1236,  -7.4643,  -7.5867,  ...,  -6.2846,  -6.0555,  -5.9624],\n",
      "         ...,\n",
      "         [ -2.6023,  -2.4726,  -2.4946,  ...,  -3.1137,  -2.5609,  -5.7110],\n",
      "         [-12.4776, -11.6226, -12.0902,  ...,  -8.5657,  -8.6248,  -9.9745],\n",
      "         [-13.0405, -12.6342, -12.8806,  ..., -11.3091,  -9.5470,  -7.7884]],\n",
      "\n",
      "        [[ -7.3994,  -7.4028,  -7.3616,  ...,  -6.7011,  -6.5596,  -4.3256],\n",
      "         [ -5.5359,  -5.3580,  -5.5771,  ...,  -4.8382,  -4.2018,  -3.2051],\n",
      "         [ -9.7457,  -9.5142,  -9.5863,  ...,  -9.6299,  -5.0987,  -8.2372],\n",
      "         ...,\n",
      "         [ -7.1857,  -7.3233,  -7.0628,  ...,  -6.5686,  -5.4512,  -6.1135],\n",
      "         [ -7.1241,  -7.2071,  -7.0208,  ...,  -6.2093,  -5.6273,  -6.0123],\n",
      "         [ -7.8397,  -7.8358,  -7.7970,  ...,  -6.8685,  -6.4394,  -6.4101]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.9942626953125\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4258, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0149,  -7.0439,  -6.9444,  ...,  -6.6481,  -6.0482,  -4.6740],\n",
      "         [-11.6545, -12.1567, -11.9022,  ..., -11.9428, -10.3345,  -9.3457],\n",
      "         [-10.1906, -10.1385, -10.0132,  ..., -10.3404,  -7.9421,  -9.4193],\n",
      "         ...,\n",
      "         [ -6.0884,  -6.3003,  -6.2008,  ...,  -7.2349,  -5.9415,  -7.9900],\n",
      "         [ -6.3479,  -6.5544,  -6.4069,  ...,  -7.6896,  -5.3069,  -8.3353],\n",
      "         [ -6.9560,  -7.0821,  -7.0254,  ...,  -7.8723,  -6.1380,  -7.2808]],\n",
      "\n",
      "        [[ -7.0765,  -7.0297,  -6.9779,  ...,  -6.5329,  -6.2000,  -4.0977],\n",
      "         [ -9.7796,  -9.7767,  -9.4494,  ...,  -7.8570,  -8.6514,  -8.1745],\n",
      "         [-14.6019, -14.6036, -14.3191,  ..., -13.1479, -10.7688, -11.1688],\n",
      "         ...,\n",
      "         [ -6.7978,  -6.9043,  -6.8854,  ...,  -5.2558,  -5.7635,  -5.9929],\n",
      "         [ -7.4276,  -7.6313,  -7.4346,  ...,  -6.3223,  -6.6786,  -3.7733],\n",
      "         [ -5.9518,  -5.9299,  -5.7625,  ...,  -4.6942,  -4.5682,  -3.6624]],\n",
      "\n",
      "        [[ -7.0571,  -7.0958,  -7.0309,  ...,  -6.5075,  -6.2372,  -4.5641],\n",
      "         [ -6.0706,  -5.9587,  -6.0707,  ...,  -7.6408,  -7.2039,  -3.0958],\n",
      "         [-12.4198, -12.3098, -12.1337,  ..., -12.1142, -10.0710,  -9.4014],\n",
      "         ...,\n",
      "         [ -6.9990,  -7.0013,  -6.7784,  ...,  -6.0696,  -5.0890,  -5.9595],\n",
      "         [ -5.5313,  -5.6837,  -5.6644,  ...,  -4.9964,  -4.8006,  -5.0102],\n",
      "         [ -5.5943,  -5.4961,  -5.4530,  ...,  -5.9479,  -4.6171,  -4.5665]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6347,  -6.6577,  -6.5846,  ...,  -6.0226,  -6.0294,  -4.0174],\n",
      "         [ -5.3067,  -5.3687,  -5.3957,  ...,  -5.4703,  -4.5730,  -3.5662],\n",
      "         [-12.9434, -13.3183, -13.0360,  ..., -11.3370,  -8.8669, -10.9931],\n",
      "         ...,\n",
      "         [ -8.1488,  -8.3372,  -8.0321,  ...,  -8.6629,  -7.8058,  -6.6020],\n",
      "         [ -6.1800,  -6.2570,  -5.7581,  ...,  -5.9355,  -5.0014,  -3.7785],\n",
      "         [ -7.4160,  -7.5796,  -7.2012,  ...,  -8.4096,  -6.9383,  -5.9788]],\n",
      "\n",
      "        [[ -6.3589,  -6.2805,  -6.2857,  ...,  -5.5866,  -5.3875,  -3.7373],\n",
      "         [-11.2171, -11.2727, -11.1144,  ...,  -8.8256,  -9.1040,  -9.6876],\n",
      "         [ -3.8412,  -4.0359,  -4.0091,  ...,  -4.0520,  -5.1311,  -2.4214],\n",
      "         ...,\n",
      "         [ -4.6332,  -4.7744,  -4.7023,  ...,  -4.6465,  -5.2847,  -3.3984],\n",
      "         [ -5.2734,  -5.4576,  -5.3526,  ...,  -5.5916,  -5.9065,  -3.1688],\n",
      "         [ -4.7166,  -4.7512,  -4.6340,  ...,  -4.9760,  -5.3836,  -3.0657]],\n",
      "\n",
      "        [[ -7.3921,  -7.4553,  -7.2152,  ...,  -7.1482, -10.2044,  -8.5370],\n",
      "         [-14.3656, -14.4242, -14.2907,  ..., -11.8776, -12.2571, -12.2270],\n",
      "         [ -3.4002,  -3.6555,  -3.4633,  ...,  -4.3879,  -5.4713,  -3.5701],\n",
      "         ...,\n",
      "         [ -3.9911,  -4.2086,  -4.0198,  ...,  -4.6230,  -5.8561,  -2.7693],\n",
      "         [ -4.8975,  -5.1336,  -4.9795,  ...,  -5.2970,  -6.4712,  -2.4016],\n",
      "         [ -4.7163,  -5.0829,  -4.9723,  ...,  -4.8962,  -6.2205,  -3.6582]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.4257612228393555\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5457, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2171,  -7.3823,  -7.2590,  ...,  -6.8811,  -6.0638,  -5.1937],\n",
      "         [-10.3047, -10.4876, -10.2696,  ..., -10.2016,  -7.5318, -10.3752],\n",
      "         [ -4.3495,  -4.2232,  -4.3542,  ...,  -4.2866,  -4.6079,  -5.3866],\n",
      "         ...,\n",
      "         [ -3.2966,  -3.0669,  -3.3832,  ...,  -4.8607,  -2.8657,  -4.8631],\n",
      "         [-13.6332, -13.6389, -13.6293,  ..., -13.7289, -11.7721,  -6.2590],\n",
      "         [-10.8302, -10.2976, -10.9134,  ...,  -8.4496,  -7.5599,  -9.6207]],\n",
      "\n",
      "        [[ -7.0960,  -7.1580,  -7.0576,  ...,  -6.5147,  -6.0217,  -4.7944],\n",
      "         [-14.6100, -14.4192, -14.6980,  ..., -13.4066, -11.9810, -10.9966],\n",
      "         [ -8.9016,  -8.9657,  -8.8883,  ...,  -8.6773,  -9.0167,  -6.7722],\n",
      "         ...,\n",
      "         [-13.1022, -13.2446, -13.0631,  ..., -11.7321,  -9.8277,  -9.5290],\n",
      "         [-14.0885, -13.7610, -13.6571,  ..., -12.5190, -11.1503, -11.3913],\n",
      "         [-11.3814, -11.6544, -11.7536,  ..., -10.3637,  -8.5512,  -9.1932]],\n",
      "\n",
      "        [[ -6.5067,  -6.5159,  -6.4787,  ...,  -5.8636,  -5.8686,  -3.3968],\n",
      "         [-10.6437, -10.6799, -10.6494,  ...,  -7.3871,  -8.2821,  -9.6079],\n",
      "         [ -4.3023,  -4.4308,  -4.2989,  ...,  -4.9758,  -5.8061,  -2.8269],\n",
      "         ...,\n",
      "         [ -4.5066,  -4.5571,  -4.5051,  ...,  -4.4798,  -4.9504,  -3.0374],\n",
      "         [ -4.0159,  -4.0481,  -4.0291,  ...,  -4.3728,  -4.8060,  -3.3867],\n",
      "         [ -3.8560,  -4.0248,  -3.8975,  ...,  -4.3440,  -4.9908,  -2.0657]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.1388,  -8.0512,  -8.1802,  ...,  -7.0120,  -7.8771,  -4.8060],\n",
      "         [-10.0810, -10.2553, -10.1843,  ...,  -7.3085,  -7.6907,  -8.5043],\n",
      "         [ -3.7296,  -4.1110,  -4.0698,  ...,  -4.7411,  -6.0899,  -3.0586],\n",
      "         ...,\n",
      "         [ -4.0794,  -4.3271,  -4.2405,  ...,  -4.5715,  -5.4757,  -2.6428],\n",
      "         [ -3.9721,  -4.2907,  -4.1473,  ...,  -5.1389,  -5.5318,  -3.8532],\n",
      "         [ -4.6207,  -4.8921,  -4.6978,  ...,  -4.6219,  -5.0636,  -2.8018]],\n",
      "\n",
      "        [[ -7.0111,  -6.9739,  -6.9526,  ...,  -6.1885,  -6.1689,  -4.3450],\n",
      "         [-10.9238, -11.0744, -10.5464,  ...,  -8.3270,  -8.5925,  -9.7076],\n",
      "         [ -4.6510,  -4.8718,  -4.6783,  ...,  -5.6658,  -6.5438,  -3.2030],\n",
      "         ...,\n",
      "         [ -5.3746,  -5.5432,  -5.3296,  ...,  -6.0678,  -6.3186,  -4.7409],\n",
      "         [ -5.5080,  -5.5416,  -5.4532,  ...,  -6.0642,  -6.7152,  -4.6162],\n",
      "         [ -5.9058,  -6.0244,  -5.9231,  ...,  -6.4413,  -6.9945,  -5.1344]],\n",
      "\n",
      "        [[ -7.7106,  -7.7844,  -7.5753,  ...,  -6.8589,  -6.7507,  -4.3077],\n",
      "         [-17.5026, -16.8858, -17.0184,  ..., -15.1424, -14.2618, -12.3470],\n",
      "         [ -7.6202,  -7.4899,  -7.6160,  ...,  -8.7899,  -6.1466,  -5.4033],\n",
      "         ...,\n",
      "         [ -5.3532,  -5.4285,  -5.0920,  ...,  -5.9082,  -5.0008,  -4.5199],\n",
      "         [ -4.5253,  -4.5774,  -4.4271,  ...,  -5.1268,  -4.7062,  -3.4141],\n",
      "         [ -6.4986,  -6.6411,  -6.4689,  ...,  -6.3081,  -6.0010,  -4.9681]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5457314252853394\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8292, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6388,  -6.6071,  -6.6256,  ...,  -5.8409,  -5.6660,  -3.9689],\n",
      "         [-14.4081, -14.1849, -14.2312,  ..., -11.5343, -10.2461,  -8.1854],\n",
      "         [ -8.0331,  -8.0621,  -8.0527,  ...,  -7.6426,  -6.3239,  -4.5870],\n",
      "         ...,\n",
      "         [ -6.4206,  -6.4735,  -6.3270,  ...,  -6.1120,  -5.5940,  -4.0604],\n",
      "         [ -5.9297,  -6.1110,  -6.0497,  ...,  -5.4363,  -5.0665,  -3.5383],\n",
      "         [ -5.2120,  -5.3245,  -5.1839,  ...,  -5.0944,  -3.6700,  -4.1978]],\n",
      "\n",
      "        [[ -7.5125,  -7.4698,  -7.5115,  ...,  -6.7522,  -7.0720,  -4.0016],\n",
      "         [-13.2078, -12.9559, -13.0142,  ..., -12.3107, -10.4669,  -9.9320],\n",
      "         [ -3.5606,  -3.7444,  -3.7485,  ...,  -3.6920,  -5.3949,  -2.6070],\n",
      "         ...,\n",
      "         [ -3.4478,  -3.4409,  -3.4033,  ...,  -3.5279,  -4.7832,  -3.2286],\n",
      "         [ -3.9988,  -4.0099,  -4.0018,  ...,  -4.1136,  -5.0318,  -3.6492],\n",
      "         [ -3.5453,  -3.5821,  -3.5612,  ...,  -3.3766,  -5.1374,  -3.8856]],\n",
      "\n",
      "        [[ -7.4619,  -7.5602,  -7.4147,  ...,  -6.9404,  -6.6125,  -4.1514],\n",
      "         [ -8.0090,  -8.0894,  -8.4663,  ...,  -8.2589,  -6.4780,  -7.1012],\n",
      "         [-13.6512, -13.3599, -13.3700,  ..., -13.0709, -11.4332,  -8.5534],\n",
      "         ...,\n",
      "         [ -7.1462,  -6.7955,  -7.0051,  ...,  -5.8833,  -5.2761,  -1.8799],\n",
      "         [-13.1540, -13.3888, -12.9763,  ..., -11.5924, -11.9410,  -7.4462],\n",
      "         [-12.1031, -11.5596, -11.9482,  ..., -10.1816,  -9.3857,  -9.1551]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3234,  -6.4502,  -6.4677,  ...,  -6.4737,  -6.0545,  -2.3461],\n",
      "         [-10.4955, -10.7646, -10.8215,  ...,  -8.1882,  -6.5463,  -8.1997],\n",
      "         [ -6.1676,  -6.2814,  -6.3011,  ...,  -6.9064,  -6.4166,  -3.1896],\n",
      "         ...,\n",
      "         [ -6.1084,  -6.2845,  -6.2219,  ...,  -6.7558,  -6.2867,  -2.6837],\n",
      "         [ -5.6638,  -5.8127,  -5.8280,  ...,  -6.6762,  -5.7113,  -2.5560],\n",
      "         [ -6.2929,  -6.3269,  -6.3536,  ...,  -7.2204,  -6.6463,  -1.9198]],\n",
      "\n",
      "        [[ -7.7729,  -7.8268,  -7.6989,  ...,  -7.2782,  -6.9790,  -5.4728],\n",
      "         [ -9.8734,  -9.7140,  -9.5917,  ...,  -9.2333,  -8.7297,  -8.2829],\n",
      "         [ -7.0982,  -7.1032,  -6.7178,  ...,  -7.0100,  -7.7745,  -4.8640],\n",
      "         ...,\n",
      "         [ -9.9855,  -9.8378,  -9.8813,  ...,  -9.7209,  -9.2611,  -9.5165],\n",
      "         [ -4.6887,  -4.7751,  -4.8510,  ...,  -6.0386,  -4.8825,  -4.8472],\n",
      "         [-11.4434, -11.0609, -11.6964,  ...,  -8.8137,  -9.1517,  -5.9496]],\n",
      "\n",
      "        [[ -7.1563,  -7.2434,  -7.1680,  ...,  -6.4616,  -6.2027,  -4.7300],\n",
      "         [ -9.9474, -10.2112, -10.2768,  ..., -11.8708,  -9.0890, -11.4956],\n",
      "         [ -7.4575,  -7.4978,  -7.3010,  ...,  -7.8740,  -6.7188,  -5.7261],\n",
      "         ...,\n",
      "         [ -8.3540,  -8.4045,  -8.1650,  ...,  -8.5938,  -6.7440,  -7.6353],\n",
      "         [ -7.3245,  -7.3099,  -7.3552,  ...,  -8.0290,  -6.5638,  -6.5303],\n",
      "         [-10.9183, -10.9096, -11.0181,  ...,  -9.4560,  -9.4453,  -8.9944]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.8292263746261597\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2732, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8650,  -6.8608,  -6.7430,  ...,  -6.4305,  -6.0646,  -4.1906],\n",
      "         [ -5.7010,  -5.7869,  -5.6006,  ...,  -4.7358,  -5.9898,  -1.4409],\n",
      "         [-13.8771, -14.0511, -13.5505,  ..., -10.8643,  -9.3562, -13.2721],\n",
      "         ...,\n",
      "         [ -7.9384,  -8.1276,  -7.4556,  ...,  -6.7419,  -6.5172,  -6.7257],\n",
      "         [ -3.5023,  -3.7861,  -3.1397,  ...,  -4.3593,  -1.5341,  -2.8672],\n",
      "         [-14.3207, -13.9910, -13.9607,  ..., -12.8435, -11.0360,  -9.9804]],\n",
      "\n",
      "        [[ -6.8038,  -6.8277,  -6.7254,  ...,  -6.5007,  -6.0142,  -3.3552],\n",
      "         [ -6.1568,  -6.0412,  -5.8638,  ...,  -4.9656,  -4.3725,  -4.8744],\n",
      "         [ -7.5234,  -7.5562,  -7.4496,  ...,  -6.6985,  -5.6486,  -8.2794],\n",
      "         ...,\n",
      "         [-10.3845, -10.5892, -10.1004,  ...,  -8.2020,  -8.7322,  -9.7042],\n",
      "         [ -4.2978,  -4.6662,  -4.3352,  ...,  -4.3360,  -4.1640,  -7.4625],\n",
      "         [ -9.7052,  -9.9317,  -9.4759,  ...,  -9.0723,  -9.3262,  -7.7503]],\n",
      "\n",
      "        [[ -7.2802,  -7.2180,  -7.1435,  ...,  -6.6914,  -6.0717,  -5.0123],\n",
      "         [-14.8830, -14.9564, -14.6239,  ..., -13.1891, -12.1577, -13.9851],\n",
      "         [ -4.5968,  -4.7618,  -4.6355,  ...,  -4.7087,  -5.6416,  -3.3805],\n",
      "         ...,\n",
      "         [ -3.3748,  -3.4987,  -3.3915,  ...,  -3.2217,  -4.3420,  -2.2090],\n",
      "         [ -3.6632,  -3.7442,  -3.5551,  ...,  -3.2624,  -4.5675,  -2.7434],\n",
      "         [ -4.4072,  -4.4807,  -4.3256,  ...,  -4.1211,  -5.3655,  -3.2264]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.0859,  -6.0717,  -6.0704,  ...,  -5.4499,  -5.3444,  -3.4857],\n",
      "         [ -5.1550,  -5.5287,  -5.4842,  ...,  -4.6386,  -6.1933,   1.5108],\n",
      "         [ -6.9612,  -6.7940,  -6.8179,  ...,  -6.7835,  -6.5819,  -3.5085],\n",
      "         ...,\n",
      "         [ -6.2116,  -6.2408,  -6.0772,  ...,  -5.4488,  -5.8382,  -1.9417],\n",
      "         [ -5.5937,  -5.6918,  -5.5205,  ...,  -4.7454,  -5.2866,  -2.4275],\n",
      "         [ -5.7094,  -5.8052,  -5.5371,  ...,  -5.0945,  -5.5735,  -2.8979]],\n",
      "\n",
      "        [[ -6.7914,  -6.8233,  -6.7105,  ...,  -6.4343,  -5.9786,  -4.6020],\n",
      "         [-10.4832, -10.2996, -10.1960,  ..., -10.3943,  -8.2833, -11.6204],\n",
      "         [ -7.9170,  -8.1379,  -7.9848,  ...,  -7.6958,  -6.1284,  -6.4660],\n",
      "         ...,\n",
      "         [ -5.6882,  -6.1544,  -5.9320,  ...,  -6.1927,  -4.3414,  -3.6206],\n",
      "         [ -6.3551,  -6.6341,  -6.5673,  ...,  -6.7926,  -5.0476,  -3.4462],\n",
      "         [ -6.2880,  -6.5624,  -6.4590,  ...,  -7.1850,  -5.5962,  -4.4499]],\n",
      "\n",
      "        [[ -9.0286,  -9.0064,  -8.9847,  ...,  -7.9973,  -8.8579,  -7.8393],\n",
      "         [-12.6317, -12.6607, -12.5598,  ..., -11.4766, -10.2714,  -9.7335],\n",
      "         [ -4.3077,  -4.4256,  -4.5719,  ...,  -4.8602,  -5.2687,  -2.7164],\n",
      "         ...,\n",
      "         [ -4.7919,  -4.9431,  -4.9486,  ...,  -5.8710,  -6.1550,  -4.0240],\n",
      "         [ -3.4258,  -3.6005,  -3.6400,  ...,  -4.1849,  -5.2038,  -2.7639],\n",
      "         [ -4.6651,  -4.8627,  -4.6892,  ...,  -5.2015,  -5.5100,  -2.8559]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.2732025384902954\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4163, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1673,  -7.2735,  -7.1399,  ...,  -6.6686,  -6.1285,  -4.5388],\n",
      "         [ -8.8581,  -8.7964,  -8.8372,  ...,  -9.6726,  -7.8777, -10.9234],\n",
      "         [ -3.2294,  -3.4462,  -3.7296,  ...,  -3.6959,  -3.4429,  -4.3100],\n",
      "         ...,\n",
      "         [ -9.1212,  -9.2073,  -8.9596,  ...,  -8.3655,  -7.3757,  -7.2274],\n",
      "         [ -5.4245,  -5.3186,  -5.5325,  ...,  -6.2603,  -6.8651,  -6.5282],\n",
      "         [-10.9175, -10.8224, -11.0304,  ...,  -7.9825,  -8.7479, -10.4633]],\n",
      "\n",
      "        [[ -6.4020,  -6.6624,  -6.5365,  ...,  -6.2125,  -5.4744,  -4.5978],\n",
      "         [-12.4870, -12.7609, -12.7586,  ..., -12.9627,  -9.8882,  -8.7565],\n",
      "         [ -9.0111,  -8.8026,  -8.7319,  ...,  -9.1734,  -5.7878,  -9.8325],\n",
      "         ...,\n",
      "         [ -5.3111,  -5.8980,  -5.6567,  ...,  -6.0577,  -4.1355,  -8.6510],\n",
      "         [-12.3929, -12.5688, -12.2348,  ..., -10.2404, -11.2704,  -8.8786],\n",
      "         [-11.0539, -11.3730, -11.2987,  ...,  -9.8316,  -8.6668, -10.4400]],\n",
      "\n",
      "        [[ -6.4324,  -6.3903,  -6.4244,  ...,  -5.7242,  -5.8289,  -3.5537],\n",
      "         [-19.8371, -19.7418, -19.9813,  ..., -17.2269, -17.0073, -13.8748],\n",
      "         [ -3.8809,  -3.7953,  -4.0714,  ...,  -4.7968,  -4.4318,  -2.5931],\n",
      "         ...,\n",
      "         [ -5.1629,  -5.2189,  -5.2813,  ...,  -5.5681,  -5.4885,  -3.1187],\n",
      "         [ -5.3735,  -5.2965,  -5.4653,  ...,  -6.0513,  -5.6934,  -3.7857],\n",
      "         [ -4.7122,  -4.7146,  -4.7854,  ...,  -5.2119,  -5.0782,  -4.1058]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1781,  -7.2228,  -7.0965,  ...,  -6.4437,  -6.0168,  -4.3405],\n",
      "         [ -5.9924,  -5.8196,  -6.3475,  ...,  -6.1104,  -5.8477,  -2.0953],\n",
      "         [-13.0984, -12.9728, -13.1725,  ..., -11.9584, -10.1065, -11.2820],\n",
      "         ...,\n",
      "         [ -5.7903,  -5.9263,  -5.8771,  ...,  -5.9127,  -5.1304,  -3.9549],\n",
      "         [ -6.9072,  -7.1353,  -7.0048,  ...,  -6.6336,  -5.9496,  -3.6514],\n",
      "         [ -7.4751,  -7.6487,  -7.5394,  ...,  -7.5552,  -6.7223,  -4.0230]],\n",
      "\n",
      "        [[ -6.5954,  -6.5690,  -6.5799,  ...,  -5.8438,  -5.7864,  -3.9652],\n",
      "         [-10.8353, -11.0208, -10.6485,  ...,  -8.9676,  -8.1335,  -8.9836],\n",
      "         [ -4.0284,  -4.1298,  -4.1677,  ...,  -4.1203,  -5.3258,  -2.4638],\n",
      "         ...,\n",
      "         [ -4.0529,  -4.0723,  -4.1426,  ...,  -4.1464,  -5.1831,  -2.5183],\n",
      "         [ -4.3745,  -4.3588,  -4.3879,  ...,  -4.5589,  -5.5490,  -2.9793],\n",
      "         [ -4.2646,  -4.3798,  -4.3063,  ...,  -4.3932,  -5.1323,  -3.2668]],\n",
      "\n",
      "        [[ -7.2327,  -7.3401,  -7.2799,  ...,  -6.7899,  -6.3949,  -4.6768],\n",
      "         [ -9.8303,  -9.7616,  -9.7973,  ..., -10.4909,  -8.5380,  -5.5221],\n",
      "         [ -9.4525,  -9.4264,  -9.7669,  ...,  -9.6558,  -7.4205,  -8.3093],\n",
      "         ...,\n",
      "         [ -6.1742,  -6.1807,  -5.6731,  ...,  -6.8848,  -4.6729,  -1.5240],\n",
      "         [ -6.4370,  -6.4618,  -6.0717,  ...,  -6.9320,  -5.1109,  -3.1317],\n",
      "         [ -7.2543,  -7.3793,  -7.0893,  ...,  -8.2273,  -6.2012,  -5.7044]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.4163310527801514\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6675, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7578,  -6.9089,  -6.8022,  ...,  -6.1575,  -5.7788,  -4.5642],\n",
      "         [ -7.3104,  -7.5101,  -7.3051,  ...,  -7.1317,  -7.1870,  -7.1378],\n",
      "         [-10.5477, -10.6082, -10.5530,  ..., -10.3842,  -9.5900,  -8.0498],\n",
      "         ...,\n",
      "         [ -6.6407,  -6.5268,  -6.4930,  ...,  -8.0059,  -5.6573,  -6.2004],\n",
      "         [ -5.6132,  -5.6352,  -5.3190,  ...,  -6.5199,  -5.1093,  -5.7832],\n",
      "         [ -6.9452,  -7.0270,  -6.9496,  ...,  -7.5506,  -6.3930,  -6.2931]],\n",
      "\n",
      "        [[-14.6082, -14.6302, -14.3358,  ..., -13.0936, -13.0767, -10.2031],\n",
      "         [-13.6297, -13.7260, -13.7961,  ..., -10.7056, -10.8584,  -9.8789],\n",
      "         [ -4.8540,  -4.9271,  -4.9270,  ...,  -4.8467,  -6.7233,  -3.5799],\n",
      "         ...,\n",
      "         [ -4.2793,  -4.3039,  -4.4422,  ...,  -4.3457,  -5.8824,  -2.8596],\n",
      "         [ -4.5623,  -4.6796,  -4.8022,  ...,  -5.1759,  -6.7603,  -2.8910],\n",
      "         [ -4.0585,  -4.2773,  -4.3285,  ...,  -4.3092,  -5.4665,  -2.2339]],\n",
      "\n",
      "        [[ -6.1546,  -6.1691,  -6.1459,  ...,  -5.5337,  -5.4235,  -3.3103],\n",
      "         [ -4.1192,  -4.1536,  -4.3096,  ...,  -5.0289,  -4.7497,  -2.9727],\n",
      "         [ -9.6159,  -9.3031,  -9.4692,  ...,  -8.7065,  -8.0597,  -7.6204],\n",
      "         ...,\n",
      "         [ -3.6846,  -3.6812,  -3.7172,  ...,  -4.0877,  -3.9139,  -1.0560],\n",
      "         [ -4.2888,  -4.2988,  -4.3352,  ...,  -4.5226,  -4.8354,  -2.4874],\n",
      "         [ -3.6720,  -3.7596,  -3.7018,  ...,  -4.1587,  -3.6813,  -1.3867]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.1971,  -9.4405,  -9.2530,  ...,  -8.3565,  -8.7352,  -7.1098],\n",
      "         [-12.0854, -11.8570, -12.0761,  ...,  -9.0090,  -8.4679, -10.9351],\n",
      "         [ -2.8587,  -2.9344,  -3.0013,  ...,  -3.3070,  -4.8683,  -3.4198],\n",
      "         ...,\n",
      "         [ -3.7346,  -3.7305,  -3.7923,  ...,  -3.8372,  -4.9574,  -4.4666],\n",
      "         [ -3.6067,  -3.7028,  -3.7868,  ...,  -3.8733,  -5.0230,  -4.0137],\n",
      "         [ -3.2770,  -3.3186,  -3.3352,  ...,  -3.5884,  -4.4749,  -3.7337]],\n",
      "\n",
      "        [[ -6.4824,  -6.5120,  -6.3800,  ...,  -6.1164,  -5.5966,  -4.6697],\n",
      "         [ -7.1227,  -7.3784,  -7.3002,  ...,  -6.3492,  -6.6168,  -7.0983],\n",
      "         [ -9.9610, -10.0389, -10.1378,  ...,  -8.8390,  -8.5930, -11.7946],\n",
      "         ...,\n",
      "         [ -6.3751,  -6.7592,  -6.4469,  ...,  -7.3808,  -6.2990,  -6.6513],\n",
      "         [ -3.8572,  -4.1762,  -4.1541,  ...,  -5.5735,  -4.1635,  -3.9529],\n",
      "         [ -6.1816,  -6.4888,  -6.2436,  ...,  -7.2339,  -5.7923,  -6.4610]],\n",
      "\n",
      "        [[ -5.9016,  -5.9589,  -5.9424,  ...,  -5.1698,  -5.4538,  -3.0965],\n",
      "         [ -4.6799,  -4.4866,  -4.3087,  ...,  -4.9315,  -5.1185,  -1.6516],\n",
      "         [ -4.3613,  -4.5585,  -4.1158,  ...,  -3.9737,  -3.7197,  -3.0319],\n",
      "         ...,\n",
      "         [ -5.1274,  -5.2385,  -5.1621,  ...,  -4.8054,  -4.3369,  -2.5840],\n",
      "         [ -4.4171,  -4.4306,  -4.4971,  ...,  -4.3904,  -3.8092,  -2.2937],\n",
      "         [ -4.2205,  -4.2251,  -4.2861,  ...,  -4.6989,  -4.2564,  -1.1289]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6674654483795166\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5667, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2036,  -7.1801,  -7.0804,  ...,  -6.3569,  -5.9166,  -4.2364],\n",
      "         [-13.2399, -12.7556, -12.8516,  ..., -11.0558,  -7.9570, -12.3784],\n",
      "         [-11.1807, -12.5260, -11.5070,  ..., -11.2378,  -9.1853,  -4.2907],\n",
      "         ...,\n",
      "         [-12.3886, -12.4628, -11.8437,  ...,  -8.8661,  -8.0059, -10.8281],\n",
      "         [-11.5875, -11.6474, -11.4277,  ...,  -9.8793,  -7.1676, -11.8549],\n",
      "         [-16.6790, -16.8364, -16.3500,  ..., -13.0324, -13.3293, -12.6556]],\n",
      "\n",
      "        [[ -6.6081,  -6.5792,  -6.5871,  ...,  -5.9562,  -5.7904,  -4.0066],\n",
      "         [-10.7609, -10.8203, -10.8456,  ...,  -9.1998,  -8.2102, -10.2594],\n",
      "         [ -6.0453,  -6.1234,  -6.0079,  ...,  -6.4141,  -5.7412,  -4.7401],\n",
      "         ...,\n",
      "         [ -6.3336,  -6.4439,  -6.3418,  ...,  -6.4274,  -5.7555,  -4.6087],\n",
      "         [ -6.5561,  -6.6742,  -6.6088,  ...,  -6.7171,  -6.2067,  -5.1831],\n",
      "         [ -6.9558,  -7.1235,  -6.9372,  ...,  -6.9160,  -5.9896,  -5.5329]],\n",
      "\n",
      "        [[ -6.3626,  -6.3288,  -6.3532,  ...,  -5.6744,  -5.7886,  -3.4595],\n",
      "         [ -5.9644,  -5.8528,  -6.1358,  ...,  -6.7212,  -6.8058,  -2.4454],\n",
      "         [ -3.0784,  -3.5206,  -3.3993,  ...,  -3.5716,  -4.6517,  -0.8024],\n",
      "         ...,\n",
      "         [ -3.9428,  -4.1042,  -3.9432,  ...,  -4.6723,  -4.5278,  -2.0988],\n",
      "         [ -3.8593,  -4.0821,  -3.9852,  ...,  -4.0390,  -5.1139,  -1.0511],\n",
      "         [ -3.8285,  -3.9466,  -3.9411,  ...,  -4.6274,  -4.5046,  -1.5700]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.9318,  -7.9683,  -7.8086,  ...,  -7.1421,  -6.6579,  -5.2683],\n",
      "         [-15.2290, -15.1356, -15.4822,  ..., -12.8296, -11.7490, -14.5218],\n",
      "         [-12.6223, -12.5166, -12.4297,  ..., -12.1716,  -9.9812, -12.9547],\n",
      "         ...,\n",
      "         [ -9.3703,  -9.4701,  -9.0793,  ...,  -8.1562,  -7.2468,  -9.2355],\n",
      "         [ -1.9328,  -2.0913,  -1.7999,  ...,  -3.2375,  -1.4341,   0.1292],\n",
      "         [-13.5459, -13.7617, -13.4767,  ..., -12.1755,  -9.4919, -11.3561]],\n",
      "\n",
      "        [[ -7.6888,  -7.7677,  -7.6197,  ...,  -7.4151,  -6.6499,  -5.1415],\n",
      "         [ -8.6590,  -8.4107,  -8.3831,  ...,  -8.9709,  -7.4747,  -7.9889],\n",
      "         [ -2.9390,  -3.0218,  -2.7890,  ...,  -3.5825,  -2.2244,  -3.7992],\n",
      "         ...,\n",
      "         [-12.0802, -11.8688, -12.2305,  ..., -11.1479,  -9.4363, -11.1196],\n",
      "         [-13.1580, -13.5760, -13.1310,  ..., -14.4446, -10.5434, -10.2404],\n",
      "         [ -7.1699,  -7.2304,  -6.8469,  ...,  -7.0194,  -5.8033,  -7.4556]],\n",
      "\n",
      "        [[ -6.5962,  -6.5460,  -6.5445,  ...,  -5.7110,  -5.6139,  -3.6049],\n",
      "         [ -7.2804,  -7.2780,  -7.0176,  ...,  -6.8289,  -8.8950,  -5.3843],\n",
      "         [ -9.1227,  -9.0317,  -8.8757,  ...,  -7.4054,  -7.2139,  -7.9861],\n",
      "         ...,\n",
      "         [ -5.0568,  -5.1002,  -4.9781,  ...,  -5.3272,  -5.6514,  -4.0348],\n",
      "         [ -4.3844,  -4.3712,  -4.2172,  ...,  -4.8414,  -4.9683,  -3.2994],\n",
      "         [ -4.4770,  -4.6522,  -4.2941,  ...,  -4.7680,  -5.0686,  -4.5419]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5667394399642944\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.6311, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8347,  -6.8612,  -6.7972,  ...,  -6.0270,  -6.1662,  -3.5932],\n",
      "         [ -7.2189,  -7.2217,  -7.3980,  ...,  -8.4960,  -8.4692,  -2.9626],\n",
      "         [ -7.6892,  -8.4392,  -8.2230,  ...,  -8.8457,  -7.3170,  -4.3671],\n",
      "         ...,\n",
      "         [ -4.8513,  -4.8512,  -4.8052,  ...,  -4.8357,  -5.3691,  -1.9800],\n",
      "         [ -5.4342,  -5.4203,  -5.2701,  ...,  -5.9216,  -5.6077,  -1.3371],\n",
      "         [ -4.4359,  -4.4130,  -4.4349,  ...,  -4.5915,  -5.0212,  -2.0299]],\n",
      "\n",
      "        [[ -6.8455,  -6.8113,  -6.8032,  ...,  -5.8755,  -6.0240,  -4.2995],\n",
      "         [-15.3480, -15.5451, -15.3495,  ..., -11.2174, -11.7656, -15.9208],\n",
      "         [ -5.6705,  -6.2416,  -5.7763,  ...,  -6.0789,  -4.9763,  -7.6328],\n",
      "         ...,\n",
      "         [ -7.8243,  -7.9865,  -8.1212,  ...,  -8.4758,  -6.6525,  -8.3515],\n",
      "         [ -5.8962,  -6.1251,  -5.9969,  ...,  -6.9483,  -5.5618,  -6.5270],\n",
      "         [ -8.1247,  -8.3973,  -8.4367,  ...,  -8.4748,  -7.5685,  -7.0994]],\n",
      "\n",
      "        [[ -6.7703,  -6.8129,  -6.6976,  ...,  -6.0113,  -5.9247,  -4.1376],\n",
      "         [ -9.4777,  -9.9520,  -9.6118,  ...,  -8.4211,  -9.9434,  -9.1502],\n",
      "         [ -8.7137,  -9.2482,  -8.8817,  ...,  -8.4082,  -9.5987,  -6.9032],\n",
      "         ...,\n",
      "         [ -4.5049,  -4.7961,  -4.5031,  ...,  -6.0041,  -4.5520,  -7.0370],\n",
      "         [ -5.2111,  -5.5751,  -5.3397,  ...,  -6.3269,  -5.0411,  -5.5791],\n",
      "         [ -5.3773,  -5.4610,  -5.3239,  ...,  -5.9914,  -5.2146,  -6.5666]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9060,  -6.9960,  -6.9030,  ...,  -6.9962,  -6.3950,  -3.6743],\n",
      "         [-12.8126, -12.6325, -12.5496,  ..., -10.2025,  -9.5478, -11.7062],\n",
      "         [ -6.2780,  -6.5643,  -6.3508,  ...,  -7.0227,  -6.0510,  -3.5121],\n",
      "         ...,\n",
      "         [ -6.4998,  -6.7801,  -6.5178,  ...,  -7.1953,  -6.1221,  -3.3528],\n",
      "         [ -6.7022,  -6.8592,  -6.7242,  ...,  -7.3623,  -6.3130,  -3.8828],\n",
      "         [ -6.2544,  -6.5205,  -6.2791,  ...,  -7.1117,  -6.4714,  -2.7314]],\n",
      "\n",
      "        [[ -5.5663,  -5.6593,  -5.6883,  ...,  -5.3340,  -6.1327,  -4.2255],\n",
      "         [-11.2064, -11.1094, -11.2209,  ..., -10.5723,  -8.7964,  -8.9845],\n",
      "         [ -5.0174,  -5.3028,  -5.2874,  ...,  -4.7830,  -5.8327,  -3.7304],\n",
      "         ...,\n",
      "         [ -5.2846,  -5.4235,  -5.3926,  ...,  -5.1564,  -5.4169,  -3.8984],\n",
      "         [ -5.3184,  -5.4948,  -5.4528,  ...,  -5.0503,  -5.3334,  -3.5442],\n",
      "         [ -4.9740,  -5.0781,  -5.1457,  ...,  -5.3965,  -5.4806,  -3.4714]],\n",
      "\n",
      "        [[ -6.8837,  -6.8993,  -6.8777,  ...,  -6.1873,  -6.0228,  -3.8715],\n",
      "         [ -8.6328,  -8.1506,  -8.1368,  ...,  -6.4738,  -7.6900,  -9.3563],\n",
      "         [ -6.3250,  -6.3989,  -6.3627,  ...,  -6.8422,  -6.5628,  -3.4651],\n",
      "         ...,\n",
      "         [ -6.2701,  -6.2924,  -6.3163,  ...,  -6.7843,  -6.3707,  -3.5452],\n",
      "         [ -6.4902,  -6.5405,  -6.5038,  ...,  -6.9196,  -6.1794,  -4.2744],\n",
      "         [ -6.2810,  -6.3348,  -6.3369,  ...,  -6.8800,  -6.4460,  -4.2220]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.6310665607452393\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3273, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2513,  -6.2534,  -6.2507,  ...,  -5.7510,  -5.6293,  -3.5674],\n",
      "         [ -6.1559,  -6.2558,  -6.3122,  ...,  -7.2664,  -7.5973,  -2.9540],\n",
      "         [ -6.9794,  -7.3315,  -7.1752,  ...,  -8.0001,  -7.4898,  -2.1328],\n",
      "         ...,\n",
      "         [ -4.5008,  -4.6022,  -4.6038,  ...,  -5.8042,  -5.7814,  -2.1667],\n",
      "         [ -4.3651,  -4.4269,  -4.4276,  ...,  -5.2175,  -5.1615,  -2.6126],\n",
      "         [ -4.1119,  -4.2262,  -4.2244,  ...,  -5.1102,  -5.0549,  -3.2220]],\n",
      "\n",
      "        [[ -7.3674,  -7.4850,  -7.4157,  ...,  -7.0417,  -6.6130,  -4.4456],\n",
      "         [ -6.2067,  -6.2585,  -5.5706,  ...,  -6.7492,  -4.7871,  -4.3470],\n",
      "         [ -5.2983,  -5.2194,  -5.1343,  ...,  -5.6669,  -4.5025,  -4.6312],\n",
      "         ...,\n",
      "         [ -2.2468,  -2.1172,  -1.8789,  ...,  -1.2059,  -1.5551,  -1.3223],\n",
      "         [ -7.0728,  -7.1421,  -6.8521,  ...,  -5.8170,  -5.5851,  -4.6406],\n",
      "         [ -7.3400,  -7.4588,  -7.1235,  ...,  -6.7661,  -5.8913,  -5.8841]],\n",
      "\n",
      "        [[ -6.6084,  -6.6238,  -6.6129,  ...,  -6.0836,  -5.8228,  -4.5996],\n",
      "         [ -8.6395,  -8.5843,  -8.5419,  ...,  -7.6666,  -6.1853,  -7.5449],\n",
      "         [ -5.6159,  -5.7598,  -5.2442,  ...,  -5.1197,  -3.3673,  -7.9147],\n",
      "         ...,\n",
      "         [ -6.9978,  -7.0673,  -6.9671,  ...,  -7.9995,  -6.0303,  -7.2194],\n",
      "         [ -5.9713,  -6.0717,  -5.8659,  ...,  -6.6511,  -4.7582,  -5.2499],\n",
      "         [ -7.5372,  -7.6700,  -7.5098,  ...,  -8.0633,  -6.0831,  -7.2195]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8062,  -6.7714,  -6.7594,  ...,  -5.9921,  -5.8521,  -3.9686],\n",
      "         [ -5.7911,  -6.0016,  -5.7422,  ...,  -5.6235,  -4.6691,  -4.4409],\n",
      "         [ -6.3497,  -6.5251,  -6.5430,  ...,  -5.9468,  -4.3439,  -7.9880],\n",
      "         ...,\n",
      "         [ -5.9423,  -5.9702,  -5.8244,  ...,  -5.6440,  -5.6084,  -2.5895],\n",
      "         [ -6.1392,  -6.2603,  -6.1979,  ...,  -5.3078,  -6.0947,  -2.8867],\n",
      "         [ -5.4710,  -5.5208,  -5.4937,  ...,  -4.9307,  -5.0205,  -4.8073]],\n",
      "\n",
      "        [[ -6.5892,  -6.6183,  -6.5678,  ...,  -6.0136,  -6.0696,  -3.4465],\n",
      "         [ -5.4607,  -5.3579,  -5.3151,  ...,  -6.0422,  -6.6969,  -1.0767],\n",
      "         [ -4.2626,  -4.3290,  -4.1689,  ...,  -4.8498,  -5.0973,   0.2897],\n",
      "         ...,\n",
      "         [ -4.1590,  -4.1587,  -4.2187,  ...,  -5.2094,  -5.1742,  -1.7412],\n",
      "         [ -3.6536,  -3.7896,  -3.6980,  ...,  -4.4235,  -4.2994,  -1.2909],\n",
      "         [ -4.1752,  -4.2807,  -4.1464,  ...,  -4.8443,  -4.9431,  -2.4334]],\n",
      "\n",
      "        [[ -6.7605,  -6.9329,  -6.8255,  ...,  -6.4197,  -6.7192,  -4.0422],\n",
      "         [-11.2844, -11.1446, -10.9091,  ...,  -7.9710,  -8.2799,  -9.1614],\n",
      "         [ -3.8681,  -4.0824,  -4.0023,  ...,  -4.7549,  -5.3312,  -2.7073],\n",
      "         ...,\n",
      "         [ -3.5606,  -3.6079,  -3.5434,  ...,  -4.1781,  -4.5234,  -3.3060],\n",
      "         [ -3.4674,  -3.5999,  -3.4710,  ...,  -4.0335,  -4.5043,  -2.9227],\n",
      "         [ -3.6882,  -3.8091,  -3.6881,  ...,  -4.6985,  -4.9665,  -3.6137]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.3273003101348877\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4400, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.0520,  -6.0124,  -6.0110,  ...,  -5.4969,  -5.4539,  -3.3867],\n",
      "         [ -5.7728,  -5.6538,  -5.8365,  ...,  -6.2935,  -7.0571,  -4.3905],\n",
      "         [ -2.4020,  -2.5700,  -2.3969,  ...,  -3.1868,  -3.5306,  -2.4496],\n",
      "         ...,\n",
      "         [ -3.5630,  -3.7917,  -3.7217,  ...,  -4.9471,  -4.5401,  -2.2783],\n",
      "         [ -3.6338,  -3.7308,  -3.6666,  ...,  -4.6645,  -4.8955,  -2.4590],\n",
      "         [ -3.1008,  -3.4870,  -3.2584,  ...,  -4.2722,  -4.5156,  -2.4438]],\n",
      "\n",
      "        [[ -8.0039,  -7.8956,  -7.8963,  ...,  -7.2620,  -7.2951,  -4.9337],\n",
      "         [-11.0384, -11.0126, -10.8806,  ...,  -8.6294,  -7.7710, -10.0663],\n",
      "         [ -4.0895,  -4.3532,  -4.2795,  ...,  -4.8450,  -5.8982,  -2.3322],\n",
      "         ...,\n",
      "         [ -3.9436,  -4.1897,  -4.0730,  ...,  -5.0192,  -5.8609,  -2.0945],\n",
      "         [ -3.8615,  -4.2273,  -3.9494,  ...,  -4.5170,  -5.5172,  -1.9451],\n",
      "         [ -4.4278,  -4.6979,  -4.4534,  ...,  -5.3958,  -6.2806,  -3.1364]],\n",
      "\n",
      "        [[ -7.0368,  -6.9118,  -6.7650,  ...,  -5.9813,  -6.9425,  -4.1939],\n",
      "         [ -9.8386,  -9.8038,  -9.7999,  ...,  -6.1879,  -8.7567,  -8.6991],\n",
      "         [ -3.8748,  -3.9120,  -3.8086,  ...,  -4.2295,  -5.5577,  -3.0783],\n",
      "         ...,\n",
      "         [ -4.5259,  -4.5433,  -4.5121,  ...,  -4.5973,  -5.9392,  -3.3827],\n",
      "         [ -4.1619,  -4.2150,  -4.1969,  ...,  -4.5589,  -5.4746,  -2.6944],\n",
      "         [ -4.6315,  -4.7211,  -4.6211,  ...,  -4.8951,  -5.7442,  -3.2810]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.5197,  -8.5913,  -8.4998,  ...,  -7.9699,  -7.9293,  -5.2554],\n",
      "         [-10.7992, -10.8049, -11.1082,  ...,  -8.1176,  -8.3663,  -7.6254],\n",
      "         [ -4.3635,  -4.5106,  -4.6132,  ...,  -4.9934,  -5.7019,  -2.7905],\n",
      "         ...,\n",
      "         [ -4.4225,  -4.5320,  -4.5159,  ...,  -4.8159,  -5.2713,  -3.1878],\n",
      "         [ -4.0198,  -4.2224,  -4.1748,  ...,  -4.7958,  -5.4828,  -2.8743],\n",
      "         [ -4.7297,  -4.8674,  -4.8750,  ...,  -4.9086,  -5.4300,  -3.3958]],\n",
      "\n",
      "        [[ -6.4121,  -6.3423,  -6.3903,  ...,  -5.5318,  -5.9495,  -3.1974],\n",
      "         [ -5.2014,  -4.9337,  -5.0768,  ...,  -5.4761,  -5.9871,  -0.9345],\n",
      "         [ -3.8441,  -3.7597,  -3.8982,  ...,  -4.7119,  -4.0505,  -2.0288],\n",
      "         ...,\n",
      "         [ -4.1353,  -4.1460,  -4.0390,  ...,  -4.6460,  -4.5435,  -1.8626],\n",
      "         [ -4.1900,  -4.2551,  -4.1516,  ...,  -4.7978,  -4.8822,  -1.2031],\n",
      "         [ -4.2508,  -4.2333,  -4.2771,  ...,  -5.2767,  -5.3111,  -2.0967]],\n",
      "\n",
      "        [[ -6.7072,  -6.6892,  -6.7066,  ...,  -5.9889,  -5.8202,  -3.7833],\n",
      "         [-11.8553, -11.3482, -11.3608,  ...,  -9.6519,  -8.8423,  -8.8384],\n",
      "         [ -5.3950,  -5.7078,  -5.5021,  ...,  -5.9269,  -6.0445,  -3.0742],\n",
      "         ...,\n",
      "         [ -6.5688,  -6.7050,  -6.6696,  ...,  -7.0509,  -6.4614,  -3.1649],\n",
      "         [ -6.3555,  -6.4466,  -6.4337,  ...,  -6.6095,  -6.5263,  -4.3403],\n",
      "         [ -6.1575,  -6.2568,  -6.1853,  ...,  -6.7053,  -6.1975,  -2.8887]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.4399526119232178\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.9509, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5787,  -6.5998,  -6.5716,  ...,  -6.0090,  -5.9188,  -3.6823],\n",
      "         [-10.1941,  -9.8866,  -9.7367,  ...,  -9.3484,  -8.5255,  -5.2090],\n",
      "         [ -5.1127,  -5.5948,  -5.0710,  ...,  -4.6718,  -3.8780,  -5.4645],\n",
      "         ...,\n",
      "         [ -6.7498,  -6.8280,  -6.9504,  ...,  -6.6146,  -7.0832,  -3.0613],\n",
      "         [ -5.7357,  -5.8400,  -5.8416,  ...,  -5.5211,  -5.6542,  -1.9851],\n",
      "         [ -7.1232,  -7.1891,  -7.3234,  ...,  -7.2696,  -7.1560,  -3.3004]],\n",
      "\n",
      "        [[ -6.6466,  -6.6307,  -6.6566,  ...,  -5.8720,  -5.8141,  -3.9613],\n",
      "         [-11.7131, -11.5179, -11.7780,  ...,  -8.9598,  -7.7062,  -8.7131],\n",
      "         [ -3.7720,  -3.8362,  -3.8948,  ...,  -3.7518,  -5.6122,  -1.7020],\n",
      "         ...,\n",
      "         [ -4.7639,  -4.8981,  -4.9425,  ...,  -4.7489,  -5.8031,  -2.7067],\n",
      "         [ -4.3416,  -4.4669,  -4.4924,  ...,  -4.2959,  -5.8496,  -2.8975],\n",
      "         [ -4.5940,  -4.7562,  -4.8161,  ...,  -4.7966,  -5.4539,  -2.2757]],\n",
      "\n",
      "        [[ -6.3555,  -6.4265,  -6.4080,  ...,  -5.9738,  -5.9374,  -3.9701],\n",
      "         [ -5.1364,  -4.8837,  -5.0872,  ...,  -6.2825,  -6.7808,  -0.0239],\n",
      "         [ -4.8475,  -4.7529,  -5.0003,  ...,  -6.6016,  -6.4393,  -1.0514],\n",
      "         ...,\n",
      "         [ -2.9218,  -3.1942,  -3.0334,  ...,  -4.3371,  -4.8154,  -2.6417],\n",
      "         [ -3.1075,  -3.2937,  -3.1880,  ...,  -4.4017,  -4.8305,  -1.6822],\n",
      "         [ -3.9780,  -4.1246,  -4.0185,  ...,  -4.7244,  -5.2066,  -2.1395]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6435,  -6.6431,  -6.6218,  ...,  -6.2880,  -6.3090,  -3.7723],\n",
      "         [ -5.0228,  -4.8609,  -4.9866,  ...,  -6.3833,  -7.1351,  -0.0983],\n",
      "         [ -6.7123,  -6.4611,  -6.4847,  ...,  -7.2215,  -7.7695,  -1.4288],\n",
      "         ...,\n",
      "         [ -3.1960,  -3.1893,  -3.0166,  ...,  -3.8022,  -4.5968,  -0.2871],\n",
      "         [ -3.6390,  -3.7805,  -3.6467,  ...,  -4.6475,  -4.7531,  -1.3080],\n",
      "         [ -4.1550,  -4.2969,  -4.1204,  ...,  -4.8500,  -4.8679,  -2.2137]],\n",
      "\n",
      "        [[ -6.0849,  -6.0493,  -6.0968,  ...,  -5.6140,  -5.5798,  -3.4986],\n",
      "         [ -7.2412,  -6.8621,  -7.2270,  ...,  -7.8520,  -8.8348,  -2.7263],\n",
      "         [ -5.6661,  -5.3398,  -5.5800,  ...,  -7.3015,  -6.6740,  -1.4667],\n",
      "         ...,\n",
      "         [ -4.0990,  -4.1461,  -4.1906,  ...,  -4.6934,  -4.9486,  -1.9535],\n",
      "         [ -3.5581,  -3.5172,  -3.5352,  ...,  -4.1153,  -4.5002,  -0.9837],\n",
      "         [ -4.3364,  -4.2153,  -4.3069,  ...,  -5.1287,  -5.1883,  -1.7773]],\n",
      "\n",
      "        [[ -7.1442,  -7.2917,  -7.0557,  ...,  -6.6868,  -6.2637,  -4.9645],\n",
      "         [-12.7218, -12.8811, -12.6605,  ..., -11.3245, -10.2748, -13.6811],\n",
      "         [ -5.6606,  -6.1077,  -5.8797,  ...,  -6.2559,  -5.4470,  -5.2931],\n",
      "         ...,\n",
      "         [ -1.8786,  -1.9168,  -1.3422,  ...,  -2.8245,  -2.2494,  -1.3138],\n",
      "         [ -2.7925,  -2.9110,  -2.7588,  ...,  -2.8229,  -1.8170,  -3.1444],\n",
      "         [-12.0864, -11.4860, -11.8136,  ...,  -9.7873, -10.3981,  -7.7891]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.9508814215660095\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.4917, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6974,  -6.7737,  -6.6656,  ...,  -6.5450,  -5.6954,  -4.8549],\n",
      "         [ -6.8148,  -7.2800,  -6.8235,  ...,  -6.8240,  -5.4920,  -4.9337],\n",
      "         [ -6.0002,  -6.1097,  -5.8630,  ...,  -6.1252,  -2.2331,  -7.3851],\n",
      "         ...,\n",
      "         [ -9.4185,  -9.6488,  -9.3304,  ...,  -8.7860,  -6.0011,  -8.1152],\n",
      "         [ -8.5465,  -8.8328,  -8.3371,  ...,  -7.4623,  -7.9737,  -5.2743],\n",
      "         [-12.1331, -12.3252, -12.4423,  ..., -10.4007, -10.5283,  -8.0654]],\n",
      "\n",
      "        [[ -6.4479,  -6.4243,  -6.4104,  ...,  -5.6040,  -5.7142,  -3.5737],\n",
      "         [ -5.7075,  -5.7560,  -5.8550,  ...,  -6.1206,  -6.6130,   0.4249],\n",
      "         [ -7.0191,  -7.0584,  -7.0690,  ...,  -7.7505,  -7.8173,  -0.5230],\n",
      "         ...,\n",
      "         [ -4.4233,  -4.6144,  -4.4775,  ...,  -4.9028,  -5.5964,  -1.4019],\n",
      "         [ -4.4234,  -4.6018,  -4.4875,  ...,  -5.5046,  -5.3458,  -1.0785],\n",
      "         [ -4.4403,  -4.5183,  -4.4901,  ...,  -5.2642,  -5.3578,  -1.2672]],\n",
      "\n",
      "        [[ -7.7082,  -7.6779,  -7.6096,  ...,  -7.3416,  -6.8847,  -4.9333],\n",
      "         [-14.8169, -14.5959, -14.8899,  ..., -13.7341, -13.7132, -10.0239],\n",
      "         [ -9.2120,  -9.4121,  -8.6818,  ...,  -8.9377,  -9.6875,  -9.7350],\n",
      "         ...,\n",
      "         [ -9.4374,  -9.0777,  -9.0692,  ...,  -8.5415,  -8.9998,  -7.5443],\n",
      "         [ -7.0983,  -6.8711,  -7.2370,  ...,  -7.9955,  -6.8433,  -3.6946],\n",
      "         [-12.4472, -12.5666, -12.8651,  ..., -10.2244,  -8.0499, -10.1398]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0073,  -7.0407,  -7.0120,  ...,  -6.3776,  -6.0663,  -4.2145],\n",
      "         [-10.6334, -10.4540, -10.7776,  ..., -10.1455,  -8.7601, -10.2113],\n",
      "         [-11.6423, -11.5701, -11.9361,  ..., -12.1961, -10.9460,  -8.1204],\n",
      "         ...,\n",
      "         [-13.0451, -13.0432, -13.0417,  ..., -10.6855,  -9.6979, -10.3541],\n",
      "         [-12.3166, -12.4692, -12.0754,  ..., -11.3581,  -9.5439, -10.0048],\n",
      "         [-10.4368, -10.6953, -10.6378,  ...,  -8.5513,  -9.0387,  -6.7189]],\n",
      "\n",
      "        [[ -6.2114,  -6.2441,  -6.1952,  ...,  -5.6348,  -5.3156,  -3.3548],\n",
      "         [ -5.6153,  -5.9387,  -5.5108,  ...,  -5.6442,  -3.9144,  -8.5494],\n",
      "         [ -6.1239,  -5.9700,  -5.7942,  ...,  -5.5446,  -4.4410,  -8.4089],\n",
      "         ...,\n",
      "         [ -7.8697,  -7.8776,  -7.7717,  ...,  -6.1624,  -5.8525,  -7.4707],\n",
      "         [ -8.1625,  -8.3993,  -8.0933,  ...,  -7.6904,  -6.4912,  -8.0088],\n",
      "         [ -7.6852,  -7.9271,  -7.7753,  ...,  -7.1665,  -6.2072,  -8.0978]],\n",
      "\n",
      "        [[ -7.2647,  -7.3253,  -7.2431,  ...,  -6.9711,  -7.3462,  -4.3397],\n",
      "         [-11.9508, -11.9308, -11.8404,  ...,  -9.8784,  -9.3691, -12.4663],\n",
      "         [ -4.6008,  -4.7916,  -4.7326,  ...,  -5.4561,  -6.5703,  -3.7095],\n",
      "         ...,\n",
      "         [ -5.3775,  -5.4848,  -5.4480,  ...,  -6.1606,  -6.3407,  -4.7278],\n",
      "         [ -4.6222,  -4.9047,  -4.8155,  ...,  -5.1999,  -6.3872,  -3.3253],\n",
      "         [ -4.7000,  -4.8656,  -4.7760,  ...,  -5.1649,  -6.1249,  -3.0121]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.4916589260101318\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7193, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.6657,  -7.6408,  -7.6555,  ...,  -7.0192,  -6.2028,  -5.1082],\n",
      "         [ -7.0349,  -7.0544,  -7.2657,  ...,  -7.5006,  -5.3228,  -6.7146],\n",
      "         [ -4.6241,  -4.7107,  -4.5527,  ...,  -4.7323,  -2.7359,  -6.7833],\n",
      "         ...,\n",
      "         [ -8.1592,  -8.4631,  -8.3864,  ...,  -8.4577,  -8.4455,  -2.7407],\n",
      "         [ -7.0466,  -6.9539,  -6.8730,  ...,  -6.2200,  -5.1639,  -5.3941],\n",
      "         [-15.6471, -15.8014, -15.6502,  ..., -14.4293, -13.5141, -13.8471]],\n",
      "\n",
      "        [[ -6.8733,  -6.8641,  -6.8425,  ...,  -6.1505,  -6.4363,  -3.6084],\n",
      "         [ -5.3966,  -5.3306,  -5.5290,  ...,  -6.6027,  -6.5458,  -0.3744],\n",
      "         [ -3.8636,  -3.9772,  -3.8966,  ...,  -3.9299,  -4.0324,  -2.2238],\n",
      "         ...,\n",
      "         [ -4.2456,  -4.3492,  -4.2261,  ...,  -4.9672,  -5.1264,  -3.0261],\n",
      "         [ -2.5376,  -2.7239,  -2.6682,  ...,  -3.8018,  -3.7356,  -0.6621],\n",
      "         [ -3.5304,  -3.6253,  -3.5631,  ...,  -4.6362,  -4.4156,  -0.7653]],\n",
      "\n",
      "        [[ -6.8535,  -7.0761,  -7.0587,  ...,  -6.1881,  -6.7222,  -3.6221],\n",
      "         [-12.3577, -12.1505, -12.0088,  ...,  -8.5346,  -8.5865,  -9.6194],\n",
      "         [ -3.4288,  -3.5993,  -3.7133,  ...,  -4.0689,  -5.4681,  -2.5371],\n",
      "         ...,\n",
      "         [ -3.8209,  -3.9375,  -3.9882,  ...,  -3.5798,  -5.0763,  -2.9791],\n",
      "         [ -4.5139,  -4.6733,  -4.6399,  ...,  -4.3281,  -5.5394,  -4.3354],\n",
      "         [ -4.2272,  -4.4412,  -4.3639,  ...,  -4.3344,  -5.6015,  -4.1110]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.5827,  -6.6092,  -6.5673,  ...,  -6.3062,  -6.1056,  -4.2615],\n",
      "         [ -4.4697,  -4.3531,  -4.5075,  ...,  -6.0788,  -6.0239,   0.2766],\n",
      "         [ -5.8852,  -5.6852,  -5.7360,  ...,  -5.8415,  -5.9026,  -1.3572],\n",
      "         ...,\n",
      "         [ -3.5819,  -3.6964,  -3.4794,  ...,  -4.5145,  -4.3802,  -1.4107],\n",
      "         [ -4.4922,  -4.6008,  -4.5972,  ...,  -5.4888,  -4.9574,  -1.8316],\n",
      "         [ -3.9931,  -3.9579,  -3.9927,  ...,  -4.9159,  -4.5399,  -1.1558]],\n",
      "\n",
      "        [[ -6.6967,  -6.6959,  -6.7028,  ...,  -6.0609,  -5.8676,  -3.6512],\n",
      "         [ -6.0358,  -5.7945,  -5.8312,  ...,  -6.5653,  -6.2273,  -4.0931],\n",
      "         [ -2.9189,  -2.8521,  -2.7467,  ...,  -2.9832,  -1.5162,  -2.2520],\n",
      "         ...,\n",
      "         [ -7.3163,  -7.4738,  -7.2844,  ...,  -6.9988,  -6.6570,  -2.9471],\n",
      "         [ -7.6213,  -7.8149,  -7.6071,  ...,  -7.2311,  -6.7474,  -3.6804],\n",
      "         [ -6.9605,  -6.8756,  -6.7095,  ...,  -7.0867,  -6.0826,  -4.3503]],\n",
      "\n",
      "        [[ -6.3419,  -6.3090,  -6.3287,  ...,  -5.6821,  -5.6171,  -3.7823],\n",
      "         [ -4.1433,  -4.1937,  -4.2660,  ...,  -5.4888,  -5.9090,  -2.9672],\n",
      "         [ -6.1273,  -6.3865,  -6.3489,  ...,  -7.1369,  -6.9718,  -2.7243],\n",
      "         ...,\n",
      "         [ -2.8559,  -3.1245,  -2.9842,  ...,  -4.1170,  -4.2098,  -0.9772],\n",
      "         [ -3.8470,  -3.9945,  -3.8338,  ...,  -5.0448,  -4.9352,  -1.9566],\n",
      "         [ -3.7163,  -3.8193,  -3.7403,  ...,  -4.3134,  -4.4419,  -2.5036]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.719328761100769\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5062, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3109,  -7.3635,  -7.2277,  ...,  -6.9662,  -6.5631,  -5.2863],\n",
      "         [ -8.2395,  -8.3141,  -7.9884,  ...,  -8.3972,  -7.9699,  -7.7321],\n",
      "         [ -1.3760,  -1.2189,  -1.3183,  ...,  -2.8035,  -1.0320,  -2.2590],\n",
      "         ...,\n",
      "         [-10.7445, -10.6309, -11.3168,  ...,  -7.9619,  -7.9645,  -5.3307],\n",
      "         [-12.7886, -12.7059, -12.4658,  ..., -12.0214, -11.5279, -12.0251],\n",
      "         [-12.7050, -13.1417, -12.3147,  ..., -13.7956, -11.4417, -12.2672]],\n",
      "\n",
      "        [[ -4.9402,  -5.0677,  -4.7085,  ...,  -4.6483,  -5.1289,  -7.9493],\n",
      "         [-13.8089, -13.6779, -13.5005,  ..., -11.4158, -11.0656, -12.5140],\n",
      "         [ -4.1144,  -4.2103,  -4.1721,  ...,  -4.8608,  -5.6317,  -3.9887],\n",
      "         ...,\n",
      "         [ -4.0628,  -4.1439,  -3.9956,  ...,  -4.5857,  -4.9882,  -3.1890],\n",
      "         [ -4.1546,  -4.2993,  -4.1194,  ...,  -4.6866,  -5.0887,  -3.7006],\n",
      "         [ -3.8530,  -3.9843,  -3.7967,  ...,  -4.3846,  -4.8106,  -3.1069]],\n",
      "\n",
      "        [[ -6.9309,  -6.9115,  -6.8988,  ...,  -6.3778,  -6.2236,  -4.3565],\n",
      "         [-14.0657, -13.8609, -13.7756,  ..., -12.5678, -13.2495, -12.5237],\n",
      "         [ -4.6684,  -4.8182,  -4.8262,  ...,  -5.3186,  -6.6942,  -3.1047],\n",
      "         ...,\n",
      "         [ -3.6619,  -3.7321,  -3.8197,  ...,  -3.5676,  -5.2822,  -2.5654],\n",
      "         [ -3.4706,  -3.5018,  -3.5526,  ...,  -3.2680,  -4.9497,  -2.6640],\n",
      "         [ -4.4904,  -4.7028,  -4.6884,  ...,  -4.7690,  -6.1586,  -3.4708]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0728,  -7.1410,  -7.0974,  ...,  -6.5399,  -6.1687,  -4.2244],\n",
      "         [-11.5542, -11.1639, -11.3497,  ..., -10.8916,  -9.0653, -10.6182],\n",
      "         [ -8.3710,  -8.6215,  -8.8067,  ...,  -9.4358,  -6.4342,  -5.6710],\n",
      "         ...,\n",
      "         [ -4.8881,  -4.9766,  -4.8629,  ...,  -5.9148,  -4.1701,  -6.4450],\n",
      "         [ -6.3788,  -6.4072,  -6.2822,  ...,  -6.9446,  -5.9731,  -8.1532],\n",
      "         [ -7.0289,  -7.1707,  -6.9236,  ...,  -7.2779,  -6.1795,  -6.6438]],\n",
      "\n",
      "        [[ -7.6100,  -7.6473,  -7.5551,  ...,  -6.9844,  -6.9614,  -5.7695],\n",
      "         [-11.1057, -11.4643, -11.5200,  ..., -12.4138, -10.2896,  -8.6031],\n",
      "         [ -7.7960,  -7.9518,  -7.6367,  ...,  -8.0382,  -6.5103,  -5.4878],\n",
      "         ...,\n",
      "         [ -6.6533,  -6.8796,  -6.4930,  ...,  -4.1077,  -5.3621, -11.0519],\n",
      "         [ -6.2733,  -6.2495,  -6.4127,  ...,  -4.0844,  -6.3055,  -4.7039],\n",
      "         [-14.2594, -14.3736, -14.2609,  ..., -14.6302, -12.6139, -11.1843]],\n",
      "\n",
      "        [[ -6.8561,  -6.7421,  -6.7755,  ...,  -6.2401,  -5.8381,  -4.2846],\n",
      "         [-12.2100, -11.7554, -12.1780,  ..., -10.7889, -11.0213, -10.1819],\n",
      "         [ -8.8465,  -8.6751,  -9.0187,  ...,  -9.3708,  -8.3106,  -6.0137],\n",
      "         ...,\n",
      "         [ -5.3178,  -5.0733,  -5.0702,  ...,  -4.8279,  -5.4598,  -4.1352],\n",
      "         [ -3.7745,  -3.6421,  -3.6538,  ...,  -3.2529,  -4.4801,  -3.2054],\n",
      "         [ -5.7396,  -5.5497,  -5.7394,  ...,  -5.7674,  -5.4147,  -4.9552]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5062146186828613\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4801, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6659,  -6.6910,  -6.6180,  ...,  -6.0415,  -5.8341,  -4.0211],\n",
      "         [-10.9802, -10.7621, -10.7211,  ...,  -8.7044,  -8.3229,  -6.1163],\n",
      "         [ -5.5727,  -5.7418,  -5.5639,  ...,  -5.5073,  -4.8410,  -5.3222],\n",
      "         ...,\n",
      "         [ -6.1228,  -6.4210,  -5.9179,  ...,  -7.2224,  -6.7747,  -2.4940],\n",
      "         [-10.9272, -10.8571, -10.9555,  ...,  -9.9292,  -8.3478,  -9.8174],\n",
      "         [-11.4186, -11.5999, -11.6575,  ..., -11.0565,  -8.6505,  -8.7751]],\n",
      "\n",
      "        [[ -8.2542,  -8.2906,  -8.2898,  ...,  -7.0144,  -7.0735,  -4.6355],\n",
      "         [-13.5378, -13.4758, -13.1990,  ..., -11.6939, -10.7122, -12.0713],\n",
      "         [ -3.3098,  -3.5495,  -3.4878,  ...,  -4.5198,  -5.5654,  -2.7649],\n",
      "         ...,\n",
      "         [ -2.8629,  -3.0145,  -2.9433,  ...,  -3.6132,  -5.0716,  -2.8983],\n",
      "         [ -3.1719,  -3.3369,  -3.1944,  ...,  -3.6392,  -5.1952,  -2.7532],\n",
      "         [ -3.4399,  -3.5759,  -3.5675,  ...,  -4.0276,  -4.8439,  -2.2011]],\n",
      "\n",
      "        [[ -6.4058,  -6.3665,  -6.3831,  ...,  -5.7096,  -5.5681,  -3.7830],\n",
      "         [-11.3389, -11.5054, -11.1224,  ...,  -8.7071,  -9.4377, -10.0506],\n",
      "         [ -3.8512,  -4.0712,  -4.0579,  ...,  -4.2573,  -5.5336,  -2.9800],\n",
      "         ...,\n",
      "         [ -4.6551,  -4.7911,  -4.8255,  ...,  -4.6438,  -5.9619,  -3.4993],\n",
      "         [ -4.5260,  -4.6060,  -4.6359,  ...,  -4.7227,  -5.8825,  -3.3164],\n",
      "         [ -3.9394,  -4.0955,  -3.9989,  ...,  -4.1807,  -5.2799,  -2.7915]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6188,  -6.6400,  -6.6218,  ...,  -6.2394,  -5.7041,  -4.5592],\n",
      "         [-11.5245, -11.3045, -11.1541,  ..., -11.2348,  -7.6749, -12.1554],\n",
      "         [ -4.3559,  -4.1142,  -4.3106,  ...,  -4.9106,  -3.2154,  -8.9372],\n",
      "         ...,\n",
      "         [ -4.4028,  -4.7133,  -4.2650,  ...,  -4.3911,  -3.9376,  -6.0465],\n",
      "         [ -3.0493,  -3.6472,  -3.2358,  ...,  -2.2392,  -2.6567,  -0.0509],\n",
      "         [-11.5323, -11.2324, -11.4410,  ...,  -9.4397,  -8.6008,  -9.7888]],\n",
      "\n",
      "        [[ -6.6909,  -6.6831,  -6.6671,  ...,  -5.9567,  -5.7786,  -3.6886],\n",
      "         [-11.0090, -11.2975, -11.0717,  ...,  -8.3082,  -7.1587,  -8.0349],\n",
      "         [ -5.8859,  -6.0876,  -5.9818,  ...,  -6.3970,  -6.1621,  -2.8841],\n",
      "         ...,\n",
      "         [ -5.5724,  -5.8015,  -5.6680,  ...,  -5.8642,  -5.6486,  -1.8540],\n",
      "         [ -6.1351,  -6.3711,  -6.3452,  ...,  -6.8284,  -6.5722,  -2.2858],\n",
      "         [ -6.5433,  -6.6846,  -6.6744,  ...,  -6.9023,  -6.4402,  -2.9250]],\n",
      "\n",
      "        [[ -6.8238,  -6.8654,  -6.8445,  ...,  -6.1280,  -6.1917,  -4.0104],\n",
      "         [-15.4781, -15.3193, -15.4842,  ..., -14.0245, -12.6826,  -9.4421],\n",
      "         [ -4.1406,  -4.4201,  -4.3553,  ...,  -4.4039,  -5.4315,  -1.6174],\n",
      "         ...,\n",
      "         [ -3.9546,  -4.1288,  -3.9133,  ...,  -3.9953,  -4.7937,  -1.8266],\n",
      "         [ -4.1799,  -4.3859,  -4.1607,  ...,  -4.3206,  -5.0581,  -1.6549],\n",
      "         [ -4.5032,  -4.7599,  -4.6156,  ...,  -4.8023,  -5.2151,  -2.0510]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.480090856552124\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6568, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1460,  -7.1374,  -7.0614,  ...,  -6.1302,  -6.0817,  -3.6098],\n",
      "         [ -8.2864,  -8.3971,  -8.2698,  ...,  -7.3911,  -8.0224,  -3.7629],\n",
      "         [-14.1771, -14.7136, -13.8882,  ..., -14.1237, -11.3571,  -6.5399],\n",
      "         ...,\n",
      "         [ -7.4251,  -7.5836,  -7.4284,  ...,  -7.0502,  -7.2058,  -3.1876],\n",
      "         [ -7.5858,  -7.7164,  -7.4695,  ...,  -6.9429,  -6.7165,  -2.2541],\n",
      "         [ -8.1176,  -8.3038,  -8.1819,  ...,  -8.2214,  -7.7147,  -3.3471]],\n",
      "\n",
      "        [[ -6.2092,  -6.1987,  -6.1695,  ...,  -5.4682,  -5.8007,  -3.4893],\n",
      "         [ -4.6958,  -4.3886,  -4.4481,  ...,  -5.2645,  -6.1606,  -1.4936],\n",
      "         [ -4.2569,  -4.2465,  -4.1136,  ...,  -4.1621,  -3.9646,  -3.3745],\n",
      "         ...,\n",
      "         [ -3.6656,  -3.6262,  -3.6330,  ...,  -4.2854,  -4.1943,  -3.3403],\n",
      "         [ -2.9990,  -2.9692,  -3.0003,  ...,  -3.8767,  -4.0063,  -1.1561],\n",
      "         [ -3.5439,  -3.4894,  -3.5932,  ...,  -3.8664,  -4.6715,  -1.6743]],\n",
      "\n",
      "        [[ -6.0422,  -5.9755,  -5.9822,  ...,  -5.5177,  -5.1799,  -3.6393],\n",
      "         [-11.7644, -11.4561, -11.5388,  ...,  -9.3829, -10.0865,  -7.6582],\n",
      "         [ -3.5886,  -3.6836,  -3.7545,  ...,  -4.3934,  -5.2437,  -2.7046],\n",
      "         ...,\n",
      "         [ -3.7552,  -3.7169,  -3.7859,  ...,  -3.8684,  -4.8038,  -2.4262],\n",
      "         [ -4.0084,  -4.0089,  -4.1168,  ...,  -4.8786,  -5.4806,  -3.6472],\n",
      "         [ -3.8057,  -3.8255,  -3.8537,  ...,  -4.1915,  -5.1346,  -2.2981]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.7576,  -6.1748,  -5.5373,  ...,  -5.3988,  -4.5486,  -4.1912],\n",
      "         [-12.5192, -12.5422, -12.3217,  ..., -10.3508,  -9.9502, -12.9338],\n",
      "         [ -3.5492,  -3.7302,  -3.7601,  ...,  -4.2656,  -5.5298,  -2.8640],\n",
      "         ...,\n",
      "         [ -3.5076,  -3.6382,  -3.5565,  ...,  -3.4888,  -4.7483,  -3.8230],\n",
      "         [ -3.2299,  -3.3676,  -3.3527,  ...,  -3.5747,  -4.4103,  -2.4012],\n",
      "         [ -2.4574,  -2.6644,  -2.4656,  ...,  -1.5419,  -3.6932,  -2.7983]],\n",
      "\n",
      "        [[ -8.1495,  -8.1940,  -8.0658,  ...,  -7.4050,  -7.0292,  -4.4297],\n",
      "         [ -7.7435,  -7.4958,  -7.2809,  ...,  -7.4173,  -6.6511,  -6.6234],\n",
      "         [ -8.4252,  -8.2041,  -7.9465,  ...,  -7.5073,  -5.6570,  -6.8732],\n",
      "         ...,\n",
      "         [ -4.7851,  -5.2129,  -4.8091,  ...,  -4.1269,  -3.9113,  -6.4201],\n",
      "         [ -6.5805,  -7.0039,  -6.4212,  ...,  -6.2580,  -4.3163,  -5.6080],\n",
      "         [ -7.7389,  -8.0756,  -7.7518,  ...,  -7.7961,  -6.8995,  -5.6719]],\n",
      "\n",
      "        [[ -7.6268,  -7.6293,  -7.6286,  ...,  -7.1615,  -6.7539,  -5.0982],\n",
      "         [-11.5890, -11.4368, -11.7096,  ..., -10.1275,  -9.8629, -11.1677],\n",
      "         [ -8.1452,  -7.8536,  -8.0258,  ...,  -7.0257,  -6.7667,  -6.4649],\n",
      "         ...,\n",
      "         [ -5.7177,  -5.7393,  -5.8636,  ...,  -5.7504,  -5.0518,  -5.4549],\n",
      "         [ -6.9995,  -6.8271,  -6.9037,  ...,  -6.9156,  -5.5538,  -4.9725],\n",
      "         [-18.0878, -18.0427, -17.9169,  ..., -17.2380, -15.1928, -14.7980]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.6567989587783813\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.5665, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0479,  -7.0114,  -7.0245,  ...,  -6.2636,  -6.5884,  -3.3402],\n",
      "         [ -4.4886,  -4.2991,  -4.3576,  ...,  -5.1910,  -6.1834,  -0.8774],\n",
      "         [ -6.3042,  -6.4756,  -6.8150,  ...,  -6.6442,  -8.0617,  -4.0135],\n",
      "         ...,\n",
      "         [ -3.3676,  -3.5676,  -3.3891,  ...,  -4.5496,  -4.2215,  -1.7378],\n",
      "         [ -3.5605,  -3.6186,  -3.4847,  ...,  -4.6777,  -4.4913,  -0.4209],\n",
      "         [ -3.5832,  -3.6503,  -3.5760,  ...,  -4.3071,  -4.3764,  -0.9459]],\n",
      "\n",
      "        [[ -6.5035,  -6.4910,  -6.3466,  ...,  -5.8781,  -5.7960,  -3.8495],\n",
      "         [ -6.0540,  -6.1041,  -5.5914,  ...,  -5.8129,  -5.5916,  -0.6844],\n",
      "         [ -4.8423,  -5.4612,  -5.4952,  ...,  -2.3772,  -5.3976,  -9.5885],\n",
      "         ...,\n",
      "         [ -6.0203,  -5.7490,  -5.8479,  ...,  -5.0090,  -5.9993,  -2.0626],\n",
      "         [ -5.5048,  -5.4804,  -5.4368,  ...,  -5.7535,  -5.2639,  -4.5832],\n",
      "         [ -4.8521,  -4.8996,  -4.7977,  ...,  -5.3573,  -4.9532,  -3.8338]],\n",
      "\n",
      "        [[ -6.4867,  -6.3934,  -6.3900,  ...,  -5.7834,  -5.7211,  -3.7814],\n",
      "         [-10.0642, -10.1051, -10.4854,  ...,  -8.7013,  -9.3056,  -5.6286],\n",
      "         [ -3.1589,  -3.2378,  -3.1814,  ...,  -3.2885,  -4.8107,  -2.0128],\n",
      "         ...,\n",
      "         [ -2.6188,  -2.7682,  -2.6380,  ...,  -2.8971,  -4.2050,  -2.3709],\n",
      "         [ -2.5896,  -2.6576,  -2.4478,  ...,  -2.6468,  -4.2104,  -1.1385],\n",
      "         [ -4.2034,  -4.1919,  -4.1342,  ...,  -4.2315,  -5.1916,  -2.3829]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.0977,  -6.0682,  -6.0637,  ...,  -5.4826,  -5.5570,  -3.2181],\n",
      "         [ -5.6600,  -5.5887,  -5.5919,  ...,  -5.5630,  -7.7126,  -2.5410],\n",
      "         [ -3.8147,  -3.7507,  -3.7979,  ...,  -4.7581,  -5.7440,  -1.5102],\n",
      "         ...,\n",
      "         [ -3.3715,  -3.4689,  -3.4481,  ...,  -3.5773,  -4.5188,  -0.9524],\n",
      "         [ -3.8856,  -3.9902,  -3.9641,  ...,  -4.2568,  -4.9677,  -0.9445],\n",
      "         [ -4.6052,  -4.6482,  -4.6387,  ...,  -5.1188,  -5.7875,  -1.8665]],\n",
      "\n",
      "        [[ -7.9158,  -7.8968,  -7.8141,  ...,  -7.6444,  -6.9546,  -4.4911],\n",
      "         [-12.2400, -12.0748, -12.1171,  ...,  -9.4400,  -8.4194, -10.0818],\n",
      "         [-11.2602, -10.9962, -10.2985,  ..., -10.3284,  -7.1110,  -9.7540],\n",
      "         ...,\n",
      "         [-13.8980, -13.3229, -13.0775,  ..., -12.9562, -11.0981, -10.2440],\n",
      "         [-11.5701, -11.4343, -11.4569,  ...,  -6.8914,  -8.5790, -10.1976],\n",
      "         [-14.6431, -14.5140, -14.2258,  ..., -13.6476, -12.2947, -12.3129]],\n",
      "\n",
      "        [[ -6.7337,  -6.8660,  -6.8439,  ...,  -5.8687,  -6.3120,  -3.5767],\n",
      "         [ -4.7119,  -4.6058,  -4.7117,  ...,  -6.3265,  -6.0146,  -0.7917],\n",
      "         [-12.8355, -13.1437, -12.8104,  ..., -12.7938, -11.4665, -10.9664],\n",
      "         ...,\n",
      "         [ -5.3084,  -5.5351,  -5.4037,  ...,  -6.7023,  -5.6940,  -3.8036],\n",
      "         [ -5.1314,  -5.4364,  -5.4427,  ...,  -5.9983,  -5.5303,  -0.5241],\n",
      "         [ -3.9283,  -3.9769,  -3.9421,  ...,  -4.7846,  -4.1774,   0.2781]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.5664777755737305\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2605, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7771,  -6.6982,  -6.7194,  ...,  -6.0639,  -5.8821,  -4.0817],\n",
      "         [-10.9877, -10.5681, -10.5070,  ...,  -7.1913,  -7.5486,  -7.9353],\n",
      "         [ -3.9835,  -4.0044,  -3.9970,  ...,  -4.4861,  -5.5787,  -3.6154],\n",
      "         ...,\n",
      "         [ -3.6630,  -3.8117,  -3.7419,  ...,  -4.4254,  -5.0684,  -3.4071],\n",
      "         [ -3.7484,  -3.7444,  -3.6866,  ...,  -4.0268,  -4.9012,  -3.0881],\n",
      "         [ -3.6083,  -3.5707,  -3.6004,  ...,  -4.1174,  -5.1883,  -3.1717]],\n",
      "\n",
      "        [[ -6.1484,  -6.1480,  -6.1343,  ...,  -5.8871,  -5.9316,  -3.5000],\n",
      "         [ -5.8615,  -5.9806,  -5.9557,  ...,  -6.8157,  -6.8727,  -1.4888],\n",
      "         [ -5.5059,  -5.7528,  -5.6044,  ...,  -6.7397,  -7.1935,  -0.3543],\n",
      "         ...,\n",
      "         [ -3.3111,  -3.3851,  -3.3787,  ...,  -4.0444,  -4.5915,  -1.8813],\n",
      "         [ -3.1495,  -3.3436,  -3.1778,  ...,  -4.7950,  -4.5373,  -1.1934],\n",
      "         [ -3.3061,  -3.3895,  -3.3127,  ...,  -4.3099,  -4.4982,  -1.7039]],\n",
      "\n",
      "        [[ -6.9366,  -6.9261,  -6.8620,  ...,  -6.2347,  -6.2106,  -4.4420],\n",
      "         [ -9.6409,  -9.6814,  -9.3350,  ...,  -8.1672,  -7.8099,  -4.9353],\n",
      "         [ -3.4297,  -3.7273,  -3.2204,  ...,  -3.2120,  -3.6281,  -0.3645],\n",
      "         ...,\n",
      "         [ -7.3735,  -7.4059,  -7.5210,  ...,  -6.5307,  -6.6897,  -4.4035],\n",
      "         [ -8.2679,  -8.2949,  -8.2893,  ...,  -7.8003,  -8.1984,  -4.1407],\n",
      "         [ -7.9238,  -8.1177,  -8.0031,  ...,  -7.1230,  -7.2892,  -4.7470]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.0225,  -8.9151,  -8.8236,  ...,  -8.3229,  -8.1830,  -6.6313],\n",
      "         [-14.7583, -14.7052, -14.7206,  ..., -12.5168, -11.8075, -12.0458],\n",
      "         [ -4.4506,  -4.6020,  -4.4724,  ...,  -5.1434,  -5.9578,  -1.8808],\n",
      "         ...,\n",
      "         [ -4.3773,  -4.3480,  -4.3755,  ...,  -4.4733,  -5.1847,  -1.7612],\n",
      "         [ -5.1008,  -5.1594,  -5.1298,  ...,  -5.2760,  -5.9894,  -2.1007],\n",
      "         [ -4.8623,  -4.9733,  -4.9321,  ...,  -4.7745,  -5.7078,  -3.0109]],\n",
      "\n",
      "        [[ -6.2046,  -6.1699,  -6.1890,  ...,  -5.5678,  -5.4111,  -3.7961],\n",
      "         [-17.8994, -17.8643, -17.6499,  ..., -15.7542, -15.2699, -10.1830],\n",
      "         [ -3.6337,  -3.6840,  -3.8468,  ...,  -4.0422,  -5.2751,  -2.6737],\n",
      "         ...,\n",
      "         [ -4.5225,  -4.5700,  -4.5684,  ...,  -4.7297,  -5.6343,  -3.6586],\n",
      "         [ -2.9462,  -2.9002,  -2.9492,  ...,  -3.4725,  -4.2341,  -1.9247],\n",
      "         [ -3.5620,  -3.5970,  -3.6650,  ...,  -3.7720,  -4.7930,  -2.2666]],\n",
      "\n",
      "        [[ -6.6143,  -6.7504,  -6.5756,  ...,  -6.3040,  -6.1295,  -4.1159],\n",
      "         [-13.6229, -13.4929, -13.7610,  ..., -12.6029, -11.7205, -13.5889],\n",
      "         [ -5.5070,  -5.1892,  -5.2761,  ...,  -4.6897,  -5.6594,  -6.2649],\n",
      "         ...,\n",
      "         [  1.8914,   1.6970,   1.7457,  ...,   0.7471,   0.1343,  -3.3692],\n",
      "         [ -2.5548,  -2.4089,  -2.4355,  ...,  -2.9888,  -4.1446,  -2.8077],\n",
      "         [-10.8261, -11.0198, -10.8134,  ..., -10.5495,  -8.9441,  -7.1168]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.2605243921279907\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0996, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.4531,  -7.3706,  -7.3302,  ...,  -6.7620,  -6.5503,  -4.8385],\n",
      "         [ -8.7172,  -8.6168,  -9.0229,  ...,  -8.5050,  -6.9156,  -7.9281],\n",
      "         [ -1.3756,  -1.3520,  -1.5306,  ...,  -1.7286,   0.4624,  -5.9630],\n",
      "         ...,\n",
      "         [ -6.4960,  -6.6184,  -6.5967,  ...,  -7.0409,  -6.0772,  -8.7940],\n",
      "         [ -4.4551,  -4.5628,  -4.5780,  ...,  -4.2884,  -5.4672,  -3.9707],\n",
      "         [ -5.8768,  -5.8151,  -5.9881,  ...,  -6.3482,  -6.3169,  -4.7399]],\n",
      "\n",
      "        [[ -7.8666,  -7.9002,  -7.8667,  ...,  -7.4327,  -6.9956,  -5.2676],\n",
      "         [ -8.8123,  -8.9000,  -8.7904,  ...,  -8.9523,  -6.5864, -10.1035],\n",
      "         [ -3.4644,  -3.7481,  -3.4733,  ...,  -4.1343,  -3.4867,  -7.4321],\n",
      "         ...,\n",
      "         [ -6.4198,  -6.3713,  -6.6374,  ...,  -7.8939,  -6.7784,  -6.8962],\n",
      "         [ -6.1851,  -6.3657,  -6.4305,  ...,  -7.7579,  -7.0924,  -5.3782],\n",
      "         [ -6.5452,  -6.5677,  -6.6831,  ...,  -7.8596,  -6.9782,  -8.0666]],\n",
      "\n",
      "        [[ -6.3005,  -6.2920,  -6.2850,  ...,  -5.6873,  -5.4905,  -3.8370],\n",
      "         [ -5.6983,  -5.4488,  -5.5690,  ...,  -6.8879,  -7.0422,  -2.8752],\n",
      "         [ -2.4999,  -2.6385,  -2.6053,  ...,  -3.1252,  -3.5187,  -1.5903],\n",
      "         ...,\n",
      "         [ -3.1235,  -3.1848,  -3.2417,  ...,  -4.5368,  -4.3606,  -2.6911],\n",
      "         [ -3.9643,  -3.9002,  -3.8997,  ...,  -4.7278,  -4.7782,  -2.6828],\n",
      "         [ -3.7448,  -3.7420,  -3.8761,  ...,  -4.9418,  -4.7360,  -2.5222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.8877,  -5.9636,  -5.7255,  ...,  -5.5049,  -5.2992,  -4.2719],\n",
      "         [-12.9305, -12.6856, -12.6640,  ..., -10.9765,  -9.3845, -10.1254],\n",
      "         [ -5.3013,  -5.3605,  -5.4245,  ...,  -5.5087,  -6.1502,  -2.5130],\n",
      "         ...,\n",
      "         [ -5.3403,  -5.3719,  -5.4211,  ...,  -5.2262,  -5.6819,  -2.4909],\n",
      "         [ -4.5634,  -4.5782,  -4.5951,  ...,  -4.8597,  -4.9733,  -2.0504],\n",
      "         [ -4.2900,  -4.3694,  -4.3562,  ...,  -4.2540,  -4.8137,  -1.6244]],\n",
      "\n",
      "        [[ -7.1038,  -7.1143,  -7.0886,  ...,  -6.3626,  -5.8550,  -5.3400],\n",
      "         [ -4.3147,  -4.6470,  -4.5152,  ...,  -5.3446,  -3.3989,  -9.1153],\n",
      "         [ -4.8840,  -4.4998,  -4.2545,  ...,  -4.2610,  -4.7262,  -7.3769],\n",
      "         ...,\n",
      "         [ -5.4272,  -5.5532,  -5.2609,  ...,  -5.3250,  -5.4689,  -5.9833],\n",
      "         [ -4.2107,  -4.2425,  -3.9707,  ...,  -5.9076,  -4.8735,  -4.8905],\n",
      "         [ -5.5863,  -5.6242,  -5.4609,  ...,  -5.6667,  -4.7692,  -5.3776]],\n",
      "\n",
      "        [[ -7.7668,  -7.7520,  -7.7873,  ...,  -6.7732,  -6.8203,  -5.2017],\n",
      "         [ -4.3675,  -4.2682,  -4.7490,  ...,  -2.5618,  -5.0332,  -5.3776],\n",
      "         [ -5.9774,  -6.1739,  -6.1016,  ...,  -5.2666,  -5.1637,  -6.4335],\n",
      "         ...,\n",
      "         [ -7.9138,  -8.0047,  -8.5014,  ...,  -9.0819,  -9.2868,  -2.6173],\n",
      "         [ -4.6435,  -4.5114,  -4.5069,  ...,  -4.1539,  -2.9717,  -2.5995],\n",
      "         [-10.5441, -10.2247, -10.4371,  ...,  -9.1491,  -8.3137,  -9.3530]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.0995748043060303\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1246, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8097,  -6.7328,  -6.7589,  ...,  -6.1228,  -5.8328,  -4.4111],\n",
      "         [ -5.3585,  -5.5969,  -5.6327,  ...,  -5.3214,  -5.3549,  -4.5874],\n",
      "         [ -8.9645,  -9.5739,  -9.0725,  ...,  -7.6905,  -7.8773,  -5.6401],\n",
      "         ...,\n",
      "         [ -6.3525,  -6.5282,  -6.2942,  ...,  -5.1693,  -5.9605,  -3.0405],\n",
      "         [ -6.9386,  -6.9445,  -6.7725,  ...,  -4.5242,  -4.7930,  -4.9815],\n",
      "         [ -5.9739,  -6.1082,  -6.0794,  ...,  -4.3405,  -5.6092,  -3.5992]],\n",
      "\n",
      "        [[ -6.9218,  -6.9441,  -6.7650,  ...,  -6.1767,  -5.9590,  -3.3420],\n",
      "         [ -5.0364,  -4.9279,  -4.8406,  ...,  -5.1957,  -4.7334,  -6.4549],\n",
      "         [ -4.6133,  -4.8168,  -4.2072,  ...,  -4.6261,  -3.9362,  -7.5760],\n",
      "         ...,\n",
      "         [ -5.7097,  -5.9653,  -5.4928,  ...,  -4.9625,  -4.0483,  -2.4619],\n",
      "         [ -5.5645,  -5.6889,  -5.3560,  ...,  -4.2792,  -3.4129,  -3.6703],\n",
      "         [ -5.2798,  -5.2750,  -4.9901,  ...,  -3.9884,  -3.3816,  -3.7332]],\n",
      "\n",
      "        [[ -9.0491,  -8.9183,  -8.9712,  ...,  -7.6321,  -7.9584,  -5.5244],\n",
      "         [ -8.8538,  -8.7690,  -8.9247,  ...,  -8.3707,  -8.7975,  -6.9933],\n",
      "         [-10.0543,  -9.7361, -10.2331,  ..., -10.4760,  -9.8510,  -7.8414],\n",
      "         ...,\n",
      "         [ -8.5878,  -9.0042,  -8.5197,  ...,  -5.9962,  -6.8489,  -7.8090],\n",
      "         [ -8.3589,  -8.2420,  -8.1925,  ...,  -6.4458,  -6.3745,  -8.6890],\n",
      "         [ -7.6128,  -7.3696,  -7.2857,  ...,  -5.7480,  -6.3176,  -6.8548]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3619,  -7.3433,  -7.1342,  ...,  -7.2120,  -6.2435,  -3.7635],\n",
      "         [ -7.0712,  -6.6856,  -6.8412,  ...,  -6.8997,  -7.2807,  -6.2180],\n",
      "         [ -7.0826,  -6.5934,  -6.5004,  ...,  -7.2293,  -5.7575,  -8.6289],\n",
      "         ...,\n",
      "         [ -5.4723,  -5.2883,  -5.1999,  ...,  -4.9729,  -5.3617,  -4.5987],\n",
      "         [-10.6999, -11.1779, -10.7597,  ...,  -8.1841,  -9.1529, -10.1200],\n",
      "         [-12.4114, -13.0854, -12.8948,  ..., -12.0205, -10.6132,  -8.9434]],\n",
      "\n",
      "        [[ -6.4648,  -6.4565,  -6.4338,  ...,  -5.7422,  -5.7724,  -3.9644],\n",
      "         [-13.1836, -12.7399, -12.9175,  ...,  -9.9210,  -9.8988, -11.8811],\n",
      "         [ -4.3115,  -4.6077,  -4.5603,  ...,  -5.0335,  -5.9700,  -2.5443],\n",
      "         ...,\n",
      "         [ -3.9624,  -4.1795,  -4.1330,  ...,  -4.5281,  -5.3043,  -1.5310],\n",
      "         [ -4.8972,  -5.0685,  -5.0286,  ...,  -5.0225,  -5.9124,  -2.9148],\n",
      "         [ -4.4028,  -4.6303,  -4.4985,  ...,  -4.8303,  -5.6779,  -2.4511]],\n",
      "\n",
      "        [[ -7.4114,  -7.4805,  -7.4262,  ...,  -6.6511,  -6.6416,  -4.1909],\n",
      "         [-11.7381, -11.8512, -11.6134,  ...,  -9.8013,  -9.4203, -14.0316],\n",
      "         [ -4.2027,  -4.4521,  -4.1486,  ...,  -2.9013,  -4.4675,  -8.2450],\n",
      "         ...,\n",
      "         [ -3.5056,  -3.7518,  -3.2095,  ...,  -1.9455,  -3.6747,  -4.7470],\n",
      "         [ -3.2830,  -3.4110,  -3.2866,  ...,  -2.1271,  -3.0430,  -4.2729],\n",
      "         [-11.5742, -12.0613, -11.9585,  ..., -10.8223, -10.4463,  -8.2073]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.1246297359466553\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9156, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8332,  -6.8228,  -6.8062,  ...,  -6.4536,  -6.1319,  -4.0092],\n",
      "         [ -8.8164,  -8.5392,  -8.8095,  ...,  -7.2377,  -7.5817, -10.6853],\n",
      "         [ -7.5076,  -7.2746,  -7.6461,  ...,  -7.2104,  -5.8504, -11.6640],\n",
      "         ...,\n",
      "         [ -4.2405,  -4.1243,  -4.1603,  ...,  -5.2404,  -4.7402,  -3.6444],\n",
      "         [ -9.1645,  -9.5581,  -9.3809,  ..., -10.5198,  -8.7676,  -9.1139],\n",
      "         [-11.5898, -11.8088, -12.1306,  ...,  -8.9885,  -9.8151,  -8.3674]],\n",
      "\n",
      "        [[ -6.7327,  -6.7656,  -6.7537,  ...,  -6.1615,  -5.9104,  -3.9431],\n",
      "         [ -8.4359,  -8.5096,  -8.4071,  ...,  -7.5192,  -7.3283,  -5.2989],\n",
      "         [ -3.1055,  -3.1737,  -3.0174,  ...,  -5.0452,  -4.1017,  -4.2431],\n",
      "         ...,\n",
      "         [ -6.8320,  -6.7939,  -6.8762,  ...,  -7.3780,  -7.0742,  -6.4937],\n",
      "         [ -5.6949,  -5.6809,  -5.4663,  ...,  -6.2821,  -5.1178,  -6.4619],\n",
      "         [ -6.4857,  -6.5387,  -6.5147,  ...,  -7.2743,  -6.4941,  -5.9250]],\n",
      "\n",
      "        [[ -6.7801,  -6.8197,  -6.7828,  ...,  -6.1392,  -6.1121,  -3.9002],\n",
      "         [ -4.7456,  -4.6703,  -4.8167,  ...,  -5.8471,  -5.7460,  -0.2213],\n",
      "         [ -3.4944,  -3.4569,  -3.5695,  ...,  -4.2716,  -4.2398,   0.8068],\n",
      "         ...,\n",
      "         [ -2.8947,  -3.0797,  -2.9843,  ...,  -4.2106,  -3.9422,  -1.7050],\n",
      "         [ -3.6413,  -3.8105,  -3.8050,  ...,  -5.0025,  -4.8931,  -1.4932],\n",
      "         [ -3.8577,  -4.0116,  -4.0430,  ...,  -5.0175,  -4.7226,  -1.4833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9278,  -6.9454,  -6.9302,  ...,  -6.4853,  -5.9685,  -5.5951],\n",
      "         [ -9.3950,  -9.2499,  -8.9881,  ..., -10.2883,  -7.6945, -10.8137],\n",
      "         [ -4.1164,  -4.1304,  -4.2513,  ...,  -4.4097,  -6.0298,  -2.7480],\n",
      "         ...,\n",
      "         [ -4.8099,  -4.7406,  -4.8798,  ...,  -5.5306,  -5.4823,  -5.0457],\n",
      "         [ -4.2858,  -4.2461,  -4.3906,  ...,  -4.4803,  -5.2834,  -3.8878],\n",
      "         [ -4.8716,  -4.9604,  -4.9822,  ...,  -4.8615,  -5.3766,  -4.4600]],\n",
      "\n",
      "        [[ -7.8071,  -7.7744,  -7.6803,  ...,  -7.2360,  -6.8546,  -4.5216],\n",
      "         [ -8.1829,  -8.1798,  -8.1107,  ...,  -7.5717,  -6.7031,  -4.8065],\n",
      "         [ -4.2298,  -3.9582,  -4.3410,  ...,  -4.6236,  -3.4578,  -3.6101],\n",
      "         ...,\n",
      "         [-10.1484,  -9.7572, -10.1775,  ...,  -9.6197,  -8.4670, -11.5530],\n",
      "         [-12.1856, -12.2206, -12.1720,  ..., -12.0312, -10.9538, -12.4183],\n",
      "         [-14.1306, -13.6824, -14.1378,  ..., -10.0779, -11.0590, -10.0746]],\n",
      "\n",
      "        [[ -7.4693,  -7.4178,  -7.3930,  ...,  -6.6110,  -6.6774,  -4.9142],\n",
      "         [-10.6226, -10.6141, -10.3193,  ...,  -7.8076,  -7.0183,  -8.8193],\n",
      "         [ -3.9500,  -4.1022,  -4.0499,  ...,  -4.7495,  -5.8796,  -3.5649],\n",
      "         ...,\n",
      "         [ -3.9887,  -4.0196,  -4.0212,  ...,  -4.0857,  -4.8858,  -2.9801],\n",
      "         [ -3.7280,  -3.7765,  -3.8133,  ...,  -3.8474,  -5.0375,  -3.2209],\n",
      "         [ -4.8512,  -4.9702,  -4.9396,  ...,  -4.9443,  -5.7264,  -3.0945]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.9156430959701538\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.7575, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.1063,  -7.1848,  -7.0762,  ...,  -6.8642,  -6.1891,  -4.2817],\n",
      "         [ -7.5496,  -7.1914,  -7.4663,  ...,  -7.9406,  -7.0656,  -8.3184],\n",
      "         [-12.7641, -12.1621, -12.4867,  ..., -11.2319,  -9.2328,  -9.7423],\n",
      "         ...,\n",
      "         [ -5.9979,  -6.0254,  -6.2160,  ...,  -6.1902,  -3.9679,  -6.9593],\n",
      "         [-13.0462, -13.3046, -13.2211,  ..., -10.8560,  -9.9171, -12.6526],\n",
      "         [-12.9546, -12.9687, -13.1916,  ..., -11.7881,  -9.8898,  -9.2967]],\n",
      "\n",
      "        [[ -6.9576,  -7.1146,  -6.9452,  ...,  -6.3981,  -6.0284,  -5.1668],\n",
      "         [ -9.8641, -10.2617,  -9.9450,  ...,  -9.6975,  -8.4921,  -8.9460],\n",
      "         [ -4.5013,  -4.7141,  -4.6587,  ...,  -4.7912,  -3.4562,  -5.1285],\n",
      "         ...,\n",
      "         [ -2.4859,  -2.7267,  -2.6999,  ...,  -3.8144,  -3.3376,  -5.1497],\n",
      "         [ -5.4043,  -5.3935,  -5.0731,  ...,  -6.6662,  -5.4148,  -6.8137],\n",
      "         [-12.3328, -12.8174, -12.4253,  ..., -13.1950, -11.2888,  -9.6829]],\n",
      "\n",
      "        [[ -6.3356,  -6.2822,  -6.3069,  ...,  -5.6274,  -5.4628,  -3.8428],\n",
      "         [-11.2739, -10.9110, -10.8886,  ...,  -7.8315,  -8.0712,  -9.1172],\n",
      "         [ -5.1412,  -5.1894,  -5.3167,  ...,  -5.3514,  -6.7653,  -2.7506],\n",
      "         ...,\n",
      "         [ -5.3263,  -5.5345,  -5.5730,  ...,  -5.6125,  -6.4594,  -3.0645],\n",
      "         [ -5.1866,  -5.2462,  -5.2987,  ...,  -5.6590,  -6.0935,  -3.3952],\n",
      "         [ -4.9801,  -5.1033,  -5.1380,  ...,  -5.1840,  -6.0639,  -3.1032]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.8874,  -5.8410,  -5.8277,  ...,  -5.4637,  -4.9550,  -3.6258],\n",
      "         [-13.9356, -13.3942, -13.4425,  ..., -10.9130, -10.4253, -13.1236],\n",
      "         [ -3.8136,  -3.8797,  -3.9194,  ...,  -4.1579,  -4.8854,  -3.6236],\n",
      "         ...,\n",
      "         [ -4.3188,  -4.3238,  -4.3712,  ...,  -4.1651,  -4.9869,  -3.7761],\n",
      "         [ -3.7767,  -3.8631,  -3.8085,  ...,  -3.9526,  -4.7101,  -2.6280],\n",
      "         [ -4.4703,  -4.4329,  -4.4033,  ...,  -4.4812,  -5.2835,  -2.9221]],\n",
      "\n",
      "        [[ -6.6937,  -6.6679,  -6.6468,  ...,  -6.0705,  -5.8021,  -3.6469],\n",
      "         [ -5.2220,  -5.2905,  -5.4511,  ...,  -6.0053,  -5.6417,  -1.9390],\n",
      "         [ -6.9521,  -7.0723,  -6.8490,  ...,  -6.3676,  -5.7958,  -2.6161],\n",
      "         ...,\n",
      "         [ -4.1209,  -4.0801,  -4.1051,  ...,  -4.2805,  -3.9710,  -1.5385],\n",
      "         [ -5.7456,  -5.8305,  -5.6837,  ...,  -5.1298,  -4.9665,  -2.2940],\n",
      "         [ -5.5339,  -5.5632,  -5.5805,  ...,  -5.2976,  -5.5281,  -1.7010]],\n",
      "\n",
      "        [[ -5.9572,  -5.9043,  -5.9032,  ...,  -5.2755,  -5.1562,  -3.4641],\n",
      "         [-11.2320, -11.1172, -11.3601,  ...,  -9.2051,  -9.9496,  -9.2934],\n",
      "         [ -4.3393,  -4.5103,  -4.4659,  ...,  -4.7174,  -5.3480,  -2.8558],\n",
      "         ...,\n",
      "         [ -4.1799,  -4.2564,  -4.1569,  ...,  -4.2522,  -4.9648,  -3.3194],\n",
      "         [ -5.0670,  -5.1496,  -5.0418,  ...,  -5.2838,  -5.8810,  -2.9639],\n",
      "         [ -3.9073,  -3.9785,  -3.9002,  ...,  -4.0869,  -4.7380,  -2.0830]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.757502555847168\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.7598, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.8257,  -6.7643,  -6.6362,  ...,  -6.1253,  -7.1938,  -3.3280],\n",
      "         [-14.5766, -14.1399, -14.2224,  ..., -12.4925, -11.1323, -12.2100],\n",
      "         [ -4.3304,  -4.4442,  -4.4495,  ...,  -4.6616,  -5.5801,  -2.9662],\n",
      "         ...,\n",
      "         [ -4.3914,  -4.4332,  -4.4757,  ...,  -5.0579,  -5.3742,  -2.9231],\n",
      "         [ -3.5422,  -3.6582,  -3.6043,  ...,  -4.1829,  -4.8790,  -2.0145],\n",
      "         [ -4.0185,  -4.1431,  -4.1176,  ...,  -4.5399,  -5.3042,  -2.9612]],\n",
      "\n",
      "        [[ -7.3177,  -7.2039,  -7.2287,  ...,  -6.4266,  -6.5145,  -4.0253],\n",
      "         [-15.6369, -15.3662, -15.1200,  ..., -13.6437, -13.3188, -14.4787],\n",
      "         [ -3.4156,  -3.5847,  -3.5625,  ...,  -3.9420,  -5.3152,  -3.8759],\n",
      "         ...,\n",
      "         [ -3.2875,  -3.3174,  -3.2438,  ...,  -3.1200,  -4.4964,  -4.4132],\n",
      "         [ -3.4975,  -3.6647,  -3.6231,  ...,  -3.5807,  -4.6393,  -3.7121],\n",
      "         [ -2.8578,  -3.0298,  -2.9047,  ...,  -2.7329,  -4.0889,  -3.5165]],\n",
      "\n",
      "        [[ -8.5741,  -8.5010,  -8.4174,  ...,  -7.2950,  -7.3236,  -4.9113],\n",
      "         [ -7.8880,  -7.9452,  -8.0694,  ...,  -7.3923,  -8.7263,  -8.1797],\n",
      "         [ -9.4889,  -8.9595,  -9.0292,  ...,  -7.9532,  -7.5039,  -6.6320],\n",
      "         ...,\n",
      "         [ -5.5530,  -5.5140,  -5.5030,  ...,  -5.2221,  -5.8606,  -2.6831],\n",
      "         [ -5.5610,  -5.5912,  -5.4254,  ...,  -5.3620,  -5.7338,  -2.1620],\n",
      "         [ -5.5155,  -5.4284,  -5.4824,  ...,  -5.1349,  -5.2620,  -3.4997]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0864,  -7.0714,  -7.0409,  ...,  -6.1959,  -6.1993,  -4.5337],\n",
      "         [ -7.3843,  -7.7313,  -7.5468,  ...,  -7.9589,  -7.4988, -10.3345],\n",
      "         [ -5.4964,  -5.6817,  -5.8516,  ...,  -7.1610,  -4.6807,  -8.2153],\n",
      "         ...,\n",
      "         [-14.8932, -14.6552, -15.1002,  ..., -12.5207, -11.8835, -12.1352],\n",
      "         [-14.6690, -14.1106, -14.5595,  ..., -11.9561, -10.7189, -10.4457],\n",
      "         [ -8.6130,  -8.5925,  -8.6619,  ...,  -8.8141,  -7.9094,  -6.5682]],\n",
      "\n",
      "        [[ -5.2220,  -5.2090,  -5.1182,  ...,  -5.2248,  -5.0722,  -3.2980],\n",
      "         [-10.8761, -10.7939, -11.1105,  ...,  -9.3753, -10.1883,  -9.2635],\n",
      "         [ -3.3119,  -3.3096,  -3.3482,  ...,  -3.4701,  -4.8309,  -1.9678],\n",
      "         ...,\n",
      "         [ -3.8306,  -3.7578,  -3.6472,  ...,  -3.6874,  -4.5789,  -2.1826],\n",
      "         [ -4.1439,  -4.1563,  -3.9962,  ...,  -4.1765,  -5.4095,  -2.5025],\n",
      "         [ -3.1227,  -3.1642,  -3.1039,  ...,  -3.6087,  -4.7514,  -1.5294]],\n",
      "\n",
      "        [[ -6.3147,  -6.2224,  -6.2343,  ...,  -5.2671,  -5.7558,  -3.1146],\n",
      "         [-11.1961, -11.6963, -10.9956,  ...,  -9.6102,  -8.2432, -10.3882],\n",
      "         [ -3.4078,  -3.7275,  -3.7043,  ...,  -4.0560,  -6.2682,  -2.5778],\n",
      "         ...,\n",
      "         [ -3.6196,  -3.8666,  -3.8255,  ...,  -3.7048,  -5.7167,  -2.2446],\n",
      "         [ -4.5519,  -4.6468,  -4.6697,  ...,  -4.4538,  -5.3069,  -3.4282],\n",
      "         [ -3.7917,  -3.8837,  -3.9189,  ...,  -3.6933,  -5.6258,  -3.5918]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.759812593460083\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2074, grad_fn=<NllLossBackward0>), logits=tensor([[[ -5.2527,  -5.2231,  -5.3341,  ...,  -5.8446,  -4.9615,  -2.6126],\n",
      "         [-11.7359, -11.2783, -11.1521,  ...,  -7.9294,  -7.7693, -12.0179],\n",
      "         [ -5.9949,  -6.1588,  -6.0600,  ...,  -6.2341,  -6.3845,  -3.5172],\n",
      "         ...,\n",
      "         [ -6.4689,  -6.5592,  -6.5121,  ...,  -7.0146,  -6.2317,  -4.0418],\n",
      "         [ -6.2741,  -6.4273,  -6.3203,  ...,  -6.5904,  -5.6444,  -3.4132],\n",
      "         [ -7.0091,  -7.1589,  -7.0719,  ...,  -7.4918,  -6.2759,  -4.9051]],\n",
      "\n",
      "        [[ -6.8876,  -6.8457,  -6.8438,  ...,  -6.0486,  -6.0556,  -4.0641],\n",
      "         [-10.6879, -10.7762, -10.6358,  ...,  -8.0712,  -9.7636, -10.4817],\n",
      "         [ -4.2039,  -4.3469,  -4.2661,  ...,  -4.2230,  -5.7930,  -3.7928],\n",
      "         ...,\n",
      "         [ -3.9324,  -4.0606,  -4.0613,  ...,  -4.1361,  -5.1087,  -2.7689],\n",
      "         [ -4.3136,  -4.4515,  -4.5365,  ...,  -4.9794,  -6.0294,  -3.1056],\n",
      "         [ -4.3855,  -4.4939,  -4.4531,  ...,  -4.6477,  -5.6387,  -2.6221]],\n",
      "\n",
      "        [[ -7.0012,  -6.9826,  -6.9771,  ...,  -6.2118,  -5.9960,  -4.6517],\n",
      "         [-13.1638, -13.3718, -13.4468,  ..., -12.4816, -10.7835,  -8.6070],\n",
      "         [ -5.7727,  -5.8995,  -6.0523,  ...,  -4.4921,  -5.2448, -10.6738],\n",
      "         ...,\n",
      "         [ -6.1410,  -6.2163,  -5.9557,  ...,  -5.3239,  -5.4341,  -6.0668],\n",
      "         [ -6.3742,  -6.5163,  -6.2661,  ...,  -6.2500,  -5.7084,  -4.9596],\n",
      "         [ -6.4043,  -6.5496,  -6.3977,  ...,  -6.5117,  -5.6561,  -4.7419]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8301,  -6.9329,  -6.8940,  ...,  -5.8770,  -6.2063,  -3.8689],\n",
      "         [-11.6957, -11.5428, -11.3999,  ...,  -9.7756,  -8.3193,  -7.3178],\n",
      "         [ -4.9359,  -5.1379,  -5.0774,  ...,  -5.8810,  -6.1185,  -2.3685],\n",
      "         ...,\n",
      "         [ -4.6606,  -4.8631,  -4.7476,  ...,  -5.1455,  -5.0037,  -2.4639],\n",
      "         [ -4.8243,  -4.8853,  -4.9054,  ...,  -5.4457,  -5.5268,  -2.7771],\n",
      "         [ -4.0553,  -4.2686,  -4.1777,  ...,  -4.6991,  -5.0526,  -0.8635]],\n",
      "\n",
      "        [[ -6.6577,  -6.6175,  -6.5642,  ...,  -6.0838,  -5.7454,  -4.2042],\n",
      "         [-14.0536, -13.8009, -13.6735,  ..., -12.3291, -10.8125, -10.1464],\n",
      "         [ -3.9950,  -3.9590,  -3.9522,  ...,  -3.3224,  -4.0947,  -2.6878],\n",
      "         ...,\n",
      "         [ -4.1723,  -4.2187,  -4.0921,  ...,  -3.9793,  -2.8377,  -2.4267],\n",
      "         [ -4.2902,  -4.3408,  -4.2608,  ...,  -4.4825,  -3.2524,  -1.9548],\n",
      "         [ -7.3304,  -7.4235,  -7.2270,  ...,  -7.6757,  -6.6844,  -5.3127]],\n",
      "\n",
      "        [[ -8.0138,  -7.8992,  -7.8196,  ...,  -7.1901,  -6.2981,  -5.0888],\n",
      "         [ -5.0279,  -5.3705,  -5.2922,  ...,  -5.4280,  -3.8950,  -3.3707],\n",
      "         [-12.4879, -12.0906, -12.1922,  ..., -10.3924, -11.2372,  -8.6127],\n",
      "         ...,\n",
      "         [-11.8924, -11.9908, -12.0239,  ...,  -9.8705,  -8.1519, -11.2918],\n",
      "         [ -3.0001,  -2.6790,  -2.8549,  ...,  -2.4212,  -1.7799,  -3.7471],\n",
      "         [ -6.6690,  -6.6345,  -6.6502,  ...,  -5.3127,  -5.2072,  -3.9556]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.207420587539673\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1023, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3297,  -7.3350,  -7.3034,  ...,  -6.2802,  -6.4858,  -4.1943],\n",
      "         [ -8.8372,  -9.0652,  -8.8626,  ..., -10.1431,  -9.1188,  -7.7865],\n",
      "         [ -1.0148,  -1.2890,  -0.9212,  ...,  -3.1159,  -1.4150,  -0.2160],\n",
      "         ...,\n",
      "         [ -7.6326,  -7.8162,  -7.6451,  ...,  -7.9593,  -8.4684,  -5.3907],\n",
      "         [ -8.4188,  -8.5870,  -8.3033,  ...,  -9.4581,  -9.0197,  -6.2739],\n",
      "         [ -5.9990,  -6.1248,  -5.8909,  ...,  -6.1829,  -6.9550,  -3.5605]],\n",
      "\n",
      "        [[ -6.2982,  -6.4494,  -6.3944,  ...,  -5.7612,  -5.8376,  -3.7636],\n",
      "         [ -5.8631,  -5.9127,  -5.8493,  ...,  -6.5142,  -5.8427,  -8.3554],\n",
      "         [ -3.8286,  -3.7885,  -3.5507,  ...,  -5.1169,  -3.2223,  -6.2379],\n",
      "         ...,\n",
      "         [ -4.6972,  -4.9209,  -4.6306,  ...,  -4.7275,  -5.2275,  -3.0187],\n",
      "         [ -4.9947,  -5.1864,  -4.7810,  ...,  -5.3176,  -4.9553,  -3.6013],\n",
      "         [ -5.7980,  -5.9770,  -5.6570,  ...,  -5.9752,  -5.1712,  -4.3174]],\n",
      "\n",
      "        [[-10.2790, -10.3846, -10.0724,  ...,  -9.7806, -10.1830,  -6.5539],\n",
      "         [-11.3830, -11.3647, -11.5309,  ...,  -9.0951,  -9.2022,  -6.6699],\n",
      "         [ -5.0115,  -5.1727,  -5.2334,  ...,  -5.3808,  -6.9932,  -4.0523],\n",
      "         ...,\n",
      "         [ -5.0022,  -5.1125,  -5.1740,  ...,  -5.3509,  -6.6176,  -4.2329],\n",
      "         [ -4.2353,  -4.4052,  -4.4685,  ...,  -4.7827,  -5.7340,  -3.6715],\n",
      "         [ -5.0836,  -5.0212,  -5.1603,  ...,  -5.0751,  -6.4137,  -3.9900]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0965,  -7.2264,  -7.0700,  ...,  -6.9305,  -6.1476,  -5.2925],\n",
      "         [ -4.0562,  -4.6064,  -4.3734,  ...,  -5.0742,  -3.4843,  -3.4495],\n",
      "         [ -6.7945,  -7.0210,  -7.0724,  ...,  -7.6952,  -5.2695,  -6.4771],\n",
      "         ...,\n",
      "         [ -4.7298,  -4.9221,  -4.8676,  ...,  -3.8632,  -3.0953,  -6.8495],\n",
      "         [ -3.9711,  -4.0362,  -4.0036,  ...,  -3.4824,  -3.1392,  -4.1263],\n",
      "         [-13.1575, -12.8944, -13.0721,  ..., -12.3480, -11.3059, -10.2046]],\n",
      "\n",
      "        [[ -7.8130,  -8.0001,  -7.9031,  ...,  -7.6237,  -6.6813,  -4.7572],\n",
      "         [ -7.5189,  -7.2233,  -7.5393,  ...,  -9.4313,  -5.4509, -10.8205],\n",
      "         [-11.4755, -11.6056, -11.2469,  ...,  -8.6312,  -8.2503, -10.8363],\n",
      "         ...,\n",
      "         [ -8.4535,  -8.4693,  -7.9278,  ...,  -7.5366,  -6.2156,  -6.2144],\n",
      "         [ -3.3962,  -3.1228,  -2.5370,  ...,  -3.8494,  -3.7825,  -0.9621],\n",
      "         [-11.3006, -11.1490, -11.3895,  ...,  -9.4862,  -7.8007, -10.0421]],\n",
      "\n",
      "        [[ -9.8480,  -9.6193,  -9.5516,  ...,  -7.8355,  -7.8347,  -6.6905],\n",
      "         [-15.7866, -15.5745, -15.7067,  ..., -14.5802, -13.5354, -16.3530],\n",
      "         [ -4.0111,  -4.0503,  -4.1014,  ...,  -4.1623,  -5.8160,  -4.2377],\n",
      "         ...,\n",
      "         [ -4.1055,  -4.2076,  -4.1043,  ...,  -3.4676,  -4.7654,  -5.7023],\n",
      "         [ -3.8118,  -3.8479,  -3.7995,  ...,  -3.6391,  -4.8192,  -4.4087],\n",
      "         [ -4.9990,  -4.9689,  -5.0670,  ...,  -4.5578,  -5.5168,  -5.3164]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.102309465408325\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2791, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.6596,  -6.6306,  -6.6608,  ...,  -5.9867,  -5.8860,  -3.4938],\n",
      "         [ -4.9453,  -4.7271,  -4.5534,  ...,  -5.0453,  -5.9356,  -3.0629],\n",
      "         [ -7.7436,  -7.8140,  -7.9406,  ...,  -6.4658,  -6.1394,  -9.7970],\n",
      "         ...,\n",
      "         [ -4.5054,  -4.4448,  -4.3228,  ...,  -5.1181,  -5.6825,  -3.1492],\n",
      "         [ -4.3250,  -4.3501,  -4.1816,  ...,  -4.8084,  -5.4799,  -2.5970],\n",
      "         [ -5.1120,  -5.1929,  -5.0809,  ...,  -5.2716,  -5.6870,  -3.6300]],\n",
      "\n",
      "        [[ -6.2457,  -6.5931,  -6.0524,  ...,  -6.4248,  -7.1135,  -1.9325],\n",
      "         [-11.9349, -12.1106, -12.2216,  ..., -10.4200,  -8.9412,  -7.5204],\n",
      "         [ -4.8451,  -5.0707,  -4.9751,  ...,  -5.1797,  -6.1836,  -3.2423],\n",
      "         ...,\n",
      "         [ -5.2227,  -5.4426,  -5.2381,  ...,  -5.1298,  -6.2588,  -2.9192],\n",
      "         [ -4.9698,  -5.0774,  -4.9421,  ...,  -5.2667,  -5.7010,  -3.4913],\n",
      "         [ -4.8374,  -4.9700,  -4.8937,  ...,  -5.1845,  -6.3563,  -3.6640]],\n",
      "\n",
      "        [[ -7.8147,  -7.8631,  -7.8314,  ...,  -7.5095,  -7.1409,  -4.7060],\n",
      "         [-10.9356, -10.5855, -10.9498,  ...,  -9.0569,  -7.8648, -12.2581],\n",
      "         [ -4.2721,  -4.3859,  -4.4386,  ...,  -4.5497,  -5.0210,  -3.9929],\n",
      "         ...,\n",
      "         [ -3.6667,  -3.7924,  -3.8125,  ...,  -3.7892,  -4.7580,  -2.5545],\n",
      "         [ -3.7564,  -4.0616,  -4.0278,  ...,  -3.9242,  -4.6200,  -3.9757],\n",
      "         [ -4.3051,  -4.5353,  -4.4974,  ...,  -4.1428,  -4.7793,  -3.7269]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4393,  -7.4663,  -7.4355,  ...,  -7.0126,  -6.5365,  -4.9440],\n",
      "         [-10.3308, -10.3019, -10.1560,  ...,  -9.8826, -10.7868,  -6.3820],\n",
      "         [ -9.6847,  -9.5870,  -9.5342,  ...,  -8.8635,  -4.7919, -10.9212],\n",
      "         ...,\n",
      "         [ -6.8924,  -7.1709,  -7.0799,  ...,  -7.9116,  -6.1570,  -5.8228],\n",
      "         [ -6.4041,  -6.4877,  -6.3364,  ...,  -6.8586,  -6.1365,  -5.9701],\n",
      "         [ -4.8252,  -5.1003,  -4.8581,  ...,  -4.9091,  -4.3483,  -3.3595]],\n",
      "\n",
      "        [[ -6.5869,  -6.5519,  -6.5944,  ...,  -6.1173,  -5.8069,  -4.3759],\n",
      "         [ -8.8185,  -8.6970,  -8.9930,  ...,  -9.6462,  -6.3691,  -9.3714],\n",
      "         [ -7.9667,  -8.3404,  -8.3669,  ...,  -9.4391,  -6.5282,  -8.2329],\n",
      "         ...,\n",
      "         [ -5.4804,  -6.0857,  -5.5737,  ...,  -3.8731,  -5.9185,  -2.9115],\n",
      "         [ -7.5119,  -7.7988,  -7.7580,  ...,  -7.3872,  -7.1324,  -5.4537],\n",
      "         [ -5.4918,  -5.7559,  -5.6308,  ...,  -4.9223,  -5.1387,  -4.1332]],\n",
      "\n",
      "        [[ -7.7210,  -7.7966,  -7.7565,  ...,  -7.6022,  -6.9898,  -5.0099],\n",
      "         [ -7.6682,  -7.5301,  -7.2918,  ...,  -8.3466,  -8.4304,  -6.2850],\n",
      "         [ -5.8254,  -5.7106,  -5.7869,  ...,  -6.0734,  -6.0196,  -6.4898],\n",
      "         ...,\n",
      "         [ -0.0905,  -0.3689,  -0.8445,  ...,  -0.0258,  -2.0445,   0.8253],\n",
      "         [-13.3329, -13.7357, -13.2049,  ..., -11.5966,  -9.9482, -10.2047],\n",
      "         [-10.5362, -10.5585, -10.5620,  ...,  -8.3885,  -7.3267,  -8.0782]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.2791105508804321\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.3915, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.7948,  -6.7910,  -6.7997,  ...,  -6.2533,  -6.2832,  -4.3239],\n",
      "         [ -6.2367,  -6.3896,  -6.4912,  ...,  -6.6739,  -7.8089,  -1.2679],\n",
      "         [ -5.7831,  -5.9734,  -5.8079,  ...,  -6.0598,  -6.1574,  -0.6899],\n",
      "         ...,\n",
      "         [ -3.9665,  -4.0762,  -3.9792,  ...,  -4.7387,  -4.8395,  -1.0320],\n",
      "         [ -3.4567,  -3.5506,  -3.5308,  ...,  -4.3013,  -4.5002,  -0.7246],\n",
      "         [ -3.3929,  -3.4566,  -3.5611,  ...,  -3.6478,  -4.5879,  -0.6459]],\n",
      "\n",
      "        [[ -6.8205,  -6.7506,  -6.7944,  ...,  -5.8797,  -5.8913,  -4.0888],\n",
      "         [-10.9162, -11.0934, -10.9232,  ...,  -9.9456,  -9.2992,  -8.8960],\n",
      "         [ -4.1669,  -4.3513,  -4.2504,  ...,  -4.4089,  -6.2116,  -3.6671],\n",
      "         ...,\n",
      "         [ -4.1244,  -4.2127,  -4.1582,  ...,  -4.9042,  -5.8673,  -3.2718],\n",
      "         [ -4.0267,  -4.0707,  -3.9889,  ...,  -4.1765,  -6.1478,  -3.5889],\n",
      "         [ -4.3881,  -4.4684,  -4.4001,  ...,  -4.8955,  -5.6942,  -3.9939]],\n",
      "\n",
      "        [[ -7.1332,  -6.6644,  -6.8791,  ...,  -7.5908,  -6.7822,  -4.2144],\n",
      "         [-12.4306, -12.6911, -12.3327,  ...,  -9.8138,  -9.8483,  -9.6455],\n",
      "         [ -4.0828,  -4.1107,  -4.1148,  ...,  -4.3393,  -5.7173,  -2.4868],\n",
      "         ...,\n",
      "         [ -4.6188,  -4.6456,  -4.6614,  ...,  -4.9494,  -6.3287,  -3.2880],\n",
      "         [ -4.1881,  -4.3119,  -4.2364,  ...,  -4.0848,  -5.5959,  -2.2293],\n",
      "         [ -4.7501,  -4.7243,  -4.7459,  ...,  -4.4653,  -6.0428,  -3.1164]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9192,  -6.8840,  -6.8639,  ...,  -6.3374,  -6.0036,  -4.1365],\n",
      "         [ -4.7396,  -5.1109,  -4.9367,  ...,  -4.3194,  -3.2010,  -3.3997],\n",
      "         [ -0.9417,  -1.1268,  -1.2742,  ...,  -1.2298,  -1.8417,  -0.7566],\n",
      "         ...,\n",
      "         [ -6.7712,  -6.6699,  -6.5958,  ...,  -5.0742,  -4.4001,  -5.7661],\n",
      "         [ -4.7383,  -4.5777,  -5.0678,  ...,  -4.2214,  -3.0358,  -5.3009],\n",
      "         [-11.1055, -11.0551, -11.0465,  ...,  -9.2743,  -7.9746,  -9.2336]],\n",
      "\n",
      "        [[ -7.3418,  -7.3220,  -7.2804,  ...,  -6.8427,  -6.5480,  -4.7402],\n",
      "         [-12.0281, -12.2628, -11.9282,  ..., -12.5818,  -9.9746, -10.4666],\n",
      "         [ -9.7138,  -9.5311,  -9.4928,  ...,  -9.0321,  -8.3752,  -9.9425],\n",
      "         ...,\n",
      "         [ -5.8788,  -6.0539,  -5.8041,  ...,  -6.0406,  -4.5255,  -5.9301],\n",
      "         [ -8.3554,  -8.6520,  -8.1053,  ...,  -8.0959,  -6.5843,  -5.8115],\n",
      "         [-11.3204, -11.1984, -11.3031,  ...,  -8.7185,  -8.1988,  -8.2186]],\n",
      "\n",
      "        [[ -7.6466,  -7.6218,  -7.6300,  ...,  -7.1668,  -6.7610,  -5.1041],\n",
      "         [-11.7881, -11.7810, -12.0595,  ..., -11.6391,  -9.6263, -11.4705],\n",
      "         [ -4.3719,  -4.1344,  -3.9777,  ...,  -5.5048,  -4.6248,  -3.1722],\n",
      "         ...,\n",
      "         [ -4.4143,  -4.8345,  -4.3384,  ...,  -3.2368,  -4.4372,  -6.6486],\n",
      "         [ -4.4656,  -4.5297,  -4.2573,  ...,  -3.7971,  -5.1851,  -5.9728],\n",
      "         [-10.1435, -10.5504, -10.0756,  ..., -12.2233,  -8.6446,  -6.9267]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.3915444612503052\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9920, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.5908,  -7.7560,  -7.7686,  ...,  -7.1848,  -7.5125,  -6.6549],\n",
      "         [-12.0008, -12.0914, -12.2773,  ..., -10.4999,  -9.9423,  -7.7295],\n",
      "         [ -4.6583,  -4.7621,  -4.7017,  ...,  -5.2471,  -5.8334,  -3.9876],\n",
      "         ...,\n",
      "         [ -4.4060,  -4.4680,  -4.4937,  ...,  -4.4162,  -5.4789,  -2.7974],\n",
      "         [ -4.2917,  -4.2953,  -4.4031,  ...,  -4.3876,  -5.1846,  -4.0305],\n",
      "         [ -4.7582,  -4.8313,  -4.8299,  ...,  -4.5664,  -5.3753,  -4.6436]],\n",
      "\n",
      "        [[ -6.2862,  -6.2544,  -6.2476,  ...,  -5.6493,  -5.3716,  -3.8513],\n",
      "         [-10.7662, -10.9906, -10.9054,  ...,  -8.8568,  -6.4681,  -8.1709],\n",
      "         [ -4.5017,  -4.6210,  -4.6373,  ...,  -4.9678,  -5.8087,  -2.9434],\n",
      "         ...,\n",
      "         [ -3.8783,  -3.9863,  -3.9536,  ...,  -3.6659,  -4.8898,  -2.8830],\n",
      "         [ -4.8513,  -5.0496,  -4.9698,  ...,  -4.8685,  -5.3299,  -3.0189],\n",
      "         [ -5.2696,  -5.3667,  -5.3836,  ...,  -5.0703,  -5.7390,  -3.6076]],\n",
      "\n",
      "        [[ -7.8578,  -7.8772,  -7.7569,  ...,  -6.9973,  -6.9333,  -5.3250],\n",
      "         [-12.6112, -12.9665, -13.0257,  ..., -10.9219, -10.4819, -11.9047],\n",
      "         [ -8.0307,  -8.2852,  -8.1933,  ...,  -6.1241,  -6.7874, -10.0324],\n",
      "         ...,\n",
      "         [ -7.9949,  -8.5642,  -8.3674,  ...,  -6.1956,  -7.5959,  -6.6006],\n",
      "         [ -9.1371,  -9.6196,  -9.2833,  ...,  -8.6595,  -6.7513, -11.8898],\n",
      "         [-10.4359, -11.2166, -10.3226,  ..., -10.4014,  -9.3809, -10.6349]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3648,  -6.4005,  -6.3389,  ...,  -5.7333,  -5.5668,  -4.5011],\n",
      "         [-11.7487, -12.3989, -12.1326,  ..., -10.3807,  -8.9415, -12.5037],\n",
      "         [ -3.2194,  -3.1670,  -3.4046,  ...,  -3.7871,  -3.0021,  -5.2894],\n",
      "         ...,\n",
      "         [ -4.5083,  -4.6111,  -4.4162,  ...,  -3.6198,  -5.0080,  -5.8227],\n",
      "         [ -5.1963,  -5.3159,  -5.0870,  ...,  -4.1693,  -5.3012,  -7.2539],\n",
      "         [ -4.3810,  -4.6032,  -4.3798,  ...,  -2.7866,  -4.8265,  -6.5567]],\n",
      "\n",
      "        [[ -6.6763,  -6.6533,  -6.6483,  ...,  -6.2096,  -6.0530,  -3.6884],\n",
      "         [ -4.8862,  -4.5868,  -4.9084,  ...,  -5.3726,  -5.2459,  -4.1636],\n",
      "         [ -6.3508,  -6.1272,  -5.8298,  ...,  -8.2322,  -7.9171,  -6.6264],\n",
      "         ...,\n",
      "         [ -5.4605,  -5.8262,  -5.6680,  ...,  -6.0973,  -5.1776,  -5.9750],\n",
      "         [ -7.9878,  -8.2990,  -7.4200,  ...,  -7.2605,  -6.0864,  -5.9045],\n",
      "         [-10.9071, -11.0632, -11.1842,  ..., -11.8715,  -8.2561,  -7.1927]],\n",
      "\n",
      "        [[ -7.2802,  -7.2871,  -7.1950,  ...,  -6.8331,  -6.3644,  -4.8929],\n",
      "         [-10.4558, -10.2306, -10.1071,  ..., -10.1423,  -9.6496, -10.1686],\n",
      "         [ -7.9114,  -7.8543,  -7.6210,  ...,  -8.7197,  -8.4947,  -8.6891],\n",
      "         ...,\n",
      "         [-14.2121, -14.3192, -14.3069,  ..., -12.5448, -10.4685, -12.6513],\n",
      "         [ -8.1107,  -7.9634,  -8.3335,  ...,  -7.4032,  -7.3112,  -7.1469],\n",
      "         [-10.6803, -10.7028, -10.7370,  ...,  -8.6801,  -8.8991,  -9.6301]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.9920001029968262\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5385, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.2537,  -6.2485,  -6.2725,  ...,  -5.6544,  -5.6126,  -3.4828],\n",
      "         [ -5.6645,  -5.5847,  -5.8259,  ...,  -6.4754,  -6.8320,  -1.8012],\n",
      "         [ -5.1357,  -5.1400,  -5.2356,  ...,  -5.6805,  -6.0167,  -1.4377],\n",
      "         ...,\n",
      "         [ -3.9891,  -4.0758,  -4.1742,  ...,  -4.5795,  -5.0218,  -1.1366],\n",
      "         [ -3.9188,  -3.9995,  -3.9898,  ...,  -4.6017,  -4.8848,  -1.6255],\n",
      "         [ -4.0678,  -4.0592,  -4.0406,  ...,  -4.5199,  -4.9445,  -0.9831]],\n",
      "\n",
      "        [[ -6.6814,  -6.6627,  -6.6948,  ...,  -5.9389,  -6.2500,  -4.3588],\n",
      "         [-11.4286, -11.3998, -11.3251,  ...,  -9.1332,  -7.4203,  -9.3897],\n",
      "         [ -3.5674,  -3.8071,  -3.6714,  ...,  -3.9117,  -5.5775,  -2.4006],\n",
      "         ...,\n",
      "         [ -3.3407,  -3.5902,  -3.4710,  ...,  -3.7856,  -5.0940,  -2.9851],\n",
      "         [ -3.6819,  -3.8159,  -3.7764,  ...,  -4.0286,  -4.9279,  -3.2176],\n",
      "         [ -3.5110,  -3.6167,  -3.5189,  ...,  -3.5008,  -5.2241,  -3.2502]],\n",
      "\n",
      "        [[ -6.3388,  -6.3153,  -6.3240,  ...,  -5.6407,  -5.5877,  -3.4948],\n",
      "         [ -5.5173,  -5.3857,  -5.5337,  ...,  -6.0676,  -6.3409,  -1.7752],\n",
      "         [ -5.4859,  -5.3002,  -5.3995,  ...,  -6.3136,  -5.6235,  -2.3331],\n",
      "         ...,\n",
      "         [ -3.5936,  -3.6117,  -3.7936,  ...,  -3.5275,  -4.6104,  -3.4851],\n",
      "         [ -3.9704,  -4.0380,  -4.1173,  ...,  -4.0117,  -4.3133,  -2.8295],\n",
      "         [ -2.5308,  -2.4427,  -2.5211,  ...,  -1.9611,  -2.8279,  -5.1311]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3216,  -6.2706,  -6.2273,  ...,  -5.8081,  -5.5883,  -3.7793],\n",
      "         [-11.0262, -11.0520, -10.8445,  ..., -11.6260, -11.3811,  -7.0548],\n",
      "         [ -5.0992,  -5.2445,  -5.2109,  ...,  -6.2363,  -5.4274,  -3.7962],\n",
      "         ...,\n",
      "         [ -6.7856,  -6.8380,  -6.4779,  ...,  -7.6427,  -6.7406,  -4.2538],\n",
      "         [ -4.2350,  -3.8640,  -3.8227,  ...,  -4.0398,  -3.6231,  -0.6022],\n",
      "         [ -6.1971,  -6.1631,  -5.9747,  ...,  -7.2859,  -6.2581,  -3.3426]],\n",
      "\n",
      "        [[ -7.4832,  -7.4709,  -7.4151,  ...,  -6.7363,  -6.9173,  -4.0201],\n",
      "         [ -5.9468,  -5.6878,  -5.7203,  ...,  -6.2514,  -7.5804,  -0.4735],\n",
      "         [ -5.0124,  -4.7307,  -4.7052,  ...,  -5.4925,  -6.5789,  -0.9520],\n",
      "         ...,\n",
      "         [ -2.8713,  -2.9674,  -2.9526,  ...,  -3.2302,  -4.0877,   0.6720],\n",
      "         [ -3.7121,  -3.6910,  -3.7240,  ...,  -4.0545,  -4.6378,  -0.1165],\n",
      "         [ -3.6528,  -3.7358,  -3.7036,  ...,  -3.7420,  -4.3562,  -0.2829]],\n",
      "\n",
      "        [[ -6.6914,  -6.6896,  -6.7381,  ...,  -6.1727,  -6.2986,  -3.8096],\n",
      "         [ -4.6832,  -4.5520,  -4.7549,  ...,  -4.9756,  -5.8272,   0.3325],\n",
      "         [ -5.2861,  -5.3387,  -5.6106,  ...,  -5.3853,  -7.2585,  -0.4799],\n",
      "         ...,\n",
      "         [ -2.8584,  -2.9115,  -2.9246,  ...,  -3.3206,  -3.8536,  -0.3111],\n",
      "         [ -3.6242,  -3.7321,  -3.7353,  ...,  -4.2707,  -4.1336,  -1.0234],\n",
      "         [ -3.3403,  -3.4474,  -3.4506,  ...,  -4.2259,  -4.2046,  -0.9215]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5385286808013916\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5122, grad_fn=<NllLossBackward0>), logits=tensor([[[-6.9422e+00, -7.0172e+00, -6.9453e+00,  ..., -6.5103e+00,\n",
      "          -6.1319e+00, -4.4914e+00],\n",
      "         [-1.2017e+00, -1.3383e+00, -1.2043e+00,  ..., -1.0265e+00,\n",
      "          -1.6583e+00, -2.9800e+00],\n",
      "         [-7.0613e+00, -7.4442e+00, -7.3470e+00,  ..., -8.4722e+00,\n",
      "          -6.4882e+00, -6.5025e+00],\n",
      "         ...,\n",
      "         [-8.5141e+00, -8.4561e+00, -8.2115e+00,  ..., -7.5111e+00,\n",
      "          -5.6050e+00, -9.6652e+00],\n",
      "         [-2.7798e+00, -2.9164e+00, -2.7721e+00,  ..., -4.0942e+00,\n",
      "          -1.8758e+00, -5.8363e+00],\n",
      "         [-1.2842e+01, -1.3209e+01, -1.2992e+01,  ..., -1.3931e+01,\n",
      "          -1.1422e+01, -1.2340e+01]],\n",
      "\n",
      "        [[-7.4846e+00, -7.4334e+00, -7.3314e+00,  ..., -7.0054e+00,\n",
      "          -6.6029e+00, -4.9312e+00],\n",
      "         [-1.0604e+01, -1.0464e+01, -1.0426e+01,  ..., -1.0181e+01,\n",
      "          -7.3171e+00, -9.1901e+00],\n",
      "         [-7.5454e+00, -6.8198e+00, -7.1600e+00,  ..., -7.0856e+00,\n",
      "          -6.0086e+00, -7.5659e+00],\n",
      "         ...,\n",
      "         [-9.9960e+00, -9.6799e+00, -9.3921e+00,  ..., -7.6317e+00,\n",
      "          -7.1086e+00, -1.1314e+01],\n",
      "         [-5.2106e+00, -4.8300e+00, -5.1995e+00,  ..., -4.2622e+00,\n",
      "          -3.0577e+00, -4.0669e+00],\n",
      "         [-1.1577e+01, -1.1712e+01, -1.1878e+01,  ..., -1.0003e+01,\n",
      "          -9.4063e+00, -8.9940e+00]],\n",
      "\n",
      "        [[-7.5625e+00, -7.5121e+00, -7.5186e+00,  ..., -6.5039e+00,\n",
      "          -6.6541e+00, -4.6130e+00],\n",
      "         [-1.3485e+01, -1.3612e+01, -1.3366e+01,  ..., -1.1173e+01,\n",
      "          -1.0967e+01, -1.1186e+01],\n",
      "         [-4.1036e+00, -4.1881e+00, -4.1112e+00,  ..., -4.3598e+00,\n",
      "          -5.9900e+00, -3.3947e+00],\n",
      "         ...,\n",
      "         [-3.6418e+00, -3.7580e+00, -3.7192e+00,  ..., -3.9753e+00,\n",
      "          -4.7245e+00, -4.4179e+00],\n",
      "         [-3.6981e+00, -4.0337e+00, -3.8341e+00,  ..., -3.5687e+00,\n",
      "          -4.8206e+00, -3.9751e+00],\n",
      "         [-4.0034e+00, -4.0521e+00, -3.9835e+00,  ..., -3.6300e+00,\n",
      "          -5.1504e+00, -3.9182e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.6701e+00, -7.5869e+00, -7.5822e+00,  ..., -6.9499e+00,\n",
      "          -6.6870e+00, -4.7527e+00],\n",
      "         [-4.2845e+00, -4.2984e+00, -3.8229e+00,  ..., -4.7389e+00,\n",
      "          -4.3878e+00, -2.5081e+00],\n",
      "         [-1.3320e+01, -1.3563e+01, -1.3192e+01,  ..., -1.0433e+01,\n",
      "          -1.1167e+01, -1.0180e+01],\n",
      "         ...,\n",
      "         [-2.3286e+00, -2.5326e+00, -2.2103e+00,  ..., -3.3432e+00,\n",
      "          -3.8307e+00, -2.4093e-01],\n",
      "         [-5.3438e+00, -5.2795e+00, -5.2102e+00,  ..., -6.2364e+00,\n",
      "          -6.3610e+00, -3.3751e+00],\n",
      "         [-4.8372e+00, -4.8399e+00, -4.7612e+00,  ..., -5.2117e+00,\n",
      "          -5.9016e+00, -3.0020e+00]],\n",
      "\n",
      "        [[-8.6192e+00, -8.4474e+00, -8.5943e+00,  ..., -7.5421e+00,\n",
      "          -8.9993e+00, -9.1413e+00],\n",
      "         [-1.3450e+01, -1.3345e+01, -1.3354e+01,  ..., -1.0623e+01,\n",
      "          -9.6188e+00, -1.2694e+01],\n",
      "         [-3.9361e+00, -4.0402e+00, -4.0022e+00,  ..., -4.5317e+00,\n",
      "          -4.8740e+00, -3.2166e+00],\n",
      "         ...,\n",
      "         [-4.2039e+00, -4.3022e+00, -4.2922e+00,  ..., -4.0190e+00,\n",
      "          -5.0173e+00, -3.1405e+00],\n",
      "         [-4.5111e+00, -4.5582e+00, -4.6196e+00,  ..., -4.5040e+00,\n",
      "          -5.6001e+00, -3.8388e+00],\n",
      "         [-4.2124e+00, -4.2933e+00, -4.3227e+00,  ..., -4.5744e+00,\n",
      "          -5.3648e+00, -2.8318e+00]],\n",
      "\n",
      "        [[-7.5800e+00, -7.8066e+00, -7.6952e+00,  ..., -7.3196e+00,\n",
      "          -6.3765e+00, -5.9312e+00],\n",
      "         [-1.4451e+01, -1.4683e+01, -1.4702e+01,  ..., -1.2340e+01,\n",
      "          -1.1102e+01, -1.3640e+01],\n",
      "         [-5.1616e+00, -6.1122e+00, -5.9883e+00,  ..., -6.3377e+00,\n",
      "          -5.9189e+00, -8.7488e+00],\n",
      "         ...,\n",
      "         [-1.0224e+00, -1.4580e+00, -9.1602e-01,  ..., -8.5704e-03,\n",
      "           3.1368e-01, -4.1379e+00],\n",
      "         [-2.7734e+00, -3.3900e+00, -2.6734e+00,  ..., -2.7813e+00,\n",
      "          -2.0456e+00, -3.5058e+00],\n",
      "         [-3.7995e+00, -4.2691e+00, -3.9220e+00,  ..., -3.6635e+00,\n",
      "          -3.0198e+00, -3.3833e+00]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5121995210647583\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8773, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8717,  -7.8940,  -7.8717,  ...,  -7.3162,  -6.6658,  -5.4992],\n",
      "         [-13.7877, -13.8669, -13.9836,  ..., -13.1025, -11.2530, -11.1519],\n",
      "         [ -2.6277,  -2.5168,  -2.6264,  ...,  -1.8974,  -2.3584,  -4.5224],\n",
      "         ...,\n",
      "         [-13.3223, -13.2766, -13.3082,  ..., -11.4393, -10.2263,  -9.3448],\n",
      "         [-10.9686, -11.2622, -11.1688,  ..., -12.2274, -10.1231,  -6.4080],\n",
      "         [-12.1678, -12.2946, -12.1889,  ..., -11.9057,  -7.9790,  -8.6954]],\n",
      "\n",
      "        [[ -6.4056,  -6.3685,  -6.3641,  ...,  -5.8224,  -5.8745,  -3.4072],\n",
      "         [ -3.9927,  -3.8650,  -4.0206,  ...,  -4.8138,  -5.6738,   0.9626],\n",
      "         [ -5.0241,  -5.0345,  -4.9918,  ...,  -5.4040,  -6.1602,  -0.6235],\n",
      "         ...,\n",
      "         [ -4.0049,  -4.1005,  -4.0666,  ...,  -4.3712,  -4.8280,  -1.2987],\n",
      "         [ -3.6015,  -3.6381,  -3.7174,  ...,  -4.8187,  -4.9662,  -1.7010],\n",
      "         [ -3.0314,  -3.0568,  -3.0791,  ...,  -3.6867,  -3.6924,  -1.4533]],\n",
      "\n",
      "        [[ -7.1588,  -6.9749,  -7.0304,  ...,  -6.7647,  -6.5024,  -4.4867],\n",
      "         [ -7.8354,  -7.3531,  -7.6385,  ...,  -7.4734,  -5.7631,  -7.1306],\n",
      "         [ -5.7149,  -5.2709,  -5.6201,  ...,  -5.8813,  -4.5407,  -7.2986],\n",
      "         ...,\n",
      "         [ -4.5515,  -4.5636,  -4.5930,  ...,  -5.3635,  -4.3429,  -7.6582],\n",
      "         [ -5.3880,  -5.3975,  -5.4557,  ...,  -6.4337,  -5.0739,  -6.5181],\n",
      "         [ -6.8066,  -6.8210,  -6.8771,  ...,  -6.9297,  -6.4495,  -6.7483]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.8509,  -6.8368,  -6.7590,  ...,  -5.9511,  -6.4089,  -4.6454],\n",
      "         [ -6.4850,  -6.1171,  -6.4599,  ...,  -8.1522,  -7.0103, -10.0713],\n",
      "         [ -0.9535,  -0.9680,  -1.1227,  ...,  -2.5624,  -3.7666,  -5.4074],\n",
      "         ...,\n",
      "         [ -2.9594,  -3.0729,  -2.8470,  ...,  -3.5233,  -3.0053,  -5.6730],\n",
      "         [ -4.3682,  -4.2813,  -4.2344,  ...,  -4.0284,  -4.3660,  -6.3005],\n",
      "         [ -4.2859,  -3.9235,  -3.9470,  ...,  -3.9148,  -3.1709,  -7.6210]],\n",
      "\n",
      "        [[ -6.6443,  -6.5863,  -6.6010,  ...,  -5.9672,  -5.9798,  -3.7486],\n",
      "         [ -6.1827,  -6.0553,  -6.1027,  ...,  -6.7461,  -6.6778,  -2.0118],\n",
      "         [ -6.4937,  -6.3525,  -6.5619,  ...,  -6.3716,  -6.6807,  -2.4207],\n",
      "         ...,\n",
      "         [ -3.9015,  -4.0583,  -4.0042,  ...,  -4.2240,  -4.6518,  -1.9016],\n",
      "         [ -4.5008,  -4.5271,  -4.4943,  ...,  -4.7990,  -5.0282,  -1.3894],\n",
      "         [ -4.4764,  -4.5526,  -4.5184,  ...,  -5.3755,  -4.8967,  -2.7352]],\n",
      "\n",
      "        [[ -7.2963,  -7.3673,  -7.2784,  ...,  -6.8744,  -6.4532,  -4.8468],\n",
      "         [ -3.8444,  -3.9440,  -4.1245,  ...,  -4.2032,  -2.4615,  -6.0573],\n",
      "         [ -7.8033,  -7.9774,  -8.3894,  ...,  -7.8264,  -6.6161,  -7.8099],\n",
      "         ...,\n",
      "         [ -4.7243,  -4.8450,  -4.8514,  ...,  -5.0932,  -4.6012,  -3.8128],\n",
      "         [ -6.6816,  -6.9154,  -6.8527,  ...,  -6.5759,  -6.4044,  -5.8097],\n",
      "         [-11.5194, -11.8727, -11.5671,  ..., -11.4263,  -9.7366,  -9.5349]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.877340316772461\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.1003, grad_fn=<NllLossBackward0>), logits=tensor([[[ -8.7147,  -8.5566,  -8.5272,  ...,  -7.7862,  -7.6252,  -5.3245],\n",
      "         [ -9.7591,  -9.8689,  -9.7205,  ...,  -8.1471,  -7.3099, -12.0192],\n",
      "         [ -3.5531,  -3.6887,  -3.7824,  ...,  -4.1530,  -5.5441,  -2.0538],\n",
      "         ...,\n",
      "         [ -4.6483,  -4.8094,  -4.8181,  ...,  -5.1973,  -5.6100,  -3.8261],\n",
      "         [ -5.0827,  -5.1357,  -5.0663,  ...,  -5.6167,  -5.5665,  -3.7898],\n",
      "         [ -3.7912,  -3.9825,  -3.8708,  ...,  -4.2754,  -4.7234,  -2.6883]],\n",
      "\n",
      "        [[ -7.9207,  -7.9623,  -7.9569,  ...,  -7.2778,  -7.0738,  -4.6678],\n",
      "         [ -7.8827,  -8.0060,  -8.0385,  ...,  -9.0909,  -6.3686, -10.4676],\n",
      "         [ -5.3546,  -5.3018,  -5.4068,  ...,  -5.3650,  -5.4778,  -4.2469],\n",
      "         ...,\n",
      "         [ -7.1407,  -7.4770,  -7.4860,  ...,  -6.3548,  -7.3733,  -5.0216],\n",
      "         [ -8.0572,  -7.6848,  -8.0228,  ...,  -7.4926,  -6.2816,  -6.7940],\n",
      "         [-14.8838, -14.9202, -14.9920,  ..., -14.7049, -11.4933, -10.9005]],\n",
      "\n",
      "        [[ -7.4176,  -7.3569,  -7.3226,  ...,  -6.6078,  -6.3835,  -4.6584],\n",
      "         [-10.8269, -10.8137, -10.7451,  ..., -10.3741,  -8.6988,  -5.0945],\n",
      "         [ -3.8577,  -4.2476,  -3.7798,  ...,  -4.4165,  -3.5956,  -2.8151],\n",
      "         ...,\n",
      "         [ -6.9182,  -7.1868,  -7.0571,  ...,  -6.7146,  -6.2886,  -3.6541],\n",
      "         [ -5.7029,  -5.8498,  -5.7896,  ...,  -5.3563,  -5.4830,  -4.0157],\n",
      "         [ -6.3860,  -6.5980,  -6.4914,  ...,  -6.1408,  -5.8865,  -3.9006]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.2513,  -6.1920,  -6.2099,  ...,  -5.5506,  -5.3404,  -3.5831],\n",
      "         [ -4.3487,  -4.1069,  -4.4164,  ...,  -5.0209,  -5.0276,  -2.3007],\n",
      "         [ -5.2296,  -5.1881,  -5.3524,  ...,  -5.3690,  -5.9849,  -2.6352],\n",
      "         ...,\n",
      "         [ -4.6864,  -4.9809,  -4.8692,  ...,  -5.1297,  -5.3207,  -2.2420],\n",
      "         [ -4.0267,  -4.2104,  -4.2941,  ...,  -4.5750,  -4.6287,  -2.2659],\n",
      "         [ -3.7732,  -4.0942,  -4.0079,  ...,  -3.9153,  -4.6221,  -2.2019]],\n",
      "\n",
      "        [[ -3.3311,  -3.4033,  -3.4117,  ...,  -3.7073,  -4.4679,  -2.5751],\n",
      "         [-13.2742, -12.5798, -13.1464,  ..., -10.6091, -10.5195, -10.1567],\n",
      "         [ -5.3059,  -5.3955,  -5.4355,  ...,  -5.6829,  -6.8498,  -2.4723],\n",
      "         ...,\n",
      "         [ -5.0021,  -5.2337,  -5.1671,  ...,  -5.6263,  -6.0124,  -3.4908],\n",
      "         [ -5.2115,  -5.3817,  -5.3145,  ...,  -5.8119,  -6.4859,  -3.3259],\n",
      "         [ -5.1842,  -5.3266,  -5.2708,  ...,  -5.3520,  -5.8692,  -3.4963]],\n",
      "\n",
      "        [[ -9.3956,  -9.2795,  -9.1589,  ...,  -7.5103,  -8.7841,  -2.0051],\n",
      "         [-13.8441, -13.5314, -13.5644,  ..., -12.4117, -13.1388,  -4.9101],\n",
      "         [ -6.9228,  -6.9384,  -6.9023,  ...,  -5.9854,  -5.9794,  -3.8108],\n",
      "         ...,\n",
      "         [ -4.3183,  -4.4000,  -4.5547,  ...,  -3.3301,  -4.5031,  -1.7069],\n",
      "         [ -5.7971,  -5.8175,  -5.9918,  ...,  -4.7556,  -5.5023,  -3.1700],\n",
      "         [ -7.7343,  -7.7100,  -7.8141,  ...,  -6.9482,  -6.9275,  -5.6723]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.1002941131591797\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4625, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8133,  -7.7368,  -7.6754,  ...,  -6.5139,  -7.0604,  -5.2443],\n",
      "         [-13.5771, -13.6347, -13.4699,  ..., -10.8253,  -9.6302, -12.1647],\n",
      "         [ -4.8532,  -4.9711,  -4.9527,  ...,  -4.7809,  -5.5975,  -4.2223],\n",
      "         ...,\n",
      "         [ -4.3751,  -4.3926,  -4.4134,  ...,  -4.1859,  -5.4433,  -4.3799],\n",
      "         [ -4.9473,  -4.9984,  -4.9546,  ...,  -4.6755,  -5.1705,  -4.3557],\n",
      "         [ -4.6176,  -4.7339,  -4.6294,  ...,  -4.6611,  -5.3259,  -3.2123]],\n",
      "\n",
      "        [[ -6.6254,  -6.5987,  -6.6482,  ...,  -5.8531,  -5.8797,  -3.9785],\n",
      "         [ -4.6566,  -4.6597,  -4.6451,  ...,  -5.0473,  -6.1718,  -1.4289],\n",
      "         [ -6.2275,  -6.0887,  -6.2896,  ...,  -6.7549,  -7.4540,  -1.9387],\n",
      "         ...,\n",
      "         [ -3.9478,  -4.2491,  -4.0975,  ...,  -4.7192,  -5.0450,  -2.2191],\n",
      "         [ -3.9078,  -4.0890,  -3.9555,  ...,  -4.6348,  -4.6136,  -1.9687],\n",
      "         [ -3.4828,  -3.8028,  -3.7603,  ...,  -4.4691,  -5.0239,  -1.8214]],\n",
      "\n",
      "        [[ -6.9458,  -6.9300,  -6.9222,  ...,  -6.2684,  -6.0741,  -4.1888],\n",
      "         [-12.8788, -12.7918, -13.0135,  ..., -11.1752, -11.2308, -11.2396],\n",
      "         [-14.8541, -14.7705, -14.6374,  ..., -11.7923, -10.5489, -11.6309],\n",
      "         ...,\n",
      "         [ -6.4182,  -6.5125,  -6.5616,  ...,  -6.3213,  -6.9795,  -5.5593],\n",
      "         [ -7.0935,  -7.2023,  -7.2052,  ...,  -7.1132,  -7.0891,  -4.5399],\n",
      "         [ -6.5669,  -6.5753,  -6.6945,  ...,  -6.2983,  -7.1799,  -5.1389]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1523,  -7.1162,  -7.1291,  ...,  -6.4909,  -6.4277,  -4.5305],\n",
      "         [-11.7803, -11.7915, -11.8752,  ..., -11.1625, -10.8239,  -9.1679],\n",
      "         [ -7.9384,  -7.4710,  -7.2272,  ...,  -6.9346,  -7.0531, -10.6587],\n",
      "         ...,\n",
      "         [ -3.2393,  -3.5624,  -3.2448,  ...,  -3.4645,  -5.0893,  -2.6649],\n",
      "         [ -1.4405,  -1.7074,  -1.2825,  ...,  -1.3567,  -2.4953,  -0.5214],\n",
      "         [ -1.9266,  -2.6117,  -2.1871,  ...,  -3.3468,  -4.4134,  -2.1671]],\n",
      "\n",
      "        [[ -7.2732,  -7.1876,  -7.1273,  ...,  -7.3646,  -6.3407,  -3.7257],\n",
      "         [-10.5797, -10.7420, -10.7259,  ..., -10.2047,  -7.7091, -10.8202],\n",
      "         [ -7.4054,  -7.0443,  -7.3349,  ...,  -7.2756,  -5.8299,  -4.3242],\n",
      "         ...,\n",
      "         [ -8.9318,  -9.0521,  -8.7898,  ...,  -7.6581,  -6.2300,  -7.1189],\n",
      "         [ -4.3741,  -4.5066,  -4.5358,  ...,  -5.0431,  -4.8984,  -1.4934],\n",
      "         [ -9.8049, -10.0986,  -9.5766,  ..., -11.0049,  -6.9593,  -8.4032]],\n",
      "\n",
      "        [[ -6.6160,  -6.6478,  -6.5758,  ...,  -5.9912,  -5.6422,  -4.3432],\n",
      "         [ -6.4115,  -6.2285,  -6.2951,  ...,  -6.6199,  -6.8001,  -7.3635],\n",
      "         [ -5.6485,  -5.4833,  -5.5109,  ...,  -5.0409,  -5.0583,  -5.8350],\n",
      "         ...,\n",
      "         [ -4.9022,  -4.9075,  -4.7748,  ...,  -3.9926,  -4.3013,  -5.5318],\n",
      "         [ -4.6170,  -4.3758,  -4.2765,  ...,  -5.0709,  -4.3438,  -8.0731],\n",
      "         [ -4.3724,  -4.2137,  -4.1679,  ...,  -4.6367,  -4.5505,  -5.7761]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.4625144004821777\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.6296, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4053,  -6.3818,  -6.3981,  ...,  -5.7905,  -5.6278,  -3.7452],\n",
      "         [ -7.0108,  -6.8512,  -7.0376,  ...,  -7.6323,  -8.0105,  -3.4381],\n",
      "         [ -6.2222,  -6.3424,  -6.3395,  ...,  -7.3601,  -7.3070,  -1.8607],\n",
      "         ...,\n",
      "         [ -4.9442,  -4.8809,  -5.0320,  ...,  -4.9562,  -5.7347,  -2.4158],\n",
      "         [ -5.0007,  -5.0403,  -5.1579,  ...,  -5.0961,  -5.3593,  -2.4921],\n",
      "         [ -5.0135,  -4.9703,  -5.1682,  ...,  -5.7161,  -5.9673,  -2.6177]],\n",
      "\n",
      "        [[ -7.1183,  -6.9738,  -7.1003,  ...,  -6.4544,  -6.5220,  -3.7663],\n",
      "         [ -7.4185,  -7.0124,  -7.3460,  ...,  -7.8326,  -8.7295,  -5.5875],\n",
      "         [ -5.6094,  -6.0460,  -5.5330,  ...,  -5.0734,  -5.2240,  -6.5229],\n",
      "         ...,\n",
      "         [ -5.1175,  -5.2476,  -5.2506,  ...,  -4.9473,  -5.1696,  -3.5206],\n",
      "         [ -4.9674,  -5.0063,  -5.0124,  ...,  -4.7558,  -5.0793,  -2.8428],\n",
      "         [ -4.9634,  -5.0780,  -4.9997,  ...,  -4.8801,  -5.0483,  -1.9931]],\n",
      "\n",
      "        [[ -7.8361,  -7.7685,  -7.6975,  ...,  -7.1144,  -7.0569,  -5.0430],\n",
      "         [-11.4044, -11.2401, -11.2916,  ...,  -9.6097,  -9.1931, -10.2725],\n",
      "         [ -3.8996,  -3.9767,  -3.9421,  ...,  -4.3339,  -5.6213,  -3.0507],\n",
      "         ...,\n",
      "         [ -5.9608,  -5.9754,  -5.9270,  ...,  -6.2821,  -6.6455,  -3.6431],\n",
      "         [ -4.7779,  -4.8379,  -4.7341,  ...,  -4.9404,  -5.8021,  -3.2069],\n",
      "         [ -4.5550,  -4.5502,  -4.5377,  ...,  -4.5064,  -5.3559,  -3.9533]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4031,  -6.3672,  -6.3779,  ...,  -5.6980,  -5.5494,  -3.9032],\n",
      "         [-12.5316, -12.4265, -12.1108,  ...,  -9.3580,  -9.9916, -10.7489],\n",
      "         [ -5.7207,  -5.8866,  -5.9907,  ...,  -6.2169,  -6.7421,  -5.4644],\n",
      "         ...,\n",
      "         [ -5.1877,  -5.1287,  -5.3463,  ...,  -5.3150,  -6.1013,  -3.4640],\n",
      "         [ -5.3895,  -5.4802,  -5.5967,  ...,  -5.6378,  -6.0728,  -4.5248],\n",
      "         [ -5.7751,  -5.8725,  -5.8919,  ...,  -5.6113,  -6.4274,  -3.7693]],\n",
      "\n",
      "        [[ -7.1829,  -7.1607,  -7.1842,  ...,  -6.1724,  -6.3727,  -4.1201],\n",
      "         [-11.9559, -11.7053, -11.5506,  ...,  -8.6647,  -8.6963, -11.9151],\n",
      "         [ -4.5486,  -4.6235,  -4.7653,  ...,  -5.2862,  -7.1275,  -3.8794],\n",
      "         ...,\n",
      "         [ -5.1865,  -5.4420,  -5.4373,  ...,  -5.5691,  -6.8873,  -3.6368],\n",
      "         [ -5.1041,  -5.2371,  -5.2794,  ...,  -5.3121,  -6.0615,  -4.0435],\n",
      "         [ -3.4372,  -3.5604,  -3.6358,  ...,  -3.8334,  -5.2712,  -4.2354]],\n",
      "\n",
      "        [[ -9.8777,  -9.6903,  -9.8685,  ..., -10.0018, -11.4675, -12.9579],\n",
      "         [-12.2756, -12.0628, -12.4104,  ..., -10.2043, -10.1285,  -8.7848],\n",
      "         [ -3.0514,  -3.0886,  -3.1476,  ...,  -4.3905,  -5.6684,  -4.6369],\n",
      "         ...,\n",
      "         [ -4.2840,  -4.1994,  -4.4785,  ...,  -5.1001,  -5.1115,  -2.7000],\n",
      "         [ -4.2218,  -4.2025,  -4.1893,  ...,  -5.0651,  -5.4135,  -3.1021],\n",
      "         [ -3.4617,  -3.3679,  -3.5477,  ...,  -4.3770,  -5.3920,  -3.6040]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.6295959949493408\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2567, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.9010,  -7.8486,  -7.7486,  ...,  -7.1907,  -6.5530,  -4.6977],\n",
      "         [ -6.0991,  -5.9416,  -6.1069,  ...,  -5.9199,  -4.9636,  -6.9202],\n",
      "         [ -2.1161,  -2.1428,  -1.6087,  ...,  -3.6032,  -1.4747,  -3.9893],\n",
      "         ...,\n",
      "         [ -5.3058,  -5.3237,  -4.5685,  ...,  -4.3503,  -4.1974,  -3.5111],\n",
      "         [ -2.6269,  -2.4624,  -1.9437,  ...,  -3.7759,  -2.0988,  -3.2998],\n",
      "         [-11.9398, -12.0157, -12.3361,  ...,  -9.2638,  -8.8437,  -9.3407]],\n",
      "\n",
      "        [[ -6.8248,  -6.8696,  -6.8046,  ...,  -5.9627,  -5.6497,  -4.2496],\n",
      "         [-10.2247, -10.2213, -10.4599,  ...,  -8.8038,  -8.5206,  -6.4854],\n",
      "         [ -3.6659,  -3.7192,  -3.7551,  ...,  -2.9279,  -3.8726,  -3.8885],\n",
      "         ...,\n",
      "         [ -6.0999,  -6.2227,  -6.0531,  ...,  -6.2339,  -6.0117,  -4.6070],\n",
      "         [ -6.6158,  -6.7751,  -6.6441,  ...,  -6.9858,  -6.6584,  -4.7583],\n",
      "         [ -6.3830,  -6.5498,  -6.2653,  ...,  -6.3076,  -6.1571,  -5.4924]],\n",
      "\n",
      "        [[ -7.7492,  -7.6916,  -7.6349,  ...,  -7.2142,  -6.4056,  -5.5018],\n",
      "         [ -5.0346,  -5.3386,  -5.1902,  ...,  -5.3557,  -5.1465,  -5.7262],\n",
      "         [ -8.1415,  -7.8666,  -7.6947,  ...,  -6.5681,  -3.5915,  -8.3901],\n",
      "         ...,\n",
      "         [ -6.8802,  -6.8272,  -6.8233,  ...,  -5.2579,  -5.2153,  -6.3121],\n",
      "         [ -7.1275,  -6.9390,  -6.8022,  ...,  -5.2502,  -4.6962,  -5.5757],\n",
      "         [ -8.1936,  -8.3090,  -8.2578,  ...,  -7.8162,  -7.0698,  -7.7502]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.3369,  -7.2954,  -7.1564,  ...,  -7.3948,  -6.5164,  -3.7715],\n",
      "         [ -6.5424,  -6.8372,  -6.3998,  ...,  -6.6908,  -6.7671,  -5.7001],\n",
      "         [-12.5753, -12.6514, -12.4720,  ..., -12.2505, -11.1009, -13.2387],\n",
      "         ...,\n",
      "         [ -7.4362,  -7.3121,  -7.3405,  ...,  -6.0086,  -6.7825,  -4.7595],\n",
      "         [ -3.7572,  -3.0862,  -3.2056,  ...,  -3.2465,  -1.4070,  -2.8707],\n",
      "         [ -9.1021,  -9.5628,  -8.7929,  ...,  -9.5861,  -7.6136,  -7.1365]],\n",
      "\n",
      "        [[ -6.5036,  -6.4426,  -6.4754,  ...,  -5.8126,  -5.8405,  -3.9784],\n",
      "         [-11.9300, -11.8486, -12.0561,  ..., -10.4214,  -8.6199, -10.0380],\n",
      "         [ -4.6061,  -4.8166,  -4.7836,  ...,  -4.8465,  -6.0870,  -3.0082],\n",
      "         ...,\n",
      "         [ -4.0275,  -4.2193,  -4.2898,  ...,  -3.9853,  -5.7149,  -1.7763],\n",
      "         [ -4.1111,  -4.2011,  -4.2616,  ...,  -3.9724,  -5.3244,  -2.1418],\n",
      "         [ -4.1821,  -4.3552,  -4.4000,  ...,  -4.3661,  -5.5534,  -2.8587]],\n",
      "\n",
      "        [[ -7.3790,  -7.4400,  -7.4069,  ...,  -6.6806,  -6.6246,  -4.2432],\n",
      "         [-12.6901, -12.7917, -13.1617,  ..., -12.5836,  -9.4351,  -9.4630],\n",
      "         [-12.8548, -13.2797, -13.1732,  ..., -13.4493, -10.0415,  -6.4283],\n",
      "         ...,\n",
      "         [ -7.0328,  -7.2946,  -7.0578,  ...,  -7.4505,  -6.6831,  -7.2139],\n",
      "         [ -5.6162,  -5.8166,  -5.7429,  ...,  -5.8385,  -5.6161,  -4.2056],\n",
      "         [-12.1031, -12.4493, -12.2718,  ..., -11.8946,  -9.1424, -10.2006]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.2566554546356201\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.9913, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3272,  -7.3114,  -7.2382,  ...,  -6.4941,  -6.5487,  -4.3899],\n",
      "         [ -6.0864,  -6.0363,  -6.2362,  ...,  -5.2927,  -5.3751,  -5.2218],\n",
      "         [ -8.7701,  -9.0346,  -8.8949,  ...,  -6.2563,  -6.2439,  -7.9414],\n",
      "         ...,\n",
      "         [ -6.9358,  -6.8074,  -6.9557,  ...,  -6.6485,  -5.5766,  -5.2019],\n",
      "         [ -7.5983,  -7.5322,  -7.6639,  ...,  -7.3411,  -6.7347,  -7.8488],\n",
      "         [ -7.1633,  -7.0466,  -7.2930,  ...,  -6.3850,  -5.6094,  -6.9178]],\n",
      "\n",
      "        [[ -6.1748,  -6.1713,  -6.2650,  ...,  -5.6724,  -5.7954,  -3.8454],\n",
      "         [ -7.3069,  -7.2845,  -7.2772,  ...,  -7.9714,  -8.2375,  -2.4240],\n",
      "         [ -6.9176,  -7.0631,  -6.7542,  ...,  -6.3065,  -7.0417,  -2.1239],\n",
      "         ...,\n",
      "         [ -3.9510,  -4.0917,  -3.9876,  ...,  -4.8679,  -4.8156,  -2.6231],\n",
      "         [ -3.8185,  -3.8750,  -3.7200,  ...,  -4.5621,  -4.5591,  -1.2360],\n",
      "         [ -4.1332,  -4.1370,  -4.1451,  ...,  -5.0563,  -4.9025,  -2.2794]],\n",
      "\n",
      "        [[ -6.4253,  -6.3930,  -6.4160,  ...,  -5.8159,  -5.6638,  -3.8181],\n",
      "         [ -5.8124,  -5.7343,  -5.8329,  ...,  -6.4648,  -7.2589,  -2.4122],\n",
      "         [ -6.4286,  -6.2929,  -6.2999,  ...,  -6.8826,  -6.4450,  -5.0123],\n",
      "         ...,\n",
      "         [ -4.3826,  -4.3724,  -4.3134,  ...,  -4.3275,  -5.1451,  -1.9089],\n",
      "         [ -4.3287,  -4.3692,  -4.3446,  ...,  -4.5249,  -5.0858,  -2.7973],\n",
      "         [ -4.3009,  -4.2621,  -4.2886,  ...,  -4.5357,  -5.0497,  -1.8470]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.6980,  -6.7387,  -6.7012,  ...,  -6.2556,  -6.3279,  -4.3517],\n",
      "         [ -4.8168,  -4.9362,  -4.8643,  ...,  -4.5152,  -3.2717,  -5.3652],\n",
      "         [ -8.0882,  -8.5441,  -8.2748,  ...,  -7.4603,  -5.2788,  -7.4887],\n",
      "         ...,\n",
      "         [ -4.7455,  -4.9525,  -4.9992,  ...,  -4.9644,  -4.8617,  -2.4861],\n",
      "         [ -5.6959,  -5.7839,  -5.8752,  ...,  -6.2108,  -5.2335,  -3.9670],\n",
      "         [ -4.7027,  -4.7658,  -4.7185,  ...,  -5.3499,  -4.5049,  -3.3962]],\n",
      "\n",
      "        [[ -6.7743,  -6.6537,  -6.6533,  ...,  -5.9207,  -5.6494,  -4.4349],\n",
      "         [-11.1809, -10.6779, -11.1494,  ...,  -8.3041,  -8.9288,  -9.9157],\n",
      "         [ -5.1407,  -5.1795,  -5.2328,  ...,  -5.1140,  -5.9576,  -4.1170],\n",
      "         ...,\n",
      "         [ -4.5710,  -4.4745,  -4.5035,  ...,  -4.3378,  -5.3932,  -2.8378],\n",
      "         [ -4.1235,  -4.2301,  -4.2466,  ...,  -3.7619,  -4.6872,  -3.2436],\n",
      "         [ -4.4110,  -4.4483,  -4.4733,  ...,  -4.2441,  -5.2372,  -3.2622]],\n",
      "\n",
      "        [[ -6.6431,  -6.6600,  -6.6302,  ...,  -6.1184,  -6.1032,  -3.7006],\n",
      "         [-11.7797, -11.9342, -11.9524,  ...,  -9.3088,  -9.8492,  -9.1344],\n",
      "         [-12.2468, -12.3368, -12.0461,  ...,  -9.5307, -11.3810, -10.6778],\n",
      "         ...,\n",
      "         [-11.1122, -10.7424, -11.1908,  ...,  -8.8955, -10.2945, -12.2075],\n",
      "         [ -6.6711,  -6.6747,  -6.5844,  ...,  -5.6019,  -6.4095,  -5.2026],\n",
      "         [-11.2497, -11.2311, -11.2738,  ...,  -9.1600,  -7.9280,  -9.1318]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.991287112236023\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.9320, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0835,  -7.0280,  -7.0066,  ...,  -6.2041,  -6.0337,  -4.2961],\n",
      "         [-10.8533, -10.7448, -10.6377,  ...,  -7.1570,  -8.0617,  -8.7804],\n",
      "         [ -4.0362,  -4.1179,  -4.1242,  ...,  -4.2942,  -5.3490,  -1.0569],\n",
      "         ...,\n",
      "         [ -4.5669,  -4.5814,  -4.5586,  ...,  -4.8072,  -5.7886,  -2.5674],\n",
      "         [ -3.9006,  -4.0410,  -3.9823,  ...,  -4.2740,  -5.0559,  -1.1869],\n",
      "         [ -4.6790,  -4.7775,  -4.7359,  ...,  -4.9304,  -5.8450,  -2.6052]],\n",
      "\n",
      "        [[ -6.5999,  -6.5659,  -6.5814,  ...,  -5.8522,  -5.6890,  -3.6839],\n",
      "         [-10.6345, -10.5707, -10.7612,  ...,  -8.9284,  -6.5436,  -7.7223],\n",
      "         [ -5.6913,  -5.8192,  -5.7508,  ...,  -6.0116,  -5.9569,  -4.0036],\n",
      "         ...,\n",
      "         [ -5.7074,  -5.7754,  -5.8548,  ...,  -5.8779,  -5.9028,  -3.7028],\n",
      "         [ -6.2459,  -6.4068,  -6.4396,  ...,  -6.0104,  -6.5170,  -3.6299],\n",
      "         [ -5.5039,  -5.6170,  -5.6373,  ...,  -5.4293,  -5.7612,  -3.3949]],\n",
      "\n",
      "        [[ -6.3171,  -6.3157,  -6.3108,  ...,  -5.5676,  -5.6680,  -3.7915],\n",
      "         [-11.8806, -11.7356, -11.7021,  ...,  -7.8292,  -8.5556,  -9.5493],\n",
      "         [ -4.7107,  -4.8606,  -4.9025,  ...,  -4.7425,  -6.2824,  -3.9538],\n",
      "         ...,\n",
      "         [ -5.2804,  -5.4670,  -5.4668,  ...,  -5.3169,  -6.4508,  -2.8610],\n",
      "         [ -4.2741,  -4.3531,  -4.4479,  ...,  -4.1825,  -5.7666,  -2.3423],\n",
      "         [ -4.5923,  -4.6869,  -4.7355,  ...,  -4.5672,  -5.7495,  -2.7697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.4863,  -6.3686,  -6.4138,  ...,  -5.6220,  -5.5100,  -3.7846],\n",
      "         [-13.2045, -13.4937, -12.8552,  ..., -11.3777, -11.9978, -11.9632],\n",
      "         [ -4.4207,  -4.4829,  -4.5599,  ...,  -4.5444,  -5.5613,  -3.3280],\n",
      "         ...,\n",
      "         [ -4.6664,  -4.6988,  -4.6062,  ...,  -4.3870,  -5.3931,  -4.0525],\n",
      "         [ -4.7426,  -4.8561,  -4.7031,  ...,  -4.4572,  -5.4504,  -3.5543],\n",
      "         [ -4.2418,  -4.3163,  -4.2077,  ...,  -4.0011,  -5.3361,  -3.7278]],\n",
      "\n",
      "        [[ -7.5043,  -7.5236,  -7.4187,  ...,  -6.7130,  -6.3716,  -4.3615],\n",
      "         [-15.0452, -14.9099, -14.8031,  ..., -14.3395, -11.1645, -11.9477],\n",
      "         [ -8.2604,  -8.0352,  -8.5485,  ...,  -8.1260,  -5.3139,  -8.3153],\n",
      "         ...,\n",
      "         [-13.2326, -13.1074, -12.9871,  ..., -10.3280,  -8.5811, -10.1565],\n",
      "         [ -8.6462,  -9.3655,  -8.9998,  ...,  -8.4852,  -7.1337,  -7.2886],\n",
      "         [-12.6587, -12.6505, -12.5268,  ..., -11.1174,  -8.9878, -10.0812]],\n",
      "\n",
      "        [[-10.7714, -11.0546, -10.7754,  ...,  -9.8316, -10.8542, -11.2429],\n",
      "         [-13.4498, -13.1996, -13.3434,  ..., -12.4039,  -9.9218,  -8.9050],\n",
      "         [ -4.8839,  -4.9476,  -5.0360,  ...,  -5.8974,  -6.6253,  -4.1297],\n",
      "         ...,\n",
      "         [ -5.0195,  -5.0384,  -4.9697,  ...,  -5.1075,  -5.5599,  -3.2614],\n",
      "         [ -5.2014,  -5.2488,  -5.2837,  ...,  -5.5162,  -6.2160,  -5.3426],\n",
      "         [ -5.1225,  -5.2949,  -5.1987,  ...,  -5.5356,  -5.9928,  -4.3405]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.9320273399353027\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.3966, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3730,  -6.3526,  -6.3978,  ...,  -5.7429,  -5.7343,  -3.3281],\n",
      "         [ -4.8853,  -4.8838,  -5.1197,  ...,  -5.6852,  -6.1649,  -1.2440],\n",
      "         [ -7.2947,  -7.3453,  -7.6008,  ...,  -7.5649,  -8.0722,  -3.6056],\n",
      "         ...,\n",
      "         [ -3.4201,  -3.4026,  -3.4511,  ...,  -3.7583,  -4.1579,  -1.6515],\n",
      "         [ -4.6253,  -4.6589,  -4.6642,  ...,  -5.5950,  -5.0091,  -1.1653],\n",
      "         [ -4.7122,  -4.6168,  -4.8550,  ...,  -5.1024,  -5.1150,  -1.7971]],\n",
      "\n",
      "        [[ -8.3898,  -8.3780,  -8.1953,  ...,  -7.5783,  -7.6556,  -4.1275],\n",
      "         [-11.9427, -11.8712, -11.6722,  ..., -10.0183,  -8.4411, -11.6649],\n",
      "         [ -4.5669,  -4.5195,  -4.6175,  ...,  -5.0101,  -5.9528,  -4.0681],\n",
      "         ...,\n",
      "         [ -4.9975,  -5.0795,  -5.1395,  ...,  -4.7174,  -6.0051,  -3.9160],\n",
      "         [ -3.8276,  -3.6385,  -3.7504,  ...,  -4.1103,  -4.9874,  -3.1594],\n",
      "         [ -4.1209,  -3.9498,  -4.1764,  ...,  -4.2288,  -4.8899,  -4.2592]],\n",
      "\n",
      "        [[ -7.1661,  -7.2190,  -7.1212,  ...,  -6.4174,  -6.2462,  -4.7407],\n",
      "         [-10.8707, -10.3743, -10.8331,  ..., -11.2174,  -9.6575,  -9.8325],\n",
      "         [ -6.7984,  -7.2143,  -7.0322,  ...,  -7.4594,  -4.7461, -10.7228],\n",
      "         ...,\n",
      "         [ -5.6057,  -5.7879,  -5.5954,  ...,  -5.5264,  -4.2694,  -4.4944],\n",
      "         [ -6.0775,  -6.4244,  -6.2952,  ...,  -5.6261,  -5.5811,  -4.9853],\n",
      "         [-10.5427, -10.7431, -10.3244,  ..., -11.2284,  -9.9100,  -6.7804]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.4947,  -8.4309,  -8.4300,  ...,  -7.0454,  -7.5342,  -5.4953],\n",
      "         [-14.3236, -14.6256, -14.5280,  ..., -11.6037,  -9.7493,  -8.2162],\n",
      "         [ -4.5017,  -4.6088,  -4.6714,  ...,  -4.7690,  -5.9074,  -4.6529],\n",
      "         ...,\n",
      "         [ -4.8152,  -4.9406,  -4.8951,  ...,  -5.5358,  -6.9611,  -4.3361],\n",
      "         [ -4.2926,  -4.3327,  -4.4170,  ...,  -4.3706,  -6.0202,  -3.4225],\n",
      "         [ -4.7727,  -4.9154,  -4.8037,  ...,  -4.3746,  -5.6100,  -4.0457]],\n",
      "\n",
      "        [[ -8.2066,  -8.1887,  -8.1142,  ...,  -7.2431,  -6.7762,  -5.2756],\n",
      "         [-12.7827, -12.4669, -12.8002,  ..., -11.4671,  -8.5098, -10.1902],\n",
      "         [ -5.4523,  -5.3674,  -5.5400,  ...,  -6.1257,  -3.4164,  -4.1049],\n",
      "         ...,\n",
      "         [ -6.6807,  -6.7838,  -6.7962,  ...,  -6.0570,  -5.7419,  -6.6516],\n",
      "         [ -8.1311,  -8.1961,  -8.3223,  ...,  -7.7374,  -6.1729,  -8.2809],\n",
      "         [ -7.8999,  -7.9655,  -8.0626,  ...,  -7.4334,  -6.0331,  -8.1108]],\n",
      "\n",
      "        [[ -7.2529,  -7.2910,  -7.2040,  ...,  -6.3534,  -6.4228,  -4.9588],\n",
      "         [-11.0717, -10.9703, -10.9499,  ..., -11.1119,  -8.3850, -11.3711],\n",
      "         [-14.1471, -14.2818, -14.0314,  ..., -11.4286, -10.7704, -13.7152],\n",
      "         ...,\n",
      "         [ -3.4648,  -3.6588,  -3.3192,  ...,  -1.8450,  -1.3552,  -3.4876],\n",
      "         [ -7.1673,  -7.3823,  -7.1107,  ...,  -6.2496,  -6.7703,  -6.4377],\n",
      "         [ -6.8880,  -7.1829,  -7.0265,  ...,  -5.8205,  -5.8785,  -5.1211]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.396580457687378\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.0019, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3843,  -6.3751,  -6.3872,  ...,  -5.8101,  -5.5614,  -3.7297],\n",
      "         [ -9.6706,  -9.6270,  -9.7414,  ..., -10.1833, -10.2597,  -5.9844],\n",
      "         [ -7.3203,  -7.3588,  -7.3722,  ...,  -8.4148,  -7.4770,  -3.5589],\n",
      "         ...,\n",
      "         [ -4.3052,  -4.5629,  -4.5979,  ...,  -5.1893,  -4.8881,  -3.5194],\n",
      "         [ -4.1395,  -4.2509,  -4.2955,  ...,  -4.7652,  -5.0406,  -3.3041],\n",
      "         [ -4.0831,  -4.2886,  -4.3348,  ...,  -4.7015,  -4.9104,  -2.4880]],\n",
      "\n",
      "        [[ -6.9531,  -6.8766,  -6.9171,  ...,  -6.2764,  -6.0034,  -4.4036],\n",
      "         [ -8.6528,  -8.7371,  -8.7420,  ...,  -6.5508,  -6.5041,  -8.1914],\n",
      "         [ -4.6229,  -4.8217,  -4.7971,  ...,  -5.1783,  -6.3510,  -2.0814],\n",
      "         ...,\n",
      "         [ -4.8954,  -4.9451,  -5.0049,  ...,  -5.0011,  -5.6373,  -3.3110],\n",
      "         [ -4.8709,  -5.0026,  -5.0170,  ...,  -4.9213,  -5.4973,  -3.2244],\n",
      "         [ -4.7374,  -4.8501,  -4.8889,  ...,  -5.0575,  -6.1323,  -3.2015]],\n",
      "\n",
      "        [[ -7.0912,  -7.0376,  -7.0685,  ...,  -6.4346,  -6.2942,  -4.3550],\n",
      "         [ -6.2788,  -6.0769,  -6.2348,  ...,  -6.1318,  -7.3243,   0.0667],\n",
      "         [ -4.6565,  -4.6105,  -4.9302,  ...,  -5.2926,  -5.7232,  -1.7310],\n",
      "         ...,\n",
      "         [ -4.9109,  -4.9965,  -5.1519,  ...,  -5.5336,  -5.5788,  -2.1164],\n",
      "         [ -5.0597,  -5.1945,  -5.1891,  ...,  -5.6861,  -5.8231,  -3.0591],\n",
      "         [ -4.2685,  -4.3869,  -4.4069,  ...,  -4.6998,  -4.8568,  -2.0694]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.4702,  -7.5747,  -7.5418,  ...,  -7.1804,  -6.5428,  -4.0955],\n",
      "         [-10.2295, -10.1672, -10.0329,  ..., -10.1427,  -9.4319, -11.6851],\n",
      "         [ -4.9470,  -5.0335,  -4.8480,  ...,  -4.7677,  -4.2559,  -4.6603],\n",
      "         ...,\n",
      "         [ -3.1050,  -3.2234,  -2.9294,  ...,  -3.5751,  -3.4969,  -4.6394],\n",
      "         [ -7.3310,  -7.2643,  -7.1141,  ...,  -7.6535,  -6.6769,  -5.4391],\n",
      "         [-11.8101, -11.9352, -11.7058,  ...,  -9.5133,  -9.6014, -13.5213]],\n",
      "\n",
      "        [[ -7.6197,  -7.6023,  -7.4986,  ...,  -6.6076,  -6.6276,  -3.1256],\n",
      "         [-11.2539, -11.4212, -10.9192,  ..., -10.6092,  -7.5541,  -5.5246],\n",
      "         [ -6.8722,  -7.0403,  -7.1526,  ...,  -5.0450,  -4.9922,  -4.7284],\n",
      "         ...,\n",
      "         [-14.7347, -14.1637, -14.2114,  ..., -12.9918, -11.0215,  -9.9958],\n",
      "         [-15.9420, -16.2655, -15.9456,  ..., -15.3105, -13.0001, -12.5006],\n",
      "         [ -8.3846,  -8.3938,  -8.3954,  ...,  -7.7435,  -7.0105,  -4.3248]],\n",
      "\n",
      "        [[ -8.1418,  -8.0978,  -8.1780,  ...,  -7.6152,  -7.2085,  -3.9540],\n",
      "         [ -4.7011,  -4.5497,  -4.4137,  ...,  -4.8334,  -4.2041,  -6.0763],\n",
      "         [-10.3670, -11.1061, -10.4575,  ..., -11.6862,  -8.5553,  -5.2595],\n",
      "         ...,\n",
      "         [ -4.5197,  -4.3218,  -4.2023,  ...,  -4.6547,  -4.3813,  -6.3435],\n",
      "         [-10.7185, -10.7223, -10.7804,  ..., -10.7465,  -7.9938,  -7.7495],\n",
      "         [-11.1927, -11.1854, -10.9931,  ..., -10.3110,  -7.5388,  -8.4953]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.0019495487213135\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(3.3219, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3864,  -6.3754,  -6.3830,  ...,  -5.6748,  -5.6392,  -3.6712],\n",
      "         [ -5.7158,  -5.4239,  -5.6454,  ...,  -5.8241,  -5.9849,  -3.3099],\n",
      "         [ -5.8686,  -5.9265,  -5.8898,  ...,  -6.1119,  -6.1341,  -3.8281],\n",
      "         ...,\n",
      "         [ -4.5631,  -4.5527,  -4.6394,  ...,  -4.7890,  -5.5343,  -2.0457],\n",
      "         [ -5.0258,  -5.0153,  -5.1498,  ...,  -5.3777,  -5.7441,  -2.6936],\n",
      "         [ -5.9451,  -5.8490,  -5.9813,  ...,  -6.5772,  -6.5035,  -3.4607]],\n",
      "\n",
      "        [[ -8.0370,  -8.0386,  -7.9273,  ...,  -7.0959,  -7.1250,  -4.5848],\n",
      "         [ -7.2457,  -7.5165,  -7.2656,  ...,  -7.8839,  -6.4240,  -3.7222],\n",
      "         [ -2.0592,  -2.3787,  -2.0520,  ...,  -2.0090,  -1.4569,  -1.9080],\n",
      "         ...,\n",
      "         [ -6.7304,  -6.7883,  -6.6784,  ...,  -6.5832,  -6.8327,  -4.2073],\n",
      "         [ -8.3830,  -8.4067,  -8.3288,  ...,  -8.0513,  -7.3819,  -4.8315],\n",
      "         [ -8.6968,  -8.6540,  -8.7131,  ...,  -8.9885,  -7.7989,  -4.4198]],\n",
      "\n",
      "        [[ -7.2582,  -7.2979,  -7.2073,  ...,  -6.7338,  -6.4278,  -4.3792],\n",
      "         [ -9.0299,  -9.1020,  -8.4135,  ...,  -7.8977,  -7.2972,  -9.0388],\n",
      "         [ -8.4413,  -8.2959,  -8.0811,  ...,  -7.0786,  -6.7791,  -4.2342],\n",
      "         ...,\n",
      "         [ -7.2560,  -7.3480,  -7.4231,  ...,  -7.3556,  -7.0469,  -6.5248],\n",
      "         [ -6.9405,  -7.0834,  -7.1134,  ...,  -7.6140,  -7.0753,  -5.3103],\n",
      "         [ -3.2908,  -3.3158,  -3.3250,  ...,  -4.4362,  -2.2090,  -3.0647]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9175,  -6.8879,  -6.8497,  ...,  -6.3641,  -6.0948,  -4.0680],\n",
      "         [ -5.3508,  -5.6045,  -5.4012,  ...,  -5.4914,  -5.4946,  -4.9952],\n",
      "         [ -6.7342,  -6.6847,  -6.0531,  ...,  -6.7133,  -3.8987,  -5.8630],\n",
      "         ...,\n",
      "         [ -6.6801,  -6.7122,  -6.5692,  ...,  -6.6985,  -5.6372,  -5.6294],\n",
      "         [ -7.9537,  -7.8419,  -7.5217,  ...,  -8.5170,  -6.9450,  -6.1883],\n",
      "         [ -5.8214,  -5.7101,  -5.5680,  ...,  -6.1067,  -4.8315,  -4.9457]],\n",
      "\n",
      "        [[ -6.1993,  -6.1602,  -6.1421,  ...,  -5.5354,  -5.2762,  -3.8138],\n",
      "         [-11.7358, -11.1360, -11.4971,  ...,  -9.0335,  -8.4659,  -9.6863],\n",
      "         [ -3.7651,  -3.7826,  -3.8070,  ...,  -3.9011,  -5.5275,  -3.1127],\n",
      "         ...,\n",
      "         [ -4.1914,  -4.2570,  -4.3071,  ...,  -4.2577,  -5.7222,  -3.7710],\n",
      "         [ -3.8587,  -3.8387,  -3.9861,  ...,  -4.2297,  -5.2946,  -3.6621],\n",
      "         [ -4.7064,  -4.7428,  -4.8120,  ...,  -4.9402,  -5.9363,  -4.5478]],\n",
      "\n",
      "        [[ -6.2860,  -6.2653,  -6.1850,  ...,  -5.7855,  -6.1890,  -2.9136],\n",
      "         [ -9.1082,  -8.7475,  -8.8657,  ...,  -7.2136,  -7.1396,  -5.4601],\n",
      "         [ -5.4546,  -5.4609,  -5.5174,  ...,  -5.6950,  -6.2383,  -2.5977],\n",
      "         ...,\n",
      "         [ -5.2356,  -5.2947,  -5.3351,  ...,  -5.5107,  -5.8933,  -3.1954],\n",
      "         [ -5.8397,  -5.7840,  -5.8522,  ...,  -6.0593,  -6.4585,  -2.4258],\n",
      "         [ -4.9941,  -4.9714,  -5.0609,  ...,  -5.2605,  -5.8946,  -2.7363]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 3.321918487548828\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8584, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.5989,  -6.5569,  -6.5133,  ...,  -5.4669,  -5.5481,  -3.7802],\n",
      "         [ -9.6022,  -9.8686,  -9.9794,  ...,  -9.1388,  -7.1473,  -6.7498],\n",
      "         [ -7.8218,  -8.1808,  -7.9250,  ...,  -8.6898,  -7.1313,  -5.8856],\n",
      "         ...,\n",
      "         [ -7.2846,  -7.5146,  -7.2244,  ...,  -7.0319,  -5.8356,  -3.5375],\n",
      "         [ -7.5665,  -7.7623,  -7.4574,  ...,  -8.1613,  -6.5962,  -4.3412],\n",
      "         [ -6.9587,  -7.2727,  -7.0297,  ...,  -7.5008,  -6.2013,  -4.2094]],\n",
      "\n",
      "        [[ -6.7341,  -6.5739,  -6.5835,  ...,  -5.6409,  -6.5226,  -3.6417],\n",
      "         [-12.5108, -12.1900, -12.2175,  ...,  -8.8581,  -9.6148, -10.8370],\n",
      "         [ -5.1709,  -5.3305,  -5.3816,  ...,  -5.3919,  -7.0160,  -2.5755],\n",
      "         ...,\n",
      "         [ -5.2053,  -5.3601,  -5.4691,  ...,  -5.3845,  -6.6303,  -1.7534],\n",
      "         [ -5.4304,  -5.4854,  -5.4659,  ...,  -5.8180,  -6.6171,  -2.5455],\n",
      "         [ -5.7486,  -5.8175,  -5.8096,  ...,  -6.0739,  -7.0122,  -2.6074]],\n",
      "\n",
      "        [[ -6.7663,  -6.7142,  -6.7067,  ...,  -5.8759,  -5.7930,  -4.1354],\n",
      "         [ -9.5293,  -8.8633,  -9.4974,  ...,  -8.6611,  -7.0237,  -7.8116],\n",
      "         [ -5.0429,  -5.2110,  -5.2159,  ...,  -5.3307,  -6.2092,  -3.7313],\n",
      "         ...,\n",
      "         [ -4.9154,  -4.8787,  -4.9977,  ...,  -4.7381,  -5.8289,  -3.9141],\n",
      "         [ -5.3259,  -5.4398,  -5.5129,  ...,  -5.3431,  -6.0296,  -4.0269],\n",
      "         [ -4.6955,  -4.7549,  -4.7608,  ...,  -4.5602,  -5.5272,  -3.3368]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.0100,  -8.0052,  -7.9328,  ...,  -7.0662,  -7.1820,  -4.5491],\n",
      "         [ -5.8994,  -5.8800,  -5.6874,  ...,  -5.9418,  -5.6490,  -4.7391],\n",
      "         [-10.3095,  -9.8476, -10.1749,  ...,  -8.2955,  -8.1497,  -8.7021],\n",
      "         ...,\n",
      "         [ -8.4343,  -8.4245,  -8.3462,  ...,  -7.3801,  -6.2515,  -9.0694],\n",
      "         [ -7.6501,  -7.4174,  -7.5039,  ...,  -6.3895,  -5.2124,  -8.6303],\n",
      "         [ -7.5818,  -7.5321,  -7.4657,  ...,  -6.2929,  -6.1906,  -8.0013]],\n",
      "\n",
      "        [[ -6.8418,  -6.8533,  -6.7802,  ...,  -6.1993,  -5.9290,  -4.3989],\n",
      "         [ -5.0285,  -5.4366,  -4.8283,  ...,  -5.4057,  -5.5758,  -4.1648],\n",
      "         [ -1.0122,  -1.1424,  -1.4979,  ...,  -1.5450,  -1.9340,  -4.0584],\n",
      "         ...,\n",
      "         [ -6.3936,  -6.5097,  -6.3821,  ...,  -6.1885,  -6.3278,  -7.1961],\n",
      "         [ -6.6277,  -6.5636,  -6.4164,  ...,  -6.2924,  -6.2335,  -2.9008],\n",
      "         [ -6.2383,  -6.1459,  -6.1612,  ...,  -6.2910,  -6.1572,  -3.0249]],\n",
      "\n",
      "        [[ -6.9251,  -6.8454,  -6.8283,  ...,  -6.2589,  -6.0537,  -4.5480],\n",
      "         [ -9.4571,  -9.7565,  -9.7913,  ..., -10.2845,  -8.8778,  -8.5545],\n",
      "         [ -9.6295,  -9.4208,  -9.7698,  ...,  -7.8021,  -6.1384,  -7.5637],\n",
      "         ...,\n",
      "         [ -8.5363,  -8.5391,  -8.6260,  ...,  -9.1216,  -7.9053,  -7.4890],\n",
      "         [ -7.5848,  -7.4318,  -7.4692,  ...,  -8.0501,  -6.3944,  -6.7150],\n",
      "         [ -4.9973,  -5.0898,  -5.0214,  ...,  -5.7626,  -4.0457,  -4.3848]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.8584113121032715\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.4219, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2480,  -7.2165,  -7.2221,  ...,  -6.7598,  -6.4783,  -4.3487],\n",
      "         [-10.6450, -10.6508, -10.8073,  ...,  -9.5163,  -9.8615,  -8.3000],\n",
      "         [ -7.9741,  -8.0001,  -8.0501,  ...,  -9.0197,  -5.0835,  -6.3670],\n",
      "         ...,\n",
      "         [ -3.7728,  -4.1818,  -3.8896,  ...,  -4.7184,  -4.2861,  -1.6929],\n",
      "         [ -7.4491,  -7.3226,  -7.1411,  ...,  -7.0664,  -6.3186,  -3.9327],\n",
      "         [-14.6545, -14.8163, -14.7694,  ..., -15.7501, -12.2005, -14.5462]],\n",
      "\n",
      "        [[ -6.8883,  -6.8651,  -6.8730,  ...,  -6.0828,  -6.2654,  -4.1323],\n",
      "         [-12.1583, -12.2385, -12.1115,  ...,  -9.6507, -10.2892, -11.6130],\n",
      "         [ -5.4187,  -5.4207,  -5.4809,  ...,  -5.3859,  -6.2826,  -3.4583],\n",
      "         ...,\n",
      "         [ -5.2997,  -5.3837,  -5.3718,  ...,  -5.1676,  -6.1609,  -3.9190],\n",
      "         [ -4.5903,  -4.6253,  -4.6657,  ...,  -4.6520,  -5.5147,  -3.0835],\n",
      "         [ -4.8330,  -4.8532,  -4.8856,  ...,  -4.6876,  -6.0071,  -3.0468]],\n",
      "\n",
      "        [[ -7.4157,  -7.4027,  -7.3430,  ...,  -7.0537,  -6.3224,  -4.8856],\n",
      "         [ -9.0801,  -9.3350,  -9.1264,  ...,  -8.6349,  -6.2262, -10.7351],\n",
      "         [ -8.6899,  -8.5371,  -8.7238,  ...,  -7.6388,  -5.0554,  -8.0608],\n",
      "         ...,\n",
      "         [ -8.5979,  -8.8047,  -8.8816,  ...,  -7.9433,  -7.1193,  -7.2931],\n",
      "         [ -6.6263,  -6.8303,  -6.8547,  ...,  -6.4413,  -5.3723,  -6.5129],\n",
      "         [ -6.9752,  -7.0231,  -7.1841,  ...,  -6.6145,  -5.7593,  -6.6749]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-10.4373, -10.6605, -10.5234,  ...,  -9.6392,  -9.9514,  -9.2745],\n",
      "         [-13.4032, -13.6190, -13.1096,  ..., -11.7573, -10.7639, -11.2593],\n",
      "         [ -4.1216,  -4.1869,  -4.2383,  ...,  -5.4220,  -5.8220,  -3.1715],\n",
      "         ...,\n",
      "         [ -4.3761,  -4.3642,  -4.4688,  ...,  -4.7034,  -5.5819,  -4.3246],\n",
      "         [ -3.8491,  -3.8256,  -3.9111,  ...,  -4.8436,  -5.1271,  -4.0098],\n",
      "         [ -3.8942,  -3.8523,  -3.8429,  ...,  -4.3976,  -5.3922,  -2.9504]],\n",
      "\n",
      "        [[ -6.5634,  -6.5202,  -6.5763,  ...,  -5.8362,  -5.8564,  -3.4519],\n",
      "         [ -7.7330,  -7.4962,  -7.8239,  ...,  -7.9215,  -8.6766,  -2.1541],\n",
      "         [ -7.1136,  -6.8994,  -6.9560,  ...,  -6.7768,  -7.7350,  -1.6126],\n",
      "         ...,\n",
      "         [ -4.8513,  -4.9092,  -4.9493,  ...,  -4.7734,  -4.9307,  -0.3950],\n",
      "         [ -4.9820,  -5.0072,  -5.0588,  ...,  -5.1506,  -5.3684,  -1.4305],\n",
      "         [ -5.1510,  -5.1642,  -5.1891,  ...,  -5.3485,  -5.7266,  -0.9931]],\n",
      "\n",
      "        [[ -7.1206,  -7.2022,  -7.0466,  ...,  -6.5884,  -6.0018,  -4.8782],\n",
      "         [ -6.9630,  -7.0369,  -6.9585,  ...,  -7.2132,  -5.9385,  -8.1998],\n",
      "         [-12.5959, -12.9776, -12.5095,  ..., -12.0892,  -9.0801,  -9.4089],\n",
      "         ...,\n",
      "         [ -8.1139,  -8.2590,  -7.9366,  ...,  -6.6875,  -6.4632,  -8.1844],\n",
      "         [ -8.3666,  -8.5505,  -8.5558,  ...,  -8.6704,  -7.8796,  -7.2174],\n",
      "         [-11.8361, -11.8341, -11.9728,  ...,  -9.2584, -11.3282, -11.4468]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.421912431716919\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.6343, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4188,  -6.4061,  -6.3978,  ...,  -5.7424,  -5.5977,  -3.9235],\n",
      "         [ -9.9425,  -9.4423,  -9.9041,  ...,  -7.3104,  -7.0618,  -9.3843],\n",
      "         [ -4.6104,  -4.7141,  -4.7395,  ...,  -4.8067,  -6.0440,  -2.9151],\n",
      "         ...,\n",
      "         [ -4.9941,  -5.0921,  -5.0680,  ...,  -5.2287,  -6.0270,  -3.7651],\n",
      "         [ -5.2660,  -5.3092,  -5.4399,  ...,  -5.5576,  -6.4301,  -3.2495],\n",
      "         [ -5.9935,  -6.0082,  -6.1471,  ...,  -5.7797,  -6.8369,  -3.9045]],\n",
      "\n",
      "        [[ -7.8177,  -7.8597,  -7.7959,  ...,  -7.0688,  -6.8659,  -4.1793],\n",
      "         [-12.1832, -11.9565, -12.1672,  ..., -10.7036,  -9.5860,  -6.6365],\n",
      "         [-11.2707, -11.4566, -11.0206,  ...,  -8.7350,  -9.5215,  -9.9304],\n",
      "         ...,\n",
      "         [-12.3505, -12.5037, -12.0330,  ..., -10.0050,  -8.5500, -10.5731],\n",
      "         [-12.5178, -12.7272, -12.5259,  ...,  -8.9152,  -7.7942, -12.9928],\n",
      "         [-12.8954, -13.3565, -12.6396,  ..., -10.6963,  -9.8553,  -8.3876]],\n",
      "\n",
      "        [[ -6.3630,  -6.3129,  -6.2983,  ...,  -5.5494,  -5.4626,  -3.8410],\n",
      "         [-15.6428, -15.3709, -15.5751,  ..., -13.0982, -13.4738, -13.7941],\n",
      "         [ -4.7238,  -4.8223,  -4.8135,  ...,  -4.5983,  -6.4960,  -3.6825],\n",
      "         ...,\n",
      "         [ -4.8079,  -4.8964,  -4.8405,  ...,  -5.2261,  -6.3490,  -2.7758],\n",
      "         [ -4.3179,  -4.3528,  -4.2981,  ...,  -4.1544,  -5.4338,  -3.3097],\n",
      "         [ -4.5659,  -4.5741,  -4.4943,  ...,  -3.8727,  -5.6329,  -2.8732]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.5474,  -9.4218,  -9.3423,  ...,  -8.3133,  -8.3374,  -6.3952],\n",
      "         [-11.8768, -11.6192, -11.6762,  ..., -11.5214,  -9.6761,  -7.9696],\n",
      "         [ -5.0964,  -5.2452,  -5.2346,  ...,  -5.3511,  -6.9980,  -4.2720],\n",
      "         ...,\n",
      "         [ -5.2752,  -5.2678,  -5.1621,  ...,  -4.6825,  -5.6921,  -5.3815],\n",
      "         [ -5.2153,  -5.2706,  -5.2580,  ...,  -5.1731,  -6.3537,  -5.0494],\n",
      "         [ -5.8999,  -5.9510,  -5.9001,  ...,  -5.6372,  -6.5031,  -5.1462]],\n",
      "\n",
      "        [[ -6.7407,  -6.7097,  -6.7175,  ...,  -6.0462,  -5.8614,  -4.2152],\n",
      "         [ -9.9666,  -9.8342,  -9.8620,  ...,  -7.8781,  -7.5625,  -6.1795],\n",
      "         [ -5.7942,  -5.8614,  -5.7402,  ...,  -5.6477,  -5.5832,  -4.7173],\n",
      "         ...,\n",
      "         [ -5.5251,  -5.5771,  -5.5080,  ...,  -5.3995,  -5.8333,  -4.0568],\n",
      "         [ -5.7205,  -5.8215,  -5.6535,  ...,  -5.7730,  -5.6888,  -4.6864],\n",
      "         [ -5.7934,  -5.8417,  -5.7362,  ...,  -5.8159,  -5.8606,  -4.2998]],\n",
      "\n",
      "        [[ -6.4473,  -6.4587,  -6.4742,  ...,  -5.7698,  -5.9606,  -3.6766],\n",
      "         [ -7.5785,  -7.6672,  -7.7414,  ...,  -7.1368,  -8.8464,  -2.7369],\n",
      "         [ -8.7045,  -8.6426,  -8.6005,  ...,  -8.7266,  -9.7284,  -4.5031],\n",
      "         ...,\n",
      "         [ -4.3452,  -4.4564,  -4.4250,  ...,  -5.1956,  -5.5613,  -1.8861],\n",
      "         [ -4.8877,  -5.0046,  -5.0100,  ...,  -5.2777,  -5.2081,  -2.3700],\n",
      "         [ -5.0109,  -5.0644,  -5.1896,  ...,  -5.6996,  -5.6990,  -2.3300]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.634253740310669\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.2958, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.8058,  -7.8150,  -7.7923,  ...,  -7.0079,  -6.8783,  -5.1261],\n",
      "         [-11.7716, -11.9830, -12.0406,  ...,  -9.9636, -11.3999,  -7.6366],\n",
      "         [ -9.3105,  -9.2481,  -9.6264,  ...,  -8.6051,  -9.9417,  -5.6209],\n",
      "         ...,\n",
      "         [-11.0614, -10.6181, -11.3402,  ..., -10.0980,  -8.6907,  -9.7292],\n",
      "         [-10.0650, -10.0827, -10.1934,  ...,  -9.4147,  -8.5075,  -8.2281],\n",
      "         [-17.2846, -17.4274, -17.4134,  ..., -17.0947, -13.6949, -11.6654]],\n",
      "\n",
      "        [[ -6.5457,  -6.5284,  -6.5601,  ...,  -5.8878,  -5.7772,  -3.8885],\n",
      "         [ -7.5154,  -7.3435,  -7.5780,  ...,  -7.9966,  -7.5134,  -5.9035],\n",
      "         [ -4.1002,  -4.3455,  -4.4680,  ...,  -4.9200,  -4.5350,  -3.6187],\n",
      "         ...,\n",
      "         [ -4.4213,  -4.6923,  -4.6102,  ...,  -4.7458,  -4.8076,  -3.9039],\n",
      "         [ -4.7764,  -5.0630,  -5.0660,  ...,  -5.1147,  -5.4425,  -3.9286],\n",
      "         [ -5.4463,  -5.6302,  -5.6040,  ...,  -5.9528,  -5.7988,  -4.5044]],\n",
      "\n",
      "        [[ -8.1930,  -8.1329,  -8.0487,  ...,  -7.2855,  -7.5317,  -4.1206],\n",
      "         [-17.1620, -16.9096, -16.7641,  ..., -15.2929, -13.9665,  -9.7143],\n",
      "         [-13.0039, -12.7514, -12.9413,  ..., -11.6571, -10.7021,  -6.5229],\n",
      "         ...,\n",
      "         [ -8.0369,  -8.9706,  -8.3866,  ...,  -8.7228,  -7.7815,  -8.5646],\n",
      "         [ -8.8421,  -9.3009,  -8.9874,  ...,  -6.7223,  -7.3862,  -6.5472],\n",
      "         [-15.0048, -15.0380, -14.8181,  ..., -13.1990, -12.1774,  -7.7190]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.1500,  -7.1411,  -7.1607,  ...,  -6.6282,  -6.3092,  -4.4895],\n",
      "         [-15.4358, -15.3414, -15.7101,  ..., -12.7347, -12.1979, -11.9899],\n",
      "         [-10.1449,  -9.9970, -10.4133,  ...,  -9.3739, -10.0774, -11.2377],\n",
      "         ...,\n",
      "         [ -3.2284,  -3.0600,  -3.1879,  ...,  -3.2572,  -3.9714,  -4.4731],\n",
      "         [-10.3868, -10.3512, -10.2825,  ..., -10.2022,  -8.1054,  -7.3101],\n",
      "         [-13.0628, -13.1406, -13.2697,  ..., -11.2390,  -8.4649,  -9.3954]],\n",
      "\n",
      "        [[ -6.1221,  -6.0688,  -6.1150,  ...,  -5.4278,  -5.5667,  -3.7872],\n",
      "         [ -7.5014,  -7.6140,  -7.7045,  ...,  -8.4633,  -9.1145,  -3.6793],\n",
      "         [ -6.7429,  -6.9416,  -7.1809,  ...,  -6.5780,  -6.6494,  -4.7733],\n",
      "         ...,\n",
      "         [ -4.1762,  -4.1749,  -4.3199,  ...,  -4.7087,  -5.2368,  -3.2098],\n",
      "         [ -4.5318,  -4.5468,  -4.7273,  ...,  -5.4698,  -5.2703,  -2.7744],\n",
      "         [ -4.2150,  -4.2562,  -4.2690,  ...,  -4.8107,  -5.0151,  -2.7800]],\n",
      "\n",
      "        [[ -5.9553,  -6.0240,  -5.8432,  ...,  -5.9751,  -5.6530,  -4.4784],\n",
      "         [-13.7538, -13.3062, -13.5494,  ..., -11.6341, -11.3947, -10.2003],\n",
      "         [ -5.1416,  -5.2742,  -5.4017,  ...,  -5.3989,  -6.0775,  -3.4034],\n",
      "         ...,\n",
      "         [ -5.7261,  -5.8041,  -5.8027,  ...,  -6.1100,  -6.1853,  -4.4361],\n",
      "         [ -5.4443,  -5.5149,  -5.5274,  ...,  -5.6643,  -5.5578,  -4.2110],\n",
      "         [ -5.0399,  -5.0928,  -5.1770,  ...,  -5.3125,  -5.8852,  -3.7098]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.295813798904419\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(2.8567, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.3809,  -7.3925,  -7.3318,  ...,  -6.8088,  -6.5355,  -4.8161],\n",
      "         [-10.2562,  -9.8521, -10.6788,  ..., -10.9217,  -7.2331,  -6.8913],\n",
      "         [ -3.5297,  -3.6402,  -3.3566,  ...,  -3.0573,  -2.5336,  -2.5771],\n",
      "         ...,\n",
      "         [ -4.6443,  -4.3446,  -4.5468,  ...,  -4.3098,  -4.3696,  -2.3133],\n",
      "         [ -4.9260,  -4.9464,  -4.9977,  ...,  -5.6845,  -4.6503,  -4.3852],\n",
      "         [-13.9065, -13.9624, -13.9420,  ..., -14.2348, -11.6323,  -9.6667]],\n",
      "\n",
      "        [[ -6.7627,  -6.8050,  -6.6860,  ...,  -6.0160,  -5.8478,  -4.4624],\n",
      "         [ -5.9827,  -6.1054,  -6.0964,  ...,  -5.2727,  -4.6944,  -5.3016],\n",
      "         [ -6.0963,  -5.6528,  -6.0409,  ...,  -5.0062,  -4.8455,  -4.7669],\n",
      "         ...,\n",
      "         [ -7.4254,  -7.5440,  -7.6633,  ...,  -6.7806,  -6.9913,  -5.2613],\n",
      "         [ -8.2550,  -8.3713,  -8.5231,  ...,  -7.6003,  -7.6580,  -6.6143],\n",
      "         [ -8.4146,  -8.5640,  -8.6991,  ...,  -7.6587,  -7.6774,  -6.8415]],\n",
      "\n",
      "        [[ -6.6681,  -6.6457,  -6.6221,  ...,  -6.0364,  -5.7014,  -4.0905],\n",
      "         [ -7.6921,  -7.9513,  -8.0310,  ...,  -8.2077,  -6.8918,  -5.2181],\n",
      "         [-13.7939, -13.9439, -13.8473,  ..., -12.2881, -11.5363, -10.9441],\n",
      "         ...,\n",
      "         [ -6.5093,  -6.7337,  -6.6168,  ...,  -6.2279,  -6.1679,  -4.1483],\n",
      "         [ -6.5532,  -6.7376,  -6.6552,  ...,  -6.2393,  -5.9703,  -3.9711],\n",
      "         [ -6.6813,  -6.8814,  -6.7841,  ...,  -6.7279,  -6.3862,  -4.5044]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0688,  -7.0977,  -7.0342,  ...,  -6.5554,  -6.2184,  -4.3032],\n",
      "         [ -5.6214,  -5.7981,  -5.6050,  ...,  -5.6661,  -5.2089,  -5.1406],\n",
      "         [ -5.1416,  -5.1686,  -4.9394,  ...,  -5.3571,  -4.9711,  -4.3035],\n",
      "         ...,\n",
      "         [ -2.1709,  -2.3988,  -2.2624,  ...,  -3.3081,  -1.6258,  -2.3421],\n",
      "         [ -8.2214,  -8.4845,  -8.3813,  ...,  -9.6447,  -6.3007,  -7.4550],\n",
      "         [-12.2501, -12.3143, -12.1333,  ..., -10.5506,  -8.0876,  -7.8454]],\n",
      "\n",
      "        [[ -6.9696,  -6.9481,  -6.8857,  ...,  -6.2357,  -6.2576,  -4.6252],\n",
      "         [-11.8425, -11.7898, -11.3957,  ...,  -8.5267,  -8.6422, -11.0328],\n",
      "         [ -4.9909,  -5.0865,  -5.0234,  ...,  -5.3242,  -5.9363,  -5.4216],\n",
      "         ...,\n",
      "         [ -5.0493,  -5.0492,  -5.0116,  ...,  -5.3313,  -5.6038,  -4.7148],\n",
      "         [ -5.0611,  -5.0680,  -5.0175,  ...,  -5.2553,  -5.6210,  -5.0275],\n",
      "         [ -5.3669,  -5.4490,  -5.3658,  ...,  -5.4275,  -5.8784,  -5.3305]],\n",
      "\n",
      "        [[ -6.1662,  -6.1424,  -6.1826,  ...,  -5.5462,  -5.4134,  -3.6748],\n",
      "         [ -7.2574,  -7.2189,  -7.4185,  ...,  -7.3705,  -7.5657,  -4.7174],\n",
      "         [ -7.8751,  -8.0555,  -8.3004,  ...,  -8.8005,  -8.0004,  -5.4012],\n",
      "         ...,\n",
      "         [ -4.3379,  -4.5712,  -4.5072,  ...,  -4.6846,  -4.9223,  -2.5991],\n",
      "         [ -4.1931,  -4.4239,  -4.4538,  ...,  -4.4938,  -5.0096,  -3.7160],\n",
      "         [ -4.7380,  -5.0120,  -5.0265,  ...,  -5.1637,  -5.6332,  -3.5362]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 2.8567066192626953\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2659, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.0049,  -6.9316,  -6.9082,  ...,  -6.2238,  -6.1081,  -3.3890],\n",
      "         [-10.7454, -10.9250, -10.9358,  ...,  -9.7351,  -9.8455,  -3.8386],\n",
      "         [ -4.8711,  -4.9396,  -4.9542,  ...,  -5.5184,  -5.1538,  -3.7300],\n",
      "         ...,\n",
      "         [ -7.5830,  -7.5340,  -7.5289,  ...,  -7.1995,  -7.0326,  -2.9878],\n",
      "         [ -7.8415,  -7.8259,  -7.7907,  ...,  -7.7462,  -7.2637,  -3.6223],\n",
      "         [ -8.5533,  -8.5530,  -8.5029,  ...,  -8.3054,  -8.0686,  -3.6807]],\n",
      "\n",
      "        [[ -6.3287,  -6.2544,  -6.2692,  ...,  -5.6950,  -5.3905,  -3.9778],\n",
      "         [-10.8586, -10.9121, -11.1226,  ...,  -8.8380,  -8.9802,  -7.8279],\n",
      "         [ -4.4384,  -4.5578,  -4.5998,  ...,  -4.0955,  -5.9200,  -2.9320],\n",
      "         ...,\n",
      "         [ -5.2447,  -5.2829,  -5.2746,  ...,  -4.9306,  -5.9054,  -3.2016],\n",
      "         [ -4.4748,  -4.5898,  -4.5931,  ...,  -4.3136,  -5.9195,  -2.9632],\n",
      "         [ -4.9538,  -5.0479,  -5.0703,  ...,  -4.7101,  -6.2758,  -3.5788]],\n",
      "\n",
      "        [[ -6.7329,  -6.7718,  -6.7222,  ...,  -6.2157,  -5.9828,  -4.1692],\n",
      "         [-12.6599, -12.7278, -12.4837,  ..., -10.2791, -10.7044,  -9.4242],\n",
      "         [ -6.2589,  -6.7026,  -5.9825,  ...,  -5.6902,  -6.0961,  -4.7813],\n",
      "         ...,\n",
      "         [ -6.6460,  -7.0807,  -6.7990,  ...,  -6.3841,  -5.9165, -11.1087],\n",
      "         [ -7.2034,  -7.7093,  -7.2037,  ...,  -6.8593,  -5.9011, -11.9663],\n",
      "         [ -4.9352,  -4.8148,  -4.8200,  ...,  -4.1904,  -4.4834,  -4.8007]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.1812,  -6.1577,  -6.1605,  ...,  -5.6496,  -5.2670,  -3.9707],\n",
      "         [-12.0176, -12.1888, -11.8072,  ...,  -9.6178,  -9.9544,  -8.5728],\n",
      "         [ -5.1214,  -5.2534,  -5.3204,  ...,  -5.5723,  -6.4450,  -3.9325],\n",
      "         ...,\n",
      "         [ -5.3517,  -5.3259,  -5.4434,  ...,  -5.5141,  -6.3504,  -3.3409],\n",
      "         [ -5.0751,  -5.1195,  -5.1819,  ...,  -5.1300,  -5.8753,  -3.5830],\n",
      "         [ -5.3561,  -5.3385,  -5.3996,  ...,  -5.3929,  -5.9423,  -3.6262]],\n",
      "\n",
      "        [[ -7.1811,  -7.1890,  -7.1802,  ...,  -6.6697,  -6.6019,  -3.9695],\n",
      "         [ -8.1780,  -7.9437,  -7.9864,  ...,  -8.6604,  -8.0568,  -5.8599],\n",
      "         [-10.5584, -10.2225, -10.2348,  ..., -10.2038,  -9.6926,  -5.9079],\n",
      "         ...,\n",
      "         [ -4.6503,  -4.6428,  -4.4522,  ...,  -4.9063,  -5.5476,  -4.9193],\n",
      "         [ -3.9205,  -4.0153,  -3.8335,  ...,  -4.0173,  -4.6733,  -3.6080],\n",
      "         [ -4.2344,  -4.2118,  -4.0719,  ...,  -4.7448,  -4.7967,  -3.8209]],\n",
      "\n",
      "        [[ -7.6091,  -7.6469,  -7.6144,  ...,  -7.1301,  -6.8933,  -5.3283],\n",
      "         [ -9.2188,  -8.9746,  -9.3864,  ...,  -8.5211,  -8.3274,  -6.7210],\n",
      "         [ -8.7110,  -8.9438,  -8.8228,  ...,  -9.0486,  -8.4350,  -8.4495],\n",
      "         ...,\n",
      "         [ -8.9878,  -8.8010,  -9.1324,  ...,  -9.8579,  -7.7656,  -8.8965],\n",
      "         [ -4.8377,  -4.8751,  -4.9032,  ...,  -4.4287,  -4.2339,  -2.9714],\n",
      "         [-14.0236, -14.3263, -14.2049,  ..., -14.6663, -12.4587,  -9.7250]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.2658796310424805\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.9379, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2307,  -7.1645,  -7.1643,  ...,  -6.3127,  -6.2186,  -4.1908],\n",
      "         [-11.8003, -11.7168, -11.8314,  ..., -11.1518, -10.3664, -12.5945],\n",
      "         [ -6.4552,  -6.3830,  -6.3878,  ...,  -6.5458,  -5.6645,  -0.6775],\n",
      "         ...,\n",
      "         [ -6.5910,  -6.4315,  -6.4307,  ...,  -6.9092,  -6.1410,  -4.1825],\n",
      "         [ -7.0782,  -6.9743,  -6.9498,  ...,  -7.5250,  -6.5564,  -4.5279],\n",
      "         [ -7.3269,  -7.2641,  -7.2216,  ...,  -7.5776,  -6.7478,  -5.5494]],\n",
      "\n",
      "        [[ -6.7590,  -6.6880,  -6.7179,  ...,  -6.2244,  -6.1648,  -3.8888],\n",
      "         [ -5.0231,  -4.9945,  -5.1525,  ...,  -5.1089,  -6.4005,  -2.5357],\n",
      "         [ -7.0166,  -7.1655,  -7.0944,  ...,  -7.0421,  -7.8930,  -3.5788],\n",
      "         ...,\n",
      "         [ -4.3683,  -4.5629,  -4.4678,  ...,  -4.2932,  -5.1959,  -2.8337],\n",
      "         [ -5.5508,  -5.7111,  -5.6800,  ...,  -5.9053,  -6.5553,  -3.3877],\n",
      "         [ -5.2939,  -5.3641,  -5.4236,  ...,  -5.7327,  -6.0038,  -2.5422]],\n",
      "\n",
      "        [[ -6.6986,  -6.6658,  -6.6845,  ...,  -5.8583,  -5.7500,  -3.7976],\n",
      "         [ -3.9184,  -4.5460,  -4.3526,  ...,  -4.3993,  -4.1750,  -3.0398],\n",
      "         [ -8.1701,  -8.4188,  -8.2092,  ...,  -5.4757,  -5.8504,  -5.6794],\n",
      "         ...,\n",
      "         [ -4.3508,  -4.6567,  -4.5562,  ...,  -4.2203,  -4.4347,  -2.1258],\n",
      "         [ -5.0655,  -5.4432,  -5.2320,  ...,  -5.2015,  -4.9894,  -1.9982],\n",
      "         [ -5.4345,  -5.7458,  -5.4839,  ...,  -5.5849,  -5.4525,  -2.5448]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.1096,  -6.0981,  -6.0360,  ...,  -5.4441,  -5.3967,  -3.5049],\n",
      "         [ -8.5393,  -8.5225,  -8.3390,  ...,  -7.4107,  -6.5146, -10.5935],\n",
      "         [ -8.9434,  -9.0142,  -8.9184,  ...,  -7.3619,  -8.0481,  -4.4572],\n",
      "         ...,\n",
      "         [ -6.6228,  -6.5041,  -6.5001,  ...,  -5.9761,  -6.8249,  -7.2737],\n",
      "         [ -6.8134,  -7.0153,  -6.9219,  ...,  -5.4292,  -7.4059,  -6.8686],\n",
      "         [ -6.9222,  -7.0359,  -6.8147,  ...,  -6.2127,  -7.0861,  -5.7835]],\n",
      "\n",
      "        [[ -7.8837,  -7.8574,  -7.9032,  ...,  -6.8025,  -6.7949,  -5.0175],\n",
      "         [-14.5562, -14.5448, -14.3338,  ..., -11.1029, -11.1373, -10.3817],\n",
      "         [ -4.4062,  -4.4679,  -4.4868,  ...,  -5.2778,  -6.4801,  -2.6687],\n",
      "         ...,\n",
      "         [ -4.7783,  -4.8712,  -4.8243,  ...,  -4.9063,  -6.0940,  -4.8562],\n",
      "         [ -4.8771,  -5.0641,  -5.0554,  ...,  -5.2025,  -6.1518,  -3.7001],\n",
      "         [ -4.6178,  -4.5684,  -4.6164,  ...,  -4.9636,  -6.1027,  -4.0067]],\n",
      "\n",
      "        [[ -6.4063,  -6.4301,  -6.4894,  ...,  -5.8253,  -5.8393,  -3.4317],\n",
      "         [ -6.7282,  -6.6873,  -6.8531,  ...,  -7.4513,  -7.7935,  -3.7139],\n",
      "         [ -5.4830,  -5.4508,  -5.3655,  ...,  -7.3541,  -6.0593,  -3.1045],\n",
      "         ...,\n",
      "         [ -4.6965,  -4.8227,  -4.7425,  ...,  -5.0428,  -5.3242,  -2.2414],\n",
      "         [ -4.4092,  -4.4847,  -4.4717,  ...,  -5.4237,  -4.7943,  -2.1940],\n",
      "         [ -5.2234,  -5.3223,  -5.3031,  ...,  -5.4780,  -5.4532,  -2.9953]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.9379432797431946\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.8736, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.3190,  -6.3014,  -6.3945,  ...,  -5.7347,  -5.7663,  -3.4020],\n",
      "         [ -7.4837,  -7.6198,  -7.9189,  ...,  -7.6881,  -7.6752,  -3.7966],\n",
      "         [ -7.1189,  -7.1807,  -7.3167,  ...,  -6.7817,  -5.7976,  -4.4696],\n",
      "         ...,\n",
      "         [ -4.0165,  -4.1145,  -4.1303,  ...,  -3.9701,  -4.3707,  -1.0939],\n",
      "         [ -4.1920,  -4.3202,  -4.2483,  ...,  -4.2518,  -4.5895,  -2.0530],\n",
      "         [ -5.4786,  -5.4915,  -5.5797,  ...,  -5.7936,  -5.9430,  -3.3118]],\n",
      "\n",
      "        [[ -6.7006,  -6.6984,  -6.6797,  ...,  -5.8970,  -5.9354,  -4.0681],\n",
      "         [-13.1694, -12.9216, -13.2571,  ..., -11.3784,  -9.8050, -12.7409],\n",
      "         [ -4.8776,  -5.3904,  -5.0698,  ...,  -5.2180,  -4.1744,  -9.2839],\n",
      "         ...,\n",
      "         [ -8.5472,  -8.7331,  -8.8221,  ...,  -8.5967,  -7.1834,  -9.8699],\n",
      "         [-16.3672, -16.4778, -16.6229,  ..., -16.2513, -13.7172, -12.3009],\n",
      "         [-12.0206, -12.0537, -12.1240,  ...,  -9.2123,  -8.7100,  -9.6736]],\n",
      "\n",
      "        [[ -6.5267,  -6.4805,  -6.4701,  ...,  -5.8299,  -5.5869,  -3.9102],\n",
      "         [-10.8981, -10.8059, -10.5965,  ...,  -7.5184,  -8.6324,  -6.7634],\n",
      "         [ -5.1488,  -5.2925,  -5.4026,  ...,  -5.0044,  -6.3385,  -3.1003],\n",
      "         ...,\n",
      "         [ -5.4321,  -5.4659,  -5.4364,  ...,  -4.8589,  -5.9166,  -3.5754],\n",
      "         [ -5.1665,  -5.2749,  -5.3243,  ...,  -5.0533,  -6.0989,  -3.0872],\n",
      "         [ -5.5269,  -5.5533,  -5.5648,  ...,  -5.2236,  -6.1902,  -4.2043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.9859,  -6.9476,  -6.9837,  ...,  -6.2073,  -6.0901,  -4.5896],\n",
      "         [-11.7470, -11.9210, -11.8248,  ...,  -9.4432,  -9.5041, -13.3586],\n",
      "         [-14.1476, -14.9621, -14.4529,  ..., -12.9094, -11.9357, -11.6640],\n",
      "         ...,\n",
      "         [ -5.2481,  -5.1895,  -5.1941,  ...,  -5.4186,  -5.3228,  -3.6940],\n",
      "         [ -8.8606,  -9.2337,  -8.4138,  ...,  -7.6836,  -8.6836,  -7.8974],\n",
      "         [-12.1457, -11.8523, -11.8015,  ..., -10.5983,  -9.2423,  -9.8805]],\n",
      "\n",
      "        [[ -5.8462,  -5.8830,  -5.8562,  ...,  -5.4497,  -5.5295,  -3.1150],\n",
      "         [ -7.8089,  -8.0828,  -8.3173,  ...,  -8.0161,  -8.6077,  -5.4902],\n",
      "         [ -5.8479,  -5.9921,  -6.1375,  ...,  -6.5896,  -6.1026,  -3.5966],\n",
      "         ...,\n",
      "         [ -4.3142,  -4.4451,  -4.4746,  ...,  -4.4720,  -4.8483,  -2.7101],\n",
      "         [ -4.7705,  -4.8929,  -4.8493,  ...,  -5.1331,  -5.6326,  -3.3822],\n",
      "         [ -4.8737,  -4.9922,  -4.9958,  ...,  -5.4904,  -5.6498,  -3.8840]],\n",
      "\n",
      "        [[ -6.4702,  -6.4196,  -6.3960,  ...,  -5.8006,  -5.5002,  -3.8277],\n",
      "         [ -4.0150,  -4.1925,  -4.2378,  ...,  -4.0942,  -4.3604,  -3.8285],\n",
      "         [ -6.1798,  -6.2939,  -6.1724,  ...,  -5.3461,  -5.0770,  -3.5371],\n",
      "         ...,\n",
      "         [ -4.7296,  -4.9829,  -4.8724,  ...,  -5.0444,  -4.8672,  -4.4384],\n",
      "         [ -5.6153,  -5.7987,  -5.6542,  ...,  -5.6704,  -5.5056,  -4.0230],\n",
      "         [ -5.7712,  -6.0368,  -5.9539,  ...,  -5.9109,  -5.3951,  -4.8294]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.8736299276351929\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.5951, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.4513,  -6.4067,  -6.4578,  ...,  -5.7535,  -5.6945,  -3.5343],\n",
      "         [ -5.4469,  -5.4557,  -5.5275,  ...,  -5.5361,  -6.9392,  -3.0742],\n",
      "         [ -4.6707,  -4.8839,  -4.5885,  ...,  -5.1494,  -5.0690,  -5.1163],\n",
      "         ...,\n",
      "         [ -4.7452,  -4.8200,  -4.7829,  ...,  -4.9518,  -4.8504,  -3.1839],\n",
      "         [ -4.8135,  -4.9250,  -4.9117,  ...,  -5.3152,  -5.3972,  -1.7127],\n",
      "         [ -4.5516,  -4.5633,  -4.5806,  ...,  -5.1315,  -5.5079,  -2.1155]],\n",
      "\n",
      "        [[ -6.7197,  -6.6707,  -6.6708,  ...,  -5.9641,  -5.7805,  -4.0477],\n",
      "         [-14.5783, -14.5847, -14.4809,  ..., -12.5068, -11.9564, -11.8336],\n",
      "         [ -4.6016,  -4.6963,  -4.7003,  ...,  -4.6324,  -5.9682,  -3.8503],\n",
      "         ...,\n",
      "         [ -4.3478,  -4.3774,  -4.4322,  ...,  -3.8604,  -5.0100,  -4.1787],\n",
      "         [ -4.6383,  -4.6004,  -4.6827,  ...,  -4.4913,  -5.1416,  -4.2502],\n",
      "         [ -4.9331,  -4.8807,  -4.9799,  ...,  -4.9734,  -5.6917,  -4.7474]],\n",
      "\n",
      "        [[-13.4704, -13.6088, -13.4606,  ..., -11.3742, -12.4155, -11.3293],\n",
      "         [-10.1891, -10.4768,  -9.9816,  ...,  -8.5219,  -9.9652,  -8.3162],\n",
      "         [ -5.3649,  -5.5726,  -5.5692,  ...,  -5.8862,  -6.9956,  -3.7553],\n",
      "         ...,\n",
      "         [ -5.1749,  -5.2457,  -5.2385,  ...,  -5.6810,  -6.5171,  -2.9320],\n",
      "         [ -5.1672,  -5.2495,  -5.2834,  ...,  -5.8677,  -6.6855,  -3.0331],\n",
      "         [ -4.2673,  -4.3730,  -4.3737,  ...,  -4.7712,  -5.3753,  -2.6886]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -9.2864,  -9.2362,  -9.1898,  ...,  -7.9081,  -8.6536,  -6.0774],\n",
      "         [-12.9683, -12.9922, -12.6753,  ..., -10.3573,  -9.1080, -10.8310],\n",
      "         [ -4.4424,  -4.5938,  -4.5258,  ...,  -4.2632,  -5.5986,  -3.6228],\n",
      "         ...,\n",
      "         [ -3.5185,  -3.6034,  -3.5707,  ...,  -2.8409,  -4.7625,  -4.6833],\n",
      "         [ -4.1933,  -4.3971,  -4.4503,  ...,  -3.8385,  -5.7677,  -3.8836],\n",
      "         [ -4.3746,  -4.4776,  -4.4125,  ...,  -3.9292,  -5.6796,  -5.0111]],\n",
      "\n",
      "        [[ -6.4508,  -6.3959,  -6.3912,  ...,  -5.5918,  -5.6201,  -4.0893],\n",
      "         [-14.5315, -14.2983, -14.3401,  ..., -11.9522, -11.3223, -10.2087],\n",
      "         [ -5.3532,  -5.3206,  -5.4014,  ...,  -4.9079,  -6.4333,  -3.4493],\n",
      "         ...,\n",
      "         [ -4.9651,  -5.0531,  -4.9932,  ...,  -4.3663,  -5.4439,  -3.5132],\n",
      "         [ -5.3444,  -5.3603,  -5.4870,  ...,  -4.8022,  -6.2807,  -2.9982],\n",
      "         [ -6.0044,  -5.9507,  -5.9682,  ...,  -5.6416,  -6.2631,  -3.3941]],\n",
      "\n",
      "        [[ -8.4687,  -8.4212,  -8.3587,  ...,  -7.6496,  -6.9357,  -4.1378],\n",
      "         [ -5.7600,  -5.9509,  -5.8911,  ...,  -6.2931,  -5.1563,  -2.4160],\n",
      "         [ -7.4893,  -8.0207,  -7.7890,  ...,  -6.4905,  -5.1725,  -4.3714],\n",
      "         ...,\n",
      "         [ -5.5135,  -5.5703,  -5.2552,  ...,  -6.0297,  -4.0281,  -2.3518],\n",
      "         [ -7.0086,  -6.9999,  -6.6728,  ...,  -6.8211,  -5.2045,  -3.3327],\n",
      "         [ -7.1452,  -7.1265,  -6.9184,  ...,  -7.0559,  -5.3235,  -2.8920]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.5951454639434814\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.0624, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9353,  -6.9402,  -6.9108,  ...,  -6.0602,  -6.1096,  -4.0159],\n",
      "         [ -8.2376,  -8.5352,  -8.4102,  ...,  -7.6226,  -6.8808,  -1.3644],\n",
      "         [ -8.7387,  -8.9929,  -8.6494,  ...,  -6.6245,  -5.7039,  -4.7162],\n",
      "         ...,\n",
      "         [ -7.0302,  -7.1375,  -7.0886,  ...,  -6.5261,  -4.5484,  -4.7248],\n",
      "         [ -7.6306,  -7.6209,  -7.6416,  ...,  -7.3936,  -5.6285,  -4.9119],\n",
      "         [ -7.4394,  -7.5318,  -7.4696,  ...,  -7.0595,  -5.9473,  -6.0915]],\n",
      "\n",
      "        [[ -6.4246,  -6.3719,  -6.4304,  ...,  -6.0830,  -5.7486,  -3.0887],\n",
      "         [ -8.6402,  -8.8612,  -8.8485,  ...,  -9.1608,  -8.9050,  -2.0200],\n",
      "         [ -5.8853,  -5.6355,  -5.9103,  ...,  -5.7548,  -6.3672,  -3.3045],\n",
      "         ...,\n",
      "         [ -4.3765,  -4.5445,  -4.5397,  ...,  -4.8115,  -5.6396,  -0.2681],\n",
      "         [ -3.8951,  -3.8854,  -4.0097,  ...,  -4.2481,  -4.6830,  -2.1782],\n",
      "         [ -4.6767,  -4.7986,  -4.8329,  ...,  -5.0747,  -5.3828,  -2.0975]],\n",
      "\n",
      "        [[ -6.1880,  -6.1405,  -6.1108,  ...,  -5.6488,  -5.2326,  -3.7377],\n",
      "         [ -9.7189,  -9.3052,  -9.6586,  ...,  -7.1640,  -6.8193, -10.7359],\n",
      "         [ -4.5482,  -4.5819,  -4.6444,  ...,  -4.9322,  -5.8185,  -2.8136],\n",
      "         ...,\n",
      "         [ -4.9140,  -5.0128,  -4.8898,  ...,  -5.1282,  -5.6240,  -3.9753],\n",
      "         [ -4.2865,  -4.2753,  -4.2820,  ...,  -4.5665,  -5.2863,  -3.6749],\n",
      "         [ -5.7093,  -5.6772,  -5.6925,  ...,  -5.8364,  -6.2070,  -3.8519]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-12.2593, -12.0411, -11.4552,  ...,  -9.6906,  -9.5085, -10.3390],\n",
      "         [-18.3127, -18.2518, -17.7043,  ..., -15.6279, -12.6498, -13.9571],\n",
      "         [ -5.2829,  -5.3123,  -5.0717,  ...,  -4.8879,  -6.2527,  -4.2442],\n",
      "         ...,\n",
      "         [ -5.2785,  -5.3194,  -5.0929,  ...,  -4.9429,  -6.2314,  -4.9537],\n",
      "         [ -5.2729,  -5.3005,  -5.1209,  ...,  -4.5445,  -6.2807,  -3.5809],\n",
      "         [ -5.4299,  -5.4111,  -5.2904,  ...,  -4.9728,  -6.4039,  -5.0542]],\n",
      "\n",
      "        [[ -6.3098,  -6.2606,  -6.2909,  ...,  -5.6586,  -5.3874,  -3.7707],\n",
      "         [-11.7546, -11.1126, -11.3084,  ...,  -8.5459,  -9.0109,  -6.8309],\n",
      "         [ -5.6227,  -5.7635,  -5.8308,  ...,  -6.0526,  -6.6921,  -3.4452],\n",
      "         ...,\n",
      "         [ -5.8206,  -5.9312,  -5.8548,  ...,  -5.7831,  -6.2183,  -4.2034],\n",
      "         [ -6.0800,  -6.2671,  -6.2356,  ...,  -6.0866,  -6.5871,  -3.0671],\n",
      "         [ -6.8092,  -6.8851,  -6.7957,  ...,  -6.6023,  -6.7704,  -4.0569]],\n",
      "\n",
      "        [[ -7.2836,  -7.3368,  -7.3011,  ...,  -6.5459,  -6.4558,  -4.0946],\n",
      "         [ -7.8829,  -7.8426,  -8.1084,  ...,  -7.2329,  -8.4770,  -6.9495],\n",
      "         [ -6.7031,  -6.5068,  -6.1557,  ...,  -6.9398,  -3.5794,  -8.6389],\n",
      "         ...,\n",
      "         [ -4.7813,  -5.0512,  -4.7772,  ...,  -5.3422,  -4.9885,  -5.6648],\n",
      "         [ -6.9745,  -7.1231,  -7.2545,  ...,  -8.2535,  -7.8328,  -6.7611],\n",
      "         [ -7.8354,  -8.1501,  -8.0419,  ...,  -8.6830,  -8.5914,  -5.4672]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.062400221824646\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(1.2758, grad_fn=<NllLossBackward0>), logits=tensor([[[ -7.2197,  -7.2438,  -7.2278,  ...,  -6.5455,  -6.5742,  -4.4702],\n",
      "         [ -8.7731,  -8.7265,  -8.7674,  ...,  -6.7789,  -5.8471,  -8.1228],\n",
      "         [ -6.4176,  -6.4956,  -6.4939,  ...,  -6.4599,  -7.1645,  -3.7924],\n",
      "         ...,\n",
      "         [ -6.3628,  -6.3388,  -6.2462,  ...,  -6.2866,  -6.6467,  -4.5870],\n",
      "         [ -6.6003,  -6.7465,  -6.7399,  ...,  -6.6959,  -7.0921,  -4.4618],\n",
      "         [ -6.3745,  -6.4911,  -6.3233,  ...,  -6.3065,  -6.6204,  -4.7640]],\n",
      "\n",
      "        [[ -7.0023,  -7.0304,  -6.9733,  ...,  -5.9792,  -6.1638,  -4.3118],\n",
      "         [-11.8316, -11.9355, -11.9161,  ..., -10.9428,  -8.5057,  -9.7582],\n",
      "         [ -6.1351,  -6.0001,  -6.3231,  ...,  -4.6496,  -4.6008,  -9.3176],\n",
      "         ...,\n",
      "         [ -5.8755,  -6.3192,  -5.8551,  ...,  -6.7230,  -4.2912,  -8.3727],\n",
      "         [ -5.9305,  -6.0642,  -5.8966,  ...,  -6.4761,  -4.4472,  -6.8159],\n",
      "         [ -6.6254,  -6.7893,  -6.6689,  ...,  -7.3105,  -5.2453,  -7.1304]],\n",
      "\n",
      "        [[ -6.8047,  -6.9071,  -6.8096,  ...,  -6.1483,  -5.7552,  -4.8035],\n",
      "         [-10.8972, -10.7267, -10.8043,  ...,  -9.1068,  -9.0821, -12.0756],\n",
      "         [ -1.6958,  -1.6723,  -1.6745,  ...,  -0.8071,  -1.5928,  -4.7074],\n",
      "         ...,\n",
      "         [ -1.3279,  -1.7303,  -1.1761,  ...,   0.0899,  -0.9059,  -2.4614],\n",
      "         [-12.0121, -11.8918, -11.7914,  ..., -10.4279,  -9.8915,  -9.9852],\n",
      "         [-11.0657, -11.5451, -11.0545,  ..., -11.7366,  -8.8600,  -8.1557]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -7.0043,  -7.0519,  -6.9896,  ...,  -6.2761,  -6.2394,  -4.0801],\n",
      "         [-11.2232, -11.3373, -11.2626,  ..., -10.3044, -10.8068,  -7.3713],\n",
      "         [ -4.2851,  -4.3427,  -4.4423,  ...,  -4.8005,  -4.5380,  -3.6520],\n",
      "         ...,\n",
      "         [ -7.3618,  -7.4262,  -7.4695,  ...,  -7.5394,  -6.7813,  -3.6218],\n",
      "         [ -7.3263,  -7.5091,  -7.3578,  ...,  -7.4062,  -6.4270,  -3.0106],\n",
      "         [ -7.3097,  -7.3825,  -7.2646,  ...,  -7.7065,  -6.6782,  -4.8676]],\n",
      "\n",
      "        [[ -7.1978,  -7.1699,  -7.1449,  ...,  -6.4480,  -6.3453,  -4.1219],\n",
      "         [-14.1571, -14.1925, -14.3245,  ..., -12.5379, -12.3279, -12.4996],\n",
      "         [ -9.0537,  -9.4600,  -9.6352,  ...,  -8.1350,  -7.5488,  -9.1740],\n",
      "         ...,\n",
      "         [ -6.4068,  -6.3955,  -6.2351,  ...,  -6.5958,  -7.5192,  -2.3679],\n",
      "         [ -7.8409,  -7.9003,  -7.8052,  ...,  -8.5264,  -7.8784,  -5.9766],\n",
      "         [ -7.1670,  -7.2588,  -7.2420,  ...,  -8.0505,  -6.6831,  -5.4691]],\n",
      "\n",
      "        [[ -6.5532,  -6.5234,  -6.5532,  ...,  -5.8961,  -5.7753,  -3.9704],\n",
      "         [ -6.9813,  -6.8743,  -7.1683,  ...,  -7.0703,  -7.8655,  -3.6220],\n",
      "         [ -6.7377,  -6.9892,  -7.0150,  ...,  -6.6967,  -6.7393,  -4.2347],\n",
      "         ...,\n",
      "         [ -4.7924,  -4.7774,  -5.0213,  ...,  -5.3721,  -5.5673,  -2.2282],\n",
      "         [ -5.1975,  -5.3119,  -5.3573,  ...,  -5.6287,  -6.0164,  -1.8052],\n",
      "         [ -5.1229,  -5.2320,  -5.2493,  ...,  -5.5672,  -5.8999,  -2.3907]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 1.275784969329834\n",
      "Batch keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "Model outputs: MaskedLMOutput(loss=tensor(0.7052, grad_fn=<NllLossBackward0>), logits=tensor([[[ -6.9810,  -6.8898,  -6.7395,  ...,  -6.0192,  -5.9763,  -4.0386],\n",
      "         [-13.7399, -13.3634, -13.6212,  ..., -10.5700, -11.5744, -11.8139],\n",
      "         [ -4.2787,  -4.4150,  -4.4364,  ...,  -4.4916,  -5.9294,  -2.1517],\n",
      "         ...,\n",
      "         [ -4.8316,  -4.8833,  -4.8296,  ...,  -4.7345,  -5.5845,  -3.5395],\n",
      "         [ -4.7776,  -4.6504,  -4.7788,  ...,  -4.7187,  -6.0562,  -3.2613],\n",
      "         [ -4.8380,  -4.8488,  -4.9075,  ...,  -4.9811,  -6.0043,  -3.1836]],\n",
      "\n",
      "        [[ -8.2936,  -8.5893,  -8.4107,  ...,  -7.8838,  -8.4278,  -5.3947],\n",
      "         [-12.5465, -12.6386, -12.1451,  ...,  -9.6026,  -9.0654, -10.1208],\n",
      "         [ -4.5610,  -4.6199,  -4.6278,  ...,  -4.7299,  -5.4200,  -2.5724],\n",
      "         ...,\n",
      "         [ -3.6222,  -3.6196,  -3.5282,  ...,  -3.5716,  -4.1851,  -3.1456],\n",
      "         [ -5.4355,  -5.4652,  -5.4012,  ...,  -5.5280,  -5.3464,  -3.9364],\n",
      "         [ -4.8030,  -4.9164,  -4.8617,  ...,  -5.1070,  -5.4673,  -3.3501]],\n",
      "\n",
      "        [[ -7.2367,  -7.2127,  -7.1862,  ...,  -6.4909,  -6.4068,  -4.1708],\n",
      "         [ -6.4508,  -6.3262,  -6.6502,  ...,  -5.3547,  -5.4760,  -4.5188],\n",
      "         [-12.0147, -12.0190, -12.0717,  ..., -10.0780, -11.0563, -13.8858],\n",
      "         ...,\n",
      "         [ -8.1784,  -8.3010,  -8.3202,  ...,  -7.8826,  -7.3943,  -4.2937],\n",
      "         [ -8.4450,  -8.4162,  -8.4844,  ...,  -7.4351,  -7.8461,  -4.6644],\n",
      "         [ -7.8950,  -7.9622,  -7.9489,  ...,  -6.7779,  -7.4964,  -4.2769]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.3365,  -6.2882,  -6.3012,  ...,  -5.6923,  -5.3449,  -3.9809],\n",
      "         [-11.4164, -11.3749, -11.1401,  ...,  -9.7066,  -8.6062,  -4.1401],\n",
      "         [ -5.3428,  -5.4914,  -5.4906,  ...,  -5.5586,  -6.4545,  -3.1780],\n",
      "         ...,\n",
      "         [ -5.0716,  -5.1188,  -5.1511,  ...,  -5.4551,  -6.3245,  -3.6592],\n",
      "         [ -4.7941,  -4.8229,  -4.8043,  ...,  -5.2254,  -5.4994,  -3.7423],\n",
      "         [ -4.0772,  -4.1072,  -4.1386,  ...,  -4.4958,  -5.4924,  -3.1018]],\n",
      "\n",
      "        [[ -7.9812,  -7.8986,  -7.8280,  ...,  -7.1395,  -6.8408,  -4.6035],\n",
      "         [-18.0972, -17.8225, -17.6456,  ..., -14.7832, -14.6481, -12.7085],\n",
      "         [ -9.0975,  -9.1130,  -9.4887,  ...,  -9.0555,  -8.0580,  -9.8072],\n",
      "         ...,\n",
      "         [ -6.7360,  -6.7946,  -6.8138,  ...,  -6.3278,  -5.6232,  -3.9707],\n",
      "         [-16.6043, -16.5263, -16.0656,  ..., -14.1030, -12.6307, -14.6891],\n",
      "         [-13.2441, -12.9823, -13.1440,  ..., -10.1541, -10.2143,  -9.4576]],\n",
      "\n",
      "        [[ -7.7519,  -7.6732,  -7.6478,  ...,  -6.7264,  -6.8487,  -4.0407],\n",
      "         [-10.6919, -10.6056, -10.6225,  ...,  -8.8047,  -9.4877,  -8.1963],\n",
      "         [ -3.6914,  -3.7117,  -3.6140,  ...,  -4.6051,  -3.5380,  -6.4926],\n",
      "         ...,\n",
      "         [ -5.8028,  -5.7871,  -5.8525,  ...,  -4.4360,  -4.4828,  -4.1186],\n",
      "         [ -5.7213,  -5.8693,  -5.7262,  ...,  -5.1276,  -4.2242,  -4.5972],\n",
      "         [ -4.1424,  -4.2006,  -4.0801,  ...,  -3.4426,  -3.1202,  -3.3860]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch 2, Loss: 0.705156683921814\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))  # Use a subset for quick training\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):  # Train for 3 epochs\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Print batch keys for debugging\n",
    "        print(\"Batch keys:\", batch.keys())\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "        # Print model outputs for debugging\n",
    "        print(\"Model outputs:\", outputs)\n",
    "        \n",
    "        # Check if loss is None\n",
    "        if outputs.loss is None:\n",
    "            raise ValueError(\"Loss is None. Check the model and input data.\")\n",
    "        \n",
    "        # Backward pass\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_bert_model\\\\tokenizer_config.json',\n",
       " './trained_bert_model\\\\special_tokens_map.json',\n",
       " './trained_bert_model\\\\vocab.txt',\n",
       " './trained_bert_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./trained_bert_model\")\n",
    "tokenizer.save_pretrained(\"./trained_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at ./trained_bert_model and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = BertForPreTraining.from_pretrained(\"./trained_bert_model\")\n",
    "\n",
    "# Test with a sample sentence\n",
    "input_text = \"The quick brown fox jumps over the [MASK] dog.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Decode the predicted token\n",
    "predicted_token_id = outputs.prediction_logits.argmax(dim=-1)[0, 6]  # Position of [MASK]\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "print(predicted_token)  # Should predict \"lazy\" or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: The capital of France is [MASK].\n",
      "Predicted word: paris\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example sentence with a masked token\n",
    "sentence = \"The capital of France is [MASK].\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "# Get the index of the masked token\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# Perform the prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Get the predicted token ID for the masked token\n",
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "\n",
    "# Decode the predicted token ID to get the word\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Original sentence: {sentence}\")\n",
    "print(f\"Predicted word: {predicted_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: The capital of france is [MASK].\n",
      "Predicted word: paris\n",
      "\n",
      "Original sentence: The largest planet in the solar system is [MASK].\n",
      "Predicted word: pluto\n",
      "\n",
      "Original sentence: The author of 'Pride and Prejudice' is [MASK].\n",
      "Predicted word: unknown\n",
      "\n",
      "Original sentence: The last day of the week is [MASK].\n",
      "Predicted word: friday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The capital of france is [MASK].\",\n",
    "    \"The largest planet in the solar system is [MASK].\",\n",
    "    \"The author of 'Pride and Prejudice' is [MASK].\",\n",
    "    \"The last day of the week is [MASK].\" \n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "    predicted_token = tokenizer.decode(predicted_token_id)\n",
    "    print(f\"Original sentence: {sentence}\")\n",
    "    print(f\"Predicted word: {predicted_token}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./my_bert_model\")\n",
    "tokenizer.save_pretrained(\"./my_bert_model\")\n",
    "\n",
    "# Load the model\n",
    "model = BertForMaskedLM.from_pretrained(\"./my_bert_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./my_bert_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
